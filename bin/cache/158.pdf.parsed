[[[ ID ]]]
158
[[[ INDEX ]]]
0
[[[ TITLE ]]]
When is n-Pairs Information a Multicommodity Flow?
[[[ AUTHORS ]]]
Girish N. Nair Member
[[[ ABSTR ]]]
Abstract—Information does not generally behave like a ﬂow in communication networks with multiple sources and sinks. However, it is often conceptually and practically useful to be able to associate separate data streams with each source- sink pair, with only routing and no coding performed at the network nodes. This raises the question of whether there is a nontrivial class of network topologies for which achievability is always equivalent to “routability”, for any combination of source signals and positive channel capacities. This paper considers a possibly cyclic, directed, errorless network with n source- sink pairs, mutually independent source signals, and a relaxed communication objective in terms of demanded information rates at sinks. The concept of triangularizability is introduced and it is shown that, if the network topology is triangularizable, then a given combination of source signals, demand rates and channel capacities is achievable if and only if the digraph supports a feasible multicommodity ﬂow.
[[[ BODY ]]]
In an n-pairs communication network, n source signals must be conveyed to their corresponding sinks without exceeding any channel capacities. Until quite recently, the belief was that this was possible iff there existed a routing solution, i.e. if every bit generated by a source could be carried without modiﬁcation, over channels and through network nodes, until it reached the sink. At a macroscopic level, this is equivalent to presuming the existence of a feasible multicommodity ﬂow [1].
However, in [2], [3], an example was constructed of a multi- source, multi-sink communication network that did not admit a routing solution, but became admissible if nodes could perform modulo-2 arithmetic on incoming bits. This counter-intuitive result started the ﬁeld of network coding, in which nodes are permitted to not just route incoming bits, but also to perform functions on them to better exploit the network structure and the available channel capacities.
It is now known that the achievable capacity regions of networks with multiple sources and sinks is not generally given by feasible multicommodity ﬂows, although in [4], the capacity region of a special class of 3-layered, acyclic n-pairs networks was demonstrated to be given by multicommodity ﬂows. However, in [5], n-pair networks were constructed with coding capacity much larger than the routing capacity. Other
related work includes [6], in which a necessary and sufﬁcient condition for broadcasting correlated sources over erroneous channels is found, and [7], in which linear network coding is shown to achieve capacity for a multicast network.
Notwithstanding the power of network codes, rout- ing/multicommodity ﬂow solutions are appealing in several respects. Most obviously they are simpler, because network nodes are not required to perform extra mathematical op- erations on arriving bits. In addition, because different data streams are not “hashed” together by means of some function, there is arguably less potential for cross-talk between different source-sink pairs, arising for instance from nonidealities dur- ing implementation in the physical layer. Furthermore, being able to treat information as a conservative ﬂuid-ﬂow could potentially provide a simple basis to analyze communication requirements in areas outside traditional multiterminal infor- mation theory, e.g. networked feedback control and multi- agent coordination/consensus problems - see, e.g. [8], [9].
These considerations raise the natural questions of whether there is a general class of network topologies on which achievability is always equivalent to the existence of a feasible multicommodity ﬂow, and of how to characterise this class. This paper derives a partial answer to this question for a possi- bly cyclic, directed, errorless network with n source-sink pairs and mutually independent source signals. The communication objective is relaxed so that, instead of reconstructing the source signals with negligible probability of error at the sinks, the aim is for the marginal information rate supplied to each sink to exceed a speciﬁed positive demand.
The structural concept of triangularizability is introduced, and the main result (Thm. 1) is that if the network topol- ogy is triangularizable then a given combination of source signals, demand rates and channel capacities is achievable iff the network supports a feasible multicommodity ﬂow. This property inheres solely in the topology of the network and suits situations where channels, switches, transceivers and interfaces are expensive to set up and difﬁcult to move, or where channel capacities, output demands and source-signal statistics are unknown.
It is emphasised that the primary signiﬁcance of this result is structural, not computational. Algorithms can be devised to check whether or not a given network topology is triangular- izable, by working directly from the deﬁnition. However, the
explicit construction of such procedures and the analysis of their computational complexity will be addressed elsewhere.
Note that although triangularizability is sufﬁcient to guar- antee that routing can always achieve the full capacity of a network, it is not necessary, and the question of ﬁnding a topological condition that is less conservative - or even tight - remains open. Further work is also needed to clarify the connections with existing results on degree-2, 3-layered acyclic networks in [4] and the directed cycle networks of [10].
For convenience, the basic notation and terminology used in this paper is described below.
• The set of nonnegative integers (i.e. whole numbers) is denoted W.
• A contiguous set {i, i + 1, . . . , j} of integers is denoted [i : j].
• A random signal or process (F(k)) ∞ k =0 is denoted F. With a mild abuse of notation, the ﬁnite sequence (F(k)) t k =0 is denoted F(0 : t).
• Given a subscripted rv or signal F j , with j belonging to a countable set J, F J denotes an ordered tuple (F j ) j ∈J , arranged according to the order on J.
• If E, F are random processes and E is discrete-valued, then
If E is continuous-valued, H is simply replaced with h. • If E, F and G are random processes, then
• A directed graph (digraph) consists of a set V of vertices, and a set A of arcs that each represent a directed link between a particular pair of vertices.
• The initial vertex of an arc is called its tail and the terminal vertex, its head.
• A walk in a digraph is an alternating sequence ω = (ν 1 , α 1 , ν 2 , α 2 , . . . , α k , ν k +1 ), k ≥ 0, of vertices and arcs, beginning and ending in vertices, s.t. each arc α l connects the vertex ν l to ν l +1 . Each vertex ν j and arc α l in the sequence is said to be in the walk; with a minor abuse of notation, this is denoted ν j , α l ∈ ω.
• A path is a walk that passes through no vertex more than once, including the initial one.
• A cycle is a walk in which the initial and ﬁnal vertices are identical, but every other vertex occurs once.
• A subpath of a path (ν 1 , α 1 , ν 2 , α 2 , . . . , α k , ν k +1 ) is a segment (ν l , α l , ν l +1 , . . . , ν j ) of it, where 1 ≤ l ≤ j ≤ k +1.
• A vertex ν is said to be reachable from another vertex µ , denoted µ ν, if ∃ a path leading from µ to ν. Equivalently, it is said that µ can reach ν. The same terminology and notation apply, with analogous meaning, for pairs of arcs as well as mixed pairs of arcs and vertices. E.g. given an arc β, µ β means that there is a path from the vertex µ to the tail of β.
• The notation OUT(U) (IN(U)) denotes the set of arcs that have tails (resp. heads) in a vertex-set U ⊂ V but heads (tails) ∈ V \ U. If U is a singleton {µ}, the braces are removed for notational compactness.
A multiterminal network of unidirectional, point-to-point channels may be modelled using a digraph (V, A), where the vertex-set V represents information sources, sinks, repeaters, routers etc., and the arc-set A indicates the directions of any channels between network nodes. As usual with digraphs, it is assumed that no arc leaves and enters the same vertex, and that at most one arc leads from the ﬁrst to the second element of any given ordered pair of vertices. In other words, every arc in A may be uniquely identiﬁed with a 2-tuple (µ, ν) ∈ V 2 , with µ = ν. 1
In an n-pairs information network, the locations of sources and sinks are respectively represented by disjoint sets S = {σ 1 , . . . , σ n } and T = {τ 1 , . . . , τ n } of distinct vertices in V, with each source σ i aiming to communicate to exactly one sink τ i . It is assumed that σ i τ i . Each ordered pair (σ i , τ i ), i ∈ [1 : n], is called a source-sink pair and the set of all such pairs is denoted P ⊂ S × T. Without loss of generality, it is assumed that every source (sink) has no in-coming (resp. out- going) arcs and exactly one out-going (in-coming) arc. 2 The boundary ∂V of the network is the set S ∪ T of source and sink vertices, and its interior is intV := V \ ∂V.
Each channel in the network can transfer information er- rorlessly up to a maximum rate, as speciﬁed by a positive arc-capacity c α ∈ R >0 . In certain situations, it may be natural to assign inﬁnite capacity to certain arcs, 3 and the set of all such arcs is denoted A i ⊂ A. In particular, the arcs leaving sources are by convention assigned inﬁnite capacity. The set of ﬁnite-capacity arcs is written A f = A \ A i , with associ- ated arc-capacity vector c := (c α ) α∈A f ∈ R |A f | >0 . The structure of the n-pairs information network is deﬁned as the tuple Σ = (V, A f , A i , P).
The communication signals in the channels are represented by a vector S ≡ (S α ) α∈A of random processes called arc- signals , with S α : W → R m α taken to be discrete-valued
∀α ∈ A f . In particular, the arc-signals leaving sources and entering sinks respectively represent the exogeneous inputs and outputs of the information network. For convenience, the signal S OUT(σ i ) leaving the i-th source σ i ∈ S is denoted X i , and the signal S IN(τ i ) entering the i-th sink τ i ∈ T is denoted Y i . It is assumed throughout this paper that the signals X 1 , X 2 , . . . , X n are mutually independent, though each may itself be a correlated process.
The arc-signal vector S is assumed to have the following property:
Remarks: In acyclic digraphs (i.e. in which every walk is a path), this is equivalent to causality at every internal vertex. However, feedback signals may be present in cyclic digraphs, in which case vertex-wise causality would not sufﬁce to guarantee that outgoing signals from an arbitrary vertex-set are uniquely and causally determined by incoming ones as required in (1). Stronger assumptions would be needed, e.g. a positive time-delay at every vertex.
In an n-pairs network, information must be conveyed from each source σ i ∈ S to its corresponding sink τ i so as to achieve some goal, without exceeding any channel capacities. In this paper, the goal is to guarantee that the marginal information rates supplied to the sinks exceed speciﬁed demands. This leads to the following deﬁnition:
Deﬁnition 2 (Achievability): Consider an n-pairs informa- tion network with structure Σ, source-signal vector X , arc- capacity vector c ∈ R |A f | >0 and demand vector d := (d i ) n i =1 ∈ R n >0 , ∀i ∈ [1 : n]. The tuple (Σ, X , c, d) is called achievable if ∃ a setwise-causal (Def. 1) arc-signal vector S s.t.
I ∞ [Y i ; X i ] ≥ d i , ∀i ∈ [1 : n], 	 (3) I ∞ [S α ; X ] ≤ c α , ∀α ∈ A f . 	 (4)
Such an S is called a solution to the n-pairs information net- work problem (Σ, X , c, d). The demand vector d is then called achievable on (Σ, X , c); c is called achievable on (Σ, X , d); and (X , c, d) is called achievable on Σ.
The closure of the set of achievable demand vectors d is called the demand region D ⊆ R n ≥0 of (Σ, X , c). c ♦
Remarks: The objective (3) is a relaxation of the usual aim of reconstructing the source signals reliably or within some speciﬁed distortion level. This allows the standard assumption that each source signal is stationary or i.i.d. to be dropped. Note that when X i is discrete-valued, d i = H ∞ [X i ] is necessary for reliable reconstruction at τ i .
Also note, it is implicit in Def. 2 that the input-output operators g ν at every internal vertex ν may be freely designed
to yield a solution S, as long as setwise causality (Def. 1) is respected.
As mentioned in the introduction, it was once thought that a network was achievable 4 iff it admitted a routing solution. In the present context, this is equivalent to presuming the existence of an (X , c, d)-feasible multicommodity ﬂow, i.e. of a nonnegative matrix f = ( f α, j ) α∈A, j∈[1:n] ∈ R |A|×n ≥0 , of bit-rates on each arc associated with every source-sink pair, s.t.
f IN(τ j ), j ≥ d j , ∀ j ∈ [1 : n] (demand met), 	 (6) f OUT(σ j ), j ≤ H ∞ [X j ], ∀ j ∈ [1 : n] (supply sufﬁces), (7)
for any j ∈ [1 : n] and ν ∈ V \ ({σ j } ∪ {τ j }). Via an explicit counter-example, the article [3] showed that this intuitive notion was incorrect, i.e. that although the existence of a feasible multicommodity ﬂow is sufﬁcient for achievability, it is not generally necessary. This laid the foundations for network coding , in which nodes are permitted to not just route incoming bits, but also to perform functions on them.
Nonetheless, routing/multicommodity-ﬂow solutions have certain virtues. This paper studies the following question:
Is there a general class of n-pair information network struc- tures Σ for which the achievability of (X , c, d) is equivalent to the existence of an (X , c, d)-feasible multicommodity ﬂow f (5)–(8)?
In general, any n-pairs information network structure Σ in which each sink is reachable from its source can support (X , c, d)-feasible multicommodity ﬂows if the arc-capacities and source entropy rates are sufﬁciently larger than the de- mands. However, there are examples of structures on which an (X , c, d)-feasible multicommodity ﬂow does not exist if arc-capacities are reduced or demands increased, even though (X , c, d) is still achievable (see sec. IV). The aim of this paper is to isolate certain structural properties that ensure routability over all achievable combinations of (X , c, d). Such properties would inhere solely in the structure Σ, suiting situations in which channels, switches, transceivers and interfaces are expensive to set up and difﬁcult to move, and/or where channel capacities, output demands and source-signal statistics are variable or unknown.
Before giving the (afﬁrmative) answer to the question above, several graph-theoretic notions must be deﬁned for an n-pairs information network with structure Σ = (V, A f , A i , P).
First, some largely familiar concepts are revisited. A path in an n-pairs information network that goes from a source σ i to its sink τ i is called an i-path and the set of all i-paths is called an i-bundle. In other words, the i-bundle is the set of all acyclic paths via which information can be routed from σ i
to τ i . Given a set J ⊆ [1 : n], the set of all i-paths with i ∈ J is called a J-bundle (note that this is not the same as the set of all paths from {σ i : i ∈ J} to {τ i : i ∈ J}, which contains it). For any vertex-set U ⊂ V such that σ i ∈ U and τ i ∈ U c = V \ U, the arc-set OUT(U) is called an i-cut. 5
Deﬁnition 3 ( J-Disjointness): Given a structure Σ, an arc- set B ⊆ A is called J-disjoint for an index set J ⊆ [1 : n] if each path in the J-bundle passes through at most one arc in B. ♦
Remarks: Every singleton {α} ⊆ A is automatically J-disjoint and every arc-set B ⊆ A is automatically /0-disjoint.
Deﬁnition 4 (Chokes): Given a structure Σ and vertex-sets W, Z ⊆ V, an arc-set B ⊆ A is called a W Z-choke if all paths from W to Z pass through B.
For a given index i ∈ [1 : n], an arc-set is called a triangular i -choke if it is a {σ 1 , . . . , σ j } τ j -choke, ∀ j ∈ [1 : i]. ♦
Deﬁnition 5 (Viable i-Cuts): For a given index i ∈ [1 : n] and structure Σ, an i-cut OUT(U) is called viable if the following conditions are met:
1) Every arc in OUT(U) is ﬁnite-capacity, i.e. OUT(U) ⊆ A f .
2) Every arc in OUT(U) lies in the [1 : i − 1]-bundle or in an i-path that passes through OUT(U) once. ♦
Remark: The deﬁnition above basically lists the structural properties of min-cuts in a certain residual capacitated digraph used to prove the main result below.
Deﬁnition 6 (Reverse Structure): Given a structure Σ, the reverse structure Σ := (V, A f , A i , P ) is given by
A f := (µ , ν ) : (ν , µ ) ∈ A f , 	 (9) A i := (µ , ν ) : (ν , µ ) ∈ A i , 	 (10) P := (σ i , τ i ) : (τ i , σ i ) ∈ P . ♦ 	 (11)
Remarks: This describes the n-pairs information network obtained by reversing arcs and swapping the roles of sources and sinks. The reverse structure is useful because a multicom- modity ﬂow on Σ can be reversed in direction to yield one on Σ and vice-versa.
Deﬁnition 7 (Triangularizability): A structure Σ is called triangularizable if there is an ordering (σ 1 , δ 1 ), . . . , (σ n , δ n ) of the source-sink pairs so that every viable i-cut OUT(U) (Def. 5) contains a [1 : i − 1]-disjoint, triangular i-choke, ∀i ∈ [2 : n] (Defs. 3 and 4). ♦
Remark: Note that triangularizability is not generally in- variant under reversals of structure. Although a viable i-cut OUT(U) corresponds exactly to a viable i-cut OUT(U c ) in the reverse structure Σ , a {σ 1 , . . . , σ i } τ i -choke becomes a σ i 	 {τ 1 , . . . , τ i }-choke, not a {σ 1 , . . . , σ i } 	 τ i -choke.
Theorem 1: Suppose an n-pairs information network has a structure Σ or reverse structure Σ (Def. 6) that is triangular- izable (Def. 7). Then Σ is always routable, i.e. (Σ, X , c, d) is
achievable (Def. 2) iff an (X , c, d)-feasible multicommodity ﬂow f (5)–(8) exists on Σ.
The central ideas behind the proof of this result are de- scribed in the next section. In sec. IV, two examples are discussed.
Throughout this section, Σ = (V, A f , A i , P) is the structure of an n-pairs information network, as described in sec. II. In both the proofs of necessity and sufﬁciency, use will be made of the fact that ∀i ∈ [1 : n], any single-commodity ﬂow q from σ i to τ i in the structure Σ can be decomposed into a superposition of i-path ﬂows and cycle ﬂows (see e.g. [11], Thm. 3.3.1). That is, if π 1,i , . . . , π p i ,i are the distinct i-paths and γ 1 , . . . , γ g , the distinct cycles, then ∃ numbers u 1,i , . . . , u p ,i ≥ 0 and w 1,i , . . . , w g ,i ≥ 0 s.t.
The proof of sufﬁciency is relatively straightforward. If f is an (X , c, d)-feasible multicommodity ﬂow (5)–(8) on Σ, the decomposition (12) is used directly to devise a routing solution S .
The proof of necessity is more difﬁcult and involves induc- tion, using the following building blocks.
Deﬁnition 8 ( J-Flow): Given an index set J ⊆ [1 : n], a nonnegative tuple f = ( f α, j ) α∈A, j∈J ∈ R |A||J| ≥0 is called a J-ﬂow on the structure Σ if ∀ j ∈ J and ν ∈ V \ {σ j } ∪ {τ j },
As a convention, the /0-ﬂow is deﬁned as the empty sequence (). ♦
Remark: A J-ﬂow is a (possibly infeasible) multicommmodity ﬂow with source-sink pairs (σ j , τ j ), j ∈ J. If each j-ﬂow f A, j is acyclic, ∀ j ∈ J, then f is called an acyclic J-ﬂow.
The next concept is central to the proof of necessity. It deﬁnes a class of feasible [1 : i]-ﬂows that obey certain information-theoretic bounds when only the signals X j , j ∈ [1 : i] need to be communicated.
Deﬁnition 9 (Informational Feasibility): Given i ∈ [1 : n] and a setwise-causal arc-signal vector S (Def. 1), a [1 : i]- ﬂow f ∈ R |A|i ≥0 (Def. 8) is called informationally feasible on the signal graph (Σ, S) if it satisﬁes the following conditions:
The following result concerning informationally feasible [1 : n ]-ﬂows also plays a key role.
Lemma 1: If the arc-signal vector S is a solution to the n- pairs information network problem (Σ, X , c, d) (Def. 2), then any informationally feasible (Def. 9) [1 : n]-ﬂow f ∈ R |A|n ≥0 on (Σ, S) is an (X , c, d)-feasible multicommodity ﬂow on Σ (5)– (8).
The proof of necessity uses upward induction to construct a sequence of informationally feasible [1 : i]-ﬂows (Def. 8), i ∈ [1 : n]. By Lemma 1, f n is then an (X , c, d)-feasible multicommodity ﬂow, as desired.
A non-triangularizable example is presented ﬁrst, adapted from [12]. Consider the 2-pairs butterﬂy information network problem depicted in Fig. 1, where all arc-capacities are inﬁnite except on the arc from ω 1 to ω 2 ; X 1 and X 2 are i.i.d. binary- valued signals with H[X 1 (t)] = H[X 2 (t)] = 1; and the demands d 1 = d 2 = 1.
It can be checked that OUT ({σ 2 , ν 1 , ω 1 , ν 2 , τ 1 }) = {(ω 1 , ω 2 )} is a 2-cut. As (ω 1 , ω 2 ) is ﬁnite-capacity and lies in the 1-path (σ 1 , µ 1 , ω 1 , ω 2 , ν 2 , τ 1 ), {(ω 1 , ω 2 )} is a viable 2- cut (Def. 5). However, it cannot contain a triangular 2-choke (Def. 4), since the path (σ 1 , µ 1 , µ 2 , τ 2 ) bypasses (ω 1 , ω 2 ). Consequently, this network is not triangularizable (Def. 7) and Thm. 1 does not apply.
This is in agreement with [12]. Observe that if if c ≡ c ω 1 ,ω 2 = 2, then (X , c, d) is achievable, since 1 unit of ﬂow can be routed from σ 1 to τ 1 and from σ 2 to τ 2 via (ω 1 , ω 2 ), without exceeding its arc-capacity. However, if c is reduced to 1, then the network can no longer support an (X , c, d)- feasible 2-commodity ﬂow (5)–(8). Nonetheless, (X , c, d) still remains achievable, by sending the signal X 1 on (µ 1 , µ 2 ), X 2 on (ν 1 , ν 2 ), and Z = X 1 + X 2 (mod 2) on (ω 1 , ω 2 ), (ω 2 , µ 2 ) and (ω 2 , ν 2 ), and setting Y 2 = Z +X 1 (mod 2) = X 2 and Y 1 = Z +X 2 (mod 2) = X 1 .
Both its arcs lie in the (only) 1-path (σ 1 , ν 1 , ω, µ 2 , µ 1 , ν 2 , τ 1 ) and are thus in the 1-bundle, so W is a viable 2-cut (Def. 5). Now consider the set B = {(ω, µ 2 )} ⊆ W. As there is only one 1-path, B is automatically [1 : 1]-disjoint (Def. 3) Furthermore, it is a triangular 2-choke (Def. 4), since all paths from σ 1 to τ 1 , σ 1 to τ 2 and σ 2 to τ 2 pass through it. Thus B is a [1 : 1]-disjoint, triangular 2-choke contained in the only viable 2-cut W, and so the network is triangularizable (Def. 7. Consequently, by Thm. 1 any tuple (X , c, d) is achievable iff there exists an (X , c, d)-feasible multicommodity ﬂow. After eliminating the ﬂow variables, (X , c, d) is thus achievable iff
The author acknowledges useful discussions on the feedback control version of this problem with Rob Evans at Uni. Melbourne. He is also indebted to the anonymous reviewer who pointed out an error in the original version of (16).
[[[ REFS ]]]
T. Leighton
S. Rao
--
Multicommodity max-ﬂow min-cut theorems and their use in designing approximation algorithms
----
R. Yeung
--
Multilevel diversity coding with distortion
----
R. Ahlswede
N. Cai
S. Li
R. Yeung
--
Network information ﬂow
----
X. Yan
J. Yang
Z. Zhang
--
An outer bound for multisource multisink network coding with minimum cost consideration
----
M. Adler
N. Harvey
K. Jain
R. Kleinberg
A. Lehman
--
On the capacity of information networks
----
T. Han
--
Multicasting multiple correlated sources to multiple sinks over a noisy channel network
----
S.-Y. Li
R. Yeung
N. Cai
--
Linear network coding
----
A. S. Matvee
A. V. Savki
--
Estimation and Control over Commu- nication Networks 
----
P. Antsakli
J. Baillieu
--
Eds
----
N. Harvey
R. Kleinberg
A. Lehman
--
On the capacity of infor- mation networks
----
J. Bang-Jense
G. Guti
--
Digraphs Theory, Algorithms and Appli- cations 
----
G. Kramer
S. Savari
--
Edge-cut bounds on network coding rates
[[[ META ]]]
parsed -> yes
file -> E:\isit2011\158.pdf
[[[ LINKS ]]]

