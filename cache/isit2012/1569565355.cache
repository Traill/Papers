{"id":"1569565355","paper":{"title":{"text":"The Capacity Loss of Dense Constellations"},"authors":[{"name":"Tobias Koch"},{"name":"Alfonso Martinez"},{"name":"Albert Guill´en i F`abregas"}],"abstr":{"text":"Abstract\u2014We determine the loss in capacity incurred by using signal constellations with a bounded support over general complex-valued additive-noise channels for suitably high signal- to-noise ratio. Our expression for the capacity loss recovers the power loss of 1.53dB for square signal constellations."},"body":{"text":"As it is well known, the channel capacity of the complex- valued Gaussian channel with input power at most P and noise variance σ 2 is given by [1]\nAlthough inputs distributed according to the Gaussian distri- bution attain the capacity, they suffer from several drawbacks which prevent them from being used in practical systems. Among them, especially relevant are the unbounded support and the inﬁnite number of bits needed to represent signal points.\nIn practice, discrete distributions with a bounded support are typically preferred\u2014in this case, the number of points is allowed to grow with the signal-to-noise ratio (SNR). Ungerboeck computed the rates that are achievable over the Gaussian channel when the channel input takes value in a ﬁnite constellation [2]. He observed that, when transmitting at a rate of R bits per channel use, there is not much to be gained from using constellations with size N larger than 2 R+1 . Ozarow and Wyner provided an analytic conﬁrmation of Ungerboeck\u2019s observation by deriving a lower bound on the rates achievable with ﬁnite constellations [3]. In both works, the channel inputs are assumed to be uniformly distributed on a lattice within some enclosing boundary, where the size of the boundary is scaled in order to ensure unit input-power.\nA related line of work considered signal constellations with favorable geometric properties, e.g., minimum Euclidean distance or minimum average error probability. For signal constellations with a large number of points, i.e., dense con- stellations, Forney et al. [4] estimated the loss in SNR with respect to the Gaussian input to be 10 log 10 πe 6 ≈ 1.53dB by comparing the volume of an n-dimensional hypercube with that of an n-dimensional hypersphere of identical average power. Later, Ungerboeck\u2019s work led to the study of multi- dimensional constellations based on lattices [5]\u2013[8].\nRecently, Wu and Verd´u have studied the information rates that are achievable over the Gaussian channel when the input takes value in a ﬁnite constellation with N signal points [9]. For every ﬁxed SNR, they show that the difference between the capacity and the achievable rate tends to zero exponentially in N. For the optimal constellation, the peak-to-average-power ratio grows linearly with N, inducing no capacity loss. This is in contrast to the constellations considered by Ungerboeck [2] and Ozarow and Wyner [3], which have a ﬁnite peak-to- average-power ratio.\nIn this work, we adopt an information-theoretic perspective to study the capacity loss incurred by signal constellations with a bounded support over the Gaussian channel for sufﬁciently small noise variance. In particular, we use the duality-based upper bound to the mutual information in [10] to provide a lower bound on the capacity loss. The results are valid for both peak- and average-power constraints and generalize directly to other additive-noise channel models. For sufﬁciently high SNR, our results recover the power loss of 1 .53dB for square signal constellations without invoking geometrical arguments.\nWe consider a discrete-time, complex-valued additive noise channel, where the channel output Y k at time k ∈ Z (where Z denotes the set of integers) corresponding to the time-k channel input x k is given by\nY k = x k + σW k , k ∈ Z. \t (2) We assume that {W k , k ∈ Z} is a sequence of independent and identically distributed, centered, unit-variance, complex random variables of ﬁnite differential entropy. We further assume that the distribution of W k does neither depend on σ > 0 nor on the sequence of channel inputs {x k , k ∈ Z}.\nThe channel inputs take value in the set S, which is assumed to be a bounded Borel subset of the complex numbers C. We further assume that S has positive Lebesgue measure and that 0 ∈ S.\nThe set S can be viewed as the region that limits the signal points. For example, for a square signal constellation, it is a square:\nfor some A > 0. Here Re (x) and Im (x) denote the real and imaginary part of x, respectively. Similarly, for a circular signal constellation,\nWe study the capacity of the above channel under an average-power constraint P on the inputs. Since the channel is memoryless, it follows that the capacity C S (P, σ) (in nats per channel use) is given by\nwhere the supremum is over all input distributions with essential support in S that satisfy E |X| 2 ≤ P.\nWe focus on C S (P, σ) in the limit as the noise variance σ tends to zero. In particular, we study the capacity loss, which we deﬁne as\n(Theorem 1 ahead asserts the existence of the limit.) Here C C (P, σ) denotes the capacity of the above channel when the support-constraint S is relaxed, i.e.,\nwhere the o(1)-term vanishes as σ tends to zero. (Here log(·) denotes the natural logarithm and h(·) denotes differential entropy.) The capacity loss (6) can thus be written as\nL = log P + log(πe) − h(W ) − lim σ↓0 \t sup\nBy choosing an input distribution that does not depend on σ, we can achieve 1\nwhich follows from the behavior of differential entropy under deterministic translation and under scaling by a complex number. Extending [10, Lemma 6.9] (see also [11]) to complex random variables yields then that, for every E |X| 2 < ∞ and E |W | 2 < ∞, the ﬁrst differential entropy on the right-hand side (RHS) of (11) satisﬁes\nConsequently, we obtain lim σ↓0 \t sup\nlim σ↓0 I(X; Y ) − log 1 σ 2 = \t sup\nLet P U denote the average power of a random variable that is uniformly distributed over S, i.e.,\nP U S |x| 2 d x S d x\nA small modiﬁcation of the proof in [12, Th. 12.1.1] shows that the density that maximizes h(X) for X ∈ S with probability one and E |X| 2 ≤ P has the form\nfor P < P U . Here I {statement} denotes the indicator function: it is equal to one if the statement in the brackets is true and it is otherwise equal to zero.\nApplying (15) to (10) yields L ≤ log P + log(πe) − log\nFor P = P U (and hence λ = 0), this becomes L ≤ log(πe) + log\nSpecializing (18) to a square signal constellation (3) yields (irrespective of A)\nwhich corresponds to a power loss of roughly 1 .53dB. Hence, we recover the rule of thumb that \u201csquare signal constellations have a 1 .53dB power loss at high signal-to-noise ratio.\u201d\nFor a circular signal constellation (4), the upper bound (18) becomes (irrespective of R)\nThe inequality in (17) holds with equality if the capacity- achieving input-distribution does not depend on σ, cf. (13). However, this is in general not the case. For example, for circularly-symmetric Gaussian noise and a circular signal constellation (4), it was shown by Shamai and Bar-David [13] that, for every σ > 0, the capacity-achieving input-distribution is discrete in magnitude, with the number of mass points growing with vanishing σ. Nevertheless, the following theorem demonstrates that the RHS of (17) is indeed the capacity loss.\nTheorem 1 (Main Result): For the above channel model, we have\nwhere λ = 0 for P ≥ P U , and where λ satisﬁes (16) for P < P U .\nNote 1: It is not difﬁcult to adapt the proof of Theorem 1 to other regions S and moment constraints. For example, the same proof technique can be used to derive the capacity loss when S is a Borel subset of the real numbers and the channel input\u2019s ﬁrst-moment is limited, i.e., E[ |X|] ≤ A.\nEquations (11)\u2013(13) demonstrate that the capacity loss (21) can be achieved with a continuous-valued channel input hav- ing density f (·). Using the lower-semicontinuity of relative entropy [14], it can be further shown that (21) can also be achieved by any sequence of discrete channel inputs {X N } for which the number of mass points N grows with vanishing σ, provided that\nwhere X is a continuous random variable having density f (·). (Here L → denotes convergence in distribution.) Such a sequence can, for example, be obtained by approximat- ing the distribution function corresponding to f (·) by two- dimensional step functions.\nIn view of (9), in order to prove Theorem 1 it sufﬁces to show that\nThe claim follows then by combining (23) with (17). To this end, we use the upper bound on the mutual information [10, Th. 5.1]\nwhere Q(·) denotes the input distribution; W (·|x) denotes the conditional distribution of the channel output, conditioned on X = x; and R(·) denotes some arbitrary distribution on the output alphabet. Every choice of R(·) yields an upper bound on I(X; Y ), and the inequality in (24) holds with equality if R(·) is the actual distribution of Y induced by Q(·) and W (·|·).\nTo derive an upper bound on I(X; Y ), we apply (24) with R(·) having density\n⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩\nis a normalizing constant; where S denotes the - neighborhood of S\nwhere S c denotes the complement of S ; and where λ is zero for P ≥ P U and satisﬁes (16) for P < P U . Some useful properties of K ,σ are summarized in the following lemma.\nWe return to the analysis of I(X; Y ) and apply (24) together with the density (25) to express the upper bound as\nwhere p(y|x) denotes the conditional probability density func- tion of Y , conditioned on X = x.\nand some algebra applied to the second summand in (29) allows us to write it as\nCombining (30) and (31) with (29) and (24) yields I(X; Y )\nWe next show that, for > 0, lim σ↓0 \t sup\nThe ﬁrst claim (33a) follows by upper-bounding sup\nwhere the second step follows because X and W are inde- pendent, and the third step follows because E |X| 2 ≤ P and E |W | 2 = 1.\nfor x = x ∈ S, so y ∈ S . By Chebyshev\u2019s inequality [15, Sec. 5.4], this can be further upper-bounded by\n2 . \t (36) It then follows that, for σ ≤ 1 π ,\nwhere the right-most term vanishes as σ tends to zero. This proves (33b).\nWe next turn to (33c). We ﬁrst note that every y ∈ S c must satisfy |y| > , since otherwise |y − x | ≤ for x = 0, which by assumption is in S. Therefore,\n≥ 0, for σ ≤ . \t (38) To prove (33c), it thus remains to show that\nwhere the last step follows from the Cauchy-Schwarz inequal- ity\nUsing (36) together with the fact that ξ → −ξ log ξ is mono- tonically increasing for ξ ≤ e −1 , we obtain for σ ≤ e −1/2\nfrom which (39)\u2014and hence (33c)\u2014follows by noting that the RHS of (42) vanishes as σ tends to zero.\nTo prove (33d), we use Jensen\u2019s inequality and (34) to obtain\n− Pr Y ∈ S c log Pr Y ∈ S c . \t (43) Using (36) together with the fact that ξ → −ξ log ξ is mono- tonically increasing for ξ ≤ e −1 , we obtain for σ ≤ e −1/2\nfrom which (33d) follows by noting that the RHS of (44) vanishes as σ tends to zero.\nCombining (33a)\u2013(33d) with (32) yields lim σ↓0 \t sup\nwhere the last equation follows from the continuity of x → log(x) for x > 0. Letting tend to zero, and using (28b) in Lemma 2, we prove (23) and therefore the desired\nA natural approach to prove Theorem 1 would be to generalize (12) to\nWhile this approach may seem simpler, our approach has the advantage that it also allows for a lower bound on the nonasymptotic capacity loss\nIndeed, combining (43), (40), and (34) with (32) yields I(X; Y ) ≤ −h(W ) + log 1 σ 2 + log K ,σ + λ P + σ 2\n(where tan −1 (·) denotes the arctangent function), and by using (35) together with the fact that ξ → −ξ log ξ is monotonically increasing for ξ ≤ e −1 and that −ξ log ξ ≤ 1/e for 0 < ξ < 1, we obtain, upon minimizing over > 0,\n+ Pr σ|W | > log 1 + P σ 2 + Pr σ|W | > − 3 2 Pr σ|W | > log Pr σ|W | >\nFigure 1 shows the lower bound on L(σ) for circularly- symmetric Gaussian noise and a square signal constellation (3) with P = P U . It further shows the information-rate losses of 2 m -ary quadrature amplitude modulation (QAM) for m = 10, 16, and 22, which were numerically obtained using\nGauss-Hermite quadratures [16], as described for example in [17, Sec. III]. Since for a ﬁxed m the information rate corresponding to 2 m -ary QAM is bounded by m bits, the rate loss of 2 m -ary QAM tends to inﬁnity as σ tends to zero. We observe that the lower bound on L(σ) converges to L = log(πe/6) ≈ 0.353 as σ tends to zero, but is rather loose for ﬁnite σ. However, in the proof of Theorem 1 we chose the density (25) to decay sufﬁciently slowly, so as to ensure that the lower bound on L holds for every unit-variance noise of ﬁnite differential entropy. For Gaussian noise, a density can be chosen that decays much faster, giving rise to a tighter bound.\nThe authors would like to thank Alex Alvarado for helpful discussions and for providing the QAM curves in Figure 1."},"refs":[{"authors":[{"name":"C. E. Shannon"}],"title":{"text":"A mathematical theory of communication"}},{"authors":[{"name":"G. Ungerboeck"}],"title":{"text":"Channel coding with multilevel/phase signals"}},{"authors":[{"name":"L. H. Ozarow"},{"name":"A. D. Wyner"}],"title":{"text":"On the capacity of the Gaussian channel with a ﬁnite number of input levels"}},{"authors":[{"name":"G. D. Forney"},{"name":"R. G. Gallager"},{"name":"G. R. Lang"},{"name":"F. M. Longstaff"},{"name":"G. R. Qureshi"}],"title":{"text":"Efﬁcient modulation for band-limited channels"}},{"authors":[{"name":"G. D. Forney"},{"name":"L.-F. Wei"}],"title":{"text":"Multidimensional constellations\u2014Part I: Introduction, ﬁgures of merit, and generalized cross constellations"}},{"authors":[{"name":"G. D. Forney"}],"title":{"text":"Multidimensional constellations\u2014Part II: Voronoi constellations"}},{"authors":[{"name":"A. R. Calderbank"},{"name":"L. H. Ozarow"}],"title":{"text":"Nonequiprobable signaling on the gaussian channel"}},{"authors":[{"name":"F. R. Kschischang"},{"name":"S. Pasupathy"}],"title":{"text":"Optimal nonuniform signaling for gaussian channels"}},{"authors":[{"name":"Y. Wu"},{"name":"S. Verd´u"}],"title":{"text":"The impact of constellation cardinality on Gaussian channel capacity"}},{"authors":[{"name":"A. Lapidoth"},{"name":"S. M. Moser"}],"title":{"text":"Capacity bounds via duality with applications to multiple-antenna systems on ﬂat fading channels"}},{"authors":[{"name":"T. Linder"},{"name":"R. Zamir"}],"title":{"text":"On the asymptotic tightness of the Shannon lower bound"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory, 2nd ed"}},{"authors":[{"name":"S. Shamai (Shitz)"},{"name":"I. Bar-David"}],"title":{"text":"The capacity of average and peak-power-limited quadrature Gaussian channels"}},{"authors":[{"name":"E. C. Posner"}],"title":{"text":"Random coding strategies for minimum entropy"}},{"authors":[{"name":"R. G. Gallage"}],"title":{"text":"Information Theory and Reliable Communication"}},{"authors":[{"name":"M. Abramowit"},{"name":"I. A. Stegu"}],"title":{"text":"Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables"}},{"authors":[{"name":"A. Alvarado"},{"name":"F. Br¨annstr¨om"},{"name":"E. Agrell"}],"title":{"text":"High SNR bounds for the BICM capacity"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565355.pdf"},"links":[{"id":"1569566381","weight":6},{"id":"1569566527","weight":3},{"id":"1569565383","weight":3},{"id":"1569565223","weight":6},{"id":"1569566725","weight":3},{"id":"1569565663","weight":15},{"id":"1569565377","weight":6},{"id":"1569566385","weight":9},{"id":"1569564635","weight":3},{"id":"1569565867","weight":6},{"id":"1569565067","weight":3},{"id":"1569559617","weight":6},{"id":"1569566981","weight":3},{"id":"1569566683","weight":9},{"id":"1569566227","weight":3},{"id":"1569566697","weight":9},{"id":"1569566597","weight":3},{"id":"1569565551","weight":3},{"id":"1569566943","weight":3},{"id":"1569566591","weight":3},{"id":"1569556029","weight":3},{"id":"1569552245","weight":6},{"id":"1569564481","weight":3},{"id":"1569564805","weight":3},{"id":"1569566469","weight":6},{"id":"1569565613","weight":3},{"id":"1569564469","weight":3},{"id":"1569565931","weight":6},{"id":"1569551535","weight":3},{"id":"1569566765","weight":9},{"id":"1569565461","weight":12},{"id":"1569564245","weight":3},{"id":"1569564227","weight":9},{"id":"1569566671","weight":6},{"id":"1569566303","weight":6},{"id":"1569564233","weight":3},{"id":"1569565317","weight":3},{"id":"1569565123","weight":6},{"id":"1569566941","weight":9},{"id":"1569566739","weight":3},{"id":"1569558459","weight":3},{"id":"1569556713","weight":3},{"id":"1569562685","weight":3},{"id":"1569566467","weight":3},{"id":"1569565771","weight":6},{"id":"1569560613","weight":9},{"id":"1569566903","weight":3},{"id":"1569566999","weight":21},{"id":"1569564249","weight":3},{"id":"1569565809","weight":3},{"id":"1569566843","weight":6},{"id":"1569566579","weight":3},{"id":"1569558483","weight":6},{"id":"1569565455","weight":9},{"id":"1569566963","weight":9},{"id":"1569566709","weight":9},{"id":"1569564989","weight":6},{"id":"1569566523","weight":3},{"id":"1569565897","weight":3},{"id":"1569566895","weight":3},{"id":"1569566749","weight":3},{"id":"1569564613","weight":3},{"id":"1569566095","weight":6},{"id":"1569565785","weight":3},{"id":"1569566239","weight":6},{"id":"1569566679","weight":3},{"id":"1569566419","weight":3},{"id":"1569559565","weight":6},{"id":"1569566905","weight":6},{"id":"1569566733","weight":3},{"id":"1569566753","weight":3},{"id":"1569558681","weight":6},{"id":"1569555999","weight":3},{"id":"1569566759","weight":3},{"id":"1569565213","weight":6},{"id":"1569565841","weight":3},{"id":"1569566369","weight":3},{"id":"1569561143","weight":9},{"id":"1569564611","weight":6},{"id":"1569565667","weight":6},{"id":"1569566423","weight":6},{"id":"1569565257","weight":3},{"id":"1569567015","weight":6},{"id":"1569566437","weight":9},{"id":"1569553909","weight":3},{"id":"1569566687","weight":15},{"id":"1569562285","weight":9},{"id":"1569565427","weight":3},{"id":"1569565915","weight":6},{"id":"1569552251","weight":3},{"id":"1569566425","weight":3},{"id":"1569554881","weight":6},{"id":"1569554971","weight":6},{"id":"1569566209","weight":6},{"id":"1569562821","weight":15},{"id":"1569566909","weight":9},{"id":"1569566127","weight":6},{"id":"1569558985","weight":9},{"id":"1569565087","weight":3},{"id":"1569566473","weight":6},{"id":"1569564857","weight":3},{"id":"1569566809","weight":3},{"id":"1569566629","weight":3},{"id":"1569565033","weight":9},{"id":"1569566447","weight":3},{"id":"1569563897","weight":3},{"id":"1569566721","weight":6},{"id":"1569565055","weight":6},{"id":"1569565279","weight":3},{"id":"1569555879","weight":9},{"id":"1569565219","weight":12},{"id":"1569566003","weight":3},{"id":"1569556671","weight":9},{"id":"1569565095","weight":3},{"id":"1569566223","weight":6},{"id":"1569566553","weight":3},{"id":"1569565469","weight":6},{"id":"1569566043","weight":3},{"id":"1569565357","weight":3},{"id":"1569566505","weight":3},{"id":"1569565393","weight":3},{"id":"1569562207","weight":6},{"id":"1569566191","weight":12},{"id":"1569567033","weight":6},{"id":"1569565527","weight":6},{"id":"1569566603","weight":3},{"id":"1569566051","weight":3},{"id":"1569555787","weight":3},{"id":"1569565467","weight":3},{"id":"1569565311","weight":3},{"id":"1569566481","weight":3},{"id":"1569565961","weight":6},{"id":"1569560503","weight":6},{"id":"1569565463","weight":9},{"id":"1569565439","weight":9},{"id":"1569566229","weight":3},{"id":"1569566133","weight":6},{"id":"1569562551","weight":6},{"id":"1569563395","weight":9},{"id":"1569566901","weight":12},{"id":"1569551347","weight":9},{"id":"1569566383","weight":6},{"id":"1569565571","weight":3},{"id":"1569565885","weight":6},{"id":"1569564411","weight":3},{"id":"1569566805","weight":3},{"id":"1569559199","weight":6},{"id":"1569565665","weight":15},{"id":"1569565549","weight":6},{"id":"1569565611","weight":6},{"id":"1569566983","weight":6},{"id":"1569556361","weight":3},{"id":"1569565397","weight":9},{"id":"1569566873","weight":6},{"id":"1569565765","weight":6},{"id":"1569565435","weight":9},{"id":"1569557275","weight":3},{"id":"1569565263","weight":3},{"id":"1569566129","weight":3},{"id":"1569566711","weight":3},{"id":"1569565241","weight":3},{"id":"1569565661","weight":6},{"id":"1569565865","weight":3},{"id":"1569566887","weight":3},{"id":"1569566267","weight":3},{"id":"1569566253","weight":9},{"id":"1569564305","weight":3},{"id":"1569566651","weight":3},{"id":"1569566823","weight":3},{"id":"1569565013","weight":21},{"id":"1569565829","weight":9},{"id":"1569566237","weight":6},{"id":"1569566283","weight":3},{"id":"1569565375","weight":3},{"id":"1569566639","weight":3},{"id":"1569565597","weight":3},{"id":"1569566813","weight":9},{"id":"1569566771","weight":9},{"id":"1569566641","weight":6},{"id":"1569564247","weight":6},{"id":"1569563975","weight":3},{"id":"1569551905","weight":12},{"id":"1569564861","weight":3},{"id":"1569565457","weight":3},{"id":"1569566487","weight":3},{"id":"1569565529","weight":3},{"id":"1569556759","weight":12},{"id":"1569566619","weight":6},{"id":"1569565271","weight":6},{"id":"1569561185","weight":3},{"id":"1569566397","weight":3},{"id":"1569565669","weight":15},{"id":"1569563721","weight":6},{"id":"1569566435","weight":3},{"id":"1569564923","weight":15},{"id":"1569565367","weight":3},{"id":"1569566299","weight":6},{"id":"1569564281","weight":6},{"id":"1569564769","weight":6},{"id":"1569566601","weight":6},{"id":"1569566933","weight":9},{"id":"1569563919","weight":12},{"id":"1569557851","weight":3},{"id":"1569565389","weight":9},{"id":"1569559919","weight":3},{"id":"1569566147","weight":9},{"id":"1569565561","weight":3},{"id":"1569565035","weight":3},{"id":"1569559597","weight":3},{"id":"1569559251","weight":3},{"id":"1569565337","weight":3},{"id":"1569560459","weight":6},{"id":"1569565853","weight":9},{"id":"1569566273","weight":3},{"id":"1569566341","weight":3},{"id":"1569565889","weight":15},{"id":"1569551539","weight":3},{"id":"1569564505","weight":6},{"id":"1569565165","weight":9},{"id":"1569566797","weight":3},{"id":"1569566413","weight":3},{"id":"1569565113","weight":3},{"id":"1569566375","weight":12},{"id":"1569564257","weight":6},{"id":"1569564141","weight":9},{"id":"1569566987","weight":3},{"id":"1569565031","weight":9},{"id":"1569564755","weight":3},{"id":"1569564509","weight":3},{"id":"1569551541","weight":6},{"id":"1569558697","weight":9},{"id":"1569565895","weight":3},{"id":"1569566067","weight":6},{"id":"1569566825","weight":6},{"id":"1569564807","weight":3},{"id":"1569566113","weight":3},{"id":"1569566443","weight":12},{"id":"1569560581","weight":3}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T7.4","endtime":"11:10","authors":"Tobias Koch, Alfonso Martinez, Albert Guillén i Fàbregas","date":"1341226200000","papertitle":"The Capacity Loss of Dense Constellations","starttime":"10:50","session":"S1.T7: Gaussian Channels","room":"Stratton (407)","paperid":"1569565355"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
