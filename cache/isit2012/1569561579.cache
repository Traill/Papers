{"id":"1569561579","paper":{"title":{"text":"New Achievable Rates for Nonlinear Volterra Channels via Martingale Inequalities"},"authors":[{"name":"Kostis Xenoulis Nicholas Kalouptsidis"},{"name":"Igal Sason"}],"abstr":{"text":"Abstract\u2014This paper establishes new achievable rates for non- linear Volterra communication channels using reﬁned versions of the Azuma-Hoeffding inequality. The characteristics of these rates are illuminated in special cases of interest that include time- invariant linear channels with memory, memoryless non-linear channels, and Volterra channel models."},"body":{"text":"Nonlinear effects are typically encountered in wireless com- munication systems and optical ﬁbers, which degrade the qual- ity of the information transmission. In satellite communication systems, the ampliﬁers located on board satellites typically operate at or near the saturation region in order to conserve energy. Saturation nonlinearities of ampliﬁers introduce non- linear distortion in the transmitted signals. Similarly, power ampliﬁers in mobile terminals are designed to operate in a non- linear region in order to obtain high power efﬁciency in mobile cellular communications. In optical ﬁbers [1], dispersion noise and nonlinearities need to be overcome with advanced signal processing techniques. Nonlinear communication channels can be represented by Volterra models [2, Chapter 14]. Analytical foundations of the Volterra series operator were presented in [3]. The optical ﬁber channel has been alternately studied by Poisson type models in [4].\nRandom coding theorems (see, e.g, [5, Chapter 5.5] con- stitute critical performance measures of coded information transmission since they describe the exponential behavior of the decoding error probability. The main difﬁculty in the derivation of calculable closed-form upper bounds on the average decoding error probability when transmission takes place over non-linear channels stems mainly from the difﬁculty of obtaining the channel output probability density function. Previous work on the analysis of coded communication for Volterra channel models is presented, e.g., in [2, Chapter 14.5] and references therein.\nError probability bounds and achievable rates for Volterra channel models were recently developed in [6] using expo- nential martingale inequalities. Improved achievable rates for\nsuch nonlinear communication channels are derived in this paper, based on some reﬁned versions of the Azuma-Hoeffding inequality from [7], [8] and [9] which provide improvements over the exponential martingale inequalities that were used in [6]. The resulting new expressions of achievable rates are exempliﬁed in this work for linear and non-linear time- invariant channel models.\nThe paper is structured as follows. Section II provides new bounds on the error probability and achievable rates under ML decoding. These bounds are exempliﬁed in Section III to time-invariant linear channels with memory and memoryless non-linear channels. These comparisons show a signiﬁcant im- provement over the results reported in [6]. Finally, Section IV concludes our discussion.\nUnder the random coding setup in [5, Section 5.5], consider an ensemble of block codes C where N is the block length, and R is the code rate in nats per channel use. The codewords of a codebook from this ensemble are assumed to be selected independently, and the symbols in each codeword are also assumed to be i.i.d. with an arbitrary probability assignment Q. Let M = exp(N R) be the cardinality of the considered codebook C from the ensemble C. Assume that the relation between the transmitted codeword u = (u 1 , . . . , u N ) ∈ C and the discrete-time channel output y = (y 1 , . . . , y N ) is given by the equality\nwhere ν = (ν 1 , . . . , ν N ) is an additive channel noise vector, and D denotes an operator describing the (linear or non- linear) communication channel without the additive noise. The Volterra operator D of order L and memory q is characterized by the equality (see [6, Eq. (4)])\nfor i ∈ {1, . . . , N } and, in the above equation, u i \t 0 for i ≤ 0. The codeword symbols {u i } are assumed to take values\nFollowing the notation in [6], let D v (Q) denote the average output variance (without the additive noise)\nGiven two randomly selected codewords from the codebook u = (u 1 , . . . , u N ), ˜ u = (˜ u 1 , . . . , ˜ u N ), let {F i } N i=1 be a ﬁltration (i.e., F 0 ⊆ F 1 ⊆ . . . ⊆ F N ) where F i\nσ(U 1 , ˜ U 1 , . . . , U i , ˜ U i ) is the minimal σ-algebra that is gener- ated by U 1 , ˜ U 1 , . . . , U i , ˜ U i (for 1 ≤ i ≤ N ), and F 0 {∅, Ω}.\nThe average decoding error probability P e under ML decod- ing, over the considered ensemble of codes, is upper bounded (for all possible transmitted codewords) by (see [6, Section II])\n(6) where\nRemark 1: A typo has been identiﬁed in the denominator of the exponent in [6, eq. (10)], which should be 8σ 2 ν instead of 4σ 2 ν .\nThe martingale difference sequence {Z i } N i=0 with respect to the ﬁltration F i satisﬁes E[Z i |F i−1 ] = 0, ∀i ∈ [1, N ]. Let us assume (to be later justiﬁed with the calculation of the proper constants) that for a positive d and a non-negative sequence {µ l } m l=2 , where m ≥ 2 is an arbitrary even number,\nParameter d denotes the maximum absolute value of the samples Z i of the martingale difference sequence with respect to any realization of the ﬁltration F i , while µ l denotes the maximum absolute value of the condition mean value of every\nd 2 . \t (11) Then one can upper bound the second term on the right hand side of (6) in the following two ways:\nIn the special case where m = 2, the upper bound in (12) specializes to\n\u2022 Second bounding technique (Bennett\u2019s inequality) (see [7, Lemma 2.4.1] and [9, Eq. (18)]):\n \n \nThe parameters d and γ 2 of the martingale {Z i , F i } depend on the input probability distribution Q.\nCombining the inequalities in (6) and (12) gives the follow- ing exponential upper bound on the conditional average error probability under ML decoding:\nRemark 2: When there is no information about the condi- tional variance of the martingale {Z i , F i } N i=0 or the calculation is too complex, then by setting γ 2 = 1 in both (17) and (18), one obtains, respectively, the following achievable rates:\nRemark 3: According to [9, Proposition 2], the achievable rate R 2 (σ 2 ν ) in (18) is larger than R (2) 1 (σ 2 ν ) in (17).\nRemark 4: Following the discussion in [9, Section III.C.1], a closed form expression for the maximal value of ρ in (17) leads to the bound in [9, Corollary 4] (see the proof in [9, Appendix C]).\nRemark 5: Both R 1 (σ 2 ν ) and R 2 (σ 2 ν ) are continuous func- tions of Q and ρ. Their maxima are attained since Q and ρ vary over compact sets.\nThe achievable rates developed above are exempliﬁed in this section for certain special cases of interest.\nFor the transmission of information through the channel y = u + ν, ν ∼ N (0, σ 2 ν ), the parameters D v (Q), d and γ 2 deﬁned in (5), (8), (9) and (11) can be calculated analytically. For the channel input u ∈ {−A, A} where Q(u = A) = α, one gets by setting f (α) α(1 − α)\nd = 4A 2 (1 − 2f (α)), D v (Q) = 4A 2 f (α),\nFurthermore, letting SNR A 2 /σ 2 ν , the achievable rates in (17) and (18) are equivalently expressed as follows:\nThe simplicity of the speciﬁc communication channel allows one to calculate analytically the normalized higher-order con- ditional moments γ l in (9). It gives that for every integer l ≥ 2\nUnder the above analysis, one can calculate the achievable rate provided by (16) for several values of m and compare it with the one provided by (17) where m = 2. More speciﬁcally, the achievable rate (16) is expressed in terms of SNR, and it gets the form:\nWe next proceed to numerically compare the achievable rates R 2 (SNR) in (23), R (6) 1 (SNR) in (25) and R 2 1 (SNR) in (22), with the achievable rate incorrectly provided in [6, Eq.(84)] and stated here correctly as:\nFigure 1 illustrates that all achievable rates provided in this analysis are larger than that provided by (26). Note also that R (m) 1 (SNR) converges fast as m grows. Furthermore, the achievable rate R (6) 1 (SNR) approximates very well the achievable rate R 2 (SNR) provided in (23), and both of them are very close to the capacity of the binary-input additive white Gaussian noise channel for large values of the SNR. The rate loss in the low SNR regime is mainly due to the use of the\nunion bound that led to the establishment of (6). Furthermore, the achievable rate R (6) 1 (SNR) almost coincides numerically with R 2 (SNR). We proceed now to examine more complex\ncases of Volterra channel models where analytic calculation of the parameters D v (Q) and γ 2 is possible.\nConsider a time-invariant linear channel model with ﬁnite memory q\nSuppose that the input to the channel is a binary i.i.d. sequence with values from the alphabet {−A, A}, with Q(u i = A) = α for all i ∈ [0, N ]. Then setting h [h 0 h 1 . . . h q ]\nwhere it is reminded that f (α) α(1 − α). Furthermore, the martingale-difference sequence {Z i } N i=1 is proved to satisfy\n(29) It then follows that\nConsider the transmission of information over a memoryless nonlinear channel with the following polynomial characteristic of degree L\nDue to the memoryless nature of the speciﬁc system, the martingale-difference sequence {Z i } N i=1 satisﬁes\n   \n  \n   \n  \nUnder the same setup of the previous subsection regard- ing the channel input characteristics, we consider next the transmission of information over the Volterra system D 1 of order L = 3 and memory q = 2, whose kernels are depicted in Table I. Such system models are used in the base-band\nrepresentation of nonlinear narrow-band communication chan- nels. Due to complexity of the channel model, the calculation of the achievable rates provided by (17), (18) requires the numerical calculation of the parameters d and σ 2 and thus of γ 2 for the martingale {Z i , F i } N i=0 . In order to achieve this goal, we have to calculate |Z i −Z i−1 | and Var(Z i |F i−1 ) for all possible combinations of the input samples which contribute to the aforementioned expressions. Thus, the analytic calculation of d and γ l increases as the system\u2019s memory q increases. Numerical results are provided in Figure 2 for the case where σ 2 ν = 1. The new achievable rates R (2) 1 (D 1 , A, σ 2 ν ) and R 2 (D 1 , A, σ 2 ν ) of (17) and (18), which depend on the channel input parameter A, are compared to the achievable rate provided in [6, Fig.2] and shown to be larger than the latter.\nFrom the previous analysis it follows that in the case of more complex Volterra systems, it is preferable to select γ 2 = 1. Then the achievable rate R 2 (σ 2 ν ) (20) admits a closed-form solution according to the analysis. The upper bound (18) on the average error decoding probability P e is expressed for 0 ≤ ρ ≤ 1 as\n \n(40) Concluding the analysis, the upper bound in (39) is expressed equivalently as\n     \n    \nNew achievable rates for random coding are derived in this work for non-linear communication channels. Exponential martingale inequalities are properly utilized for this purpose. The achievable rates obtained in this work improve previous results obtained for the same channel models in [6]. This improvement is facilitated by the use of some reﬁned versions of the Azuma-Hoeffding inequality that were introduced in [8], [10], and more recently in [9]. The analysis presented here can easily be extended to the case where the noise is a complex Gaussian or circularly complex Gaussian, and the parameters of the Volterra system are complex valued as it is in the Volterra representation of bandpass nonlinear channels [2, Section 14.3]."},"refs":[{"authors":[{"name":"A. C. Singer"},{"name":"N. R. Shanbhag"}],"title":{"text":"Electronic disper- sion compensation"}},{"authors":[{"name":"S. Benedett"},{"name":"E. Biglier"}],"title":{"text":"Principles of Digital Transmission with Wireless Applications , Kluwer Academic/ Plenum Publishers, 1999"}},{"authors":[{"name":"S. Boyd"},{"name":"L. O. Chua"},{"name":"C. A. Desoer"}],"title":{"text":"Analytical foundations of Volterra series"}},{"authors":[{"name":"M. Davis"}],"title":{"text":"Capacity and cutoff rate for Poisson-type channels"}},{"authors":[{"name":"R. Gallage"}],"title":{"text":"Information Theory and Reliable Communication, John Wiley and Sons, New York, 1968"}},{"authors":[{"name":"K. Xenoulis"},{"name":"N. Kalouptsidis"}],"title":{"text":"Achievable rates for nonlinear Volterra channels"}},{"authors":[{"name":"A. Demb"},{"name":"O. Zeitoun"}],"title":{"text":"Large Deviations Techniques and Applica- tions , Springer, second edition, 1997"}},{"authors":[{"name":"C. McDiarmid"}],"title":{"text":"On the method of bounded differences"}},{"authors":[{"name":"I. Sason"}],"title":{"text":"On reﬁned versions of the Azuma-Hoeffding inequality with applications in information theory"}},{"authors":[{"name":"C. McDiarmid"}],"title":{"text":"Concentration"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569561579.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T7.1","endtime":"17:00","authors":"Kostis Xenoulis, Nicholas Kalouptsidis, Igal Sason","date":"1341333600000","papertitle":"New Achievable Rates for Nonlinear Volterra Channels via Martingale Inequalities","starttime":"16:40","session":"S8.T7: Communication Theory","room":"Stratton (407)","paperid":"1569561579"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
