{"id":"1569566581","paper":{"title":{"text":"Polar codes for discrete alphabets"},"authors":[{"name":"Eren S¸as¸o˘glu"}],"abstr":{"text":"Abstract\u2014An open problem in polarization theory is whether all memoryless channels and sources with composite (that is, non-prime) alphabet sizes can be polarized with deterministic, Arıkan-like methods. This paper answers the question in the afﬁrmative by giving a method to polarize all discrete memoryless channels and sources. The method yields codes that retain the low encoding and decoding complexity of binary polar codes.\nIndex Terms\u2014Channel polarization, source polarization, polar codes, entropy inequality, non-binary codes."},"body":{"text":"Polar coding was introduced as a low-complexity coding technique for achieving the symmetric-capacity of binary-input discrete memoryless channels [1]. It was shown later that the same technique can be used to obtain entropy-achieving source codes [2].\nThe low-complexity properties of polar codes are due to their nested structure, which makes them suitable for recursive and efﬁcient encoding/decoding algorithms. Their capacity- and entropy-achieving properties, on the other hand, are due to polarization: Applying the polar code transform to a mem- oryless channel yields a set of (almost) noiseless and (almost) useless channels, and (almost) no mediocre channels. Polar channel coding consists in using the noiseless channels for data transmission. (For the interpretation in source coding, see [2].) One of the many appeals of this method is that the code transform to be applied is chosen independently from the underlying channel or source. That is, a single transform polarizes all binary-input channels and binary sources.\nA method that extends the polarization technique to chan- nels and sources (hereafter, processes) with prime alphabet sizes was given in [3]. There, it was shown that the technique falls short of polarizing all processes when the alphabet size is composite. It was also shown in the same reference that given any i.i.d. process, there exists a set of transforms that will yield polarization. One can also achieve optimal coding rates by viewing a process with composite alphabet size as a collection of processes with prime alphabets and polarizing each process separately, although this method in general does not polarize the original process.\nIn this note we describe a recursive method to polarize all i.i.d. processes with arbitrary discrete alphabets. Codes obtained through this method are similar to binary polar codes in performance and complexity.\nLet (X 1 , Y 1 ), (X 2 , Y 2 ), . . . be a sequence of independent and identically distributed (i.i.d.) random variables, where\nX 1 ∈ X = {0, 1} and Y 1 is arbitrary. Here, the Xs can be interpreted as i.i.d. inputs to a memoryless channel, and the Y s as the output. Alternatively, one can think of the Xs as the output of an i.i.d. source, and the Y s as side information about the source. Let N = 2 n for n = 1, 2, . . . and deﬁne a sequence of transforms G n : {0, 1} N → {0, 1} N recursively through\nwhere u = (u 1 , u 2 ) and π n is a permutation over the set {0, 1} N , known as the shufﬂe operator. Now if we deﬁne\nthen the entropies H(U i | Y N 1 U i−1 1 ) polarize, that is, they are all close to either 0 or 1 when N is large: Theorem 1 ([1],[2]). For every > 0,\nIt was later shown in [3] and [4] that Theorem 1 also holds if X = {0, . . . , q −1} for some prime q and the addition in (1) is carried out modulo-q.\nThe standard proof of Theorem 1 begins with a martingale argument that shows the existence of the claimed limits. The difﬁcult part is to show the values of these limits, which amounts to proving that almost all entropies created by (1) are close to 0 or 1. Note that in each recursion the transform in (1) creates two entropies\nout of H(X 1 | Y 1 ), where X 1 and Y 1 now are shorthand for U i and (Y N 1 U i−1 1 ), respectively. The following result states that the two entropies above are strictly different if H(X 1 | Y 1 ) is moderate 1 , and thus the only ﬁxed points of this entropy transformation are 0 and 1, yielding the theorem (see the mentioned references for details):\nLemma 1 ([4]). For all prime q and > 0, there exists δ > 0 such that H(X 1 | Y 1 ) ∈ ( , 1 − ) implies\nObserve that the statement of the lemma holds uniformly over all joint distributions on (X 1 , Y 1 ) with arbitrary Y 1 and moderate H(X 1 | Y 1 ). A statement of such generality appears to be necessary for proving polarization, since the distributions of (U i , Y N 1 U i−1 1 ) become arbitrarily complex as the transformation size grows. Unfortunately, Lemma 1 does not hold when q is composite:\nExample 1. Let X 1 be uniformly distributed over X = {0, 1, 2, 3} and let Y 1 ∈ {0, 1} be such that p Y |X (0 | 0) = p Y |X (0 | 2) = p Y |X (1 | 1) = p Y |X (1 | 3) = 1. Then,\nAlso let U 1 = X 1 + X 2 and X 2 = U 2 . Then, the pairs (X 1 , Y 1 ), (U 1 , Y 2 1 ), and (U 2 , Y 2 1 U 1 ) are identically distributed (after appropriate grouping and labelling), and therefore\nThat is, the transformation has no effect on the resulting distributions. Clearly, this also implies that applying the same transform a second time (and further) will have no effect on the distributions or on the entropies.\nThe difﬁculty illustrated in the example above is common to all alphabets X of composite size. It is also not peculiar to the transform (X 1 , X 2 ) → (X 1 + X 2 , X 2 ): Suppose that f is an operation for which the pair (X , f ) is a group, and consider the mapping (X 1 , X 2 ) → (U 1 , U 2 )\nProposition 1. If q is composite, then there exists a > 0 and a distribution on (X 1 , Y 1 ) for which H(X 1 , Y 1 ) ∈ ( , 1 − ) and\nProof: It is known [5, p. 28] that if q is composite, then the group (X , f ) has a proper nontrivial subgroup. That is, there exists a set S \t X with |S| > 1 such that (S, f ) is a group. A pair (X 1 , Y 1 ) where Y 1 is constant and X 1 is uniformly distributed over S satisﬁes (4).\nThe argument above implies that transforms (X 1 , X 2 ) → (f (X 1 , X 2 ), X 2 ) with a group operation f fail to polarize certain i.i.d. processes if applied recursively. On the other hand, it is easy to show that for all (X 1 , Y 1 ) with moderate H(X 1 | Y 1 ), there exists an invertible mapping (X 1 , X 2 ) → (f (X 1 , X 2 ), X 2 ) for which\nTherefore, all discrete i.i.d. processes can be polarized by choosing suitable mappings at each recursion [3]. Alterna- tively, if one is only interested in constructing optimal polar- like channel and source codes for composite alphabet sizes, then one can also view X 1 as a collection of random variables W 1 , . . . , W K with prime alphabet sizes, and polarize the pro- cesses {(W k , (Y 1 W k−1 1 )}, k = 1, . . . , K separately through\nthe transform in (1), obtaining a collection of K polar codes. It is easy to see that optimal rates in channel and source coding can also be achieved by this method.\nOur purpose here is different. We would like to see whether there exist transforms that recursively polarize, as in Theo- rem 1, all i.i.d. processes with a given composite alphabet size. In the proof of Proposition 1 we already saw a difﬁculty in polarizing such processes: When X 1 is uniformly distributed on certain subsets of its alphabet, the transform in (3) is ineffectual, since it also yields random variables that are also conﬁned to the same subset. In what follows we will still restrict our attention to transforms of the form (3), but will choose the mapping f : X 2 → X so as to avoid the described anomaly. In particular, we will call f a polarizing mapping if\n(p.i) for all x 2 ∈ X , the mapping x 1 → f (x 1 , x 2 ) is invertible,\n(p.ii) for all x 1 ∈ X , the mapping x 2 → f (x 1 , x 2 ) is invertible, 2 and\n(p.iii) for all 2 ≤ K ≤ q−1 and distinct a 0 , . . . , a K−1 ∈ X , the matrix\nExample 2. Consider a matrix F with F ij = f (i, j), i, j = 0, . . . q−1. (That is, F is the Cayley table of f .) Then it is easy to see that modulo- 3 addition is polarizing whereas modulo-4 addition is not, since their respective Cayley tables are\n0 1 2 1 2 0 2 0 1\n  \n0 1 2 3 1 2 3 0 2 3 0 1 3 0 1 2\n  \nNote that G 00 = G 22 = 0 and G 02 = G 20 = 2, violating (p.iii). See also Example 1.\nIn the next section, we will show that polarizing mappings deﬁned through (p.i)\u2013(p.iii) above create two strictly different entropies out of a moderate one:\nTheorem 2. For all > 0 there exists δ( ) > 0 such that if (X 1 , Y 1 ), (X 2 , Y 2 ) are i.i.d. random variable pairs with H(X 1 | Y 1 ) ∈ ( , 1 − ), and if f : X 2 → X is a polarizing mapping, then\nTheorem 2 justiﬁes our deﬁnition of a polarizing map- ping, as equation (5) and the invertibility of the mapping (X 1 , X 2 ) → (f (X 1 , X 2 ), X 2 ) sufﬁce to achieve polarization recursively. For this purpose, let us redeﬁne the sequence of transforms G n through\nwhere f is a polarizing mapping and acts on its argument vectors componentwise. Now letting\nthe main polarization result can be proved for arbitrary alpha- bets through the arguments in [4]:\nIt is worth mentioning that conditions (p.i)\u2013(p.iii) are sufﬁ- cient for Theorems 2 and 3 to hold, but may not all be neces- sary: (p.i) guarantees that the one-step mapping (X 1 , X 2 ) → (f (X 1 , X 2 ), X 2 ) is one-to-one, and (p.iii) guarantees that anomalous distributions such as the one in Example 1 are also polarized; it turns out that this is indeed the only type of irregularity that needs handling. Condition (p.ii) is in fact not necessary for polarization to take place, and can be relaxed. We include it only because it helps simplify the proofs. This condition is also not a very restrictive one; there are several simple families of mappings that satisfy (p.i)\u2013(p.iii) for all alphabet sizes. We give one example here:\nProposition 2. The mapping f (x 1 , x 2 ) = x 1 + π(x 2 ), where π : X → X is the permutation\n  \nx − 1 if 1 ≤ x ≤ q/2 x \t otherwise\nWe give a proof of Proposition 2 in Section IV. The Cayley table of f is given below for q = 6.\n      \n3 0 1 2 4 5 4 1 2 3 5 0 5 2 3 4 0 1 0 3 4 5 1 2 1 4 5 0 2 3 2 5 0 1 3 4\n      \nLet us ﬁrst introduce a deﬁnition in order to capture the anomaly described in Example 1: Given a distribution p over X , let a 0 , . . . , a q−1 be any labelling of the elements of X for which p(a 0 ) ≥ p(a 1 ) ≥ . . . ≥ p(a q−1 ). For all ν > 0, let\nRecall that an anomaly may arise for random variables X 1 and X 2 if their probability masses are conﬁned in a subset of their alphabet. This can be stated in general as M p X1 ,ν = M p X2 ,ν\nand K ν ≤ q − 2. The next lemma shows that a polarizing mapping will strictly increase entropy even under such irreg- ularities:\nLemma 2. For all , ν > 0, there exists δ( , ν) > 0 such that if X 1 , X 2 ∈ X are independent random variables with H(X 1 ), H(X 2 ) ∈ ( , 1 − ) and M p X1 ,ν = M p X2 ,ν = M for\nsome M with 1 ≤ |M | ≤ q − 1, and if f is a polarizing mapping, then\nProof: We will prove the claim for i = 2; the claim for i = 1 will follow by the symmetry in the assumptions. It follows from (p.ii) that there exist q distinct permutations π i : X → X , i = 0, . . . , q − 1 such that f (j, i) = π i (j). Observe also that (p.i) implies\nDeﬁning probability distributions r i through r i (u) = p X 2 (π −1 i (u)), we have\n(i) p X 1 (a), p X 1 (b) ≥ η( , ν) for some η( , ν) > 0, and (ii) r a − r b 1 ≥ ν,\nsince the claim will then follow immediately from (8), the strict concavity of entropy, and that H(r i ) = H(X 2 ) for all i.\nFirst consider the case M = {a} for some a ∈ X , and observe that H(X 1 ) > implies p X 1 (a) ≥ p X 1 (b) ≥ η( ) for some b = a and η( ) > 0, satisfying (i). It also follows from (7) that r a (π a (a)) − r b (π a (a)) = p X 1 (a) − p X 1 (c) for some c = a, implying (ii) since the latter difference is at least ν, and therefore yielding the claim.\nSuppose now that 2 ≤ |M | ≤ q − 1. Deﬁne, for all x ∈ X and T ⊂ X , the sets\n∀T ⊂ X , 2 ≤ |T | ≤ q − 1, ∃a, b ∈ T such that S a,T = S b,T . (9)\nNow let a, b ∈ M be such that S a,M = S b,M . It then follows from the deﬁnition of M that there exists x ∈ X for which |r a (x) − r b (x)| ≥ ν, satisfying (ii). That (i) is also satisﬁed can be seen by noting that |M | ≤ q − 1 and a, b ∈ M imply p X 2 (a), p X 2 (b) ≥ ν. This concludes the proof.\nWe are now ready to prove Theorem 2: Let H 1 , H 2 , and H u be [0, 1]-valued random variables with\nH 1 = H(X 1 | Y 1 = y 1 ) H 2 = H(X 2 | Y 2 = y 2 )\nwhenever (Y 1 , Y 2 ) = (y 1 , y 2 ). Clearly, H 1 and H 2 are i.i.d. with\nSuppose ﬁrst that Pr[H 1 ≤ /2], Pr[H 1 ≥ 1 − /2] ≥ /2(2 − ). Then, the event\nhas probability at least /2(2 − ) 2 . Further, as both func- tions x 1 → f (x 1 , x 2 ) and x 2 → f (x 1 , x 2 ) are invertible for all x 2 and x 1 respectively, we have H u ≥ H 1 , H 2 for all (Y 1 , Y 2 ) = (y 1 , y 2 ). Thus,\n= Pr[A] · E[H u | A] + Pr[A c ] · E[H u | A c ] ≥ Pr[A] · E[H 2 | A] + Pr[A c ] · E[H 1 | A c ] ≥ Pr[A] · E[H 1 + 1 − | A]\nNow suppose instead that Pr[H 1 ≤ /2] < 2(2− ) . Then, since\nA similar argument shows that the above inequality also holds when Pr[H 1 ≥ 1 − /2] < 2(2− ) . We will now show that the conditions of Lemma 2 hold with positive probability whenever we have (10): It can be shown that for all > 0, there exists ν( ) > 0 for which H(V ) ≤ 1 − /2 implies |M p V ,ν | ≤ q − 1 (see, for example, [4, Lemma 2]. Given such a ν, let S 1 ⊂ X and S 2 ⊂ X be random sets with\nS ⊂ X with 1 ≤ |S| ≤ q − 1 such that the event B = {y 1 , y 2 : S 1 = S 2 = S}\nhas probability at least [ /2 q (2 − )] 2 . It then follows from Lemma 2 that H u ≥ H 1 + δ( , ν( )) for some δ( , ν( )) > 0 whenever y 1 , y 2 ∈ B. Therefore\nE[H u ] = Pr[B] · E[H u | B] + Pr[B c ] · E[H u | B c ] ≥ Pr[B] · E[H 1 + δ( , ν( )) | B]\nHere we show that for all q = |X |, the function f : X 2 → X , f (x 1 , x 2 ) → x 1 + π(x 2 ) with\n  \n \nx − 1 if 1 ≤ x ≤ q/2 x \t otherwise\nis polarizing. That (p.i) and (p.ii) are satisﬁed readily follows from π being a permutation. It remains to show (p.iii), i.e., that for all 2 ≤ K ≤ q − 1 and a 0 < a 1 < . . . < a K−1 in X , the matrix\nhas at least K + 1 distinct entries. We will consider two cases: K ≥ 3: We will show, by contradiction, that the sets {B i1 }\nand {B i(K−1) } are not identical, which leads to the claim. For this purpose, note ﬁrst that 1 ≤ a 1 < a K−1 . Also, since B i1 = a i + π(a 1 ) and B i(K−1) = a i + π(a K−1 ), it follows that if {B i1 } = {B i(K−1) }, then there exists an L ≤ K and distinct i 1 , . . . , i L ∈ {0, 2, 3 . . . , K − 1} such that\nπ(a K−1 ) − π(a 1 ) = a i 1 − a 1 \t (11) = a i 2 − a i 1\nSince the terms on the right-hand side above sum to 0, we have L[π(a K−1 ) − π(a 0 )] = 0. As a i 1 , . . . , a i L = a 1 , this implies that L divides q, which in turn implies\nWe therefore have 1 ≤ a 1 ≤ q/2 < a K−1 . It then follows from (11) that a i 1 − a 1 = a K−1 − a 1 + 1, i.e., a i 1 = a K−1 + 1, a contradiction.\nK = 2: Suppose, contrary to the claim, that {B 00 , B 10 } = {B 01 , B 11 }. This implies B 01 = B 10 , i.e.,\na 1 − a 0 = π(a 0 ) − π(a 1 ). \t (13) A similar reasoning to the one for the case K ≥ 3 also yields (12). Since K = 2, it follows that a 1 − a 0 = q/2 . On the other hand, it follows from the deﬁnition of π that\na 1 − a 0 = q/2 \t implies π(a 0 ) − π(a 1 ) = q/2 , contradicting (13). This completes the proof.\nWe have seen that all discrete memoryless channels and sources can be polarized by recursive transforms. The trans- forms described here depend only on the alphabet size of the underlying process, and are independent of the probability structure. In this sense, they retain the universality of Arıkan\u2019s binary transform. This universality also extends beyond mem- oryless processes. It can be shown through similar arguments in [6, Chapter 5] that such transforms also polarize a large class of processes with memory.\nCodes based on the transforms described here will also retain the low encoding and decoding complexity of binary polar codes, due to their recursive structure. Their asymptotic error probability behavior is also similar to that of binary polar codes:\nTheorem 4 ([6, Chapter 3]). the block error probability P e of polar channel (respectively, source) codes based on (6) satisﬁes\nfor all β < 1/2 and sufﬁciently large blocklength N , provided that the code rate is below the capacity of the channel (respectively, above the entropy of the source).\nWe know from from previous results that Theorem 4 also gives the asymptotic performance of the multi-layered coding method in [3] (described here after Proposition 1). It is of interest to analyze and compare the performance of multi- layered coding with that of \u2018direct polarization\u2019 coding at ﬁnite blocklengths. We leave this for future study."},"refs":[{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Channel polarization: A method for constructing capacity- achieving codes for symmetric binary-input memoryless channels"}},{"authors":[{"name":"E. Arıkan"}],"title":{"text":"Source polarization"}},{"authors":[{"name":"E. S¸as¸o˘glu"},{"name":"E. Telatar"},{"name":"E. Arıkan"}],"title":{"text":"Polarization for arbitrary discrete memoryless channels"}},{"authors":[{"name":"E. S¸as¸o˘glu"}],"title":{"text":"An entropy inequality for q-ary random variables and its application to channel polarization"}},{"authors":[{"name":"A. Clar"}],"title":{"text":"Elements of Abstract Algebra"}},{"authors":[{"name":"E. S¸as¸o˘gl"},{"name":"D. Disser- tatio"}],"title":{"text":"Polar Coding Theorems for Discrete Systems"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566581.pdf"},"links":[{"id":"1569565883","weight":14},{"id":"1569566871","weight":14},{"id":"1569566207","weight":28},{"id":"1569563307","weight":42},{"id":"1569553909","weight":14},{"id":"1569559111","weight":42},{"id":"1569567051","weight":14},{"id":"1569554759","weight":14},{"id":"1569562207","weight":28},{"id":"1569566655","weight":14},{"id":"1569560503","weight":14},{"id":"1569566293","weight":42},{"id":"1569565765","weight":14},{"id":"1569565215","weight":14},{"id":"1569566737","weight":42},{"id":"1569564305","weight":28},{"id":"1569566713","weight":14},{"id":"1569566847","weight":14},{"id":"1569565143","weight":28},{"id":"1569566067","weight":14},{"id":"1569566825","weight":14},{"id":"1569566727","weight":28}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S12.T5.2","endtime":"12:10","authors":"Eren Şaşoğlu","date":"1341489000000","papertitle":"Polar codes for discrete alphabets","starttime":"11:50","session":"S12.T5: Polar Codes over Non-Binary Alphabets","room":"Kresge Little Theatre (035)","paperid":"1569566581"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
