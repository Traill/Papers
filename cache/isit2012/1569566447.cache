{"id":"1569566447","paper":{"title":{"text":"Achievable Gains in Peak Power Reduction via Single-Carrier Distribution Shaping"},"authors":[{"name":"Stella Achtenberg"},{"name":"Dani Raphaeli"}],"abstr":{"text":"Abstract\u2014This paper presents a method to ﬁnd a lower bound on the peak power reduction of single carrier signals having low rolloff pulse shaping ﬁlter, and transmitted over the Additive White Gaussian Noise channel (AWGN). Peak power as well as any other property can be controlled by judiciously choosing a codebook, such that the peak power of any of the codewords does not exceed a threshold (or exceeds in a low probability). One of the methods to generate such codebook, called shaping, is to start with a larger codebook with i.i.d. uniform distribution and choose a subcode which optimizes the property. This approach includes the popular method of Trellis Shaping. We analyze the limit of the gains obtainable by the shaping method by using the conditional limit theorem under Markov conditioning, and by that we can show achievable peak reduction bounds. We analyze two types of receivers. The ﬁrst is a receiver that is matched to the subcode, i.e., it is aware of the dilution made at the transmitter, and the second is a mismatched decoder, a decoder for the original large codebook, like in the case of Trellis Shaping. We show that signiﬁcant peak and Peak to Average (PAR) gains, as large as 1.7 dB, are achievable, even for small constellations such as 16QAM and 16APSK transmission constellations for Square Root Raised Cosine ﬁlter (SRRC) with rolloff 0.1."},"body":{"text":"We study theoretical bounds of average power reduction and peak reduction of single carrier ﬁnite constellations on AWGN channel. In many practical communication systems, such as mobile terminals, economical utilization of energy is necessary and much effort is invested in achieving this goal. In addition, narrow pulse shaping ﬁlters are used to control bandwidth, and the resulting high Peak to Average ratio (PAR) is of interest since it dictates the backoff of the Power Ampliﬁer (PA). Backoff reduction in turn increases PA efﬁciency which is beneﬁcial in power constrained systems.\nMany methods have been devised over the years for av- erage power reduction and similar methods can be used for peak power reduction. One of these methods is to choose codewords which satisfy a criterion from a larger uniformly distributed codebook. The chosen subcode consists of nontyp- ical codewords in the larger codebook and therefore peak and average power shaping is possible. Let the large codebook have 2 n (R s +R) codewords and is divided into 2 nR random sets of a shaping code of size 2 nRs , where R and R s are the information rate and shaping rate, respectively, and n is the codeword length. The decoder, to save complexity, is usually the decoder for the original large code followed\nby a reduction of the shaping code. In order to implement a matched decoder, i.e., a decoder which is aware of the subcode and its distribution, the decoder may have to repeat the selection process for each tested codeword, leading to high complexity decoding.\nSeveral practical shaping methods use this approach. Forney [3] introduces the Trellis Shaping (TS) technique for average power reduction. In his scheme, the large code is the composite code formed by joining the shaping code with the channel code. Then, given the coded bits, the free shaping bits creates a set of sequences, i.e., a coset of the large code, from which one sequence is chosen such that the transmitted codeword has minimal power in the coset. This is an example of the general method presented above. For 256QAM constellation, Forney achieves about 1dB shaping gain. Similar procedures exist in the compound LDPC-LDGM scheme [4] where given an information word the compound code creates a coset to choose the shaped codeword from. The PAR reduction was also treated using the TS framework. In [2], the authors propose TS concatenated with Turbo code for PAR reduction. In [5], PAR reduction of high order QAM signals is the prime target.\nWhile few papers show practical results on PAR reduction using TS, an analysis of the available gains is still missing. In this paper we present two important observations and a method to make this analysis possible. First, we have found that the distribution of the nontypical codewords, which are chosen to satisfy a peak power constraint, can be obtained using the conditional limit theorem under Markov conditioning [1]. The knowledge of this distribution is necessary to approximate the mutual information of this codebook on the AWGN channel. Secondly, we claim that the mutual information of the nontypical subcode at the large code SNR (the SNR which can carry R+R s bits per symbol with the uniform i.i.d. distributed codebook) less the average energy reduction, is sometimes lower that the transmitted rate R, and therefore the decoding of the subcode using the large code decoder is not error free. In other cases, this mutual information may be higher than R, and in this case we can gain SNR by using a matched decoder. In this latter case, the achievable peak and shaping gains are much higher. Our analysis includes both the matched and the mismatched decoder performance bounds.\nresult of using pulse shaping ﬁlter with low rolloff. Our goal in this work is to reduce peak power, but without compromising average power. In the rest of this paper we will call the reduction of peak power as peak gain and the reduction of average energy as shaping gain, both while maintaining a speciﬁed error free data rate over the channel.\nOur analysis shows that for 16QAM constellation with information rate R = 3, and raised cosine pulse shape with rolloff 0.1, the achievable peak gain is 1.7dB with the matched decoder and 1.45dB with the mismatched decoder at R s = 0.2. We conclude that for power constrained systems, where we do not allow the average power to exceed the average power of the reference system, low R s should be used with the matched decoder. At this working point, the shaping gain is positive, as required. In other systems, where small gain degradation is possible, the mismatched decoder may be considered to save complexity.\nLet U be a two dimensional (2D) constellation with car- dinality |U| = M . Let u = (u 0 , · · · , u n −1 ), where u i ∈ U be a frame of symbols of length n transmitted over the AWGN channel. The transmission sequence u is passed through a Square Root Raise Cosine (SRRC) pulse shape ﬁlter h (t) and ampliﬁed using an ideal power ampliﬁer. The complex continuous time baseband signal x (t), representing the RF signal at the output of the power ampliﬁer is x (t) = α n −1 i =0 u l h (t − lT ) where α represents the gain of the power ampliﬁer, and T is the symbol duration. At the receiver, x (t) is processed by a matched ﬁlter. Let y = (y 0 , · · · , y n −1 ) be a frame of received signals at the output of the matched ﬁlter. Due to the zero ISI property of the RRC, y i = αu i +N i where N i ∼ CN (0, 1) are i.i.d. complex Gaussian noise samples, normalized to unit variance.\nWe are now interested in the peak power of the transmitted signal. Let x(t) be approximated by a sampled signal x j i = x( jT J + iT ), j = 0, · · · , J − 1 where J is the over-sampling ratio. It is easy to show that x j i = α K −1 k =0 u i −k h j k , where h j k = h( jT J + kT ) are samples of the pulse shape ﬁlter h (t) at sampling times jT J + kT , where K is the ﬁlter length. The power of the sample x j i is p j i = x j i 2 . We deﬁne the power during the period (iT, (i + 1)T ] as the maximal sample power p i = max j p j i .\nLet us deﬁne channel transmission state s i by K − 1 consequent symbols s i = (u i , · · · , u i +K−2 ), with state space U K −2 , V as the set of all valid consequent states and the entire transmission state sequence by s. The power p i can be expressed by two consequent channel states (s i , s i +1 ) ∈ V, such that p i = α 2 f (s i , s i +1 ), i = 0, · · · , n − 1, ignoring edge effects. The set of all possible peak power values (before the power ampliﬁer) is denoted by P such that p i ∈ α 2 P, where each value in P is deﬁned by its origin (s i , s i +1 ) pair and equal values are considered distinct points.\nLet capital letters denote random variables and vectors and small letters their realizations. Let U be a transmission sequence, S be the transmission state sequence, P U , P S be the distribution of U and S respectively, and Y be the random vector at the receiver. It is easy to see that P U (u) = P S (s) and that H (U ) = H (S) where H (Z) = lim n →∞ 1 n H (Z 0 , · · · , Z n −1 ) deﬁnes the entropy rate of a random vector Z. The mutual information between U and Y is I (U ; Y |α) = H (S) − H (U |Y , α).\nLet us now assume a general constrained transmission, where later in this paper we consider the special case of peak power and average power constraints. Let\n1 n\nbe a set of constraints where ϕ l (·), l = 0, · · · , L − 1 are a set of constraint functions, α is the transmitter gain (parameter) and (s i , s i +1 ) are the transmission states as deﬁned in Section 2. We denote the set of all pairs (α, P U ), which satisfy the constraints in (1), as A. An important question to ask is which member of A maximizes the mutual information R A = max A I (U ; Y |α), i.e., which is the maximal reliable transmission rate under these constraints. The direct maximiza- tion of the mutual information over A has known numeric solutions in special cases only. For example, in the average power constraint case, the optimal distribution is i.i.d., and thus, the optimal solution can be obtained using the modiﬁed Arimoto-Blahut algorithm [7].\nWe consider a different, suboptimal approach, which can be applied to any general constraints of the form (1) and stationary K − 1 order Markov chain solutions P U . It is easy to verify that the state sequence distribution P S is a ﬁrst order stationary Markov chain with two dimensional distribution P , and transition matrix probability P (s i +1 |s i ) = P (s i , s i +1 ) /P (s i ). Instead of maximizing the mutual in- formation we will maximize the entropy rate subject to the constraints. The entropy rate, in the case of stationary Markov chain, depends only on consequent state variables [8], i.e., H (S) = H (S K −1 |S K −2 ) = H (P ) where H (P ) =\nP (s i , s i +1 ) log 2 P (s i +1 |s i ). The optimization pro- cess is to maximize the mutual information within the entropy rate maximizing distributions set. More precisely, for each α we ﬁnd the distribution P ⋆ (α), which maximizes H (S) under the constraints. Then, the maximization is conducted over α, i.e., R H = max α I (U ; Y |α) ≤ R A is a lower bound of the maximal achievable rate subject to the constraints. Next, we will show how to obtain the distributions set P ⋆ (α) by using the conditional limit theorem under the Markov conditioning [1].\nWe like to brieﬂy review the theory of conditional limit theorem, generalized for Markov chains [1] which we are\nintending to use for maximizing the entropy rate under a set of constraints (1). We present the theorem with respect to our constraints. Let W (· | ·) be a transition probability matrix of a ﬁrst order stationary Markov chain with state space W. We deﬁne the set of all possible transitions as S (W ) = {(s i , s i +1 ) : W (s i +1 |s i ) > 0}, where the possible distribu- tions W are restricted to S (W ) ⊂ V, i.e., if (s i , s i +1 ) / ∈ V (not valid consequent states) then W (s i +1 |s i ) = 0.\nLet s = (S 0 = s 0 , · · · , S n −1 = s n −1 ) be a state sequence realization drawn from probability W and let us deﬁne a two dimensional empirical distribution by the relative frequencies P (2) s (w j ) = 1 n |i ∈ {1, · · · , n − 1} : (s i , s i +1 ) = w j |, ∀w j ∈ S (W ). Let Π be a set of distributions which satisfy a set of constraints in (1), i.e.,\n \n \n(2) with l = 0, ..., L − 1 and let Π 0 be a subset of Π such that the two marginals of P are equal. Let D(P W ) be the Kullback-Leibler information divergence\nrestricted to {P : S (P ) ⊂ S (W )}. Deﬁnition 2 in [1] deﬁnes Markov I-projection of the transmission probability matrix W on Π 0 as a unique P ⋆ ∈ Π 0 such that D(P ⋆ W ) = min P ∈Π 0 D(P W ) < ∞. For the special case, where W = W u (s i +1 |s i ) = \t 1/M (s i , s i +1 ) ∈ V 0 \t else \t , it can be also shown that Markov I-projection P ⋆ maximizes the entropy rate H(P ).\nTheorem 4 in [1] states that if P ⋆ exists, and if the empirical distribution P (2) s of the realization s belongs to Π; then in the limit of n → ∞, Pr(s) = P ⋆ (s 0 ) n −1 i =1 P ⋆ (s i | s i −1 ). Furthermore, if P ⋆ exists, then the probability that the empirical distribution P (2) s of s belongs to Π is lim n →∞ 1 n log 2 Pr P (2) s ∈ Π = −D(P ⋆ W ) and for very large n is approximated by Pr P (2) s ∈ Π = 2 −nD(P ⋆ W ) .\nAs stated, the Markov I-projection P ⋆ maximizes the entropy under a set of constraints when using W u . We next show how to ﬁnd the Markov I-projection following [1]. Let E be an irreducible subset of W 2 such that E ⊂ S (W u ). Let λ ζ , u ζ and v ζ be the largest eigenvalue, the normalized left and right eigenvectors of the matrix Q ζ respectively, where ζ = (ζ 0 , ..., ζ L −1 ), an arbitrary set of positive variables, and the entry of Q ζ is\nfor (s i , s i +1 ) ∈ E and zero otherwise. The Markov I- projection is obtained by\nλ ˆ ζ \t (5) where\nIn previous sections we have established the set of dis- tributions which maximize the entropy rate of U , one for each ampliﬁer gain α, namely P ⋆ (α) as deﬁned by (5). Using the procedure that will be described in Section 7 we ﬁnd the solution of R = R H = max α I (U ; Y |α). Next, a codebook should be constructed according to the maximizing distribution. In this paper, we use random coding to generate our codebook.\nThe ﬁrst method to create a random codebook, is to directly generate 2 nR codewords from a desired distribution P ⋆ (α), and then amplify the transmitted signal by the corresponding α. Alternatively, we can generate a large codebook from an i.i.d. uniform distribution on U and then choose from it only those codewords which satisfy our constraints set. Such a method is called \u201cshaping\u201d might be more appealing due to its simplicity. In real life situations, good codes for uniform dis- tribution are readily available, and codeword selection might be a simple procedure for a properly structured code, for example using trellis shaping [2], [3], [5]. The conditional limit theorem has shown that those codewords have the distribution of the Markov I-projection when n → ∞. Furthermore, it is easy to verify that an i.i.d. uniform distribution on U is equivalent to W u and thus the Markov I-projection maximizes the entropy rate as we shown. More formally, let C be a random codebook with i.i.d. uniform distribution on U and 2 n (R+R s ) codewords, where R is the information rate to be transmitted and R s is an additional constant, called shaping rate. This codebook, which we refer to as the large codebook, is divided into 2 nR random sets with 2 nR s codewords in each set. A message m to be transmitted determines the random set. Out of this random set a single codeword to be transmitted is selected such that it satisﬁes the constraints in (1). The design parameter R s is chosen such that each set contains at least one codeword which satisﬁes the constraints under the obvious restriction R s + R ≤ log 2 M . According to Theorem 4 in [1] the probability that a codeword satisﬁes the constraints is P s = 2 −nD(P ⋆ (α) W u ) . It can be shown that R s = D(P ⋆ (α) W u ) + ǫ, where ǫ > 1/n insures that at least one codeword within a random set satisﬁes the constraints. The outcome of this process is a subcode C s with 2 nR codewords which can reliably transmit R information bits per symbol, when ampliﬁed by α.\nWe consider two types of decoders. The ﬁrst, called matched decoder, is a decoder that is aware of the distribution P U\nas well as the codebook set C s and is performing optimal decoding. The matched decoder performance is given by the the mutual information. The second decoder that we will consider, will be called mismatched decoder, and it is a decoder that is only aware of the large code C and perform optimal decoding as if all codewords of C might have been transmitted. This decoder is suboptimal, but occasionally more practical than the matched decoder, since the decoder for the large uniform code is readily available, and adaptation to the set C s might be extremely complex. Unfortunately we cannot provide an accurate performance bounds for the mismatched decoder. The only performance estimation that we can provide is ﬁnding the working point of the mismatched decoder according to the noise level where large code error probability tend to zero. If all codewords in code C had have same error probability when transmitted, then this estimate would have been accurate. This is correct for codes (bad codes) which their error performance is determined by the minimum distance. However, for a general code, not all codewords have same error performance and thus the codewords from the set C s might have either higher or lower error performance compared to the average codeword of C.\nWe proceed our analysis by using peak and average power reduction constraints as the Markov constraints in (1). Let us\nwhere β 0 is a threshold to the maximal peak power after the ampliﬁer and ǫ > 0 is a sufﬁciently small number, such that no sequence with peak power above β 0 satisﬁes the constraint. Let us also deﬁne an average power function ϕ 1 (α, s i , s i +1 ) =\n|u k | 2 with average power constraint β 1 . At this point, we change the problem formulation from maximizing the rate given a constraint β = (β 0 , β 1 ) to ﬁnding the set of all possible β constraints such that the rate is R. For that purpose, let us deﬁne equivalent functions to ϕ 0 and ϕ 1 as\n|u k | 2 where ˜ p i = p i /α 2 = f (s i , s i +1 ) is the normalized power and ˜ β = β/α 2 is the maximal peak power and average power, both measured before ampliﬁcation. Let ˜ B ⊂ P be the set of equivalent constraints ˜ β for which the Markov I-projection P ⋆ ˜ β exists. The mutual information I (U ; Y |α) is strictly monotonic in α for a given distribution P ⋆ ˜ β , therefore a unique α satisﬁes R = I (U ; Y |α). We ﬁnd the corresponding α to each equivalent constraint in ˜ B and this deﬁnes the set β ∈ B of all possible constraints for which the rate R is achievable. The knowledge of B allows us to choose the tradeoff between β 0 and β 1 . Next we ﬁnd P ⋆ ˜ β for each ˜ β ∈ ˜ B using (4)-(6). For (s i , s i +1 ) ∈ E, ζ 0 > 0 and ǫ → 0, the entry\nfor f (s i , s i +1 ) < ˜ β 0 and Q ζ (s i , s i +1 ) = 0 otherwise, due to lim ǫ →0 exp − ζ 0 ǫ − ζ 1 ˜ ϕ 1 (s i , s i +1 ) = 0. The entry Q ζ 1 (s i , s i +1 ) = exp (−ζ 1 ˜ ϕ 1 (s i , s i +1 )) for f (s i , s i +1 ) < ˜ β 0 and zero otherwise. We use the property that the eigenvalues of matrices A, B such that A = bB, satisfy λ (A) = bλ (B), to show that λ ζ = 1 M exp(−ζ 0 ) M K −1 λ (Q ζ 1 ). The optimiza- tion ˆ ζ = arg min ζ 0 ,ζ 1 ≥0 ζ 0 + ζ 1 − ζ 0 M K −1 + log λ ζ 1\ncan be conducted separately for ζ 0 and ζ 1 where the minimal ζ 0 → 0 and ˆ ζ 1 = arg min ζ 1 ≥0 (ζ 1 + log λ ζ 1 ). Two special cases exist. The ﬁrst is using only the peak power constraint, in this case ζ 1 = 0. The second case is using only the average power constraint, for which the solution is i.i.d. and the maximizing entropy rate distribution is the well known Maxwell-Boltzmann distribution [8]. In order to choose a working point in B, we deﬁne a reference system which transmits i.i.d. symbols from a 2D constellation U ref , with uniform distribution on U ref . The reference system transmits reliably the rate R. The average power of the reference system is β 1,ref . The shaping gain in deﬁned as γ s = [β 1,ref /β 1 ] dB .\nIn a similar manner, the peak power gain is deﬁned as γ p = [β 0,ref /β 0 ] dB . The peak power and the shaping gains are calculated for each β ∈ B. This allows us to choose the preferable working point with respect to the reference system. Another interesting parameter is the PAR, that can be calculated using P AR = γ p − γ s . The PAR is mostly important for determining the dynamic range of the transmitter. Maximizing the peak gain while not compromising the shaping gain, obviously reduces also the PAR.\nFinally we are resorting to ﬁnding a unique α which satisﬁes R = I (U ; Y |α) for a given distribution P U . It is difﬁcult to calculate the mutual information of correlated sources over the AWGN. For that reason, we use a Monte Carlo approximation [5]. For very long sequences the mutual information is approximated by\nwhere ˜ u is a long sequence sampled from the Markov I- projection P ⋆ , N is n noise samples from CN (0, 1) and ˜ y = α˜ u +N . The numerical computation of log 2 p(˜ y ) is made using p(˜ y ) = ˜ s p(˜ y , ˜ s ) by forward sum-product recursion of the BCJR algorithm, where ˜ s corresponds to ˜ u. Once the block length is long enough, this approximation becomes very accurate. Due to the monotonicity of I (U ; Y |α) in α (for a given distribution), efﬁcient search methods are used to obtain the correct α.\nFor simulations, we consider 16QAM and 16APSK con- stellations single carrier with root raised cosine ﬁlter with rolloff 0.1. For reducing complexity we truncate the pulse shape to 4 symbols window. We use oversampling J = 8. Fig. 1 presents the peak gain (PG) and shaping gain (SG) results obtained by the Markov I-projection, each corresponding to unique constraint ˜ β 0 ∈ P and shaping rate R s , for 16QAM using uniform 16APSK as reference scheme. The data rate is R = 3. The results are shown for the matched (M) and mismatched (MM) decoders. We can observe two distinct R s regions, with local maxima at each. The low R s region is\npreferable due to higher peak power gain and positive shaping gain. Furthermore, we clearly see that the matched decoder outperforms the mismatched in both peak and shaping gain, but the loss of the mismatched decoder is only signiﬁcant in high R s . The maximal peak gain using the matched decoder is 1.7dB and 1.45dB when using the mismatched at R s = 0.2. The 16APSK simulation (not given here) shows maximal peak gain of 1.9dB at R s = 0.26 for the matched and 1.6dB for the mismatched, with negative shaping gain in both cases.\nFig. 2 presents the CCDF function deﬁned by CCDF (x) = 1 − a ≤x P (a) of two different shaping rates for 16QAM versus PAR. We observe that the CCDF, which corresponds to the higher rate, has the lower maximal PAR (2.2 dB), which is a direct result of the shaping loss. This kind of PAR reduction is less preferable, but can be used in systems where the average power is not the prime concern. The lower rate CCDF has higher maximal PAR (2.4dB), however we can observe that more probability is concentrated at the lower PAR values, as opposed to the smoother CCDF of the higher rate.\nFig. 3 presents the results for the two dimensional optimiza- tion (β 0 , β 1 ) for 16QAM versus uniform 16QAM and pulse shape of two samples. The different curves represent different peak thresholds ˜ β 0 while changing ˜ β 1 . Each curve starts with no average power constraint ( ζ 2 = 0), and proceeds such that the average power ˜ β 1 decreases. We can see that the average power constraint increases the shaping gain but also decreases the peak gain, at some point it becomes not worthwhile since both peak and shaping gains decrease. Nevertheless, the two dimensional search allows more working points with better peak gain-shaping gain tradeoff. This can be observed by the curve corresponding to R s = 0.17, in which for peak gain between 1.1dB and 0.3dB, it present the maximal shaping gain compared to the other curves for the same peak power gain."},"refs":[{"authors":[{"name":"I. Csiszár"},{"name":"T. M. Cover"},{"name":"B. S. Choi"}],"title":{"text":"Conditional limit theorems under Markov conditioning"}},{"authors":[{"name":"M. Tanahashi"},{"name":"H. Ochiai"}],"title":{"text":"Turbo decoding of concatenated channel coding and trellis shaping for peak power controlled single-carrier systems"}},{"authors":[{"name":"G. D. Forney"}],"title":{"text":"Trellis shaping"}},{"authors":[{"name":"Q. Wang"},{"name":"C. He"}],"title":{"text":"Practical dirty paper coding with nested binary LDGM-LDPC codes"}},{"authors":[{"name":"M. Arnold"},{"name":"A. Loeliger"},{"name":"O. Vontobel"},{"name":"A. Kavˇci`c"},{"name":"W. Zeng"}],"title":{"text":"Simulation-Based Computation of Information Rates for Channels With Memory"}},{"authors":[{"name":"M. Tanahashi"},{"name":"H. Ochiai"}],"title":{"text":"Trellis Shaping for Controlling Envelope of Single-Carrier High-Order QAM Signals"}},{"authors":[{"name":"N. Varnica"},{"name":"X. Ma"},{"name":"A. Kavcic"}],"title":{"text":"Capacity of power con- strained memoryless AWGN channels with ﬁxed input con- stellations"}},{"authors":[{"name":"T. Cover"},{"name":"J. Thomas"}],"title":{"text":"Elements of Information Theory"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566447.pdf"},"links":[{"id":"1569566381","weight":5},{"id":"1569566485","weight":5},{"id":"1569566725","weight":5},{"id":"1569565691","weight":5},{"id":"1569566697","weight":5},{"id":"1569564805","weight":5},{"id":"1569566081","weight":5},{"id":"1569565355","weight":5},{"id":"1569566765","weight":5},{"id":"1569564897","weight":5},{"id":"1569564245","weight":5},{"id":"1569566303","weight":10},{"id":"1569563411","weight":5},{"id":"1569560427","weight":5},{"id":"1569566739","weight":5},{"id":"1569564203","weight":5},{"id":"1569566579","weight":5},{"id":"1569558483","weight":5},{"id":"1569565347","weight":5},{"id":"1569565455","weight":5},{"id":"1569566709","weight":5},{"id":"1569551763","weight":5},{"id":"1569565953","weight":5},{"id":"1569566749","weight":15},{"id":"1569564189","weight":5},{"id":"1569566865","weight":5},{"id":"1569563981","weight":5},{"id":"1569566643","weight":10},{"id":"1569565841","weight":5},{"id":"1569565257","weight":5},{"id":"1569559111","weight":5},{"id":"1569566939","weight":5},{"id":"1569553519","weight":5},{"id":"1569566231","weight":5},{"id":"1569566425","weight":10},{"id":"1569558985","weight":5},{"id":"1569566809","weight":10},{"id":"1569566257","weight":5},{"id":"1569565033","weight":5},{"id":"1569565887","weight":5},{"id":"1569566721","weight":5},{"id":"1569565633","weight":5},{"id":"1569566003","weight":5},{"id":"1569556671","weight":5},{"id":"1569565469","weight":15},{"id":"1569565029","weight":5},{"id":"1569565311","weight":5},{"id":"1569566501","weight":5},{"id":"1569565439","weight":5},{"id":"1569563395","weight":5},{"id":"1569565415","weight":10},{"id":"1569559199","weight":5},{"id":"1569565665","weight":5},{"id":"1569565397","weight":5},{"id":"1569566873","weight":5},{"id":"1569566129","weight":5},{"id":"1569565385","weight":5},{"id":"1569565241","weight":5},{"id":"1569565661","weight":10},{"id":"1569561221","weight":5},{"id":"1569566035","weight":5},{"id":"1569566547","weight":5},{"id":"1569566237","weight":5},{"id":"1569566283","weight":5},{"id":"1569565375","weight":5},{"id":"1569565597","weight":5},{"id":"1569566641","weight":5},{"id":"1569556759","weight":5},{"id":"1569561185","weight":5},{"id":"1569566817","weight":5},{"id":"1569566299","weight":5},{"id":"1569564769","weight":5},{"id":"1569565769","weight":10},{"id":"1569557851","weight":10},{"id":"1569565861","weight":5},{"id":"1569566147","weight":5},{"id":"1569565537","weight":5},{"id":"1569566457","weight":5},{"id":"1569559251","weight":5},{"id":"1569566583","weight":5},{"id":"1569566273","weight":5},{"id":"1569565635","weight":5},{"id":"1569564931","weight":10},{"id":"1569566973","weight":10},{"id":"1569551751","weight":10},{"id":"1569564419","weight":5},{"id":"1569564807","weight":5},{"id":"1569566113","weight":5}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T7.4","endtime":"18:00","authors":"Stella Achtenberg, Dan Raphaeli","date":"1341337200000","papertitle":"Achievable Gains in Peak Power Reduction via Single-Carrier Distribution Shaping","starttime":"17:40","session":"S8.T7: Communication Theory","room":"Stratton (407)","paperid":"1569566447"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
