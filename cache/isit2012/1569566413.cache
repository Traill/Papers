{"id":"1569566413","paper":{"title":{"text":"Optimality of Linear Codes over PAM for the Modulo-Additive Gaussian Channel"},"authors":[{"name":"Ayal Hitron"},{"name":"Uri Erez ∗"}],"abstr":{"text":"Abstract\u2014It has long been known that linear codes achieve the capacity of additive channels over ﬁnite ﬁelds. Much less has been known about the performance of linear codes over Z M , when used for communication over channels that are additive with respect to this group. Further, linear codes over Z M play an important role in construction of lattices in Euclidean space. When a construction-A lattice is used for communication over an additive white Gaussian noise channel, a modulo- M Z additive channel with unimodal noise is induced at the receiver. In this paper it is shown that linear codes over Z M achieve the capacity of such channels when the cardinality of the alphabet is a power of a prime."},"body":{"text":"It is well known that binary linear codes allow to reach the capacity of binary-input output-symmetric channels. More- over, the average error probability over an ensemble of random linear codes tends to 0 as the block length goes to inﬁnity, for every rate 0 < R < C, where C is the channel\u2019s capacity. See, e.g., [1]. As an extension to this result, it was shown by Dobrushin [2] that linear codes over any ﬁnite ﬁeld GF (p m ) achieve the capacity of any symmetric channel with input and output alphabets X = Y = GF (p m ). More results on the performance of algebraic codes were derived by Ahlswede and Gemma [3], [4].\nIn recent works, Como and Fagnani [5], [6] studied the capacity of Abelian group codes over symmetric channels. In their work they obtained an expression for the capacity of such codes, which involves some optimization problem, and derived an explicit expression for the capacity in the case where the group is Z M , M being a power of a prime. As a special case, they showed that the ensemble of linear codes over Z M , M being a power of a prime, achieves the capacity of any additive isotropic decreasing noise (AIDN) channel (see [5], [6] for details), where the input symbols are restricted to a PSK constellation, i.e., the M input symbols are equally-spaced along a circle around the origin. As an important example, they show that the family of AIDN channels includes the (complex) Additive White Gaussian Noise (AWGN) channel.\na modulo-additive Gaussian channel, Y = X ⊕ Z\nwhere by ⊕ we denote addition modulo M, namely, the output lies in the quotient group R /(M Z), which is identiﬁed with the interval [0, M ) with addition modulo M . The input is assumed to belong to an M -PAM constellation, i.e., the input alphabet is discrete and equally-spaced,\nThis reﬂects the fact that the input to the physical channel should be centered around the origin. The signal-to-noise ratio (SNR) is deﬁned as SNR P σ 2 .\nIt is well known that in the high SNR regime, the effect of the modulo operation becomes negligible, and the mod- M AWGN channel has approximately the same mutual in- formation as the uniform-input AWGN channel (without the modulo). For large enough alphabet size, the gap between this mutual information and the capacity of the AWGN is upper- bounded by 1 2 log 2πe 12 . Thus, a uniform distribution over a PAM constellation achieves, for a large enough alphabet size M , the full degrees of freedom of the channel, i.e.,\nis the capacity of the AWGN channel with only a power con- straint imposed on the input (i.e., the input is not constrained to belong to any constellation, but only its power is limited), and C PAM (SNR) is the capacity of a dense PAM constellation, namely,\nwith C PAM,M (SNR) being the capacity of an M -PAM con- stellation. In other words, C PAM is the mutual information\nbetween X and X + Z when X is distributed uniformly on [− √ 3SNR, √ 3SNR] and Z ∼ N(0, 1).\nThe PSK constellation on the other hand, while achieving rates close to capacity for low SNR, is essentially a one- dimensional constellation embedded in two-dimensional signal space, and therefore it can only achieve half of the degrees of freedom of the channel,\nwhere, C PSK (SNR) is the capacity of a dense PSK constella- tion, i.e., the input signal is restricted to lie on a circle around the origin. For details see, e.g., [7], [8].\nThe above observations are demonstrated in Figure 1, which depicts the capacities of QAM and modulo-additive QAM versus PSK constellations as a function of the SNR. It can be seen that PSK is nearly optimal at low rates (which correspond to low SNR), but as the SNR grows it becomes inferior to QAM and to modulo-additive QAM. 1\nFurther motivation to study the channel (1) is its connection to lattice codes. Recently there has been a growing interest in the use of lattices for various multi-user Gaussian network communication problems. See, e.g., [9] and references therein. Various methods have been proposed for constructing lattices suitable for such applications. Since much is known about linear codes over ﬁnite ﬁelds, work has been done in order to leverage such codes for building lattices; see, e.g., [10].\nA practical and simple method to obtain lattices for com- munication is via Construction A. In this method, an n- dimensional lattice is deﬁned by Λ = C + M Z n , where C is a linear code over Z M .\nWhen an (unrestricted) lattice obtained by Construction A is used for communication over an AWGN channel, maximum-\nlikelihood decoding can be performed in two steps: ﬁrst, decoding the codeword c ∈ C obtained by reducing the output modulo M Z n , and then applying a symbol-by-symbol slicer of step size M . Thus, the performance of the resulting communication scheme will depend on the performance of the linear code C over an effective modulo-additive noise channel, as given in (1). Furthermore, if a low error ﬂoor (due to the uncoded slicer operation) is desired, the cardinality of the linear code M must be increased. However, unless M is a prime, it has not been known whether capacity can be achieved using linear codes over Z M for modulo-additive noise channels.\nIn the present work, we derive an explicit upper bound on the error probability of linear codes over Z M for modulo- additive noise channels,\nThe channel input X is taken from an M -PAM constellation (2), and Z is some random variable with probability density function f Z , statistically independent of X.\nIt is important to note that even for such channels, whose capacity is achieved by a uniform input distribution, it is not guaranteed that the capacity can be achieved using linear codes over Z M . As an example, consider the following noise distribution with M = 4,\nThe capacity of this channel is 0.25 [bits/chan. use]. However, [6, Example 9] shows that a sequence of linear codes that achieves vanishing error probability over this channel must satisfy\nIn this paper we show that if M is a power or prime, then there exist linear codes over Z M that achieve the capacity of any unimodal modulo-additive channel, where Z is either discrete or continuous.\nDeﬁnition 1: A continuous probability density function f Z (z), 0 ≤ z < M, is said to be unimodal if there exists 0 ≤ m < M such that f Z (z) is non-decreasing between 0 and m, and non-increasing between m and M .\nIt is readily veriﬁed that the family of unimodal modulo- additive channels includes the mod- M AWGN channel for any noise variance (1) (i.e., that the folding of the Gaussian distribution does not violate unimodality).\nConsider a modulo-additive and memoryless channel: Y = X ⊕ Z ,\nwhere the input alphabet is X ∈ {0, 1, . . . , M − 1}, and Z is some random variable independent of X. It is well known that the capacity of this channel is achieved by a uniform input distribution. Therefore, the channel\u2019s capacity is given by:\nwhere X is a random variable distributed uniformly on {0, 1, . . . , M − 1}, independent of Z, and H denotes either entropy (in the discrete case) or differential entropy (in the continuous case).\nThe standard ensemble of (N, K) linear codes, N, K ∈ N, is deﬁned as follows,\nx (u) = Gu ⊕ v 0 \t (4) where both the matrix G ∈ Z K×N M and the vector v 0 ∈ Z N M are drawn uniformly and independently from Z M . Denote the code\u2019s rate by R = K log M N .\nStandard bounding techniques (cf., e.g., [1]) yield the following lemma, which gives a sufﬁcient condition for the existence of capacity-achieving linear codes over Z M .\nLemma 1: If the following condition holds, 1\nwhere H g (Z) H (Z | Z g ) with Z g Z mod g, then for every R < C (where C is given by (3)) and for every ǫ > 0, there exist N ∈ N and a linear code (4) over Z M , with K = N R log(M) , that achieves a probability error lower than ǫ.\nRemark 1: For an alphabet size that is a power of a prime M = p r , Lemma 1 coincides with [6, Example 9].\nOur main result states that (5) holds for any unimodal modulo-additive channel, given that the alphabet size is a power of a prime, M = p r . Namely, for every 1 < g < M such that M is divisible by g, the condition (5) is satisﬁed.\nTheorem 1: Let M > 1 be a power of a prime, and let Z be any unimodal (either discrete or continuous) random variable, taking values in [0, M ). Let C be the capacity of the channel\nwhere the input alphabet is X ∈ {0, 1, . . . , M − 1}, and let R < C. Then for every ǫ > 0 there exist N ∈ N and a linear code (4) over Z m , with K = N R log(M) , such that P e < ǫ, where P e is the error probability obtained by using the code over the channel combined with maximum-likelihood decoding.\nThe proof, which is presented in the next section, is based on the proof of [6, Theorem 25], with some modiﬁcations needed to replace the PSK constellation with PAM, and replacing the AIDN condition with a unimodality condition.\nSince the modulo-additive Gaussian channel is unimodal, we have the following corollary,\nCorollary 1: For every ǫ > 0 there exists a linear code (4), such that using this code over the modulo-additive AWGN channel:\n( M being a power of a prime) with Z ∼ N(0, σ 2 ) achieves P e < ǫ, provided that the code rate R is lower than the capacity of the channel.\nThroughout the proof, we assume that Z is a continuous random variable, having a unimodal probability density func- tion f Z (z) , 0 ≤ z < M (see Deﬁnition 1). The proof for the discrete case is analogous, replacing the probability density function f Z (z) with a discrete probability function p Z (z) , z = 0, 1, . . . , M − 1.\nWithout loss of generality, all the logarithms in this section are taken to base p.\nIn the case M = p r , taking g = p r−q , (5) is equivalent to 1\nr H 1 (Z) ∀q = 1, 2, . . . , r . In fact, we will prove a stronger result, namely,\n≤ qH(Z | Z mod p r−q− 1 ) ∀q = 1, 2, . . . , r − 1 . (6) Using the chain rule, we have\n= H(Z | Z mod p m−q , Z mod p m−q− 1 ) = H(Z | Z mod p m−q− 1 )\nWe prove a stronger result: for every y we show that H(Z | Z = y mod p m−q− 1 )\nBefore we prove (7), we need to introduce some notations. Let q and let y ∈ [0, M). Deﬁne a normalized probability vector W = (W (0), . . . , W (p q +1 − 1)), where\nFinally, deﬁne p probability vectors µ 1 . . . , µ p− 1 as µ i = (µ i (0), . . . , µ i (p q − 1)) ,\nThe following lemma plays a similar role in our proof as does [6, Lemma 20], only that it is adapted to the case of a unimodal modulo-additive channel with PAM constellation.\nLemma 2 essentially means that we can perform permuta- tions on the vectors W q,j in (8) (i.e., re-order the elements within each vector without changing their values), such that\nNote that this reordering affects neither the left nor the right hand side of (10). Therefore, from now on we assume without loss of generality that (11) holds.\nWe proceed as in [6]: Let Z(j) be a random variable on {0, . . . , p q − 1} with distribution µ j , and let the p-adic expansion of Z(j) be denoted by\nLet δ α (j) be the distribution of Y α (j) on (0, 1, . . . , p − 1). As in [6, Lemma 21], we have\nwhere (∗) follows from the concavity of the entropy function. Therefore, equation (10) holds, which completes the proof\nWe conjecture that the condition (5) holds for any modulo- additive unimodal channel over any input alphabet size M . For general alphabet sizes, numerical evidence suggests that (5) holds for any unimodal noise distribution. However, this has not yet been proved, except of some special cases that we present in the following two examples. An example of the numerical evidence is given in [11].\na) Noisy Typewriter: A straightforward calculation shows that linear codes over Z M achieve the capacity of the following channel\n  \n \n1 − ǫ z = 0 ǫ \t z = 1\nwhere the alphabet M ≥ 2 is arbitrary (not necessarily a power of a prime). See the full paper [11] for details.\nb) M -ary symmetric channel: It can be shown that linear codes over Z M achieve the capacity of the following channel\nwhere ǫ < 1 M , and the alphabet M ≥ 2 is arbitrary (not necessarily a power of a prime). In this case the calculation is more involved, and is also presented in [11].\nWe now derive the sufﬁcient condition (5) for achieving the channel\u2019s capacity. We start with the following simple lemma:\nProof: For the case of discrete noise, Z = Z mod 1, and (14) is reduced to the well-known C = log(M ) − H(Z) . If Z is continuous, the proof follows by straightforward calculation,\nFrom now on we assume that Z is continuous, with probability density function f Z (z). The results for discrete noise are similar, replacing integrals with sums.\nAssume without loss of generality that the zero codeword was transmitted. The average error probability of the ensemble is bounded by [1],\nFor a given value of g(u), the inner sum over G does not depend on the vector u itself, and the number of vectors u that satisfy g(u) = g is upper bounded by M g K . Thus,\nThus, a sufﬁcient condition for achieving lim N →∞ P e = 0, is that for every R < C and for every g|M such that g = M there will exist ρ > 0, such that\nTaking ρ inﬁnitely small, we obtain the condition 1 − C log M log (M/g) ≥ H g (Z)) ,\nwhere H g (Z) \t H (Z | Z g ) with Z g = Z mod g. Using Lemma 3, we have C log M − H 1 (Z) . Thus, a sufﬁcient condition for achieving lim N →∞ P e = 0 is\nFinally, if the average error probability of the ensemble tends to 0, then there must exist a speciﬁc code in the ensemble that achieves P e < ǫ (for a large enough value of N )."},"refs":[{"authors":[{"name":"R. G. Gallage"}],"title":{"text":"Information Theory and Reliable Communication"}},{"authors":[{"name":"R. L. Dobrushin"}],"title":{"text":"Asymptotic optimality of group and systematic codes for some channels"}},{"authors":[{"name":"R. Ahlswede"}],"title":{"text":"Group codes do not achieve Shannon\u2019s channel capacity for general discrete channels"}},{"authors":[{"name":"R. Ahlswede"},{"name":"J. Gemma"}],"title":{"text":"Bounds on algebraic code capacities for noisy channels. i"}},{"authors":[{"name":"G. Como"},{"name":"F. Fagnani"}],"title":{"text":"The capacity of ﬁnite Abelian group codes over symmetric memoryless channels"}},{"authors":[{"name":"G. Como"}],"title":{"text":"Ensembles of Codes over Abelian Groups"}},{"authors":[{"name":"J. Geist"}],"title":{"text":"Capacity and cutoff rate for dense M-ary PSK constellations"}},{"authors":[{"name":"M. Franceschini"},{"name":"G. Ferrari"},{"name":"R. Raheli"}],"title":{"text":"High-SNR mutual informa- tion of dense constellations"}},{"authors":[{"name":"M. \t Gastpar \t"},{"name":"B. \t Nazer"}],"title":{"text":"Algebraic \t structure in \t network \t information \t theory."}},{"authors":[{"name":"C. Feng"},{"name":"D. Silva"},{"name":"F. Kschischang"}],"title":{"text":"An algebraic approach to physical-layer network coding"}},{"authors":[{"name":"A. Hitron"},{"name":"U. Erez"}],"title":{"text":"Optimality of linear codes over PAM for the modulo-additive Gaussian channel."}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566413.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S10.T4.4","endtime":"12:50","authors":"Ayal Hitron, Uri Erez","date":"1341405000000","papertitle":"Optimality of Linear Codes over PAM for the Modulo-Additive Gaussian Channel","starttime":"12:30","session":"S10.T4: Coding with Lattices","room":"Stratton 20 Chimneys (306)","paperid":"1569566413"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
