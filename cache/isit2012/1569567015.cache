{"id":"1569567015","paper":{"title":{"text":"On The Sum-Capacity of Gaussian MAC With Peak Constraint"},"authors":[{"name":"Babak Mamandipoor"},{"name":"Kamyar Moshksar"},{"name":"Amir K. Khandani"}],"abstr":{"text":"Abstract\u2014This paper addresses a two-user Gaussian Multiple Access Channel (MAC) under peak constraints at the transmit- ters. It is shown that generating the code-books of both users according to discrete distributions achieves the largest sum-rate in the network. In other words, sum-capacity achieving input distributions for this channel are discrete with a ﬁnite number of mass points. We also demonstrate uniqueness of the input distributions which achieve rates at any of the corner points of the capacity region of the channel."},"body":{"text":"In his seminal thesis, J. G. Smith studies a point to point Additive White Gaussian Noise (AWGN) channel under peak constraint, as well as average power, constraints [1]. The main observation in [1], [2] is that the unique capacity achieving distribution is discrete with a ﬁnite number of mass points. We remark that characterizing the exact number and location of mass point must be done numerically. In [3], the authors extend the results in [1], [2] to a quadrature AWGN channel. [4] provides an insightful methodology in dealing with the problem considered in [1], [2]. Among other related works, [5] investigates the entropy of a sum of independent random variables with common support on a ﬁnite interval. It is shown that the entropy is maximized if one of these random variables is uniform and the rest are discrete with mass points at the endpoints of the support interval. Subsequently, [5] draws conclusions about the sum-rate of a Gaussian MAC under peak amplitude constraints at the transmitters in the high Signal-to- Noise Ratio (SNR) regime where the additive Gaussian noise at the common receiver is neglected.\nDiscrete input distributions appear in many different scenar- ios. For example, [6] explores a fast Rayleigh fading point to point channel where the channel state information is unknown to both transmitter and receiver. Surprisingly, it is shown that under only a constraint on average power at the transmitter the capacity-achieving input distribution is discrete. In another scenario, the authors in [7], [8] demonstrate optimality of discrete input distributions in channels with quantized output.\nIn this paper, we consider a two-user Gaussian MAC under peak constraints at both transmitters 1 as shown in Fig. 1. Denoting the signal transmitted by user i by X i for i = 1, 2, the signal received at the receiver is\nwhere Z ∼ N(0, 1) is the additive noise at the common receiver. Note that X 1 , X 2 and Z are independent random variables. It is required that the transmitted signal by any user be in the interval [ −A, A]. We are looking for the optimal choice X ∗ 1 and X ∗ 2 of X 1 and X 2 such that the sum-rate is maximized, i.e.,\nwhere h( ·) is the differential entropy function. The main contribution of the paper is that selecting X 1 and X 2 to be discrete random variables is an answer for the problem in (2). In order to prove our result, we extend the approach taken in [1], [2] using some key Theorems in mathematical analysis together with the results in [4]. The main idea of the proof is based on the following steps:\n1- We ﬁx X 1 = X ∗ 1 . Note that we do not know the distribution of X ∗ 1 at this point. As such, we represent X ∗ 1 by a distribution that has both continuous and discrete parts. Then we look into the new problem\nwhere following the same lines as in (4), we show X 1 is a discrete random variable. By (6),\nFinally, by (5) and (7), we have h(X 1 + X 2 + Z) ≥ h(X ∗ 1 +X ∗ 2 +Z). However, h(X 1 +X 2 +Z) ≤ h(X ∗ 1 +X ∗ 2 +Z)\nby (2). Hence, h(X 1 + X 2 + Z) = h(X ∗ 1 + X ∗ 2 + Z), i.e., the highest sum-rate is achieved by discrete input distributions.\nBased on steps 1 and 2 above, the rest of the paper is devoted to prove the following Theorem:\nTheorem 1- Let W be a ﬁxed random variable with support [ −A, A] and Z ∼ N(0, 1). Then a unique and discrete random variable X with a ﬁnite number of mass points in [ −A, A] is the answer to the optimization problem sup X:|X|≤A I(X; X + W + Z).\nNotation: The set of real and complex numbers are denoted by R and C, respectively. The imaginary number\nshown by j. For any random variable U , P U ( ·), F U ( ·) and Φ U ( ·) denote the Probability Density Function (pdf), Cumu- lative Distribution Function (cdf) and characteristic function of U , respectively. A normal random variable with mean m and variance σ 2 is denoted by N (m, σ 2 ). The imaginary part of a complex number z is denoted by Im(z). R δ denotes a portion of the complex plane deﬁned by\nR δ {z : |Im(z)| ≤ δ}. \t (8) F denotes the convex space of cdfs having all points of increase in the ﬁnite interval [ −A, A]. F is endowed a topology based on the so-called Levy metric [11]. The Levy distance between F 1 , F 2 ∈ F is denoted by d(F 1 , F 2 ). For a sequence of cdfs {F n } n≥1 , F n c − → F denotes complete convergence (convergence in the Levy metric) to a speciﬁc distribution F . f (x + ) and f (x − ) denote the limits of the function f ( ·) when approaching to the real point x from right and left, respectively. A function Ψ : F → R is called weakly differentiable at F 0 ∈ F if lim θ→0 + Ψ(F 0 +θ(F −F 0 ))−Ψ(F 0 ) θ\nexists. Finally, Ψ : F → R is called weakly differentiable if Ψ( ·) is weakly differentiable at every point in F.\nThe answer to our optimization problem in Theorem 1 is in fact the capacity of a point-to-point scalar additive noise channel Y = X + W + Z where X and Y denote input and output of the channel, respectively. Let P Y ( ·; F X ), Φ Y ( ·; F X ) and h Y (F X ) denote the output pdf, the output characteristic function and the output differential entropy, respectively, when X is generated according to F X . Let us deﬁne the mixed noise as\nto represent the total noise of the channel whose entropy is denoted by h(P M ). Let us deﬁne the marginal entropy function h(x; F X ) by\nFollowing [2], we invoke the Karush-Kuhn-Tucker (KKT) Theorem to obtain the necessary and sufﬁcient conditions for the optimum input pdf. The requirements of the KKT Theorem are convexity and compactness of F and strict convexity, continuity and weak differentiability of h Y (F X ).\nWe ﬁrst develop upper and lower bounds for P M ( ·) and P Y ( ·). Propositions 1 and 2 are devoted to establish strict convexity and continuity of h Y (F X ), respectively. Proposition 3 veriﬁes the differentiability of h Y (F X ). Lemma 5 uses the Morera Theorem [12] to prove that the continuation of P M ( ·) to the complex plane is analytic. This in turn provides us with necessary tools to demonstrate analyticity of h( ·; F X ) in Proposition 4. Analyticity of h( ·; F X ) is used in Proposition 5 where we conclude the claim in Theorem 1 based on the Identity Theorem [12] in Complex Analysis. Throughout the paper, we occasionally refer the reader to the technical report [13] where we have presented details that we can not provide here due to space limitations.\n  \n  \n \nProof: Let {x n } n≥1 be a sequence of real numbers converging to x. We have\n(18) where function rect( ·) is deﬁned by\n1 − 1 2 ≤ u ≤ 1 2 0 otherwise.\nwhere ∞ −∞ 1 √ 2π rect λ 2A dF W (λ) < ∞. On the other hand, lim n→∞ rect( λ 2A )P Z (x n − λ) = rect( λ 2A )P Z (x − λ). Hence, using Dominated Convergence Theorem [11], one can take the limit inside the integral. The result is immediate, i.e., lim n→∞ P M (x n ) = P M (x).\nProof: The proof for continuity in y is straightforward and quite similar to the lines of proof in Lemma 1. In order to prove continuity in F X , let us ﬁx a sequence {F n (x) } n≥1 in F such that F n c − → F for some F ∈ F. We know that P M ( ·) is bounded and continuous 2 . Note that\nwhere (a) follows by the Helly-Bray Theorem [11]. This completes the proof.\nLemma 3: The characteristic function Φ M ( ·) can not be uniformly zero in any interval, i.e., zeros of Φ M ( ·) are isolated.\nLemma 4: Every characteristic function is uniformly con- tinuous on the whole real line.\nProof: We know that h Y (F X ) is a convex-cap function of F X . To prove strict convexity, we need to show that d(F 1 , F 2 ) = 0 if and only if P Y (y; F 1 ) = P Y (y; F 2 ) for any two distributions F 1 , F 2 ∈ F for X. For simplicity of\nnotation, let denote the input X corresponding to distributions F 1 and F 2 by X 1 and X 2 , respectively. Based on Lemma 2, if d(F 1 , F 2 ) = 0, then P Y (y; F 1 ) = P Y (y; F 2 ). To show the other direction, let P Y (y; F 1 ) = P Y (y; F 2 ). Then Φ Y (f ; F 1 ) = Φ Y (f ; F 2 ). We can rewrite this equation as\nΦ M (f ) (Φ X 1 (f ) − Φ X 2 (f )) = 0. \t (22) Based on lemma 3, Φ M ( ·) cannot be uniformly zero in any interval. Let us denote the isolated zeros (if any) of Φ M ( ·) by f 1 , f 2 , f 3 , · · · . This implies that Φ X 1 (f ) = Φ X 2 (f ) for any f ∈ R except possibly for f ∈ {f 1 , f 2 , f 3 , · · · }. According to lemma 4, Φ X i (f + ) = Φ X i (f − ) = Φ X i (f ) for i = 1, 2 and any f ∈ {f 1 , f 2 , f 3 , · · · }. Therefore, Φ X 1 (f ) = Φ X 2 (f ) for all f ∈ R. This in turn yields d(F 1 , F 2 ) = 0.\nRemark 1: Let f : R → R be a positive-valued and bounded function, i.e., 0 ≤ f(y) ≤ c < ∞ for any y ∈ R and some positive constant c. It is easy to see that [13]\nProposition 2: h Y (F X ) is a continuous function in terms of F X .\nProof: For any sequence {F n } n≥1 in F with F n c − → F , we need to show that lim n→∞ h Y (F n ) = h Y (F ). Based on Lemma 2, lim n→∞ P Y (y; F n ) = P Y (y; F ). Then\n−P Y (y; F n ) log(P Y (y; F n )) = −P Y (y; F ) log(P Y (y; F )). (24)\n−P Y (y; F n ) log P Y (y; F n ) ≤ Γ(y) − log γ(y) + 2| log k 3 | , (25)\nwhere we have used (15) and Remark 1. It is easy to verify that [13]\nBy (24), (25) and (26), we can use Dominated Convergence Theorem to conclude lim n→∞ h Y (F n ) = h Y (F ).\nProof: The proof follows similar lines of reasoning pre- sented in [2] for an additive white Gaussian noise channel. The details are offered in [13].\nLemma 5: Continuation of P M ( ·) to the complex plane is analytic on any domain R δ for an arbitrary δ > 0.\nWe ﬁrst show that continuation of P M ( ·) to the complex plane is continuous 3 in R δ . Let {z n } n≥1 be a sequence of complex numbers in R δ converging to z ∈ R δ . Letting z n = η n + jζ n and noting that |ζ n | ≤ δ,\nAs A −A 1 √ 2π e δ2 2 dF W (λ) < ∞ and lim n→∞ P Z (z n − λ) = P Z (z − λ) exists, using the Dominated Convergence theorem, we have lim n→∞ P M (z n ) = P M (z). This implies that P M ( ·) is continuous for all z ∈ R δ . In order to verify analyticity of P M ( ·), using Morera Theorem, we need to show that\nP M (z)dz = 0 for any closed contour ω in R δ . This contour integral is described as\nwhere we have used the fact that ω P Z (z − λ)dz = 0 due to analyticity of P Z ( ·). Invoking Morera Theorem, we conclude that P M ( ·) is analytic in R δ . To complete the proof, we need to show that changing the order of integration in (29) is indeed valid. This can be done by Fubini Theorem [11] as we have\nwhere (a) is by (28) and l ω is the length of ω which is ﬁnite as ω is a closed curve. This completes the proof.\nProposition 4: Marginal entropy function h( · ; F X ) is ana- lytic on the domain R δ for all F X ∈ F and any δ > 0.\nProof: We start by proving that h( · ; F X ) is continuous. Let {z n } n≥1 be a sequence of complex numbers in R δ converging to z ∈ R δ . We show that lim n→∞ h(z n ; F X ) = h(z; F X ). We have\nNote that lim n→∞ P M (y − z n ) = P M (y − z) for any y ∈ R due to continuity of P M ( ·) as shown in Lemma 5. If we can show that there exists a function g : R → [0, ∞) such that |P M (y − z n ) log(P Y (y; F X )) | ≤ g(y) for any y ∈ R and ∞ −∞ g(y)dy < ∞, then we can invoke Dominated Convergence Theorem to conclude continuity of h( ·; F X ). We have\n  \nBy (36) and (37), |P M (y − z n ) | ≤ κ n (y) for any n ≥ 1. As z n approaches z, η n approaches η where z = η + jζ. Let us ﬁx ε > 0. There exists a natural number N (ε) such that for n ≥ N(ε), we have |η − η n | < ε. Let us deﬁne κ ∗ (y, ε) by\n  \nk ∗ \t y ∈ [η − A − ε, η + A + ε] k ∗ e − 1 2 (y−η−A−ε) 2 y > η + A + ε.\nTherefore, |P M (y − z n ) | ≤ κ ∗ (y, ε) for n ≥ N(ε). We can write\nκ ∗ (y, ε) − log γ(y) + 2| log k 3 | for y ∈ R. It is a straight- forward task to verify that ∞ −∞ g(y)dy < ∞. We refer the reader to [13] for the details. This complete the claim about continuity of h( · ; F X ). We are ready to apply Morera Theorem to show that h( · ; F X ) is analytic in R δ . Let ω be a closed contour in R δ . Then\nwhere (a) is due to Fubini Theorem 4 and (b) holds by Lemma 5 where it was shown that P M ( ·) is analytic. This completes the Proof of Proposition 4.\nwhere (a) holds by a similar argument made in Remark 1, (b) hold by (12) and (c) is an easy observation made in [13]. The proof of the following Lemma is provided in [1].\nProposition 5: sup F X ∈F I(X; Y ) is achieved for some F X ∈ F, i.e.,\nand the capacity-achieving input distribution is unique and discrete with a ﬁnite number of mass points.\nProof: Based on Lemmas 6 and 7 and Proposition 2, (43) is immediate. According to Propositions 1, 2 and 3 and Lemma 7 and invoking the KKT Theorem, there is a unique input distribution, F ∗ , that achieves sup F X ∈F I(X; Y ). Following standard arguments in Smith [1], the necessary and sufﬁcient condition for F ∗ to be the optimum input cdf is given by\nwhere equality holds if x belongs to the points of increase of F ∗ and C is deﬁned in (43). Suppose that F ∗ has an inﬁnite number of mass points in [ −A, A]. Then based on Bolzano- Weierstrass Theorem [1], the set of these points admits a limit point. According to Proposition 4 and Identity Theorem of Complex Analysis, h(x; F ∗ ) = C + h(P M ) for all x ∈ R, We will show that the this argument leads to a contradiction. To do so, we adopt the same idea as in [4]. Let us deﬁne L C + h(P M ) and ρ(y) log(P Y (y; F ∗ )) + L. Based on the deﬁnition of the constant L, ∞ −∞ P M (y − x)ρ(y) dy = −h(x; F ∗ ) + L = 0 for all x ∈ R. Deﬁne\nBy (15), we get ρ(y) ≤ log(Γ(y)) + L ≤ log(k 3 ) + L for any y ∈ R. Hence, (46) requires k 3 > 2 −L . Choose a constant l such that l > 2A + log(k 3 )+L k\n. Using (15), one has Ω + ⊆ [ −l, l]. Therefore,\nwhere (a) holds by (12) and (15). We can make this upper bound arbitrarily small by choosing x large enough. On the other hand, for x > A + l,\nwhere (a) follows from (12). By (47) and (48), (46) can not hold for x sufﬁciently large. This is a contradiction. Hence, the number of mass points of F ∗ must be ﬁnite.\nBased on Proposition 5, one can conclude that a unique and discrete random variable X with a ﬁnite number of mass points is the answer to the optimization problem addressed in Theorem 1. It can also be deduced that the input pdfs which achieve rates at any of the corner points of the capacity region of the channel are unique. For example, letting R 1 = I(X 1 ; Y ) and R 2 = I(X 2 ; Y |X 1 ), then based on [1], R 2 is achieved by a unique input pdf and according to Proposition 5, R 1 has the same uniqueness property."},"refs":[{"authors":[{"name":"J. G. Smith"}],"title":{"text":"The Information Capacity of Amplitude and Variance- Constrained Scalar Gaussian Channels"}},{"authors":[{"name":"J. G. Smith"}],"title":{"text":"On the information capacity of peak and average power constrained Gaussian channels"}},{"authors":[{"name":"S. Shamai (Shitz)"},{"name":"I. Bar-David"}],"title":{"text":"The capacity of average and peak-power limited quadrature Gaussian channel"}},{"authors":[{"name":"A. Tchamkerten"}],"title":{"text":"On the Discreteness of Capacity-Achieving Distribu- tions"}},{"authors":[{"name":"E. Ordentlich"}],"title":{"text":"Maximizing the entropy of a sum of independent random variables"}},{"authors":[{"name":"I. C. A. Faycal"},{"name":"M. D. Trott"},{"name":"S. Shamai"}],"title":{"text":"The capacity of discrete- time memoryless rayleigh-fading channels"}},{"authors":[{"name":"J. Sing"},{"name":"O. Dabee"},{"name":"U. Madho"}],"title":{"text":"On the limits of communication with low-precision analog-to-digital conversion at the receiver,\u201d IEEE Transactions on Communications , vol"}},{"authors":[{"name":"Y. W"},{"name":"M. Davi"},{"name":"R. Calderban"}],"title":{"text":"L"}},{"authors":[{"name":"A. Das"}],"title":{"text":"Capacity-achieving distributions for non-Gaussian additive noise channels"}},{"authors":[{"name":"E. Lukac"}],"title":{"text":"Characteristics Functions"}},{"authors":[{"name":"R. M. Dudle"}],"title":{"text":"Real analysis and probability, Cambridge University Press, 2002"}},{"authors":[{"name":"J. B. Conway"}],"title":{"text":"Functions of One Complex Variable I"}},{"authors":[{"name":"B. Mamandipoor"},{"name":"K. Moshksar"},{"name":"A. K. Khandani"}],"title":{"text":"On the sum-capacity of Gaussian MAC with peak constraint"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569567015.pdf"},"links":[{"id":"1569566725","weight":8},{"id":"1569566385","weight":4},{"id":"1569565067","weight":8},{"id":"1569566683","weight":4},{"id":"1569566227","weight":4},{"id":"1569566943","weight":4},{"id":"1569556029","weight":4},{"id":"1569566571","weight":4},{"id":"1569552245","weight":4},{"id":"1569566415","weight":4},{"id":"1569566081","weight":4},{"id":"1569565355","weight":8},{"id":"1569565931","weight":4},{"id":"1569565461","weight":4},{"id":"1569564731","weight":4},{"id":"1569558325","weight":4},{"id":"1569566671","weight":4},{"id":"1569566119","weight":4},{"id":"1569564233","weight":4},{"id":"1569566319","weight":8},{"id":"1569565123","weight":8},{"id":"1569558459","weight":12},{"id":"1569566751","weight":4},{"id":"1569566467","weight":4},{"id":"1569565771","weight":4},{"id":"1569566157","weight":4},{"id":"1569560613","weight":4},{"id":"1569566999","weight":20},{"id":"1569566843","weight":8},{"id":"1569566579","weight":4},{"id":"1569565455","weight":4},{"id":"1569564189","weight":4},{"id":"1569566985","weight":20},{"id":"1569564311","weight":4},{"id":"1569566239","weight":4},{"id":"1569566575","weight":4},{"id":"1569566733","weight":8},{"id":"1569566753","weight":4},{"id":"1569566759","weight":4},{"id":"1569565213","weight":8},{"id":"1569565841","weight":4},{"id":"1569566531","weight":4},{"id":"1569567665","weight":4},{"id":"1569564611","weight":4},{"id":"1569562285","weight":4},{"id":"1569553519","weight":4},{"id":"1569554971","weight":8},{"id":"1569566445","weight":4},{"id":"1569566209","weight":8},{"id":"1569566371","weight":4},{"id":"1569558985","weight":4},{"id":"1569565033","weight":4},{"id":"1569566721","weight":4},{"id":"1569565633","weight":4},{"id":"1569558509","weight":8},{"id":"1569556671","weight":4},{"id":"1569565095","weight":4},{"id":"1569564969","weight":4},{"id":"1569566593","weight":4},{"id":"1569566043","weight":4},{"id":"1569565357","weight":4},{"id":"1569561245","weight":4},{"id":"1569566191","weight":4},{"id":"1569565527","weight":8},{"id":"1569566655","weight":8},{"id":"1569566667","weight":8},{"id":"1569566297","weight":4},{"id":"1569564097","weight":4},{"id":"1569566407","weight":4},{"id":"1569566481","weight":4},{"id":"1569566387","weight":4},{"id":"1569560503","weight":4},{"id":"1569566133","weight":4},{"id":"1569566383","weight":8},{"id":"1569566805","weight":4},{"id":"1569566929","weight":4},{"id":"1569565665","weight":8},{"id":"1569566983","weight":4},{"id":"1569566097","weight":8},{"id":"1569566479","weight":4},{"id":"1569566873","weight":4},{"id":"1569566129","weight":4},{"id":"1569565241","weight":4},{"id":"1569564131","weight":4},{"id":"1569561221","weight":8},{"id":"1569566651","weight":4},{"id":"1569566823","weight":4},{"id":"1569566595","weight":4},{"id":"1569565013","weight":4},{"id":"1569565375","weight":8},{"id":"1569566755","weight":4},{"id":"1569566641","weight":4},{"id":"1569565425","weight":4},{"id":"1569559035","weight":4},{"id":"1569551905","weight":8},{"id":"1569565529","weight":4},{"id":"1569556759","weight":4},{"id":"1569566619","weight":4},{"id":"1569561185","weight":4},{"id":"1569565669","weight":4},{"id":"1569560235","weight":8},{"id":"1569564157","weight":4},{"id":"1569566389","weight":4},{"id":"1569566435","weight":4},{"id":"1569566911","weight":4},{"id":"1569566299","weight":4},{"id":"1569564281","weight":4},{"id":"1569566933","weight":4},{"id":"1569563919","weight":4},{"id":"1569559919","weight":4},{"id":"1569566847","weight":4},{"id":"1569567013","weight":4},{"id":"1569566987","weight":4},{"id":"1569564509","weight":4},{"id":"1569551541","weight":4},{"id":"1569566663","weight":4},{"id":"1569564807","weight":8},{"id":"1569566609","weight":12},{"id":"1569566113","weight":8},{"id":"1569566443","weight":4},{"id":"1569565515","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T2.2","endtime":"10:30","authors":"Babak Mamandipoor, Kamyar Moshksar, Amir K. Khandani","date":"1341223800000","papertitle":"On The Sum-Capacity of Gaussian MAC With Peak Constraint","starttime":"10:10","session":"S1.T2: Multiple Access Codes","room":"Kresge Auditorium (109)","paperid":"1569567015"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
