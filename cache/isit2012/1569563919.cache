{"id":"1569563919","paper":{"title":{"text":"Broadcast Correlated Gaussians: the Vector-Scalar Case"},"authors":[{"name":"Lin Song"},{"name":"Jun Chen"},{"name":"Chao Tian"}],"abstr":{"text":"Abstract\u2014The problem of sending a set of correlated Gaussian sources over a bandwidth-matched two-user scalar Gaussian broadcast channel is studied in this work, where the strong receiver wishes to reconstruct several source components (i.e., a vector source) under a distortion covariance matrix constraint and the weak receiver wishes to reconstruct a single source component (i.e., a scalar source) under the mean squared error distortion constraint. We provide a complete characterization of the optimal tradeoff between the transmit power and the achievable reconstruction distortion pair for this problem. The converse part is based on a new bounding technique which involves the introduction of an appropriate remote source. The forward part is based on a hybrid scheme where the digital portion uses dirty paper channel code and Wyner-Ziv source code. This scheme is different from the optimal scheme proposed by Tian et al. in a recent work for the scalar-scalar case, which implies that the optimal scheme for the scalar-scalar case is in fact not unique."},"body":{"text":"Unlike in point-to-point communication systems where the source-channel separation architecture is optimal [1], in multi- user systems, a separation-based architecture is usually not optimal. In such scenarios, hybrid schemes have emerged as a promising approach to gain performance improvement over either pure digital scheme (separation-based scheme) or pure analog scheme, e.g., in [2] for bandwidth-mismatch Gaussian source broadcast, and in [3] for sending correlated sources on multiple access channels. In a recent work [4] where the problem of broadcasting bivariate Gaussian was considered (see also [5]), it was shown for the ﬁrst time that hybrid schemes are not only able to provide such performance improvement, they can in fact be optimal.\nIn this work, we consider a generalization of the problem studied in [4]. In this generalization, there are still two receivers and the channel is still scalar Gaussian broadcast channel, however the source is not a bivariate but a multivariate Gaussian source. The strong receiver wishes to reconstruct several source components (i.e., a vector source) under a distortion covariance matrix constraint, and the weak receiver wishes to reconstruct a single source component (i.e., a scalar source) under the mean squared error distortion constraint; see Fig. 1. A complete solution is provided for the optimal tradeoff between the transmit power and the reconstruction distortion pair, and a hybrid scheme where the digital portion uses dirty paper channel code and Wyner-Ziv source code is shown to be optimal. This scheme is different from the optimal scheme\nproposed in [4] for the scalar-scalar case, and this new result implies that the optimal scheme for the scalar-scalar case is in fact not unique. It is worth noting that the brute-force proof method in [4], [5] is difﬁcult to generalize to the problem being considered. Therefore, we take a more conceptual approach in the present work. In particular, the derivation of our lower bound is based on a new bounding technique which involves the introduction of an appropriate remote source.\nThe remainder of this paper is organized as follows. We give a formal problem deﬁnition in Section II and then state our main result in Section III. The proof of the main result is divided into two parts, which are given in Section IV and Section V, respectively. We conclude the paper in Section VI.\nLet S 1 and S 2 be jointly Gaussian with mean zero and positive deﬁnite covariance matrix Σ S 1 ,S 2 , where S 1 is an L × 1 Gaussian random vector with covariance matrix Σ S 1 (which is the ﬁrst L × L diagonal submatrix of Σ S 1 ,S 2 ) and S 2 is a Gaussian random variable with variance σ 2 S 2 (which is the (L + 1, L + 1) entry of Σ S 1 ,S 2 ). Let the broadcast channel additive noises Z 1 and Z 2 be two zero-mean Gaussian random variables, jointly independent of (S 1 , S 2 ), with variances N 1 and N 2 , respectively; it is assumed that N 2 > N 1 . Let {(S 1 (t), S 2 (t), Z 1 (t), Z 2 (t))} ∞ t =1 be i.i.d. copies of (S 1 , S 2 , Z 1 , Z 2 ).\nDeﬁnition 1: An (n, P, D 1 , d 2 ) source-channel broadcast code consists of an encoding function f : R L ×n × R n → R n and two decoding functions g 1 : R n → R L ×n and g 2 : R n → R n such that\n1 , 1\nwhere X n = f (S n 1 , S n 2 ), ˆ S n 1 = g 1 (X n + Z n 1 ), and ˆ S n 2 = g 2 (X n + Z n 2 ).\nIt is clear that the performance of any source-channel broad- cast code depends on (Z n 1 , Z n 2 ) only through their marginal distributions. Therefore, we shall assume the broadcast channel is physically degraded and write Z n 2 = Z n 1 + ∆ n , where ∆ n is a zero-mean Gaussian random vector with i.i.d. entries of variance N 2 − N 1 and is independent of Z n 1 .\nDeﬁnition 2: We say power P is achievable subject to dis- tortion constraints D 1 and d 2 if there exists an (n, P, D 1 , d 2 ) source-channel broadcast code. Let P (D 1 , d 2 ) denote the inﬁ- mum of all achievable powers subject to distortion constraints D 1 and d 2 .\nWith the above deﬁnitions, it is clear that the fundamental problem in this joint source-channel coding scenario is to ﬁnd a characterization of the function P (D 1 , d 2 ), and in this work we shall provide a complete solution for this function. In the remainder of the paper, without loss of generality, we assume 0 ≺ D 1 Σ S 1 and 0 < d 2 ≤ σ 2 S\nTheorem 1: For any (L + 1) × (L + 1) positive semideﬁnite matrix Σ U 1 ,U 2 , we denote its ﬁrst L × L diagonal submatrix by Σ U 1 and its (L + 1, L + 1) entry by σ 2 U 2 . Then\n1 + Σ U 1 |(d 2 + σ 2 U 2 ) + (N 2 − N 1 ) σ\nWe shall show in this section that for any (n, P, D 1 , d 2 ) source-channel broadcast code,\n1 + Σ U 1 |(d 2 + σ 2 U 2 ) + (N 2 − N 1 ) σ\nLet U 1 and U 2 be jointly Gaussian with mean zero and covariance matrix Σ U 1 ,U 2 , where U 1 is an L × 1 Gaussian random vector with covariance matrix Σ U 1 (which is the ﬁrst L × L diagonal submatrix of Σ U 1 ,U 2 ) and U 2 is a Gaussian random variable with variance σ 2 U 2 (which is the (L+1, L+1) entry of Σ U 1 ,U 2 ). Let {U 1 (t), U 2 (t)} n t =1 be i.i.d. copies of (U 1 , U 2 ). We assume that (U n 1 , U n 2 ) is independent of (S n 1 , S n 2 , Z n 1 , ∆ n ).\nDeﬁne V n 1 = S n 1 + U n 1 , V n 2 = S n 2 + U n 2 , and Y n i = X n + Z n i , i = 1, 2. Here (V 1 , V 2 ) can be understood as the remote source that should be reconstructed, yet the encoder only has observation (S 1 , S 2 ). In this sense, our lower bound can be understood as when V 2 is provided also to the strong receiver by a genie.\nWe shall ﬁrst bound I (V n 2 ; Y n 2 ). Note that I (V n 2 ; Y n 2 ) = h(V n 2 ) − h(V n 2 |Y n 2 )\nd 2 + σ 2 U 2 . \t (2) On the other hand, in view of the fact that\n(P + N 2 )(d 2 + σ 2 U 2 ) P (σ 2 S\nI (V n 1 ; Y n 1 |V n 2 ) = h(V n 1 |V n 2 ) − h(V n 1 |Y n 1 , V n 2 ) = h(V n 1 , V n 2 ) − h(V n 2 ) − h(V n 1 |Y n 1 , V n 2 ) = n 2 log |2πe(Σ S 1 ,S 2 + Σ U 1 ,U 2 )|\n2 log |E[(S 1 (t) − ˆ S 1 (t))(S 1 (t) − ˆ S 1 (t)) T ] + Σ U 1 | ≥ n 2 log |Σ S 1 ,S 2 + Σ U 1 ,U 2 | − n 2 log(σ 2 S 2 + σ 2 U 2 )\n1 + Σ U 1 |(d 2 + σ 2 U 2 ) + (N 2 − N 1 ) σ\nΣ U 1 ,U 2 can be an arbitrary (L + 1) × (L + 1) positive semideﬁnite matrix.\n1 + Σ U 1 |(d 2 + σ 2 U 2 ) + (N 2 − N 1 ) σ\nThe upper bound is based on a hybrid scheme. Let the channel input X n , with average power P (θ), be a super- position of an analog signal X n a and a digital signal X n d\n(i.e., X n = X n a + X n d ). Before describing the scheme, let us ﬁrst deﬁne (S 1 (θ), S 2 (θ)) to be zero-mean and jointly Gaussian, which generates (S 1 , S 2 ) via a backward Gaussian test channel (S 1 , S 2 ) = (S 1 (θ) + Q 1 , S 2 (θ) + Q 2 ), where (Q 1 , Q 2 ) is independent of (S 1 (θ), S 2 (θ)); the covariance matrix of (S 1 (θ), S 2 (θ)) is to be speciﬁed later. We assume that (S 1 , S 2 , S 1 (θ), S 2 (θ)) is independent of (Z 1 , Z 2 ). Now write\nNote that W 1 is independent of (S 1 , S 2 , S 2 (θ)), and W 2 is independent of (S 1 , S 2 ). Next deﬁne\nWe are now in a position to describe the scheme. The analog portion is given by X n a = β(b T 1 S n 1 + b 2 S n 2 ) for some β to be speciﬁed later. For the digital portion X n d , the encoder ﬁrst uses a Wyner-Ziv source code [6] with codewords generated according to ˜ S 1 (θ), and with Y 1 = X a + X d + Z 1 as the decoder side information where X d is a zero-mean Gaussian random variable independent of (S 1 , S 2 , X a , Z 1 , Z 2 ). The encoder then determines the digital portion of the channel input X n d to send the Wyner-Ziv coding index, treating X n a\nas the channel state information known at the encoder, i.e., using a dirty paper code [7]. We deﬁne P a = E[X 2 a ] and P d = E[X 2 d ]. Note that P a + P d = P (θ).\nThe Wyner-Ziv coding rate and the dirty paper coding rate are set to be equal\n] by varying β. It can be shown that (10) implies that the joint distribution of (S 1 , S 2 , ˜ S 1 (θ), 1 β Y 1 ) is the same as that of (S 1 , S 2 , ˜ S 1 (θ), S 2 (θ)). Therefore, we have\n= I(S 1 , S 2 ; ˜ S 1 (θ), S 2 (θ)) − I(S 1 , S 2 ; S 2 (θ)) = I(S 1 , S 2 ; S 1 (θ), S 2 (θ)) − I(X a ; Y 1 )\nd + N 1 = 1 2 log P d + N 1 N\nAs a consequence, Receiver 1 can correctly decode the dirty paper code, then recover ˜ S 1 (θ) by decoding the Wyner-Ziv code with Y 1 as the side information. Furthermore, Receiver 1 can use ˆ S 1 (θ) ˜ S 1 (θ)+ 1 β a 3 Y 1 as the reconstruction of S 1 . Receiver 2 can form a linear MMSE estimate of S 2 based on Y 2 X a + X d + Z 2 , and the resulting distortion is denoted by d 2 (θ). Noting that the power P (θ) is determined by (11), it is seen that the scheme is speciﬁed except the covariance matrix of (S 1 (θ), S 2 (θ)), which is subject to optimization under the distortion constraints. For the purpose of determining the covariance matrix of (S 1 (θ), S 2 (θ)) we formulate the following optimization problem.\nGiven θ ∈ (0, σ 2 S 2 ], let D(θ) denote the solution to max\nsubject to D S 1 D 1 , d S 2 ≤ θ,\nwhere D S 1 is the ﬁrst L × L diagonal submatrix of D, and d S 2 is the (L + 1, L + 1) entry of D. We denote the ﬁrst L × L diagonal submatrix of D(θ) by D S 1 (θ), and the (L + 1, L + 1) entry of D(θ) by d S 2 (θ). Let the covariance matrix of (S 1 (θ), S 2 (θ)) be chosen to be Σ S 1 ,S 2 − D(θ), where the covariance matrix of S 1 (θ) is Σ S 1 − D S 1 (θ), and the variance of S 2 (θ) is σ 2 S 2 − d S 2 (θ). Accordingly, (11) reduces to\nwhich determines P (θ). Now the coding scheme including all of its parameters is fully speciﬁed.\nWith these parameters it is seen that the resulting distortion at the strong receiver satisﬁes\nwhere (13) is true because the equivalence of the joint distribu- tions between (S 1 , S 2 , ˜ S 1 (θ), 1 β Y 1 ) and (S 1 , S 2 , ˜ S 1 (θ), S 2 (θ)) implies the equivalence of the joint distributions between (S 1 , ˆ S 1 (θ)) and (S 1 , S 1 (θ)). Recall as we have deﬁned pre- viously, that the distortion at the weak receiver is d 2 (θ), and thus the performance of the scheme is also determined.\nIt can be shown that both P (θ) and d 2 (θ) are continuous functions of θ for θ ∈ (0, σ 2 S 2 ]; moreover, d 2 (θ) goes to zero as θ → 0. Note that by ignoring the distortion constraint d 2 at Receiver 2, one can easily obtain the following lower bound on P (D 1 , d 2 ) by invoking the source-channel separation theorem:\nThis bound can also be obtained from our general lower bound by setting Σ U 1 = 0 and sending σ 2 U 2 to inﬁnity. This lower bound is tight when d 2 > d 2 (σ 2 S 2 ). Therefore, it sufﬁces to show that for θ ∈ (0, σ 2 S 2 ],\nTo this end we revisit the maximization problem in (12). It can be shown that D (θ) must satisfy the following KKT conditions\nD −1 (θ) − Λ − M = 0, \t (15) Λ 1 (D 1 − D S 1 (θ)) = 0, \t (16)\nwhere M 0, Λ 1 0, λ 2 ≥ 0, and Λ = diag(Λ 1 , λ 2 ). Let V 1 Π 1 V T 1 be the eigenvalue decomposition of Λ 1 , where V 1 is a unitary matrix, and Π = diag(π 1 , · · · , π r , 0, · · · , 0) with π i > 0, i = 1, · · · , r. Let Λ 1, = V 1 Π 1, V T 1 , where Π 1, = diag(π 1 − , · · · , π r − , , · · · , ). Furthermore, let λ 2, = λ 2 − if λ 2 > 0, and λ 2, = if λ 2 = 0. We shall choose and such that Λ 1, \t 0 and λ 2, > 0; moreover, we assume is a function of , and goes to zero as → 0. Let Λ = diag(Λ 1, , λ 2, ) and Σ U 1, ,U 2, = Λ −1 − D(θ). It can be shown that Σ U 1, ,U 2, 0 when is sufﬁciently small (with ﬁxed).\nLet U 1, and U 2, be jointly Gaussian with mean zero and covariance matrix Σ U 1, ,U 2, , where U 1, is an L ×1 Gaussian random vector with covariance matrix Σ U 1, (which is the ﬁrst L × L diagonal submatrix of Σ U 1, ,U 2, ) and U 2, is a Gaussian random variable with variance σ 2 U 2, (which is the (L+1, L+1) entry of Σ U 1, ,U 2, ). We assume that (U 1, , U 2, ) is independent of (S 1 , S 2 , S 1 (θ), S 2 (θ), Z 1 , Z 2 ). Note that\n|Λ −1 | = lim\nwhere (18) and (19) are due to (15) and (17), respectively. Since Λ 1 (D 1 − D S 1 (θ)) = 0, it implies Π 1 V T 1 (D 1 − D S 1 (θ))V 1 = 0, which further implies that V T 1 (D 1 − D S 1 (θ))V 1 is of the form diag (0 r ×r , A ), where 0 r ×r denotes an r × r all-zero matrix. Also note that V T 1 Σ U 1, V 1 = Π −1 1, − V T 1 D S 1 (θ)V 1 . Therefore,\n|Π −1 1, + diag(0 r ×r , A )| = 1. \t (21) It is clear that\nd 2 (θ) + σ 2 U 2, . On the other hand,\nI (S 2 + U 2, ; Y 2 ) = h(Y 2 ) − h(Y 2 |S 2 + U 2, ) = 1 2 log P (θ) + N 2 α P (θ) + N\nI (S 1 + U 1, ; S 1 (θ), S 2 (θ)|S 2 + U 2, ) = h(S 1 + U 1, |S 2 + U 2, )\n(25) On the other hand,\n= I(S 1 + U 1, , S 2 + U 2, ; S 1 (θ), S 2 (θ)) − I(S 2 + U 2, ; S 1 (θ), S 2 (θ))\n− I(S 2 + U 2, ; S 2 (θ)) \t (26) = I(S 1 + U 1, , S 2 + U 2, ; S 1 (θ), S 2 (θ)) − I(S 2 + U 2, ; Y 1 )\nWe have characterized the optimal tradeoff between the transmit power and the achievable distortion pair for the problem of sending correlated Gaussian sources over a Gaus- sian broadcast channel, where the strong receiver wishes to reconstruct a vector source and the weak receiver wishes to reconstruct a scalar source. It is worth mentioning that our achievability scheme, when specialized to the scalar-scalar case, is different from the one proposed in [4], which implies that the optimal scheme for the scalar-scalar case is in fact not unique. Indeed, it can be shown [8] that these two schemes are two extremal examples of a general class of hybrid schemes."},"refs":[{"authors":[{"name":"C. E. Shannon"}],"title":{"text":"A mathematical theory of communication"}},{"authors":[{"name":"U. Mittal"},{"name":"N. Phamdo"}],"title":{"text":"Hybrid digital-analog (HDA) joint source- channel codes for broadcasting and robust communications"}},{"authors":[{"name":"A. Lapidoth"},{"name":"S. Tinguely"}],"title":{"text":"Sending a bivariate Gaussian over a Gaussian MAC"}},{"authors":[{"name":"C. Tian"},{"name":"S. Diggavi"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"The achievable distortion region of sending a bivariate Gaussian source on the Gaussian broadcast channel"}},{"authors":[{"name":"S. Bross"},{"name":"A. Lapidoth"},{"name":"S. Tinguely"}],"title":{"text":"Broadcasting correlated Gaus- sians"}},{"authors":[{"name":"A. D. Wyner"},{"name":"J. Ziv"}],"title":{"text":"The rate-distortion function for source coding with side information at the decoder"}},{"authors":[{"name":"M. Costa"}],"title":{"text":"Writing on dirty paper"}},{"authors":[{"name":"L. Song"},{"name":"J. Chen"},{"name":"C. Tian"}],"title":{"text":"Broadcasting correlated vector Gaus- sians"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569563919.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T2.2","endtime":"12:10","authors":"Lin Song, Jun Chen, Chao Tian","date":"1341229800000","papertitle":"Broadcast Correlated Gaussians: the Vector-Scalar Case","starttime":"11:50","session":"S2.T2: Variations on Broadcast Channels","room":"Kresge Auditorium (109)","paperid":"1569563919"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
