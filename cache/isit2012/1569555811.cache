{"id":"1569555811","paper":{"title":{"text":"Authentication over Noisy Data with the Use of Memory Containing Metric Functions"},"authors":[{"name":"Vladimir B. Balakirsky"},{"name":"A. J. Han Vinck"}],"abstr":{"text":"Abstract\u2014We propose an authentication scheme where the veriﬁer makes the decision based on the value of the metric function, which is assigned depending on the type of the vector stored in the database at the enrollment stage. The scheme has a better performance than the maximum likelihood veriﬁcation algorithm even for binary symmetric channels."},"body":{"text":"The biometric authentication is based on extraction of parameters from outcomes of biometric measurements of a person that can be used to identify the person [1], [2], [3]. For instance, one can organize enrollment in such a way that the length of observations is equal to the the number of parameters and 1\u2019s indicate positions, which of them are signiﬁcant for the particular person. If the algorithm always extracts a ﬁxed number of signiﬁcant parameters from each sequence of observations [4], an attacker knows the weight of the vector, which is stored in the database to identify of the person. The attacker wants to substitute an artiﬁcial sequence that is recognized as a sequence of outcomes of the person and leads to the acceptance of the identity claim by the veriﬁer [5]. The knowledge of the weight can essentially increase the power of the attacker when the decision is made on the basis of the likelihood of the observations received at the veriﬁcation stage.\nWe develop our previous approaches to the authentication problem [6] and consider the scheme given in Figure 1. The veriﬁer is given a pair of vectors\nwhere X and Y are ﬁnite sets. The veriﬁer makes one of two decisions, Accept (Acc) or Reject (Rej), and the algorithm is formalized as a mapping\nwhere D x ⊆ Y n , x ∈ X n , are the acceptance sets. These sets have to be ﬁxed in advance in such a way that the veriﬁer can reliably distinguish between the following cases.\nAcc: The vector y is the result of noisy observations of the vector x simulated as transmission of the vector x over the memoryless channel\nAcc/Rej V is known Ω n is unknown y ∈ Y n\n✲ ❄\n✲ ✲ Veriﬁer V (y |x)\ni.e., the conditional probability associated with the vec- tor y , given the vector x. is expressed as\nRej: The vector y is generated by an arbitrary source spec- iﬁed by the probability distribution Ω n = ( Ω(y), y ∈ Y n ). If Ω n is a stationary memoryless distribution, then we write Ω(y) = ω(y), where\nThe Acc and the Rej cases simulate the situation when the vector x represents the results of biometric measurements of a person received at the enrollment stage and stored in a database. The vector y appears at the veriﬁcation stage, and the veriﬁer has to decide whether this vector can be considered as a corrupted version of the vector x or not.\nThe decision has to be made when the V channel is known to the veriﬁer, while the Ω n is assigned by an attacker, who wants to pass through the authentication with the Acc decision. The problem can be presented as follows: discriminate be- tween the known non\u2013stationary memoryless distribution and an arbitrary probability distribution over the set Y n on the basis of the received vector y .\nTo illustrate the difﬁculties of the problem, let us consider the case when X = Y = {0, 1} and the V channel is deﬁned by the matrix\n1/2 1/2 , \t (1) where ξ ∈ (0, 1/2). Suppose that the veriﬁer wants to have the false rejection rate at most ε for a given vector x. Due to the structure of the V channel, there is an obvious (the maximum likelihood) decision: the veriﬁer does not pay attention to the bits of the vector y received at positions where the vector\nx contains ones and only controls the weight of the vector received at positions where the vector x contains zeroes. Namely, the vector y has to be included into the set D x if and only if the weight does not exceed the value of k ε , deﬁned as the minimum integer satisfying the inequality\nwhere wt (x) denotes the weight of the vector x. However, such an assignment includes the all\u2013zero vector in all ac- ceptance sets. If Ω(y) is equal to 1 for y = (0, . . . , 0) and equal to 0 for y = (0, . . . , 0), then the attacker always gets the acceptance decision (notice that the all\u2013zero vector corresponds to the so\u2013called wolf attack on a biometric system in this case [5]).\nThe main direction of our research is the design of an authentication algorithm that has good performance and it is highly protected against information leakage. In particular, for any binary memoryless channel, the authentication algorithm is ﬁxed in such a way that the attacker cannot include his knowledge about the weight of the sample vector into the attack to increase the probability of acceptance. It gives us reasons to refer to the designed scheme as to a scheme having perfect algorithmic secrecy.\nThe probabilities of the incorrect veriﬁer\u2019s decisions, called the false rejection and the false acceptance rates, can be expressed as\nWe also introduce the type of the vector x as the probability distribution over the set X whose entries are deﬁned as relative frequencies of the symbols of the alphabet X in the vector x and denote it by P x = ( P x (x) = n x (x)/n, x ∈ X ), where\nThe regular construction is understood as a threshold\u2013type set\nwhere the function m(x, y |P x ), called the normalized accu- mulated metric between the vectors x and y , is deﬁned as an additive extension of the component\u2013wise metric,\nNotice that we emphasize the point that the metrics above can depend on the composition of the vector x . If this is the case, then (3) speciﬁes a memory containing function.\nR A : Given a probability distribution P = ( P (x), x ∈ X ) such that nP (x) is an integer for all x ∈ X ,\nThe R R requirement is oriented to practical applications of the authentication scheme. For example, the scheme should guarantee a certain false rejection rate for an arbitrary chosen person whose biometric characteristics are expressed by the vector x . In the formulation of the R A requirement, we assume that the attacker knows the type of the vector x . The fact that the attacker wants the false acceptance rate to be large for all input vectors of type P results in the conclusion that the optimum assignment of the probability distribution Ω n is a uniform distribution over the vectors of the same type ˆ Q, i.e.,\nThe distribution ˆ Q has to be chosen in such a way that T n ˆ Q = ∅ and the false acceptance rate is the maximum. An asymptotically tight approximation of (4) is the memoryless extension of the probability distribution ω(y) = ˆ Q(y), y ∈ Y.\nTo reduce the possibilities of an attacker, we assign the metric function over pairs (x, y) ∈ X × Y whose expectation over the probability distribution P x does not depend on y.\n⊙ For each vector x ∈ X n , let the component\u2013wise metric be assigned as\n) , \t (5) where\n✲ wt (x)/n 1\n❄ p\nThe authentication scheme where the component\u2013wise met- ric metric is assigned by (5) will be referred to as the P x - veriﬁcation scheme.\nis a constant for any probability distribution ω over the set Y.\nand denote Q = ( Q(y), y ∈ Y ), where Q(y) =\nProposition 2. Let (8) hold and let E =\ndenote the expectations of the normalized accumulated metric for a given vector x ∈ X n . Then\nNotice that the function at the right\u2013hand side of (11) is the information distance between the distributions (P, V ) and P × Q. The proof is given in the Appendix, and an example of the functions E and E(ω) is presented in Figure 2.\nWe conclude that the expected value of the normalized accumulated metric, expressed by (7), is a constant for any probability distribution ω. Another important characteristic of the metric is the variance computed over the ensembles under considerations,\nOne can easily see that both Var and Var (ω) tend to 0 as a function 1/n when n increases. Hence, the use of Gaussian approximations of the probability distributions of the metric allows us to conclude that both the false rejection and the false acceptance rates are exponentially vanishing functions of n. Moreover, the maximization of the false acceptance rate by an attacker is equivalent to the maximization of the variance. This point will be considered in details for binary channels.\nSuppose that V is a binary channel determined by the matrix V (0 |0) V (1|0)\nξ 1 1 − ξ 1 , where ξ 0 + ξ 1 < 1. Let us denote\nIf p = wt(x)/n, then we substitute p for P in the deﬁnition of the metric. Simple algebraic manipulations bring\nm(x, y |p) = −(1 − p) ln(1 − ξ 0 ) − p ln(1 − ξ 1 ) + (µ ξ 0 + µ ξ 1 )m \u2032 (x, y |p),\n1 − p 0 . \t (15) Therefore the set D x , deﬁned in (2), can be equivalently intro- duced as the set of vectors y ∈ Y n such that m \u2032 (x, y |p) < T \u2032 , where\nIn both cases, the pairs of vectors contain the same pairs of bits at the ﬁrst 4 positions, but their contributions to the accumulated metrics are different.\nAn implementation of the scheme can be presented as fol- lows. There are n+1 matrices specifying the component\u2013wise metric and n+ 1 values of the threshold stored in the memory. Having received the vector x , the veriﬁer ﬁnds p = wt(x)/n, reads the corresponding matrix and the threshold, computes m \u2032 (x, y |p) for the vector y using (14), (15), and checks whether it is less than the threshold or not. Let E \u2032 , E \u2032 (ω) and Var \u2032 , Var \u2032 (ω q ) are deﬁned by (9), (10) and (12), (13) when the metric m \u2032 is substituted for m.\nn \t (17) where σ 2 p = p(1 − p), σ 2 ξ = ξ(1 − ξ), σ 2 q = q(1 − q).\nNotice that the vector y is the value of a randomly chosen vector Y n = (Y 1 , . . . , Y n ) whose probability distributions in the Acc and in the Rej cases are deﬁned as\nPr { Y n = y | x} = V (y|x), Pr { Y n = y | ω q } = ω q (y).\nOne can express these distributions as products of binomial distributions. By the well\u2013known fact of probability theory, the binomial probability distribution converges to the Gaus- sian probability density function when the length of obser- vations increases, the probabilities Pr { m \u2032 (x, Y n ) = µ | x} and Pr { m \u2032 (x, Y n ) = µ | ω q } tend to Gaus(µ|E \u2032 , Var \u2032 ) and Gaus (µ |E \u2032 (ω q ), Var \u2032 (ω q )), respectively, where Gaus(µ |E, σ 2 ) denotes the Gaussian probability density function with the mean E and the variance σ 2 . In particular, if ξ 0 = ξ 1 = ξ and T \u2032 = βσ p is the threshold included into the deﬁnition of the acceptance set for the vector x , then the Gaussian approximations of the false rejection and the false acceptance rates for the p-veriﬁcation scheme are expressed as\nσ ξ \t n/2 , ˜ FAR q = 1\nIf β ∈ (2ξσ p , σ p ), then the use of the well-known estimates of the values of erf-function gives the convergence of the exponents of ˜ FRR and ˜ FAR q to the ratios (β − 2ξσ p ) 2 /(2σ 2 ξ ) and (β −σ p ) 2 )/(2σ 2 q ), respectively, and we conclude that both the false rejection and the false acceptance rates tend to 0 exponentially fast when the observation length increases. The Gaussian approximations to the probability distributions of the metric for the p-veriﬁcation scheme are illustrated in Figure 3.\nAn analysis of (16) and (17) brings the following conclu- sions.\n\u2022 The expected value of the metric in the Rej case does not depend on q.\n\u2022 The variance of the metric in the Rej case is maximized when q = 1/2. If the threshold T p is greater than σ 2 p , then the attacker, who presents either the all\u2013zero or the all\u2013 one vector, always passes through the veriﬁcation with the acceptance decision. If T < σ 2 p , then the attacker has to choose an q ∈ (0, 1), since he would always get the rejection decision otherwise. At least when the probability distribution of the metric is Gaussian, the maximum deviation from the expected value is attained when the attacker maximizes the variance of the metric. As a result, we come to the claim that the p-veriﬁcation scheme has a perfect algorithmic secrecy in the Rej case, meaning the following considerations. For any cryptographic scheme, including our veriﬁcation scheme, there is a blind attacker, who presents a vector generated by ﬂipping a fair coin with probabilities of 0\u2019s and 1\u2019s equal to 1/2. It turns out that if the attacker is informed about the weight of the vector x and the veriﬁcation algorithm, then he cannot include this knowledge into the attack and it does not change the fair coin tossing strategy.\n\u2022 The expected value of the metric in the Acc case is less than the expected values of the metric in the Rej case.\n\u2022 If p ∈ {0, 1}, then the variances of the metric vanish with the length as the function 1/n in all cases under considera- tion.\n\u2022 The ratios of the expected value of the metric and the square root of the variance are proportional to σ p\nfalse acceptance and the false rejection rates are determined by the exponent of the square of this ratio taken with the negative sign. Hence, the performance essentially depends on p and the smallest probabilities of error are reached when p = 1/2.\nA similar analysis with the Gaussian approximations for the maximum likelihood (ML) veriﬁcation scheme, when the veriﬁer computes the Hamming distance between the vectors\nx and y , brings the conclusion that the performance essen- tially depends on parameter q. Let ˜ FRR ∗ and ˜ FAR ∗ q denote the estimates of the false rejection and the false acceptance rates for the ML-veriﬁcation scheme. If q = q ∗ , where q ∗ maximizes ˜ FAR ∗ q , the result differs from the false acceptance rate attained with q = 1/2 by several orders of magnitude (see Table I). Furthermore, we can prove that for any binary symmetric channel, the p-veriﬁcation scheme brings a better performance than the ML-veriﬁcation scheme in a sense that\n\u2022 The values of the metric function deﬁned by (5), (6) depend on V for non-binary channels, but the properties above are preserved.\nThe veriﬁcation algorithm is an important cryptographic tool of any data transmission scheme. We demonstrated this point for the authentication setup where the vector generated by a legitimate user is transmitted to the veriﬁer over a binary memoryless channel. If the attacker\u2019s capabilities are restricted to the generation of a vector according to a memoryless\nµ/σ p ✻\nVar = 0.25σ 2 p /n Var = σ 2 q σ 2 p /n\nprobability distribution and the p-veriﬁcation algorithm is used, then the generation of the vector by ﬂipping a fair coin (the probabilities of zeroes and ones are equal to 1/2) is the attack, which maximizes the false acceptance rate. As a result, the attacker becomes equivalent to a blind attacker, who is ignorant both about the weight of the input vector and parameters of the channel.\n1 n\nSimilarly, if the vector y is generated independently of the vector x according to the memoryless extension of the prob- ability distribution ω, then\n1 n\nThe absolute value of the difference of the obtained equalities is equal to the expression at the right-hand side of (11), since"},"refs":[{"authors":[{"name":"A. Ros"},{"name":"A. K. Jai"},{"name":"D. Zhan"}],"title":{"text":"Handbook on Multibiometrics"}},{"authors":[{"name":"A. K. Jain"},{"name":"A. Ross"},{"name":"S. Pankanti"}],"title":{"text":"An introduction to biometric recogni- tion"}},{"authors":[{"name":"D. Bhattacharyya"},{"name":"R. Ranjian"},{"name":"F. Alisherov"},{"name":"M. Choi"}],"title":{"text":"Biometric au- thentication: A review"}},{"authors":[{"name":"V. B. Balakirsky"},{"name":"A. J. Han Vinck"}],"title":{"text":"Biometric authentication based on signiﬁcant parameters\u201d, Lecture Notes in Computer Science: \u201cBiometrics and ID management"}},{"authors":[{"name":"M. Inuma"},{"name":"A. Otsuka"},{"name":"H. Imai"}],"title":{"text":"Theoretical framework for constructing matching algorithms in biometric authentication systems"}},{"authors":[{"name":"V. B. Balakirsky"},{"name":"A. J. Han Vinck"}],"title":{"text":"Performance of the veriﬁcation for binary memoryless channels"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569555811.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T6.1","endtime":"10:10","authors":"Vladimir Balakirsky, Han Vinck","date":"1341481800000","papertitle":"Authentication over Noisy Data with the Use of Memory Containing Metric Functions","starttime":"09:50","session":"S11.T6: Authentication and Signatures","room":"Kresge Rehearsal A (033)","paperid":"1569555811"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
