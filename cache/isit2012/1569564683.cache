{"id":"1569564683","paper":{"title":{"text":"On Fast and Memory-Efﬁcient Construction of an Antidictionary Array"},"authors":[{"name":"Hirotada Fukae"},{"name":"Takahiro Ota"},{"name":"Hiroyoshi Morita"}],"abstr":{"text":"Abstract\u2014 An antidictionary, a set of words that never appear in a given string, is a useful data structure for source coding as well as other ﬁelds of computer sciences. A fast and memory- efﬁcient algorithm for constructing antidictionaries by means of sufﬁx array is presented. We prove that the proposed algorithm constructs an antidictionary array with linear time and space."},"body":{"text":"Crochemore et al. [1] originally introduced an antidic- tionary, which is a set of minimal forbidden words, for a lossless data compression in 2000. A minimal forbidden word is a string of minimal length which never appears on a given input string. Various antidictionary codes have been proposed so far [2]\u2013[4]. Experimental results show that a version of antidictionary codes by Ota and Morita [4] performs as well as an efﬁcient off-line data compression algorithm using the Burrows-Wheeler transformation [5]. Up to the present, there have been proposed three efﬁcient algorithms [6]\u2013[8] for constructing antidictionaries as far as the authors know. For their construction, a sufﬁx automaton and a sufﬁx tree are utilized by Crochemore et al. [6] and Ota and Morita [7], [8], respectively. Although their algorithms are guaranteed to construct an antidictionary with time and space proportional to length of a given string, their complexity often exceed the machine power for 10 ∼100M byte data.\nTo resolve the issues on the complexities, Fiala and Holub [3] proposed a new construction algorithm of anti- dictionary by means of a sufﬁx array in 2008 since it is known that a sufﬁx array can be constructed with linear time and space complexity [9] as well and it has a much smaller proportional coefﬁcient of the time and space complexities compared with a sufﬁx automaton and a sufﬁx tree. However, their algorithm requires O(n log n) time and O(n) space with respect to input string length n.\nIn this paper, we propose a variation of a construction algorithm of antidictionary by means of a sufﬁx array. In addition to the sufﬁx array, we also introduce a new data structure, called L-array [10], which represents the length of the longest common preﬁx between two consecutive sufﬁxes in the sufﬁx array. Moreover, we show that the proposed algorithm works in O(n) time and space.\nLet X be a ﬁnite source alphabet {ξ 1 , ξ 2 , . . . , ξ m }. Let X ∗ be the set of all ﬁnite strings over X , including the empty string of length zero, denoted by λ. The length of a string x\nis denoted by |x|, and note that we also use | · | to represent a cardinality of a set and array. For a given string x, by letting n = |x|, a substring x j i is deﬁned as\nλ \t (i > j). \t (1) Hereafter, without any notice, we assume that the length of x is always given by n. Hence, the substring x n 1 of x equals x.\nLet P(x) and S(x) be the set of all preﬁxes and sufﬁxes of x, respectively.\nP(x) = {x i 1 |1 ≤ i ≤ n} ∪ {λ}, \t (2) S(x) = {x n j |1 ≤ j ≤ n} ∪ {λ}. \t (3)\nFor a given x n 1 , let π(x n 1 ) and σ(x n 1 ) be x n −1 1 ∈ P(x n 1 ) and x n 2 ∈ S(x n 1 ) For convenience, we deﬁne π(λ) = λ and σ(λ) = λ. For a non-negative integer k, let π k (x n 1 ) and σ k (x n 1 ) be the functions π( ·) and σ(·) applied k times to a string x n 1 , respectively, where π 0 (x n 1 ) = x n 1 and σ 0 (x n 1 ) = x n 1 .\nA dictionary D(x) is deﬁned as the set of all substrings of x, that is,\nv k 1 / ∈ D(x) \t (5) v k −1 1 ∈ D(x) \t (6)\nis called a Minimal Forbidden Word (MFW) of x. An antidic- tionary A(x) is the set of all MFWs of x. For convenience, we deﬁne D(λ) = {λ} and A(λ) = X . For example, A(x) for x = 122132 and X = {1, 2, 3, 4} is given by {4, 11, 23, 31, 33, 121, 212, 222, 321, 322}.\nLet lcp(v, w) be the length of the longest common preﬁx between v and w in X ∗ , that is,\nA sufﬁx x n j of x can be represented by its starting index j. A sufﬁx array S is an array consisting of n + 1 integers that represents the starting indexes of all the sufﬁxes of x in the following lexicographical order:\nFirstly, we introduce the total order into X , that is, ξ i < ξ j for 1 ≤ i < j ≤ m. For convenience, λ < ξ 1 . Secondly, for\nstrings v and w ∈ X ∗ \\{λ}, v is said to be smaller than w in the lexicographical order, denoted by v ≺ w, if and only if\nThen, S(x) can be written as S(x) = {s 0 , . . . , s n } (s i ≺ s j , 0 ≤ i < j ≤ n) where s 0 = λ. For convenience, we deﬁne s −1 = s n+1 = ⊥ where ⊥ represents the sentinel such that ⊥/∈ X ∗ . And set lcp( ⊥, v) = lcp(v, ⊥) = −1 for v ∈ X ∗ . Let the kth component of S, denoted by S[k], be deﬁned as\nIn other words, σ S[k] −1 (x) = s k . For x = 22212, S is represented as an array ⟨6, 4, 5, 3, 2, 1⟩ since S(x) = {λ, 12, 2, 212,2212, 22212}.\nLet L be an array of integers, called L-array, in which the ith component is given by lcp(s i , s i+1 ) for two adjacent sufﬁxes s i and s i+1 where the index i runs from −1 to n. The array L is also called hight array [10]. Note that L[ −1] = L[n] = −1 and |L| = n + 2. For example, L is ⟨ − 1, 0, 0, 1, 1, 2, −1⟩ for x = 22212.\nFor u ∈ D(x) and a ∈ X , the set of head symbols X H (u) of u is deﬁned as\nwhere a is called head symbol. Note that X H (λ) is a set of all symbols which appear in x, and X H (u) is the empty set ϕ iff u appears in x only once and u ∈P(x). For u∈D(x), a difference set between X H (π(u)) and X H (u), denoted by H(u), is deﬁned as\nFor u ∈D(x), there exists v ∈S(x) having u as its preﬁx, that is, v = uz for z ∈ X ∗ . A cover set C(u) is a set of successive indexes i of s i \u2019s such that u is a preﬁx of s i ;\nwhere C(λ) = {0, 1, . . . , n}. Moreover, let C(u). min and C(u). max be C(u). min = min{i | i ∈ C(u)} and C(u). max = max{i | i ∈ C(u)}, respectively. For example, for x = 22212 and u = 22, C(u) = {4, 5}. By using C(u), X H (u) can be written by\nAn antidictionary A(x) can be represented by a ∈ H(u) and u ∈ D(x) from Theorem 1.\nProof: We ﬁrst assume that au ∈A(x). From (7), a∈X and u ∈ D(x). In case of u = λ, a /∈ D(x). Since X H (λ) is the set of all symbols which appear in x, a ∈ X \\X H (λ). In\ncase of u ̸= λ, a ∈ X H (π(u)) \\X H (u) since au / ∈ D(x) and aπ(u) ∈ D(x). Hence, A(x)⊂{au | a∈H(u), u∈D(x)}.\nNext, we assume a ∈ H(u) and u ∈ D(x). In case of u = λ, X \\X H (λ) is the set of all symbols which never appear in x. Hence, if a ∈ X \\X H (λ), then a ∈ A(x). In case of u ̸= λ, au ∈ A(x) since aπ(u) ∈ D(x) and au /∈ D(x) from (12). Hence, {au | a ∈ H(u), u ∈ D(x)} ⊂ A(x).\nIf H(u) ̸= ϕ for u ∈ D(x), we call u MFW candidate. Let G T (x) be a set of all MFW candidates of x, that is,\nAs described in the next section, we use G T (x) and H(u) for u ∈G T (x) to construct A(x). B. Properties of Cover Set\nProposition 1. If C(u)⊂C(v) and |v|≤|u| for u, v ∈D(x), then v ∈P(u) and vice versa.\nProof: We ﬁrst assume that C(u) ⊂ C(v) and |v| ≤ |u|. Then, there exists i ∈ C(u) such that u ∈ P(s i ) and v ∈ P(s i ), which implies that v ∈ P(u).\nNext, we assume that v ∈ P(u). Clearly, |v| ≤ |u| holds. Since u is written as u = vw where w ∈ D(x), there exists a sufﬁx s i such that vw ∈ P(s i ). Moreover, since v ∈ P(s i ), i ∈ C(v). Therefore, C(u) ⊂ C(v).\nwhere p and q are C(u). min and C(u). max, respectively. Moreover, if p < q, then |u|≤min{L[i] | p≤i≤q−1}.\nProof: From (13), 0 ≤ p ≤ q ≤ n. In case of p = 0, L[p − 1]=L[−1]=−1. Since |u|≥0, we have |u|>L[p − 1]. In case of 1 ≤ p ≤ n, u /∈ P(s p −1 ) from (13). Therefore, |u| > lcp(s p −1 , u). Moreover, since s p = uv for v ∈ X ∗ , lcp(s p −1 , u) = lcp(s p −1 , s p ) = L[p − 1]<|u|.\nIn case of q = n, L[q] = L[n] = −1 holds. Since |u| ≥ 0, |u| > L[q]. In case of 0 ≤ q ≤ n−1, u /∈ P(s q+1 ) from (13). Therefore, |u| > lcp(u, s q+1 ). Moreover, since s q = uw for w ∈X ∗ , lcp(u, s q+1 ) = lcp(s q , s q+1 ) = L[q] < |u|. Thus, (17) holds.\nNext, if p < q, then u ∈ P(s k ) for p ≤ k ≤ q. Therefore, |u| ≤ min{L[i] | p ≤ i ≤ q − 1} since |u| ≤ L[j] for p ≤ j ≤ q − 1.\nSince |D(x)| in (15) is proportional to n 2 in the worst case, a na¨ıve construction of A(x) requires O(n 2 ) time. The next theorem gives a ground to construct an antidictionary with O(n) computational time.\nTheorem 2. For x ∈ X ∗ , G T (x) ⊂G(x) and |G(x)|≤2n+1. To prove Theorem 2, we ﬁrst give Lemmas 1 and 2\ndescribed below. Before showing the lemmas, we prepare a few more notations. For i (0 ≤ i ≤ n), partition P(s i ) into two disjoint subsets F(i) and E(i) deﬁned by\nF(i)={v∈P(s i ) ||v|̸=lcp(s i , s k )+1, −1≤k ≤n+1}, (18) E(i)={v∈P(s i ) ||v|=lcp(s i , s k )+1, −1≤k ≤n+1}. (19)\nMoreover, for s i (0 ≤ i ≤ n), let ¯u i ∈ P(s i ) and ¯ d i ∈ P(s i ) be the strings such that\n|¯u i | = L[i − 1] + 1, \t (20) |¯d i | = L[i] + 1≤|s i |. \t (21)\nNote that, for ¯ u i and ¯ d i , both C(¯u i ). min and C(¯d i ). max equal i and in case of L[i] = |s i |, ¯d i does not exist.\nProof: We assume that H(v) ̸= ϕ. Since λ ∈ E(i), we consider the case that v ∈ P(s i ) \\{λ}. From the assumption, there exists a ∈ X H (π(v)) \\X H (v) = H(v). Therefore, aπ(v) ∈ D(x) and av = aπ(v)b /∈ D(x) hold. Moreover, there exists w ∈ X ∗ such that aπ(v)w ∈ D(x) and b /∈ P(w). Since lcp(π(v)b, π(v)w) = |π(v)| and π(v)b is a preﬁx of s i , lcp(s i , π(v)w) = |π(v)|.\nOn the other hand, since π(v)w ∈ D(x), there exists k such that s k has π(v)w as its preﬁx. Therefore, lcp(s i , s k ) = |π(v)|. However, since |v| = |π(v)| + 1, it contradicts the assumption |v| ̸= lcp(s i , s k ) + 1. Therefore, H(v) = ϕ.\nLemma 2. If z ∈ E(i), then there exists k such that z = ¯u k or z = ¯ d k .\nProof: Let l and m be C(z). min and C(z). max, respec- tively. From (19) and since S(x) is an array of all sorted sufﬁxes, |z| = lcp(s l −1 , s i ) + 1 or |z| = lcp(s i , s m+1 ) + 1. Moreover, from (13), lcp(s l −1 , s i ) = lcp(s l −1 , s l ) and lcp(s i , s m+1 ) = lcp(s m , s m+1 ). Since lcp(s l −1 , s l ) + 1 = L[l −1]+1 and lcp(s m , s m+1 )+1 = L[m]+1, |z| = L[l−1]+1 or |z| = L[m] + 1. Therefore, k is given by m or l − 1. It completes the proof.\nFrom Lemmas 1 and 2, a set of MFW candidates, denoted by G(x), is given by\n(Proof of Theorem 2): For u ∈ D(x)\\G(x), there exists k such that u ∈ F(k) since D(x) can be written by {v | v ∈ P(s i ), 0 ≤ i ≤ n}. Therefore, from Lemma 1, |H(u)| = 0. On the other hand, u ∈ D(x) and |H(u)| ≥ 0 for u ∈ G(x). Therefore, from (16), G T (x) ⊂ G(x) holds. From (20) and (21), {¯u i } is a singleton set and {¯d i } is a singleton set or ϕ. Since L[ −1] = L[n] = −1, {¯u 0 } = {¯d n } = {λ}. If n ≥ 1, then {¯d 0 } = ϕ for s 0 = λ and L[0] = 0. Therefore, | ∪ n i=0 ( {¯u i } ∪ {¯d i })| ≤ 2n + 1. Hence, |G(x)| ≤ 2n + 1.\nFrom Theorem 2, the upper bound of the total number of MFW candidates is at most 2n+1. From (20) and (21), ¯ u i and ¯ d i can be obtained in a constant time by means of S and L.\nOn the other hand, we need to sort all elements of G(x) to calculate both X H (v) and X H (π(v)) for a given v ∈ G(x) in a constant time. Here, G(x) can be written as\nwhere m = |G(x)|−1 and g 0 = λ. Moreover, from (14), both C(v). min and C(v). max are required to calculate X H (v). Therefore, g i is represented by a triplet\n{¯u i } and ∪ n i=0 {¯d i }. We construct G(x) from G U (x) and G D (x) by mean of the Merge Sort [11] in linear time. Then, G U (x) and G D (x) can be written as\nG U (x) = {u 0 , . . . , u n } (u i ≺u j , 0 ≤i<j ≤n), \t (25) G D (x) = {d 0 , . . . , d k } (d i ≺d j , 0 ≤i<j ≤k, k =|G D (x) |).\nSince ¯ u i and ¯ d i are also represented by (24), we will give Propositions 3 and 4 to construct G U (x), G D (x), and G(x).\nProposition 3. For u, v ∈ D(x), if C(u). min < C(v). min, then u ≺ v.\nProof: Let C(u). min and C(v). min be i and j, respec- tively. From (13), u ∈ P(s i ), and v ∈ P(s j ). From (13) and i < j, i / ∈ C(v). Therefore, from (13), u /∈ P(s j ). Moreover, since s i ≺ s j , u ≺ v holds.\nSince C(¯u i ). min = i, C(¯u i ). min < C(¯u j ). min holds for j such that 0 ≤ i < j ≤ n. Therefore, Corollary 1 holds.\nCorollary 1. For ¯ u i and ¯ u j such that 0 ≤i<j ≤n, ¯u i ≺ ¯u j . From Corollary 1, G U (x) can be written as ⟨¯u 0 , . . . , ¯ u n ⟩.\nIn other words, ¯ u i = u i (0 ≤ i ≤ n). To construct G D (x) and G(x) in O(n) time, we give Proposition 4.\nProposition 4. For u, v ∈ D(x), if C(u). min = C(v). min and C(u). max > C(v). max, then u ≺ v.\nProof: From (13), C(v)⊊C(u). We assume that |u|≥|v|. For p ∈ C(u)∩C(v), u ∈ P(s p ) and v ∈ P(s p ). Therefore, from the assumption |u| ≥ |v|, C(u) ⊂ C(v). It contradicts the assumption C(v) ⊊ C(u). Hence, |u| < |v| holds. Since |u| < |v| and C(v) ⊂ C(u), from Proposition 1, u ≺ v.\nIn a na¨ıve construction of ¯ u i , we do obtain |¯u i | and C(¯u i ). min in (24) in a constant time while we may not do C(¯u i ). max so. On the other hand, from Proposition 2, C(¯u i ). max = min {j | |¯u i | > L[j], i ≤ j ≤ n}. In other words, for a given i, C(¯u i ). max is the nearest small right neighborhood. Similarly, in a na¨ıve construction of ¯ d i , we obtain |¯d i | and C(¯d i ). max in (24) in a constant time while we may not C(¯d i ). max. On the other hand, from Proposition 2, C(¯d i ). max = max {k | |¯d i | > L[k − 1], 0 ≤ k ≤ i}. Thus, C(¯d i ). max is the nearest small left neighborhood. The total time of the nearest right and left small neighborhood is O(n) and the details are described in this section. Note that a ﬁnding nearest large (small) neighborhood algorithm in linear complexity has been proposed [12].\nWe now present the algorithm to construct G(x) in linear time. We will use a stack s to store integers as its elements. Let s.push ( ·) and s.pop () be the functions to store and retrieve elements from the stack, respectively, and let s.is empty () be the function to check whether the stack is empty. If d i does not exists for i, we denote ¯ d i by ε. Moreover, for g ∈ G(x), let g.len, g.min, and g.max be |g|, C(g). min, and C(g). max, respectively. The algorithm uses the procedure merge sort ( G U (x), G D (x)) to construct G(x) using the Merge Sort algorithm by means of Propositions 3 and 4. In the Merge Sort, notice that if a string is already stored in G(x), then its\nduplicate is never added to G(x). The outline of the algorithm is as follows.\nIn Step 2 and Step 3, ﬁnding the nearest right (resp. left) small neighborhoods for u i . len and d i . len are imple- mented, respectively. Moreover, in Step 3, G D (x) is built from {¯d i | ¯d i ̸= ε, 0 ≤ i ≤ n}. For ¯d i and ¯ d j (i < j), since C(¯d i ). max < C(¯d j ). max, {¯d i | ¯d i ̸= ε, 0 ≤ i ≤ n} is a set of sorted strings with respect to the maximum value of their cover sets. From Propositions 3 and 4, G D (x) can be built from {¯d i |¯d i ̸= ε, 0 ≤ i ≤ n} by means of the nearest small left neighborhood searching algorithm. Step 4 uses Propositions 3 and 4 to sort strings in G U (x) and G D (x) by the Merge Sort. B. Construction of Sets of Head Symbols\nFor g i ( ̸= λ), let l(i) be an integer such that l(i) = max {j | j < i, |g j | < |g i |}. For a given g i , to calculate X H (π(g i )) in a constant time, we ﬁrst show Proposition 5.\nProposition 5. For a given g i ( ̸=λ), X H (π(g i )) = X H (g l(i) ). Proof: Since G(x) is an array of sorted strings, g l(i) is\nthe longest string in P(g i ) ∩ {g 0 , . . . , g i −1 }. Moreover, since |g l(i) | < |g i |, g l(i) ∈ P(π(g i )). Hence, from Proposition 1,\nC(π(g i )) ⊂C(g l(i) ). In case of |π(g i ) | = |g l(i) |, since π(g i ) = g l(i) , X H (π(g i )) = X H (g l(i) ) holds.\nNext, we consider the case that |g l(i) | < |π(g i ) |. We assume that C(g l(i) ) \\C(π(g i )) ̸= ϕ. For j ∈ C(g l(i) ) ∩ C(π(g i )) and k ∈ C(g l(i) ) \\C(π(g i )), lcp(s j , s k ) = |g l(i) | since g l(i) ∈ P(π(g i )). Hence, from (19), there exists w ∈ X ∗ such that w ∈ E(j) and |w| = |g l(i) | + 1 so that w ∈ G(x) from Lemma 2. On the other hand, since g l(i) , w ∈ P(g i ) and |g l(i) | < |w| < |g i |, g l(i) ≺ w ≺ g i . However, it contradicts the maximality of g l(i) since g l(i) ≺ w ≺ g i and |g l(i) | < |w| < |g i |. Hence, C(g l(i) ) \\C(π(g i )) = ϕ. Therefore, from (14), X H (π(g i )) = X H (g l(i) ).\nFrom Corollary 2, to obtain X H (π(g i )), we can utilize g l(i) instead of π(g i ).\nWe now present the algorithm to construct H(g i ) in linear time. Let X H (i) and H be X H (g i ) and an array of H(g i ), re- spectively. For a given a ∈X , X H (i). add(a) and H(u).add(a) add a symbol a to X H (i) and H(u), respectively.\nFor a given a and u, if Λ(a) ∈ C(u), then a ∈ X H (u). Thus, Step 2 uses the fact whether g k . min ≤ Λ(a) ≤ g k . max is satisﬁed or not. Step 3-1 calculates l(i) , and g l(i) is the nearest left small neighborhood for g i with respect to string length. Step3-2 utilizes Proposition 5.\nFrom Theorem 1, A(x) can be constructed from G(x) and H. We now present the algorithm to construct A(x) in linear time. In the proposed algorithm, an MFW u (= av) is represented by a triplet (a, i, l) where a ∈ H(u), i is the start index of v in x, and l = |v|. In case of u = λ, l = 0. The algorithm uses the procedure construct sufﬁx array (x) and construct L array (x, S) to construct S and L using the algorithm presented in [9] and [10], respectively. The outline of the algorithm is as follows.\nTheorem 3. For a given string x of length n, T (n) = O(n). We ﬁrst prove Theorems 4 and 5 to prove Theorem 3.\nFor a given string x of length n, let T G (n) and T H (n) be time complexity of the construct G and construct H algorithm, respectively.\nTheorem 4. For a given string x of length n, T G (n) = O(n). Sketch of Proof: Let T 1 , T 2 , T 3 , and T 4 be the execution\ntime of Step 1, Step 2, Step 3 and Step 4, respectively. The time complexity T G (n) of the proposed algorithm can thus be expressed by T G (n) = T 1 + T 2 + T 3 + T 4 . From Theorem 2, both T 1 and T 4 are O(n). In Step 2 and Step 3, the upper bound on the number of times of s.push ( ·) is 2n+2. The number of times of s.pop () is also upper bounded by 2n+2. Therefore, T 2 and T 3 are O(n). Hence, T G (n) = O(n).\nTheorem 5. For a given string x of length n, T H (n) = O(n). Sketch of Proof: Let T 1 , T 2 , T 3 , T 31 , and T 32 be the\nexecution time of Step 1, Step 2, Step 3, Step 3-1, and Step 3- 2, respectively. The time complexity T H (n) of the proposed algorithm can thus be expressed by T H (n) = T 1 + T 2 + T 3 .\nAs for T 1 , T 1 = O(1). In Step 2, since 0 ≤ i ≤ n and from Theorem 2, the total number of times of operations in lines 10-16 is upper bounded by 3n+1. Hence, T 2 = O(n). For T 3 , T 3 = T 31 + T 32 + c where c is a positive constant. In Step 3-1, the number of times of s.push ( ·) and s.pop () is upper bounded by 2n since g 0 has the strictly smallest length 0 among all the elements of the stack. Hence, T 31 = O(n). Since T 32 = O(n), T 3 = O(n). Therefore, T H (n) = O(n).\n(Sketch of Proof of Theorem 3): Let T 1 , T 2 , T 3 , T 4 , and T 5 be the execution time of Step 1, Step 2, Step 3, Step 4, and Step 5, respectively. The time complexity T (n) of the proposed algorithm can thus be expressed by T (n) = T 1 + T 2 + T 3 + T 4 + T 5 .\nFrom [9], T 1 = O(n), and from [10], T 2 = O(n). Moreover, from Theorem 4, T 3 = O(n), and from Theorem 5, T 4 = O(n). From Theorem 2, since |G(x)| ≤ 2n + 1, T 5 = O(n). It follows that T (n) = O(n).\nFrom Theorem 3, the proposed algorithm SA2AD works in linear time. Moreover, the proposed algorithm works in linear space. The proof with respect to computational space is omitted here.\nWe presented a fast and memory-efﬁcient algorithm for the construction of the antidictionary of a given string, and we showed that the time and space complexity is linear with the string length. This allows antidictionary codes to use extremely longer string lengths and thus yield better compression."},"refs":[{"authors":[{"name":"M. Crochemore"},{"name":"F. Mignosi"},{"name":"A. Restivo"},{"name":"S. Salemi"}],"title":{"text":"Data Compres- sion Using Antidictionaries"}},{"authors":[{"name":"M. Crochemore"},{"name":"C. Epifanio"},{"name":"R. Grossi"},{"name":"F. Mignosi"}],"title":{"text":"A Trie-Based Approach for Compacting Automata"}},{"authors":[{"name":"M. Fiala"},{"name":"J. Holub"}],"title":{"text":"DCA Using Sufﬁx Arrays"}},{"authors":[{"name":"T. Ota"},{"name":"H. Morita"}],"title":{"text":"On the Adaptive Antidictionary Code Using Minimal Forbidden Words with Constant Lengths"}},{"authors":[{"name":"M. Burrows"},{"name":"J. Wheeler"}],"title":{"text":"A Block-Sorting Lossless Data Compres- sion Algorithm"}},{"authors":[{"name":"M. Crochemore"},{"name":"F. Mignosi"},{"name":"A. Restivo"}],"title":{"text":"Automata and Forbidden Words"}},{"authors":[{"name":"T. Ota"},{"name":"H. Morita"}],"title":{"text":"On the Construction of an Antidictionary with Linear Complexity Using the Sufﬁx Tree"}},{"authors":[{"name":"T. Ota"},{"name":"H. Morita"},{"name":"H. Fukae"}],"title":{"text":"On the Dynamic Construction of an Antidictionary with Linear Complexity"}},{"authors":[{"name":"J. K¨arkk¨ainen"},{"name":"P. Sanders"}],"title":{"text":"Simple Linear Work Sufﬁx Array Con- struction"}},{"authors":[{"name":"T. Kasai"},{"name":"G. Lee"},{"name":"H. Arimura"},{"name":"S. Arikawa"},{"name":"K. Park"}],"title":{"text":"Linear- Time Longest-Common-Preﬁx Computation in Sufﬁx Arrays and Its Applications"}},{"authors":[],"title":{"text":"R"}},{"authors":[{"name":"T. Asano"},{"name":"S. Bereg"},{"name":"D. Kirkpatrick"}],"title":{"text":"Finding Nearest Larger Neighbors -A Case Study in Algorithm Design and Analysis-"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564683.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S7.T1.2","endtime":"15:20","authors":"Hirotada Fukae, Takahiro Ota, Hiroyoshi Morita","date":"1341327600000","papertitle":"On Fast and Memory-Efficient Construction of an Antidictionary Array","starttime":"15:00","session":"S7.T1: Lossless and Universal Source Coding","room":"Kresge Rehearsal B (030)","paperid":"1569564683"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
