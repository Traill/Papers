{"id":"1569565919","paper":{"title":{"text":"An Achievable Region for the Wiretap Multiple-Access Channel with Common Message"},"authors":[{"name":"Moritz Wiese"},{"name":"Holger Boche"}],"abstr":{"text":"Abstract\u2014We derive a rate region which is achievable by the Wiretap MAC with Common Message under the strong secrecy criterion. We follow Devetak\u2019s approach to establishing strong secrecy. Using the concentration of the normed sum of bounded i.i.d. random variables around its mean, it is possible to show the existence of a code where the channel outputs at the eavesdropper are almost independent of the messages. The encoders may use a certain amount of common randomness. We give the example of a channel where the availability of common randomness is necessary for secret transmission."},"body":{"text":"This paper studies the discrete memoryless Multiple Access Channel (MAC) where communication is overheard by a second receiver named Eve who acts as an eavesdropper. The encoders Alice 1 and Alice 2 have a private message each and a common message all of which need to be kept secret from Eve, whereas the intended receiver Bob should be able to decode all messages with arbitrarily small average error, see Fig. I. We apply the strong secrecy criterion. In order to satisfy this criterion, the encoders may use some amount of common randomness measured by its entropy. Conditional on this randomness, they can additionally apply independent stochastic encoding. The result of this paper will be the basis for deriving a strongly secret rate region for the wiretap MAC with conferencing encoders as in [18]. This is the basic model for base station cooperation and requires to keep track of the common randomness used by the encoders.\nWe use Devetak\u2019s approach [7] to establishing strong se- crecy, which was originally used to establish strong secrecy in the Quantum Wiretap channel with classical inputs. In contrast to the weak secrecy criterion introduced in the papers of Wyner [19] and Csisz´ar and K¨orner [6], only the strong secrecy criterion has been given an operational meaning so far. It was shown in [1] that if the strong secrecy criterion is satisﬁed, then the average error of the non-legitimate user for any decoding scheme it might apply tends to one as the codelength tends to inﬁnity. The strong secrecy criterion was used, among others, in [2][3][4][13].\nWe do not obtain a converse, but a single-letter achievable region. This is in contrast to [9], where a multi-letter achiev- able region for the wiretap MAC with external eavesdroppers, without common message nor common randomness is derived under the weak secrecy criterion. For special \u201cweak\u201d wiretap MACs, a multi-letter converse is found.\nThere are many other ways of incorporating secrecy issues into MAC models. For example, each encoder may obtain generalized feedback and want to keep the other sender instead of an eavesdropper uninformed about its message [8][11][12]. The case where the encoders have access to generalized feedback but do not have to keep their messages secret from each other, but from an external eavesdropper, is considered in [16].\nIn the cognitive MAC, the encoders have a common mes- sage and one has a private message. If there is no eavesdropper, the encoder without a private message obtains a noisy version of the codeword sent by the other encoder and must be kept ignorant of the other encoder\u2019s private message [10]. In [14], the cognitive MAC without feedback was investigated where the messages must be kept secret from an eavesdropper and the encoders have unrestricted access to common randomness.\nOur paper is organized as follows. Section II contains the problem and the main result which is proved in Section III. In the last section, we discuss the result and give an example.\nNotation: We set [K] := {1, . . . , K} for positive integers K. [x] + := max(x, 0). P(X ) are the probability measures on the ﬁnite set X , and for measures µ 1 , µ 2 on X , we deﬁne the metric µ 1 − µ 2 := x∈ X |µ 1 (x) − µ 2 (x)|. δ(x, ·) is the Dirac measure with mass in x. P X is the distribution of the random variable X. For a random pair (U, X), T n U,δ denotes the U -typical n-sequences and T n X|U,δ (u) the X|U -typical n- sequences conditional on u with constant δ, see [5] for details.\nThe encoders have the ﬁnite input alphabets X and Y , respectively, Bob\u2019s alphabet is T , and Eve receives outputs from the alphabet Z . The wiretap channel is memoryless, it is determined by a stochastic matrix W : X ×Y → P(T ×Z ) whose marginals are denoted by W T and W Z , respectively.\nThe transmission of words x ∈ X n and y ∈ Y n is governed by the probabilities\nEncoding may be stochastic. We ﬁx a number H C ≥ 0 and let the encoders have access to any source of common randomness with entropy at most H C which can be used in encoding. That means that if the message sets are [K 0 ], [K 1 ], [K 2 ] for the common and the private messages, respectively, blocklength- n encoding is given by a stochastic matrix G : [K 0 ] × [K 1 ] × [K 2 ] → P(X n × Y n ) which has the form\nG(x, y|k 0 , k 1 , k 2 ) =\nHere J is a ﬁnite set and H(G 0 (·|k 0 )) ≤ nH C for every k 0 . Decoding is done deterministically in the usual way. A code with blocklength n and message sets [K 0 ], [K 1 ], [K 2 ] is called a code (n, K 0 , K 1 , K 2 ).\nA rate R is achievable if for every ε > 0 there is for sufﬁciently large n a code (n, K 0 , K 1 , K 2 ) satisfying\nP[φ(T n ) = (M 0 , M 1 , M 2 )] ≤ ε, I(M 0 , M 1 , M 2 ∧ Z n ) ≤ ε,\nwhere the M ν are uniformly distributed on [K ν ] (ν = 0, 1, 2), where φ is the decoder of the code (n, K 0 , K 1 , K 2 ) and where T n and Z n are the output random variables at Bob and Eve, respectively, induced by the random message selection, the stochastic encoding, and transmission over the channel.\nLet U , V 1 , V 2 be ﬁnite alphabets and let U, (V 1 , V 2 ), (X, Y ), (T, Z) be a Markov chain with U taking values in U , with V 1 , V 2 taking values in V 1 and V 2 and independent conditional on U , with X only depending on V 1 and Y only depending on V 2 and with P T Z|XY = W . We denote the joint distribution of this Markov chain by p. If H C = 0, we need that U is single-valued, i.e. we have independent inputs. For H C > 0, the form of the rate region achievable with input distribution p depends on the information between the inputs and Eve\u2019s outputs. Due to lack of space we concentrate here on the most challenging case that I(Z ∧ U ) < H C ≤ min{I(Z ∧ V 1 , U ), I(Z ∧ V 2 , U )}.\nI(Z ∧ V 1 |U ) ≤ I(T ∧ V 1 |V 2 , U ), \t (1) I(Z ∧ V 2 |U ) ≤ I(T ∧ V 2 |V 1 , U ), \t (2)\nI(Z ∧ V 1 , V 2 |U ) ≤ I(T ∧ V 1 |V 2 , U ) + I(Z ∧ V 2 |V 1 , U ), (3) I(Z ∧ V 1 , V 2 ) ≤ I(T ∧ V 1 , V 2 ). \t (4)\n− [I(Z ∧ V 2 |V 1 , U ) − I(T ∧ V 2 |V 1 , U )] + , R 2 ≤ I(T ∧ V 2 |V 1 , U ) − I(Z ∧ V 2 |U )\n− [I(Z ∧ V 1 |V 2 , U ) − I(T ∧ V 1 |V 2 , U )] + , R 1 + R 2 ≤ I(T ∧ V 1 , V 2 |U ) − I(Z ∧ V 1 , V 2 |U ),\nWe set p ∈ Π 0 if U is deterministic and (1)-(4) are satisﬁed. R(p) is deﬁned analogously in this case except that the transmission of a common message is impossible.\nTheorem 1. For the common randomness entropy limited by H C ≥ 0, an achievable rate region for the wiretap MAC with common message is given by\nwhere conv is the convex hull operator. III. T HE P ROOF\nwhere η = P Z n ⊗P M 0 M 1 M 2 −P Z n M 0 M 1 M 2 . Thus if η tends to zero exponentially and if the K ν do not grow faster than exponentially, then I(Z n ∧ M 0 , M 1 , M 2 ) also tends to zero exponentially. If there is a measure θ on Z n satisfying\nfor some β > 0 uniformly in k 0 , k 1 , k 2 , then η is exponentially small, because\nThus for secrecy, it is sufﬁcient to show (5). We concentrate on proving the achievability of those sets R(p) whose p does not involve the auxiliary random variables V 1 , V 2 . These can be included in the usual way by preﬁxing them to W independently at the two encoders. Note that no common randomness is needed to do that. Thus let a p ∈ Π H C be given which is the joint probability distribution of random variables U, (X, Y ), (T, Z). We use a random code construction. Let a family {(U l 0 k\n)} be given, where k 0 , k 1 , k 2 are messages and l ν ∈ [L ν ], ν = 0, 1, 2 are indices needed in stochastic encoding. The U l 0 k\nare conditionally i.i.d. on X n according to\non Y n according to P Y n |U n which is deﬁned analogously to P X n |U n with x replaced by y and X replaced by Y . Following Devetak\u2019s approach [7], we obtain the fol- lowing bounds (6)-(8) on the L ν that need to be satisﬁed to establish (5):\nlog L 0 ≥ n(I(Z ∧ U ) + 4τ ), \t (6) log L 1 ≥ n(I(Z ∧ X|Y, U ) + 4τ ), \t (7) log L 2 ≥ n(I(Z ∧ Y |U ) + 4τ ). \t (8)\nAn alternative triple of bounds (6\u2019)-(8\u2019) can be obtained with X and Y exchanged. τ depends on δ and τ \t 0 as δ → 0. (6)-(8) and (6\u2019)-(8\u2019) ensure that the probability of obtaining a realization of the random variables {U l 0 k\n} for which (5) is not true is exponentially small. The proofs of (6)-(8) all build on the following Chernoff-Hoeffding bound.\nLemma 2. Let b > 0. For an independent sequence of random variables Z 1 , . . . , Z L with values in [0, b] with µ l := E[X l ] and µ := 1 L l µ l , one has\n1 L\nIn order to make use of Lemma 2, we need to exploit the structure of the random family. For (6)-(8), we use that\nare i.i.d. given the U l 0 k 0 and the U l 0 k 0 are unconditionally i.i.d. Analogous properties are used for (6\u2019)-(8\u2019). All the applications of Lemma 2 involve modiﬁcations of W Z which are necessary to obtain useful estimates. They can be undone with small error after choosing an appropriate realization of the random variables as the modiﬁcations are restrictions to typicality. Due to lack of space, we cannot go into the details of the proof of (6)-(8), but we describe the settings to which Lemma 2 is applied. For every (k 0 , k 1 , k 2 ), the corresponding random variables exhibit the same behavior, so we pick one (k 0 , k 1 , k 2 ) and omit these indices here. Starting with (7), let (u, y) ∈ T n U Y,2δ and\nThis will give a bound on the random variables corresponding to the b from Lemma 2. τ > 0 is chosen later when\nθ uy (z) := E[W ⊗n Z (z|X 11 , y)1 E(u,X 11 ,y) (z)|U 1 = u], F 1 (u, y) := {z ∈ T n Z|Y U,2| X |δ (y, u) :\nand θ uy := θ uy · 1 F 1 (u,y) . This will provide a lower bound on the mean of the random variables used. We set E 2 (u, x, y) := E 1 (u, x, y) ∩ F 1 (u, y). For every z ∈ Z n and every (l 0 , l 2 ), let A 1 (l 0 , l 2 , z) be the event\nThen, conditioning on all possible realizations of U l 0 , Y l 0 l 2 adn applying the law of total probability, one obtains with Lemma 2 for n sufﬁciently large\n(9) We denote the intersection of all A 1 (l 0 , l 2 , z) as l 0 , l 2 and z are varied by A 1 .\nFurther set θ u = θ u · 1 F 2 (u) and E 0 (u, x, y) := E 2 (u, x, y) ∩ F 2 (u, y). For every l 0 and z ∈ Z n , let A 2 (l 0 , z) be the event\nThe ﬁrst term in the above bound comes from the probability that conditional on any realization of U l 0 , Y l 0 l 2 , the family {X l 0 l 1 : l 1 ∈ [L 1 ]} does not satisfy A 1 (l 0 , l 2 , z) . The second term is obtained by an application of Lemma 2 to the L 2 normed sums over l 1 of random variables found in the deﬁnition of A 2 (l 0 , z) where the realizations of the X l 0 l 1 do satisfy A 1 (l 0 , l 2 , z) for every realization of U l 0 , Y l 0 l 2 . F 2 (u) again gives a lower bound on their mean. We denote the intersection of the A 2 (l 0 , z) by A 2 .\nNext we consider (6). We also need A 2 (z), the intersection over l 0 of the A 2 (l 0 , z). For every z deﬁne a new probability measure ˆ P z := P[·|A 2 (z)]. Let θ (z) := ˆ E z [θ U 1\nFinally, set θ := θ · 1 F 0 . For z ∈ F 0 let A 0 (z) be the event that\nHere we again use the law of total probability. The ﬁrst two terms in (11) come from the bound on P[A 2 (l 0 , z) c ]. The third term results from an application of Lemma 2 to the L 0 random variables appearing in the deﬁnition of A 0 (z) which are i.i.d. conditional on A 2 (z) with respect to ˆ P z . We denote the intersection of all A 0 (z) by A 0 .\nLemma 2 also establishes that given l 0 , l 2 , most of the X l 0 l 1 : l 1 ∈ [L 1 ] are typical conditional on (Y l 0 l 2 , U l 0 ) with high probability. For every (l 0 , l 2 ) let the event A ∗ (l 0 , l 2 ) be deﬁned by\nA ∗ (l 0 , l 2 ) := |{l 1 ∈ [L 1 ] : X l 0 l 1 ∈ T n X|Y U,δ (Y l 0 l 2 , U l 0 )}| ≥ (1 − ε)(1 − 2 · 2 −ncδ 2 )L 1 }.\nIf ε = 2 −nβ for sufﬁciently small β > 0 and L 0 , L 1 , L 2 are chosen according to (6)-(8), then the bounds (9)-(12) tend to zero doubly-exponentially. By symmetry, it is possible to prove an analogous sequence of statements where the roles of the X l 0 l 1 and Y l 0 l 2 are exchanged. This gives the alternative bounds (6\u2019)-(8\u2019).\nNow we use the indices k 0 , k 1 , k 2 again. Before passing to a realization of our random variables, we need to consider the transmission of messages to Bob. By the coding theorem for the MAC W T with common message and without an eavesdropper [15], all rate triples ( ˜ R 0 , ˜ R 1 , ˜ R 2 ) are achievable that are contained in the set ˜ R(p) deﬁned by\n˜ R 1 ≤ I(T ∧ X|Y, U ), ˜ R 2 ≤ I(T ∧ Y |X, U ),\n˜ R 1 + ˜ R 2 ≤ I(T ∧ X, Y |U ), ˜ R 0 + ˜ R 1 + ˜ R 2 ≤ I(T ∧ X, Y ).\nIt is easy to see that with probability exponentially close to 1, the elements of {X l 0 l 1 k\n: k 0 , . . . , l 2 } are the codewords of a deterministic code for the non-wiretap MAC W T with common message with an exponentially small average error if (1/n)(log(K 0 L 0 ) + η, log(K 1 L 1 ) + η, log(K 2 L 2 ) + η) is contained in ˜ R(p) for some η > 0.\nIn particular, this requires (1/n)(log(L 0 ) + η, log(L 1 ) + η, log(L 2 ) + η) ∈ ˜ R(p). This does not have to be true for the vector I (1) := (I(Z ∧ U ), I(Z ∧ X|Y, U ), I(Z ∧ Y |U ))\nnor its analog I (2) with the roles of X and Y exchanged. However, a convex combination of the two might be contained in ˜ R(p). Thus we have to include time-sharing in the random coding structure instead of doing it after derandomization as usual. We need two families of random variables as above, one with blocklength n 1 , the other with blocklength n 2 , and with message and randomization sets [K (1) ν ], [L (1) ν ] and [K (2) ν ], [L (2) ν ], respectively (ν = 0, 1, 2). For the ﬁrst of these families, we know that A ∗ ∩ A 0 ∩ A 1 ∩ A 2 holds and that it is the deterministic codeword set for a non-wiretap MAC code\nwith exponentially high probability. Analogous statements are true for the second family, where the roles of X and Y\nare exchanged in (9)-(12). Thus we can conclude that there is a realization of the two families satisfying all the above events. We thus obtain for the two concatenated parts ν = 1, 2 of the code independent stochastic encoders G (1) , G (2) . They are deﬁned analogously. For G (ν) set J (ν) = [L (ν) 0 ] and G (ν) 0 (l (ν) 0 |k (ν) 0 ) := 1/L (ν) 0 . Given k (ν) 0 , k (ν) 1 , l (ν) 0 , Alice 1 chooses the codeword x l (ν) 0 l (ν) 1\nability 1/L (ν) 2 . For δ small and L 0 = L (1) 0 L (2) 0 close to its bound (6), the encoder satisﬁes the common randomness restriction because of I(Z ∧ U ) < H C . Bob can still decode all messages from the Alices using the deterministic MAC encoder given by the realization of the random variables. If n 1 /(n 1 + n 2 ) ≈ α ∈ [0, 1] , then the rates achieved by this code are approximately\nR 1 ≈ I(T ∧ X|Y, U ) − αI(Z ∧ X|Y, U ) − (1 − α)I(Z ∧ X|U ),\nR 2 ≈ I(T ∧ Y |X, U ) − αI(Z ∧ Y |U ) − (1 − α)I(Z ∧ Y |Y, U ),\nR 1 + R 2 ≈ I(T ∧ X, Y |U ) − I(Z ∧ X, Y )|U ), R 0 + R 1 + R 2 ≈ I(T ∧ X, Y ) − I(Z ∧ X, Y ).\nWe denote the rate region deﬁned by the bounds on the right- hand side by R α (p). It remains to show (5) for the chosen realization. As the encoders in the two parts of the code are independent and the channel memoryless, it is sufﬁcient to prove the secrecy of the ﬁrst part, the proof for the second being analogous. We omit the family index (also setting n 1 =: n) and introduce the symbols \t := (1/L 0 L 1 L 2 )\nWe denote the ﬁve terms by I-V in that order. I is at most ε because A 0 is satisﬁed by choice of the realization of the random family. II-IV are shown backwards. One has to apply several properties of typical sets together with assumption A 1 in IV , A 2 in III and A 0 in II. In V , we use that A ∗ is satisﬁed. Altogether this gives an upper bound on (5) of 20 · ε + 5 · 2 −ncδ 2 .\nSo far, we have proved that for every p ∈ Π H C without auxiliary random variables V 1 , V 2 , the union of all R α (p) is achievable for those α satisfying\nIt remains to determine this union and the extremal α (the con- vexity of the rate region implies that the set of permissible α is an interval). The Markovity of the sequence U, (X, Y ), (T, Z) easily implies that the union of the permissible R α (p) is the set deﬁned by the bounds\n− (1 − α 0 )I(Z ∧ X|U ), \t (13) R 2 ≤ I(T ∧ Y |X, U ) − α 1 I(Z ∧ Y |U )\n− (1 − α 1 )I(Z ∧ Y |Y, U ), (14) R 1 + R 2 ≤ I(T ∧ X, Y |U ) − I(Z ∧ X, Y )|U ), (15)\nwhere α 0 is the smallest permissible α and α 1 the largest. First note that there is no permissible α at all if (4) is not satisﬁed. (1) and (2) must be satisﬁed as α ∈ [0, 1] and (3) ensures α 0 ≤ α 1 . The extremal alphas can be determined to be\nHere we show that H C > 0 may be necessary for secret transmission. In an easy generalization of van Dijk\u2019s result [17], one sees that I(T ∧ V 1 V 2 ) − I(Z ∧ V 1 V 2 ) ≤ 0 for every input-p where V 1 and V 2 are independent, meaning that trans- mission at H C = 0 is impossible, if and only if this difference is concave in both P V 1 and P V 2 (not necessarily jointly). This is satisﬁed for the following channel: let X = Y = {0, 1}, T = GF (3), Z = {−2, . . . , 3}, and let N 1 , N 2 be random variables uniformly distributed on {0, 1}. Let the outputs t of W T and the outputs z of W Z be given by\nThe concavity of the above difference of mutual information terms can be shown by elementary analysis. If sufﬁcient common randomness is available to the encoders, however, the joint input distribution giving probability 1/2 to both (0, 0) and (1, 1) can be obtained. If V 1 , V 2 denote the corresponding input random variables, then I(T ∧ V 1 , V 2 ) = 1/2 and I(Z ∧ V 1 , V 2 ) = 0, so R 0 + R 1 + R 2 may be positive.\nWe conjecture this behavior to also be observable for the true capacity region of wiretap MACs. The relation to the wiretap MAC with conferencing encoders mentioned in the introduction will then imply that base station cooperation may enable secret transmission where this is not possible without.\nThis work was partly supported by the German Ministry of Education and Research (BMBF) under Grant 01BQ1050 and by the German Research Foundation (DFG) under Grant BO 1734/25-1."},"refs":[{"authors":[{"name":"I. Bjelakovi´c"},{"name":"H. Boche"},{"name":"J. Sommerfeld"}],"title":{"text":"Secrecy Results for Compound Wiretap Channels"}},{"authors":[{"name":"R. Bloch"},{"name":"N. Laneman"}],"title":{"text":"Secrecy from Resolvability"}},{"authors":[{"name":"N. Cai"},{"name":"A. Winter"},{"name":"W. Yeung"}],"title":{"text":"Quantum Privacy and Quantum Wiretap Channels"}},{"authors":[{"name":"I. Csisz´ar"}],"title":{"text":"Almost Independence and Secrecy Capacity"}},{"authors":[{"name":"I. Csisz´a"},{"name":"J. K¨orne"}],"title":{"text":"Information Theory: Coding Theorems for Discrete Memoryless Systems , 2nd edition, Cambridge: Cambridge University Press, 2011"}},{"authors":[{"name":"I. Csisz´ar"},{"name":"J. K¨orner"}],"title":{"text":"Broadcast Channels with Conﬁdential Messages"}},{"authors":[{"name":"I. Devetak"}],"title":{"text":"The Private Classical Capacity and Quantum Capacity of a Quantum Channel"}},{"authors":[{"name":"E. Ekrem"},{"name":"S. Ulukus"}],"title":{"text":"Effects of Cooperation on the secrecy of Multiple Access Channels with Generalized Feedback"}},{"authors":[{"name":"E. Ekrem"},{"name":"S. Ulukus"}],"title":{"text":"On the Secrecy of Multiple Access Wiretap Channel"}},{"authors":[{"name":"R. Liu"},{"name":"Y. Liang"},{"name":"V. Poor"}],"title":{"text":"Fading Cognitive Multiple-Access Chan- nels With Conﬁdential Messages"}},{"authors":[{"name":"Y. Liang"},{"name":"V. Poor"}],"title":{"text":"Multiple-Access Channels With Conﬁdential Messages"}},{"authors":[{"name":"R. Liu"},{"name":"I. Mari´c"},{"name":"D. Yates"},{"name":"P. Spasojevi´c"}],"title":{"text":"The Discrete Memoryless Multiple-Access Channel with Conﬁdential Messages"}},{"authors":[{"name":"M. Maurer"},{"name":"S. Wolf"}],"title":{"text":"Information-Theoretic Key Agreement: From Weak to Strong Secrecy for Free"}},{"authors":[{"name":"O. Simeone"},{"name":"A. Yener"}],"title":{"text":"The Cognitive Multiple Access Wire-Tap Channel"}},{"authors":[{"name":"D. Slepian"},{"name":"K. Wolf"}],"title":{"text":"A coding theorem for multiple access channels with correlated sources"}},{"authors":[{"name":"X. Tang"},{"name":"R. Liu"},{"name":"P. Spasojevi´c"},{"name":"H. V. Poor"}],"title":{"text":"Multiple Access Channels with Generalized Feedback and Conﬁdential Messages"}},{"authors":[{"name":"M. van Dijk"}],"title":{"text":"On a Special Class of Broadcast Channels with Conﬁ- dential Messages"}},{"authors":[{"name":"J. Willems"}],"title":{"text":"The Discrete Memoryless Multiple Access Channel with Partially Cooperating Encoders"}},{"authors":[{"name":"A. Wyner"}],"title":{"text":"The Wire-Tap Channel"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565919.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T4.4","endtime":"12:50","authors":"Moritz Wiese, Holger Boche","date":"1341232200000","papertitle":"An Achievable Region for the Wiretap Multiple-Access Channel with Common Message","starttime":"12:30","session":"S2.T4: Wiretap Channels with Feedback, Side Information, and Common Messaes","room":"Stratton 20 Chimneys (306)","paperid":"1569565919"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
