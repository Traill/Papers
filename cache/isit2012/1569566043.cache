{"id":"1569566043","paper":{"title":{"text":"On the Sum Capacity of the Discrete Memoryless Interference Channel with One-Sided Weak Interference and Mixed Interference"},"authors":[{"name":"Fangfang Zhu"},{"name":"Biao Chen"}],"abstr":{"text":"Abstract\u2014The sum capacity of a class of discrete memoryless interference channels is determined. This class of channels is deﬁned analogous to the Gaussian Z-interference channel with weak interference; as a result, the sum capacity is achieved by letting the transceiver pair subject to the interference commu- nicates at a rate such that its message can be decoded at the unintended receiver using single user detection. Moreover, this class of discrete memoryless interference channels is equivalent in capacity region to certain discrete degraded interference channels. This allows the construction of a capacity outer- bound using the capacity region of associated degraded broadcast channels. The same technique is then used to determine the sum capacity of the discrete memoryless interference channel with mixed interference. The above results allow one to determine sum capacities or capacity regions of several new discrete memoryless interference channels."},"body":{"text":"The interference channel (IC) models the situation where the transmitters communicate with their intended receivers while generating interference to unintended receivers. Despite decades of intense research, the capacity region of IC remains unknown except for a few special cases. These include in- terference channels with strong and very strong interference [1]\u2013[5]; classes of deterministic and semi-deterministic ICs [6], [7]; and classes of discrete degraded ICs [8], [9].\nParallel capacity results exist for the discrete memoryless IC (DMIC) and the Gaussian IC (GIC). Carleial ﬁrst obtained capacity region for GIC with very strong interference [1]. This result was subsequently extended by Sato [2] to that of DMICs with very strong interference. Note that the deﬁnition of DMIC with very strong interference can actually be broadened to be more consistent with its Gaussian counterpart [10]. Sato [3] and Han and Kobayashi [4] independently established in 1981 the capacity region of GIC with strong interference, where the capacity is the same as that of a compound multiple access channel. In [3] Sato also conjectured the conditions of DMICs under strong interfernce, which was eventually proved by Costa and El Gamal [5] in 1987.\nWhile the capacity region for the general GIC remains unknown, there have been recent progress in characterizing the sum capacity of certain GICs, including: GICs with one- sided weak interference [11], noisy interference [12]\u2013[14], and mixed interference [13]. This paper attempts to derive parallel sum capacity results for DMICs with weak one-sided and mixed inference. Our deﬁnitions of one-sided, weak, or mixed\ninterference are motivated by properties associated with the corresponding Gaussian channels. Some of those deﬁnitions are intimately related to those introduced in [15] which studies the capacity region of the discrete memoryless Z-channel.\nThe rest of the paper is organized as follows. Section II presents the channel model and relevant previous results. Section III deﬁnes DMICs with one-sided weak interference and derives their sum capacities. We refer to those DMICs with one-sided interference as DMZIC (i.e., discrete memoryless Z interference channel) for ease of presentation. The equivalence between the DMZIC with weak interference and the discrete degraded interference channel (DMDIC) is established which allows one to construct a capacity outer-bound for the DMZIC using the capacity region of the associated degraded broadcast channel. Section IV deﬁnes DMICs with mixed interference and derives the sum capapcity for this class of channels. Section V concludes this paper.\nA DMIC is speciﬁed by its input alphabets X 1 and X 2 , out- put alphabets Y 1 and Y 2 , and the channel transition matrices:\nA (n, 2 nR 1 , 2 nR 2 , λ 1 , λ 2 ) code for a DMIC with inde- pendent information consists of two message sets M 1 = {1, 2, · · · , 2 nR 1 } and M 2 = {1, 2, · · · , 2 nR 2 } for senders 1 and 2 respectively, two encoding functions:\nA rate pair (R 1 , R 2 ) is said to be achievable for the DMZIC if and only if there exist a sequence of (2 nR 1 , 2 nR 2 , n, λ 1 , λ 2 ) codes such that λ 1 , λ 2 → 0 as n → ∞. The capacity region of a DMZIC is deﬁned as the closure of the set of all achievable rate pairs.\nY 1 = X 1 + √ aX 2 + Z 1 , \t (4) Y 2 =\nwhere a and b are the channel coefﬁcients corresponding to the interference links, X i and Y i are the transmitted and received signals, and the channel input sequence X i1 , X i2 , · · · , X in is subject to the power constraint\nand Z 2 are Gaussian noises with zero mean and unit variance, independent of X 1 , X 2 .\nSason in [11] proved that the sum capacity for GICs with one-sided weak interference (a < 1 and b = 0) is\nMotahari and Khandani in [13] established that the sum capacity for GICs with mixed interference (a ≤ 1 and b ≥ 1) is\nWe attempt to extend these results to DMICs with appropri- ately deﬁned one-sided weak interference and mixed interfer- ence.\nThe following properties of Markov chains are useful throughout the paper:\n\u2022 Decomposition: X − Y − ZW =⇒ X − Y − Z; \u2022 Weak Union: X − Y − ZW =⇒ X − Y W − Z;\n\u2022 Contraction: (X − Y − Z) and (X − Y Z − W ) =⇒ X − Y − ZW .\np(y 2 |x 2 ) = p(y 2 |x 1 x 2 ), \t (6) for all x 1 , x 2 , y 2 , or equivalently,\nforms a Markov chain, this DMIC is said to have one-sided interference.\nWe refer to such DMIC as simply DMZIC. The deﬁnition is a natural extension of that for Gaussian ZIC where X 2 causes interference on Y 1 . From the deﬁnition, it follows that X 1 and Y 2 are independent for all input distribution p(x 1 )p(x 2 ).\nTo deﬁne DMZIC with weak interference, we ﬁrst revisit some properties of Gaussian ZIC with weak interference. Similar to that established in [15], it is straightforward to show that a Gaussian ZIC with weak interference is equivalent in its capacity region to a degraded Gaussian ZIC satisfying the Markov chain\nThis is referred in [15] as degraded Gaussian Z channel of type-I. This motivates us to deﬁne DMZIC with weak interference as follows.\nDeﬁnition 2: A DMZIC is said to have weak interference if the channel transition probability factorizes as\nfor some p (y 1 |x 1 y 2 ), or, equivalently, the channel is stochas- tically degraded.\nIn the absence of receiver cooperation, a stochastically degraded interference channel is equivalent in its capacity to a physically degraded interference channel. As such, we will as- sume in the following that the channel is physically degraded, i.e., the DMZIC admits the Markov chain X 2 −(X 1 , Y 2 ) −Y 1 . As a consequence, the following inequality holds\np(y 1 y 2 |x 1 x 2 ) = p(y 2 |x 1 x 2 )p(y 1 |x 1 x 2 y 2 ) = p(y 2 |x 2 )p(y 1 |x 1 y 2 ).\nThe above deﬁnition of weak interference leads to the following sum capacity result.\nTheorem 1: The sum capacity of a DMZIC with weak interference as deﬁned above is\nProof: This sum rate is achieved by two receivers de- coding their own messages while treating any interference, if present, as noise.\nwhere U i \t Y i −1 2 for all i, (a) follows the Fano\u2019s In- equality, (b) is from the chain rule and the deﬁnition of mutual information, (c) is because of the fact that con- ditioning reduces entropy, and that Y 2i is independent of any other random variables given X 2i , (d) is due to the memoryless property of the channel and the fact that Y 1i is independent of any other random variables given X 1i and Y 2i , then (X n 1,i , Y 1i ) − (X i −1 1 , Y i −1 2 ) − Y i −1 1 forms a Markov chain. By the weak union property, the Markov chain Y 1i − (X n 1 , Y i −1 2 ) − Y i −1 1 holds; (e) is because of the Markov chain (X i −1 1 , X n 1,i+1 ) − (X 1i , Y i −1 2 ) − Y 1i . The easiest way to prove it is using the Independence Graph. Alternatively, we ﬁrst note that the Markov chain\nholds, since given X 1i and Y 2i , Y 1i is independent of X i −1 1 , X n 1,i+1 , Y i −1 2 . By the weak union property, the follow- ing Markov chain is obtained:\nbecause of the independence between Y n 2 and X n 1 , we get the Markov chain:\nby the contraction property. Again, using the weak union property and then the decomposition property, we obtain the Markov chain\nas desired. Since U i and X 1i are independent, then p(x 1 x 2 u) = p(x 1 )p(u, x 2 ), thus (f ) comes from (10). Finally,\n(g) follows from the Markov chain U i − X 2i − Y 2i . At last, by introducing a time-sharing random variable Q, one obtains\nRemark 1: The Markov chain (8) is a sufﬁcient, but not necessary, condition for the mutual information condition\nfor all product input distribution on X 1 × X 2 . One can ﬁnd examples such that the mutual information condition holds but the Markov chain is not valid. This is different from that of the Gaussian case; it can be shown that the coefﬁcient a ≤ 1 in a Gaussian ZIC is a sufﬁcient and necessary condition for (12) to hold. It is yet unknown if condition (12) is sufﬁcient for the sum capacity result (11) to hold for DMZIC with weak interference.\nB. Capacity Outer-bound for DMZIC with Weak Interference For Gaussian ZICs with weak interference, Sato [2] ob-\ntained an outer-bound using the capacity region of a related Gaussian broadcast channel constructed due to the equivalence in capacity between a GZIC with weak interference and a degraded GIC. The same technique can be used to obtain a capacity outer-bound for DMZIC with weak interference, i.e., that satisﬁes the Markov chain X 2 −(X 1 , Y 2 ) −Y 1 . Speciﬁcally, for any such DMZIC with weak interference, one can ﬁnd an equivalent (in capacity region) DMDIC whose capacity region is bounded by that of an associated degraded broadcast channel.\nTheorem 2: For a DMZIC that satisﬁes the Markov chain X 2 − X 1 Y 2 − Y 1 , the capacity region is outer-bounded by\nwhere U −X 1 X 2 −Y 2 −Y 1 forms a Markov chain and U = min { Y 1 , Y 2 , X 1 · X 2 }.\nProof: Suppose that the DMZIC with weak interference has inputs and outputs X 1 , X 2 and Y 1 , Y 2 respectively. Let us denote by X 1 , X 2 and Y 1 , Y 2 the inputs and outputs of another DMIC. Set X 1 = X 1 , X 2 = X 2 , and Y 1 = Y 1 but deﬁne Y 2 to be a bijection of X 1 and Y 2 , denoted as Y 2 = f (X 1 , Y 2 ). As the Markov chain (X 1 , X 2 ) − Y 2 − Y 1 holds, the DMIC speciﬁed by the input pair (X 1 , X 2 ), and the output pair (Y 1 , Y 2 ) is indeed a DMDIC.\nThe proof that this DMDIC has the same capacity region as the speciﬁed DMZIC, and hence is outer-bounded by the associated broadcast channel follows in exactly the same fashion as Costa\u2019s proof for the Gaussian case [16], hence is omitted here.\nRemark 2: The output Y 2 need not necessarily be a bijection function of X 1 and Y 2 ; instead, depending on the transition probability p(y 1 |x 1 y 2 ), other Y 2 can be constructed. However, the associated broadcast channels would have the same the capacity region. It will become clear in the following example.\nExample 1: Let X 1 = X 2 = Y 1 = Y 2 = 2 and the channel transition probability be given by\nUsing Theorem 2, the capacity region of the DMZIC is outer-bounded by that of the associated DMDBC:\nIf one takes the bijection function to construct Y 2 , it will lead to the same outer-bound. If we ﬁx R 2 to be x, then\nwhere f T ( ·) is a function deﬁned by Witsenhausen and Wyner [17]. Fig. 1 depicts the new outer-bound speciﬁed by\nThis new outer-bound signiﬁcantly improves upon the follow- ing bound\nR 1 ≤ I(X 1 ; Y 1 |X 2 ), R 2 ≤ I(X 2 ; Y 2 ),\nDeﬁnition 3: A DMIC is said to have mixed interference if it satisﬁes the Markov chain\nThis deﬁnition is motivated by GIC with mixed interference, which can be shown to be equivalent in capacity region to a degraded GIC satisfying (13) by setting p(y 1 y 2 |x 1 x 2 ) = p(y 2 |x 1 x 2 )p (y 1 |x 1 y 2 ), where p (y 1 |x 1 y 2 ) is normal distribu- tion with mean (1 −\n2 and variance 1 − a. The sum capacity for GIC with mixed interference was established in [13]. We obtain a parallel result for the DMIC with mixed interference as deﬁned above.\nTheorem 3: The sum capacity of the DMIC with mixed interference satisfying the two conditions (13) and (14) is\nProof: In order to achieve this sum rate, user 1 transmits its message at a rate such that both receivers can decode it by treating the signal from user 2 as noise; user 2 transmits at the interference-free rate since receiver 2 is able to subtract the interference from user X 1 .\nFor the converse, we prove the following two sum rate bounds separately:\nFor (16), the derivation follows the same steps as Costa and El Gamal\u2019s result [5]. For (17), we use similar techniques for establishing the sum capacity of the DMZIC with weak interference in Section III. First, notice that (13) implies\nwhere (a) is because of the independence between X n 1 and X n 2 ; (b) is from the fact that conditioning reduces entropy and U i \t (X i −1 1 X n 1,i+1 , Y i −1 2 ); (c) is from (18); and (d) is because the memoryless property of the channel and (19). Finally, from (16) and (17), we have\nWe give the following example where the obtained sum capacity helps determine the capacity region of a DMIC.\nwhere the input and output alphabets X 1 , X 2 , Y 1 and Y 2 = {0, 1}. Notice that this channel does not satisfy the condition of the deterministic interference channel in [6]. Obviously, the Markov chain (13) holds. Moreover,\nfor all possible input product distributions on X 1 × X 2 . Therefore, this is a DMIC with mixed interference. Apply Theorem 3, we compute the sum capacity is\nGiven that (1, 0) and (0, 1) are both trivially achievable, the above sum capacity leads to the capacity region for this DMIC to be {(R 1 , R 2 ) : R 1 + R 2 ≤ 1}.\nIn this paper, we derived the sum capacity for the DMZICs with weak interference where weak interference is deﬁned using a Markov condition. Similar techniques are then applied to derive the sum capacity for DMIC with mixed interference. Both results are analogous to the sum capacity results for the corresponding Gaussian channel, both in the expression of the capacity and in the encoding schemes that achieve the capacity.\nThe weak interference condition is deﬁned using a Markov chain, as opposed to that using the mutual information in- equality. While it appears to be somewhat restrictive, it is not known whether the deﬁnition using the mutual information condition will lead to the same sum capacity result."},"refs":[{"authors":[{"name":"A. B. Carleial"}],"title":{"text":"A case where interference does not reduce capacity"}},{"authors":[{"name":"H. Sato"}],"title":{"text":"On the capacity region of a discrete two-user channel for strong interference"}},{"authors":[{"name":"H. Sato"}],"title":{"text":"The capacity of the Gaussian interference channel under strong interference"}},{"authors":[{"name":"T. S. Han"},{"name":"K. Kobayashi"}],"title":{"text":"A new achievable rate region for the interference channel"}},{"authors":[{"name":"M. H. M. Costa"},{"name":"A. El Gamal"}],"title":{"text":"The capacity region of the discrete memoryless interference channel with strong interference"}},{"authors":[{"name":"A. El Gamal"},{"name":"M. H. M. Costa"}],"title":{"text":"The capacity regio of a class of deterministic interference channels"}},{"authors":[{"name":"H. F. Chong"},{"name":"M. Motani"}],"title":{"text":"The capacity region of a class of semideterministic interference channels"}},{"authors":[{"name":"R. Benzel"}],"title":{"text":"The capacity region of a class of discrete additive degraded interference channels"}},{"authors":[{"name":"N. Liu"},{"name":"S. Ulukus"}],"title":{"text":"The capacity region of a class of discrete degraded interference channels"}},{"authors":[{"name":"J. Xu"},{"name":"H. Chen"},{"name":"B. Chen"}],"title":{"text":"New observation on interference channels under strong/very strong interference"}},{"authors":[{"name":"I. Sason"}],"title":{"text":"On achievable rate regions for the Gaussian interference channels"}},{"authors":[{"name":"X. Shang"},{"name":"G. Kramer"},{"name":"B. Chen"}],"title":{"text":"A new outer bound and the noisy- interference sum-rate capacity for Gaussian interference channels"}},{"authors":[{"name":"A. S. Motahari"},{"name":"A. K. Khandani"}],"title":{"text":"Capacity bounds for the Gaussian interference channel"}},{"authors":[{"name":"V. S. Annapureddy"},{"name":"V. V. Veeravalli"}],"title":{"text":"Gaussian interference networks: sum capacity in the low-interference regime and new outer bounds on the capacity region"}},{"authors":[{"name":"H. F. Chong"},{"name":"M. Motani"},{"name":"H. K. Garg"}],"title":{"text":"Capacity theorems for the \u201cZ\u201d channel"}},{"authors":[{"name":"M. H. M. Costa"}],"title":{"text":"On the Gaussian interference channel"}},{"authors":[{"name":"H. S. Witsenhausen"},{"name":"A. D. Wyner"}],"title":{"text":"A conditional entropy bound for a pair of discrete random variables"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566043.pdf"},"links":[{"id":"1569566381","weight":11},{"id":"1569566485","weight":23},{"id":"1569566725","weight":7},{"id":"1569567049","weight":23},{"id":"1569564635","weight":3},{"id":"1569565067","weight":15},{"id":"1569565691","weight":3},{"id":"1569566981","weight":3},{"id":"1569566683","weight":7},{"id":"1569559259","weight":3},{"id":"1569566597","weight":7},{"id":"1569566591","weight":15},{"id":"1569556029","weight":3},{"id":"1569552245","weight":3},{"id":"1569564481","weight":7},{"id":"1569566415","weight":3},{"id":"1569566469","weight":7},{"id":"1569565355","weight":3},{"id":"1569565931","weight":11},{"id":"1569551535","weight":3},{"id":"1569564245","weight":3},{"id":"1569566207","weight":3},{"id":"1569564227","weight":3},{"id":"1569565837","weight":3},{"id":"1569566671","weight":3},{"id":"1569566319","weight":7},{"id":"1569566941","weight":3},{"id":"1569558459","weight":3},{"id":"1569564203","weight":15},{"id":"1569566821","weight":3},{"id":"1569556713","weight":3},{"id":"1569566843","weight":11},{"id":"1569558483","weight":3},{"id":"1569566173","weight":3},{"id":"1569565455","weight":3},{"id":"1569566709","weight":3},{"id":"1569566523","weight":3},{"id":"1569551763","weight":3},{"id":"1569565953","weight":3},{"id":"1569564613","weight":3},{"id":"1569566095","weight":3},{"id":"1569565907","weight":3},{"id":"1569566239","weight":3},{"id":"1569566733","weight":7},{"id":"1569566753","weight":3},{"id":"1569566311","weight":3},{"id":"1569566063","weight":7},{"id":"1569558681","weight":3},{"id":"1569555999","weight":3},{"id":"1569566643","weight":3},{"id":"1569565841","weight":3},{"id":"1569566531","weight":7},{"id":"1569561143","weight":3},{"id":"1569565833","weight":23},{"id":"1569564611","weight":11},{"id":"1569566325","weight":3},{"id":"1569566423","weight":3},{"id":"1569567015","weight":3},{"id":"1569566437","weight":3},{"id":"1569553909","weight":3},{"id":"1569562285","weight":3},{"id":"1569553537","weight":3},{"id":"1569565427","weight":3},{"id":"1569567051","weight":3},{"id":"1569566231","weight":7},{"id":"1569554881","weight":7},{"id":"1569566371","weight":11},{"id":"1569565655","weight":7},{"id":"1569566127","weight":3},{"id":"1569558985","weight":3},{"id":"1569564333","weight":3},{"id":"1569565033","weight":11},{"id":"1569557083","weight":3},{"id":"1569565055","weight":3},{"id":"1569555879","weight":7},{"id":"1569565219","weight":3},{"id":"1569558509","weight":7},{"id":"1569566553","weight":7},{"id":"1569564969","weight":3},{"id":"1569566593","weight":42},{"id":"1569565029","weight":3},{"id":"1569565357","weight":3},{"id":"1569561245","weight":7},{"id":"1569566505","weight":3},{"id":"1569565393","weight":3},{"id":"1569566191","weight":3},{"id":"1569565527","weight":7},{"id":"1569565363","weight":7},{"id":"1569566695","weight":3},{"id":"1569566051","weight":3},{"id":"1569566673","weight":3},{"id":"1569565441","weight":7},{"id":"1569566233","weight":7},{"id":"1569566667","weight":3},{"id":"1569566407","weight":3},{"id":"1569566501","weight":3},{"id":"1569566481","weight":19},{"id":"1569565961","weight":7},{"id":"1569566387","weight":11},{"id":"1569565463","weight":7},{"id":"1569562551","weight":3},{"id":"1569563395","weight":19},{"id":"1569551347","weight":3},{"id":"1569555367","weight":3},{"id":"1569566805","weight":3},{"id":"1569565549","weight":3},{"id":"1569565611","weight":19},{"id":"1569566097","weight":7},{"id":"1569565397","weight":3},{"id":"1569565435","weight":7},{"id":"1569557275","weight":3},{"id":"1569565263","weight":3},{"id":"1569566261","weight":3},{"id":"1569565919","weight":3},{"id":"1569565661","weight":7},{"id":"1569566267","weight":7},{"id":"1569564131","weight":19},{"id":"1569561221","weight":3},{"id":"1569566917","weight":3},{"id":"1569566691","weight":3},{"id":"1569565177","weight":3},{"id":"1569566823","weight":7},{"id":"1569565375","weight":3},{"id":"1569566813","weight":11},{"id":"1569565293","weight":38},{"id":"1569565457","weight":3},{"id":"1569556759","weight":3},{"id":"1569565271","weight":3},{"id":"1569565669","weight":11},{"id":"1569565233","weight":3},{"id":"1569560235","weight":7},{"id":"1569566817","weight":3},{"id":"1569564157","weight":7},{"id":"1569566911","weight":3},{"id":"1569564923","weight":7},{"id":"1569566299","weight":11},{"id":"1569564281","weight":3},{"id":"1569564769","weight":3},{"id":"1569565769","weight":3},{"id":"1569566933","weight":7},{"id":"1569563919","weight":3},{"id":"1569557851","weight":11},{"id":"1569565537","weight":3},{"id":"1569566457","weight":3},{"id":"1569559251","weight":7},{"id":"1569560459","weight":3},{"id":"1569550425","weight":3},{"id":"1569556327","weight":3},{"id":"1569566375","weight":3},{"id":"1569564141","weight":11},{"id":"1569561579","weight":3},{"id":"1569566987","weight":19},{"id":"1569565031","weight":3},{"id":"1569551751","weight":3},{"id":"1569564419","weight":19},{"id":"1569566067","weight":3},{"id":"1569566609","weight":7},{"id":"1569563007","weight":3},{"id":"1569566113","weight":3},{"id":"1569565315","weight":3}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T2.4","endtime":"16:00","authors":"Fangfang Zhu, Biao Chen","date":"1341502800000","papertitle":"On the Sum Capacity of the Discrete Memoryless Interference Channel with One-Sided Weak Interference and Mixed Interference","starttime":"15:40","session":"S13.T2: Interference Channels","room":"Kresge Auditorium (109)","paperid":"1569566043"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
