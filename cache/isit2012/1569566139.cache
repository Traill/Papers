{"id":"1569566139","paper":{"title":{"text":"Pliable Index Coding"},"authors":[{"name":"Siddhartha Brahma"},{"name":"Christina Fragouli"}],"abstr":{"text":"Abstract\u2014We propose a new formulation of the index coding problem, where instead of demanding a speciﬁc bit (or message), clients are \u201cpliable\u201d and are happy to receive any one bit they do not have. We prove that with this relaxation, although some instances of this problem become simple, in general the problem of ﬁnding the optimal linear code remains NP-hard. We also show that if the server has n bits, O(log n log( n log n )) coded bit transmissions are sufﬁcient to satisfy the clients in the worst case, in contrast to the Ω( n) transmissions required in index coding. We develop several approximation algorithms and evaluate their performance through simulations. 1"},"body":{"text":"In the well-known Index Coding with side-information problem (ICOD), a server holds m bits (or messages), and can broadcast over a noiseless channel to a set of n receivers or clients. Each client has as side information some subset of the m bits, and requests from the server a speciﬁc message she does not have. The objective is to devise an optimal coding strategy that minimizes the number of broadcast transmissions the server makes to satisfy the demands of all clients [4]. This problem has been proven to be NP-hard; infact, it is even hard to ﬁnd constant-factor approximations [2], [13], [11].\nBut what if the clients are \u201cpliable\u201d, and are happy to receive any one message they do not already have? There are several applications that motivate this relaxation: for example, the clients might be doing an internet search, have collected some information and are interested in receiving with low delay additional information on the subject they are searching; they do not care which speciﬁc piece of information they do receive, as long as it is something they do not already have. We term this formulation Pliable Index Coding (PICOD). In this paper, we are interested in linear coding solutions.\nOur ﬁrst question was, whether removing the speciﬁc re- quirements we can ﬁnd an optimal linear code in polynomial time. We hoped that this might be true, since we now have a signiﬁcantly larger number of choices in what to transmit to each receiver. This turns out not to be the case; we prove that the problem remains NP-hard.\nOur second question was, how many transmissions do we need in this case, i.e., what is the effect on the length of the code. In traditional index coding, it is easy to construct instances that require Ω( n) bits and even for random instances of the problem (i.e. random side information sets), Haviv et.al. [10] show that the minimum length of linear index codes is almost surely Ω(\nclients have no side information; if each one of them requests a different message, with index coding we need n transmissions, while if the clients are pliable, we can simply send any one message. Using a probabilistic argument, we in fact show that only O(log n log( n log n )) coded bits are sufﬁcient in the worst case and this improves to O(log n) (almost surely) for random side information sets (for the case m = n).\nThe ﬁnal contribution of this paper is a family of approxi- mation algorithms we develop. These are based on a bipartite graph representation of the problem and employ coverings of the graph. We present three algorithms: the ﬁrst based on a greedy covering of the graph, the second based on randomized covering and the third based on a reduction to ICOD.\nThe paper is organized as follows. After a brief survey of work related to index coding in Section II, in Section III we precisely deﬁne the PICOD problem. In Section IV, we prove that ﬁnding the optimal linear code for PICOD is NP-Hard. In Section V we prove upper bounds on the number of coded bits required to solve an instance of PICOD. In Section VI we develop several efﬁcient polynomial time approximation algorithms. In Section VII we show through simulations on random instances of the problem that the algorithms work very well in practice and the required number of broadcasts is signiﬁcantly less than that required in ICOD for similar settings.\nOver the past few years, there has been a signiﬁcant amount of work on the theory of ICOD, especially for linear codes. The problem was introduced by Birk et. al. [4] in the context of an application in satellite communication networks. Bar- Yossef et.al. [2] presented the ﬁrst theoretical analysis of the problem. They showed that the optimal length for a scalar linear index code is given by a graph functional called the minrk. They conjectured this to be true even for non-linear codes, which was disproved by Lubetzky et.al. [12]. New graph parameters were introduced in [1] showing the strict separation of optimal solutions for different ﬁeld sizes.\nBuilding on the work of [11], [9] which investigate the connections between Index Coding and Network Coding and using information theoretic linear programs Blasiak et.al [5] prove some of the best known bounds for the index coding problem. The work of Blasiak et.al [5], [6] also shows several separation results between the optimal linear and non-linear index codes. These results can also be used to come up with instances in network coding that have large gaps between linear and non-linear coding rates. There have been several other papers dealing with variants of the ICOD problem\nincluding the complementary index coding problem [7], secure index coding [8] and index coding with outerplanar side information [3].\nWe will assume that the messages are bits and encodings are linear, i.e., the encoded bits are the binary sum of uncoded bits over the ﬁeld GF (2). Suppose that the server has m information bits b 1 , · · · , b m and there are n clients c 1 , · · · , c n . Each client c i knows a subset of bits b N c [i] , where N c [i] is a strict subset of [ m]. Here b N c [i] denotes the set {b j , j ∈ N c [i]} and [ m] = {1, 2, · · · , m}. Thus N c [i] represents the indices of the bits that client c i has as side information. Given m, n and the side information sets N c [i], the linear Pliable Index Coding with Side Information (PICOD) problem is to devise a minimum length linear code C which consists of\n1) A linear encoding function E mapping x ∈ {0, 1} m to E(x) ∈ {0, 1} l , where l is the length of the code.\n2) Decoding functions D 1 , · · · , D n for the n clients such that D i (E(x), b N c [i] ) = b k i for some k i ∈ N c [i] = [m]\\ N c [i].\nAs is standard, it is assumed that the server knows the side information sets. In contrast to ICOD where the bit requirements k i ∈ N c [i] are speciﬁed precisely, in PICOD it is sufﬁcient for each client c i to learn any one bit that she does not already know. To illustrate the difference, consider the scenario shown in Figure 1. In ICOD, at least 2 broadcast transmissions are needed. Client 1 can decode b 1 from b 1 ⊕b 2 as she knows b 2 . Client 2 can decode b 2 from b 1 ⊕ b 2 as well, and client 3 gets b 3 directly. It is easy to see that one transmission does not sufﬁce in this case. On the other hand, in PICOD, it is sufﬁcient to send just b 1 ⊕ b 2 as clients 1 and 3 can decode b 1 = b 2 ⊕ (b 1 ⊕ b 2 ) while client 3 can decode b 2 = b 1 ⊕ (b 1 ⊕ b 2 ). Note that in both cases, coding does help as the number of transmissions is less than 3.\nFor given side information sets, the length of the optimal pliable index code cannot be worse than the length of the optimal index code. This is because the index code encodes for a speciﬁc set of required bits, which is just one of the many conﬁgurations allowed in the pliable case. However, as we show in this section, even for linear codes, PICOD is an NP-Hard problem. This will be accomplished by reducing the MONOTONE-1in3-SAT problem to the PICOD problem.\nGiven a 3SAT instance φ with all literals in non-negated form, the MONOTONE-1in3-SAT problem asks whether there is a satisfying assignment such that exactly one literal is True in each clause of the formula. MONOTONE-1in3-SAT has\nbeen shown to be NP-Hard by Schaefer [14]. Suppose φ is made up of M literals α i , · · · , α M and N 0 clauses\nwhere clause i is a disjunction of the literals α i,1 , α i,2 , α i,3 . The precise reduction is shown in the following lemma.\nLemma 4.1: Given an instance φ of MONOTONE-1in3- SAT as deﬁned above, there is an instance I φ,M,N 0 of linear PICOD such that φ has a satisfying assignment if and only if we can ﬁnd for I φ,M,N 0 a solution of length 1.\nProof: Given the MONOTONE-1in3-SAT instance φ, consider an instance I φ,M,N 0 of PICOD deﬁned as follows:\n1) There are N 0 clients c i , i ∈ [N 0 ] corresponding to the clauses where c i corresponds to clause i.\n2) There are M bits b j , j ∈ [M ] corresponding to the literals where bit b j corresponds to literal α j .\n3) The side information set for c i consists of all the bits that do not correspond to the literals in clause i. That is\nSuppose there exists a linear code of length 1 that is a solution to I φ,M,N 0 . It is of the following form\nimplies that PICOD is NP-Hard. Therefore, in general we cannot hope to get polynomial time algorithms for ﬁnding the minimum length code unless P=NP.\nWe know that for ICOD there are instances which require Ω(n) coded bits. Is it also the case with PICOD? We show in this section that for PICOD we can do much better. For the remaining of the paper, we will assume that m = n to simplify the exposition. Similar results can be obtained for general values of m as well.\nWe can visualize an instance of PICOD using a bipartite graph G with n vertices on one side representing the bits\n(termed as \u201cbit vertices\u201d) and n vertices on the other side representing the clients (termed as \u201cclient vertices\u201d). We will identify the vertices by the bits or clients they represent. There is an edge from b j to c i if j ∈ N c [i]. In Figure 2(a) shown above, bit b 1 is not in the side information sets of clients c 1 , c 2 , c 3 and hence is connected to them in G. In what follows, we will denote the neighborhood of c i in G by N [c i ] and its degree by d(c i ) = |N[c i ]|. N[b j ] and d(b j ) = |N[b j ]| are similarly deﬁned. We will use the term \u201csatisfy\u201d to imply that a code solves the PICOD problem for a speciﬁc subset of clients.\nConsider two bits b 1 and b 2 and their neighborhoods N [b 1 ] and N [b 2 ] in G. We distinguish the client vertices in N[b 1 ] ∪ N [b 2 ] into two types, depending on the number of bit vertices they are adjacent to. The set of client vertices that are adjacent to exactly one of the bit vertices in B, is denoted by W (B). In Figure 2(a), for B = {b 1 , b 2 }, W (B) = {c 1 , c 2 , c 4 , c 5 } and is depicted by the double circles. Note that if b 1 ⊕b 2 is sent to these |W (B)| = 4 vertices, each of them can decode a bit she does not have: c 1 and c 2 can decode b 1 = b 2 ⊕ (b 1 ⊕ b 2 ) as they know b 2 ; similarly, c 4 and c 5 can decode b 2 as they know b 1 . On the other hand, the set of clients which are adjacent to more than one bit vertex, as is {c 3 }, can decode neither b 1 nor b 2 . The same logic can be extended if B contains more than two bit vertices: if we transmit the sum of the bits in B, all the |W (B)| client vertices will be able to decode a bit they do not have; in other words, it is sufﬁcient to broadcast the sum bit to \u201csatisfy\u201d all the |W (B)| clients. We use this intuition to prove the following results.\nLemma 5.1: W.l.o.g let C = {c 1 , c 2 , . . . , c k } be a group of k client vertices and d max = max{d(c i )| i ∈ [k]} and d min = min{d(c i )| i ∈ [k]}. Let d max ≤ rd min for some ﬁxed constant r ≥ 1. Then there is a code of length O(log(k)) that \u201csatisﬁes\u201d C.\nProof: We will use a probabilistic argument. Consider the neighborhood B 0 of C in G, i.e., B 0 = ∪ k i=1 N [c i ]. Randomly select a subset B 1 of bit vertices by selecting each vertex of B 0 with probability p (which will be determined later). Then the probability P i of c i being adjacent to exactly one vertex\nThe expression p(1 − p) x is maximized for p = 1 x . Therefore by selecting p = 1 d max we get\nBy the probabilistic method, there is at least one subset of B 1 for which |W (B 1 )| ≥ k er which means the sum of the bits in B 1 can satisfy a constant fraction of the k client vertices. We are then left with at most k(1 − 1 er ) client vertices. The ratio of the maximum and minimum degrees in this set is also bounded by r and hence the argument can be repeated until only a constant number of them are left. Since the number of client vertices reduces by a constant fraction in each iteration, at most O(log(k)) coded bits are required to satisfy all the k client vertices.\nFor a general graph G representing an instance of PICOD, we use a suitable partition of the client vertices along with the above lemma to prove the following result.\nTheorem 5.2: For any PICOD instance with n bits and n client vertices, all the client vertices can be satisﬁed with a code of length O(log n log( n log n )) bits.\nProof: The degrees of the client vertices can range from 1 to n. Partition the vertices into t subsets S 1 , . . . , S t such that S i = {c l | 2 i−1 ≤ d(c l ) ≤ 2 i }. For the non-empty ones, clearly the ratio of the maximum and minimum degrees in each of the sets S i is at most 2 and t ≤ log 2 (n) . Therefore, by the previous lemma, we need at most K log(|S i |) bits to satisfy the clients in S i , for some absolute constant K. The number of coded bits required is at most\nwhere the ﬁrst inequality follows from the Arithmetic Mean- Geometric Mean inequality [15].\nTheorem 5.3: For a random PICOD instance where an edge between b j and c i in G exists with a constant probability q, for a large enough n, all the clients can be satisﬁed with O(log n) coded bit transmissions almost surely.\nProof: By the law of large numbers, the degree of each client vertex is concentrated near the mean nq. That is, for a large enough n, almost surely d(c i ) ∈ [n(q − ), n(q + )], for any > 0. If we select an < q/3, almost surely the ratio of the maximum and minimum degrees is ≤ 2. Then the claim follows from Lemma 5.1.\nIn this section we propose polynomial approximation algo- rithms for solving the linear PICOD problem. The ﬁrst two\nalgorithms are developed on the bipartite graph representation and the use of sets B and W (B), described in the beginning of Section V. They differ in the way we choose the set of bit vertices B. The third one is based on a reduction to the index coding problem.\nWe try to ﬁnd a set of bit vertices B such that |W (B)| is maximized. Rather than trying to obtain the maximum such set, we greedily ﬁnd a maximal such set. Let B = {b v 1 , · · · , b v t } be a set of bit vertices. B is a maximal set if for any vertex b v t+1 / ∈ B, |W (B ∪ {b v t+1 })| < |W (B)|. To ﬁnd a maximal set, we start with the null set and keep on adding bit vertices that greedily maximize |W (B)| in each step; we stop when no further additions are possible without decreasing |W (B)|. For example, Figure 2 represents a possible sequence of operations where B = {b 1 , b 2 , b 3 } is a maximal set. When b 3 is added, the cardinality of W (B) increases but further addition of b 4 decreases it, in which case we stop.\nOnce such a maximal set B M is obtained, an encoded bit consisting of the sum of all the bits in B M is broadcasted. The vertices in W (B M ) and all edges incident to it are removed and the algorithm is resumed for the remaining graph, until all the client vertices are satisﬁed. We call this GRCOV (for greedy cover). A simple implementation of the algorithm has a running time of O(n 3 ). While we have not been able to prove worst case approximation guarantees for GRCOV, there exist examples where GRCOV can take Ω(log n) bits while the optimal code requires just two bits. We omit them due to lack of space.\nThe RANDCOV (for randomized cover) algorithm follows the procedure in the proof of Theorem 5.2 (in Section V) to ﬁnd an encoding. The client vertices are partitioned into at most t = O(log n) groups S 1 , . . . , S t such that the ratio of the maximum and minimum degrees in each group is at most r (a ﬁxed constant). Let the maximum degree of client vertices in S i be d max,i . In the neighborhood N [S i ], we select each vertex with probability p i = 1 d max,i . If B i is the set of selected vertices, the clients in W (B i ) are satisﬁed. This process is continued until all the vertices in S i are satisﬁed. The number of randomly sampled sets required is also the number of coded bits required. This is done for each of the sets S i to ﬁnd a code for all the client vertices. Along the lines of Theorem 5.2, it can be proved that RANDCOV requires O(log n log( n log(n) ) bits in expectation. (We omit the proof due to lack of space). The expected running time of RANDCOV is O(n log 2 n).\nAlgorithm RANDCOV-PP: Although it is possible to prove bounds on the number of bits required by RANDCOV, as we shall see in the next section, a simple implementation does not perform very well as compared to GRCOV on random instances. To make it more efﬁcient we propose the following post processing phase. Let B 1 and B 2 be two sets of bit vertices and let the corresponding client vertex sets that they satisfy be W (B 1 ) and W (B 2 ) respectively. If B 1\nhas no edges to W (B 2 ) and B 2 has no edges to W (B 1 ), then by the same reasoning as above, we can send the sum of all the bits in B 1 ∪ B 2 to satisfy all the client vertices in W (B 1 ) ∪ W (B 2 ). This can be extended to include more than two sets by selecting the sets greedily. When this post- processing step is added to RANDCOV, we call the algorithm RANDCOV-PP. The expected running time of RANDCOV-PP remains O(n log 2 n).\nFinally, we propose another algorithm that is based on a reduction to the ICOD problem. In an instance of PICOD, it is sufﬁcient that c i is able to decode any one bit in N [i]. We split client c i into |N[i]| \u201cpseudo-clients\u201d each with a distinct bit from N [i] as a requirement and with the same common side information sets. Therefore, in total we get n i=1 |N[i]| pseudo-clients. This is an instance of the ICOD problem and can be solved using one of the algorithms proposed in [4]. We use the simplest one based on greedy clique cover.\nLet the set of encoded bits be E. For the greedy clique cover algorithm, each encoded bit allows for decoding in one step. In other words, each client can decode its required bit using just one encoded bit and each encoded bit can satisfy the requirements of a certain number of pseudo-clients. This naturally deﬁnes a \u201ccovering\u201d relationship where an encoded bit covers a set of pseudo-clients. Also note that each pseudo- client in fact corresponds to an original client, the one from which it was created. Therefore, for each encoded bit e t ∈ E we can deﬁne the set of original clients that it \u201ccovers\u201d as\nIn this section, we present results of extensive simulations on random instances of PICOD to evaluate the performance of the algorithms presented in the previous section. The number of clients and bits is chosen to be both n = 512. For RANDCOV and RANDCOV-PP we choose r = 3. The ﬁrst set of results correspond to random instances of PICOD generated as a function of the bit probability p bit - the probability of a client knowing a particular bit. 2 Figure 3 shows the average performance of the algorithms over several runs (more than\n10, 000 for each value of p bit ). We also plot the performance of the clique cover algorithm for ICOD presented in [4].\nAs expected, we observe a signiﬁcant difference between the performance of the PICOD algorithms and the ICOD algorithm for the same p bit . While all the three PICOD algorithms proposed above take less than 26 bits on average, the ICOD solution hovers in this range only for p bit ≥ 0.87 which is the case when the side information sets are dense. In the remaining range of p bit values, all the PICOD algorithms use fewer bits and the difference only becomes larger when the side information sets are sparser.\nAmong the four algorithms for PICOD presented in the paper, GRCOV performs by far the best. For the random graphs on which the simulations were run, arguments similar to the ones used in Section V can be used to show that it produces an encoding with the same asymptotic performance as RANDCOV, but the practical performance is much better. In fact, the maximum number of coded bits required by GRCOV (this is among the random instances in the simulation, not globally), which is also plotted in the ﬁgure, is not substan- tially different from the average number. The performance of RANDCOV-PP is substantially better than RANDCOV, especially when the side information sets are denser and hence the G is sparser. Also, the performance of RANDCOV takes a hit in this regime. Both of these are due to the fact that the number of partitions in the client vertices increases, al- though most of them are \u201cdisjoint\u201d which allows RANDCOV- PP to improve the performance signiﬁcantly. Finally, ICOD- SETCOV performs as good as GRCOV when p bit ≤ 0.5 but becomes worse as G becomes sparser. This can be partly explained by the suboptimal nature of the greedy SET-COVER algorithm that we are using.\nFinally, Figure 4 shows the average performance of the PICOD algorithms on random instances of graphs as a function of the number of different degrees of the client vertices. For example, the points corresponding to 16 on the x-axis represents the average performance of the algorithms over\nmany random graphs, where in each graph there are client vertices with degrees {1, 2, . . . , 16}, n/16 for each degree. Even in this case, GRCOV beats all the other algorithms. However, RANDCOV-PP performs signiﬁcantly better than ICOD-SETCOV over most of the range."},"refs":[{"authors":[{"name":"N. Alon"},{"name":"A. Hassidim"},{"name":"E. Lubetzky"},{"name":"U. Stav"},{"name":"A. Weinstein"}],"title":{"text":"Broad- casting with side information"}},{"authors":[{"name":"Z. Bar-Yossef"},{"name":"Y. Birk"},{"name":"T. S. Jayram"},{"name":"T. Kol"}],"title":{"text":"Index Coding with Side Information"}},{"authors":[{"name":"Y. Berliner"},{"name":"M. Langberg"}],"title":{"text":"Index coding with outerplanar side information"}},{"authors":[{"name":"Y. Birk"}],"title":{"text":"Informed-source coding-on-demand (ISCOD) over Broadcast Channels"}},{"authors":[{"name":"A. Blasiak"},{"name":"R. Kleinberg"},{"name":"E. Lubetzsky"}],"title":{"text":"Index coding via linear programming"}},{"authors":[{"name":"A. Blasiak"},{"name":"R. Kleinberg"},{"name":"E. Lubetzsky"}],"title":{"text":"Lexicographic products and the power of non-linear network coding"}},{"authors":[{"name":"M. A. R. Chaudhry"},{"name":"Z. Asad"},{"name":"A. Sprintson"},{"name":"M. Langberg"}],"title":{"text":"On the complementary index coding problem"}},{"authors":[{"name":"S. H. Dau"},{"name":"V. Skachek"},{"name":"Y. M. Chee"}],"title":{"text":"On secure index coding with side information"}},{"authors":[{"name":"S. El Rouayheb"},{"name":"A. Sprintson"},{"name":"C. Georghiades"}],"title":{"text":"On the relation between the index coding and the network coding problems"}},{"authors":[{"name":"I. Haviv"},{"name":"M. Langberg"}],"title":{"text":"On linear index coding for random graphs"}},{"authors":[{"name":"M. Langberg"},{"name":"A. Sprintson"}],"title":{"text":"On the hardness of approximating the network coding capacity"}},{"authors":[{"name":"E. Lubetzky"},{"name":"U. Stav"}],"title":{"text":"Non-linear index coding outperforming the linear optimum"}},{"authors":[{"name":"R. Peeters"}],"title":{"text":"Orthogonal representations over ﬁnite ﬁelds and the chro- matic number of graphs"}},{"authors":[],"title":{"text":"The complexity of satisﬁability problems"}},{"authors":[],"title":{"text":"The Cauchy-Schwarz Master Class"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566139.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T1.5","endtime":"16:20","authors":"Siddhartha Brahma, Christina Fragouli","date":"1341504000000","papertitle":"Pliable Index Coding","starttime":"16:00","session":"S13.T1: Index Coding","room":"Kresge Rehearsal B (030)","paperid":"1569566139"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
