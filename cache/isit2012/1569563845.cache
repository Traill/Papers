{"id":"1569563845","paper":{"title":{"text":"On Three-Receiver More Capable Channels"},"authors":[{"name":"Chandra Nair"},{"name":"Lingxiao Xia"}],"abstr":{"text":"Abstract\u2014In this paper we show that superposition coding is not optimal for three-receiver more capable channels. The optimality of superposition coding region has been open for k -receiver (k ≥ 3) more capable broadcast channel. The main contribution is in identifying a counterexample to demonstrate that superposition coding is sub-optimal. We also compute the capacity region for the counter example. On the other hand, we show that the sum-capacity for a k-receiver more capable broadcast channel is obtained by transmitting all the information to the most capable receiver."},"body":{"text":"Broadcast channel models a basic communication sce- nario where a single sender X wishes to communicate possibly different messages to multiple receivers Y 1 , ..., Y k over a noisy medium. For details of previous results on this problem the readers are encouraged to refer to Chapters 5, 8, and 9 of [1]. This paper addresses an open question in the book (open problem 5.2), and we show that superposition coding technique (the main material presented in Chapter 5) is not optimal for the three-receiver more capable channel.\nDetermining the capacity region of a two-receiver discrete memoryless broadcast channel continues to remain open as one of the most fundamental unsolved problems in this ﬁeld; yet, there has been remarkable success when there is an ordering between the decoding capabilities of the receivers. The ﬁrst such ordering is the degraded broadcast channel[3] where X → Y 1 → · · · Y k forms a Markov chain, and the optimality of superposition coding was established by Bergmans[2] and Gallager[6]. Two progressively less stringent orderings[8] called less noisy and more capable were introduced by Korner and Marton. The optimality of the superposition coding scheme for these classes for the two-receiver case were established in [8], [5], respectively. The optimality of superposition coding for three-receiver less noisy broadcast channels was established in [10]. Our results here show that superposition coding is not optimal for three-receiver more capable channels. This represents the ﬁrst instance where an ordering on the decodability of the receivers is established, yet superposition coding is not optimal.\nIt has been shown in [7] that the more-capable ordering is a much weaker ordering than less noisy ordering. In particular it was shown that if one substitutes a receiver (in a two-receiver broadcast channel) by a more-capable receiver then the capacity region could strictly decrease (!). Further it was also shown that such a phenomenon would\nnot occur for less noisy ordering. Hence our result should not come as very surprising. However, based on the work in [7], a natural instinct for beating the superposition coding\u2019s achievable region would be to show that the maximum sum-rate achieved by superposition coding region is strictly smaller than the sum-rate capacity. This fails because, as we show later, the sum-rate capacity can be achieved by transmitting only to the best receiver. Furthermore, since the capacity region would indeed reduce to the time-division region when all the channels have the same point-to-point capacity, which is the class studied in [7], we cannot conclude in a straightforward manner from the results in [7] that superposition coding is sub-optimal. Therefore, even though this work is based on one of the authors\u2019 insights in [7], the counterexample is nevertheless interesting.\nDeﬁnition 1. A receiver Y 1 is said to be more capable than receiver Y 2 if the following holds: for every -error channel codebook 1 of size 2 nR from sender X to Y 2 , there exists an\n-error channel codebook of size 2 n (R−δ) from sender X to Y 1 where δ, → 0 as → 0.\nRemark: This is essentially equivalent to saying that Y 1 could decode any codebook that Y 2 could decode.\nKorner and Marton[8] showed that the above deﬁnition is equivalent to the following:\nDeﬁnition 2. A receiver Y 1 is said to be more capa- ble than receiver Y 2 if the following holds: I(X; Y 1 ) ≥ I (X; Y 2 ), ∀p(x).\nEl Gamal[5] showed that superposition coding is optimal, i.e. achieves the capacity region, for any two-receiver more capable broadcast channel. Note that the deﬁnition of more capable induces a partial ordering among the receivers (or equivalently probability transition matrices), hence we are assuming here that the three receivers satisfy an induced more capable ordering.\nDeﬁnition 3. A three-receiver more capable channel con- sists of a single sender X and three receivers Y 1 , Y 2 and Y 3 such that the mutual information I(X; Y 1 ), I(X; Y 2 ) and I (X; Y 3 ) satisﬁes I(X; Y 1 ) ≥ I(X; Y 2 ) ≥ I(X; Y 3 ) for any ﬁxed distribution p(x) on X.\ntion coding region for the three receiver broadcast channel. We select the natural order induced by the more capable ordering for superposition coding.\nTheorem 1. The following set, S, obtained by taking the union of all non-negative rate triples (R 1 , R 2 , R 3 ) satisfying\nover all pairs of random variables (U 2 , U 3 ) such that (U 2 , U 3 ) → X → (Y 1 , Y 2 , Y 3 ) forms a Markov chain is achievable for the private-messages-only case. We call this region the superposition coding region.\nTheorem 2. Any set of achievable rates R 1 , . . . , R k for a k -receiver more capable channel must satisfy\nProof: We will prove the theorem for three-receiver more capable channels, the proof for more receivers shall follow with similar steps. Note that\nwhich, as we mentioned before, is achieved by transmitting only to the best receiver with superposition coding. In the above chain of inequalities we have used Fano\u2019s inequality, chain-rule for mutual information, data-processing inequal- ity, Csiszar-sum lemma (equalities (a),(c)) (reproduced be- low) and the more capable ordering (inequalities (b),(d)). The data-processing inequalities used above come from the following Markov chain\nFurthermore, noting the similarity of the second inequality and (2), a k-receiver proof could be generated by eliminating one receiver at a time.\nLemma 1. (Csiszar-sum Lemma) For any p(U, y n 11 , y n 21 ) we have\nOriginally presented in [4], this is one of the most com- monly used identities to derive outer bounds and converses for discrete memoryless broadcast channels.\nTheorem 2 implies that it is not possible to beat the sum- rate. What we could try is to beat the achievable region along some other directions, which is what we will do in the counter example.\nWe consider a DM-BC with X ∈ {0, 1}, Y 1 ∈ {0, 1, e}, Y 2 ∈ {0, 1, e}, and Y 3 ∈ {0, 1}, where the channel from X to Y 1 , Y 2 and Y 3 are BEC( 1 ), BEC( 2 ) and BSC(p),\nrespectively (see Figure 1). Let p ∈ [0, 1 2 ], 1 = 4p(1 − p) and 2 = H(p), then from [9] we know that this is a three- receiver more capable channel.\nIn fact, for this particular case, Y 1 is also less noisy than Y 3 and Y 2 is a degraded version of Y 1 . However Y 2 is only more capable than Y 3 . Let C denote the true (as yet unknown) capacity region and S denote the superposition coding region.\nSuppose the private message rates are R 1 , R 2 and R 3 for receivers Y 1 , Y 2 and Y 3 , respectively. We try to maximize the following equation\n1 − 2 . Lemma 2. For all (R 1 , R 2 , R 3 ) ∈ S we have\nProof: Note that if (R 1 , R 2 , R 3 ) ∈ S is in the achiev- able region, then so is (R 1 , R 2 , 0), where R 2 = R 2 + R 3 .\nOne can see this by plugging the choice into the region in Theorem 1. However the channel X → Y 1 → Y 2 is a degraded broadcast channel consisting of two BEC\u2019s and its capacity region consists of all non-negative pairs (R 1 , R 2 ) satisfying\nThis well-known fact holds since for any U → X → (Y 1 , Y 2 ) we have I(U ; Y 2 ) = (1 − 2 )I(U ; X) and I (X; Y 1 |U ) = (1 − 1 )H(X|U ) which can be obtained by routine manipulations. Hence\nLemma 2 implies that T ≤ 1 if superposition coding were optimal.\nBeating superposition coding region: Next, we will show that one can actually achieve T > 1. Instead of treating Y 2 as the second best receiver, we ignore Y 2 completely; i.e. it does not need to decode any message. This way the channel is transformed into a two-receiver less noisy broadcast channel with receivers Y 1 , Y 3 . Using superposition coding on this two-receiver channel, we can achieve R 1 = I (X; Y 1 |U ), R 3 = I(U ; Y 3 ) for any U → X → (Y 1 , Y 3 ).\nLet U → X be a BSC with crossover probability s, 0 < s < 1 2 . Further, let P (U = 0) = 1 2 . We have,\nTherefore, superposition coding region is not optimal for the three-receiver more capable channel.\nA. An achievable rate region for the three-receiver more capable broadcast channel\nSince the sum-capacity is bounded by what one can transmit to the receiver Y 1 , a natural guess would be to allow the Y 1 to decode all the messages. Now, one can employ Marton\u2019s binning scheme to transmit non-nested messages to receivers Y 2 and Y 3 .\nTheorem 3. Consider a three receiver more capable broad- cast channel with Y 1 being the most capable receiver and Y 3 the least. Then any rate triple (R 1 , R 2 , R 3 ) satisfying\nProof: The proof follows standard techniques of ran- dom binning, superposition coding, and jointly typical de- coding. Receiver Y 2 decodes U n 2 , W n , receiver Y 3 decodes U n 3 , W n , and receiver Y 1 decodes W n , U n 2 , U n 3 , X n . The analysis is routine and straightforward (but messy) and hence is omitted.\nis obtained during the process of Fourier-Motzkin Elimina- tion, but it is easy to see that this condition is redundant to the computation of the region.\nIn the event where Y 1 is less noisy than both Y 2 and Y 3 pairwise(as in the counter example), the achievable region in Theorem 3 reduces to\nAlso, since Y 3 is essentially less noisy[9] than Y 2 in the counter example, by symmetrization argument 2 we can further assume P(X = 0) = 1 2 , and hence I(U 2 , W ; Y 3 ) ≥ I (U 2 , W ; Y 2 ). Therefore we can set ˜ W = (U 2 , W ), ˜ U 2 = ∅, ˜ U 3 = U 3 to obtain the following achievable region:\nTheorem 4. For the channel depicted in 1, the union of rate triples (R 1 , R 2 , R 3 ) satisfying\nThis is just superposition coding by treating Y 3 as the second best receiver. We will prove in the next section that this is indeed the capacity region for the counterexample.\nIn this section we show that the region presented in Theo- rem 4 is indeed the capacity region for the counterexample.\nNote that it sufﬁces to just show a converse to Theorem 4 to establish the capacity region. The arguments are reason- ably routine once the identiﬁcations of the auxiliaries have been made:\nIdentify ˜ U 3i = (M 3 , Y i− 1 11 ) and ˜ W i = (M 2 , Y n 3i+1 , Y i− 1 21 ). Observe that\nIn the above the usual toolset: Fano\u2019s inequality, Csiszar sum-lemma (steps (a), (b)), data-processing inequality, and chain rule of mutual information. All the data processing inequalities come from the following Markov chain:\nThe equality (c) comes from the fact that Y 2 is a degraded version 3 of Y 1 and hence\nis Markov. Finally in the usual manner, let Q be an independent random variable distributed uniformly in [1 : n] and set ˜ W = ( ˜ W Q , Q ), ˜ U 3 = ˜ U 3Q , X = X Q .\nThe other inequalities follow a similar line (but is simpler) of reasoning. Observe that\nThe last inequality (on R 2 ) is very straightforward with this identiﬁcation and is omitted. This completes the proof for the capacity region of the channel in Figure 1.\nRemark 2. It may appear a bit strange to see that even though superposition coding in the natural more-capable ordering (i.e. Y 1 better than Y 2 better than Y 3 ) is suboptimal, a re-ordering of the receivers, i.e. (i.e. Y 1 better than Y 3 better than Y 2 ) could make superposition coding optimal again. But of course, this is a carefully chosen counter- example and hence the peculiar situation. It is natural to ask whether there exists a three-receiver more capable broadcast channel where superposition coding is not optimal with either ordering. We will show such an example (a minor perturbation of the example in Figure 1) in the next section.\nConsider the same channel as in Figure 1. Set 1 = 4 ∗ (0.1) ∗ 0.9 = 0.36, 2 = H(0.1). Slightly change the value of p from 0.1 to 0.11. Clearly since the new receiver Y 3 is a degraded version of the old receiver Y 3 (which was BSC (0.1)), this setting is still a three-receiver more capable channel. As before, we try to maximize\nIf superposition coding in the more capable ordering were optimal, then again the same arguments would imply that T ≤ 1. However, if we ignore Y 2 again and use superpo- sition coding between receivers Y 1 and Y 3 , we can obtain, taking U → Xto be BSC(0.1) with uniform distribution,\nHence, superposition coding in the more capable ordering is not optimal.\nTo show that superposition coding in the Y 1 , Y 3 , Y 2 or- dering is not optimal, we can maximize\nIf superposition coding in Y 1 , Y 3 , Y 2 ordering were optimal, this would be the same as maximizing R 3 , whose maximum is 1 − H(0.11) ≈ 0.501. On the other hand, by just transmitting to receiver Y 2 we can obtain R 2 = 1 − 2 = 1 − H(0.1) ≥ 0.531. Thus superposition coding in the Y 1 , Y 3 , Y 2 order is also not optimal for this modiﬁed counter example.\nRemark 3. The converse in the last section continues to hold for this modiﬁed setting. However, since Y 3 is no longer an essentially less noisy receiver than Y 2 , the achievability of the region depicted by Theorem 4 fails to hold.\nA natural guess for the capacity region in this modiﬁed counterexample would be given by the constraints in Equa- tions (5).\nIn this paper, we showed that superposition coding does not achieve the capacity region for a three-receiver broadcast channel. In fact, we presented a counterexample where capacity could be achieved by treating the least capable receiver as the intermediate receiver and the intermediately- capable receiver the worst receiver. The main purpose of this counterexample is to show that more capable is a very weak ordering that does not preserve the nested decoding properties a less noisy ordering would, at least in the three receiver case. Then we produced a modiﬁed counterexample to show that superposition coding (in whatever order one wishes) cannot yield the capacity region for general three- receiver more capable broadcast channels.\nOn the other hand, we showed that one can achieve the sum-rate capacity for any k-receiver more capable channel by just transmitting to the best receiver. Motivated by this result we presented certain achievable regions for the three- receiver more capable broadcast channels.\nThe work of Chandra Nair was partially supported by the following grants from the University Grants Committee of the Hong Kong Special Administrative Region, China: a) (Project No. AoE/E-02/08), b) GRF Project 415810. He also acknowledges the support from the Institute of Theoretical Computer Science and Communications (ITCSC) at the Chinese University of Hong Kong."},"refs":[{"authors":[],"title":{"text":"Young-Han Kim Abbas El Gamal, Network information theory, Cambridge University Press, 2012"}},{"authors":[],"title":{"text":"P F Bergmans, Coding theorem for broadcast channels with degraded components, IEEE Trans"}},{"authors":[],"title":{"text":"T Cover, Broadcast channels, IEEE Trans"}},{"authors":[],"title":{"text":"I Csiz´ar and J K¨orner, Broadcast channels with conﬁdential messages, IEEE Trans"}},{"authors":[],"title":{"text":"A El Gamal, The capacity of a class of broadcast channels, IEEE Trans"}},{"authors":[],"title":{"text":"R G Gallager, Capacity and coding for degraded broadcast channels, Probl"}},{"authors":[],"title":{"text":"Y Geng, C Nair, S Shamai, and Z V Wang, On broadcast channels with binary inputs and symmetric outputs, International Symposium on Information Theory (2010)"}},{"authors":[{"name":"I. Csisza"}],"title":{"text":"J K¨orner and K Marton, Comparison of two noisy channels, Topics in Inform"}},{"authors":[],"title":{"text":"C Nair, Capacity regions of two new classes of two-receiver broadcast channels, Information Theory, IEEE Transactions on 56 (2010), no"}},{"authors":[{"name":"C. Nai"},{"name":"V. Wan"}],"title":{"text":"Z"}},{"authors":[],"title":{"text":"Chandra Nair, Abbas El Gamal, and Yeow-Khiang Chia, An achiev- ability scheme for the compound channel with state noncausally available at the encoder, CoRR abs/1004"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569563845.pdf"},"links":[{"id":"1569564189","weight":20},{"id":"1569553519","weight":20},{"id":"1569566037","weight":20},{"id":"1569566481","weight":20},{"id":"1569565435","weight":20},{"id":"1569566817","weight":20},{"id":"1569565537","weight":20}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S3.T2.1","endtime":"15:00","authors":"Chandra Nair, Lingxiao Xia","date":"1341240000000","papertitle":"On Three-Receiver More Capable Channels","starttime":"14:40","session":"S3.T2: Three-Receiver Broadcast Channels","room":"Kresge Auditorium (109)","paperid":"1569563845"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
