{"id":"1569566091","paper":{"title":{"text":"Behavior of the Minimum Singular Value of a Random Vandermonde Matrix"},"authors":[{"name":"Gabriel H. Tucci"},{"name":"Philip A. Whiting"}],"abstr":{"text":"Abstract\u2014In this work we examine the behavior of the minimum singular value of random Vandermonde matrices. In particular, we prove that the minimum singular value s 1 (N ) is at most N exp(−C\nN ) where N is the dimension of the matrix and C is a constant. Furthermore, the value of the constant C is determined explicitly. The main result is obtained in two different ways. One approach uses techniques from stochastic processes and in particular, a construction related to the Brownian bridge. The other one is a more direct analytical approach involving combinatorics and complex analysis. As a consequence, we obtain a lower bound on the maximum absolute value of a random polynomial on the unit circle, which may be of independent mathematical interest."},"body":{"text":"In this paper we study several aspects of random Vandermonde matrices with unit magnitude complex entries and their gen- eralizations. An N × L matrix V with unit complex entries is a Vandermonde matrix if there exist values θ 1 , . . . , θ L ∈ [0, 1] such that\n   \ne 2πiθ 1 \t . . . e 2πiθ L .. . \t . . . .. .\n   \n(see [3] or [1] for more details). A random Vandermonde matrix is produced if the entries of the phase vector θ := (θ 1 , . . . , θ L ) ∈ [0, 1] L are random variables. For the purposes of this paper it will be assumed that the phase vector has i.i.d. components, with distribution drawn according to a measure ν that has a density f (x) on [0, 1].\nRandom Vandermonde matrices and their generalized versions, also called d-fold Vandermonde matrices, are a natural con- struction with a wide range of applications in ﬁelds as diverse as ﬁnance [9], signal processing [4], wireless communications [6], statistical analysis [5], security [7] and biology [11]. This stems from the close relationship that unit magnitude complex Vandermonde matrices have with the discrete Fourier trans- form. Among these, there is an important recent application for signal reconstruction using noisy samples (see [4]) where an asymptotic estimate is obtained for the mean\u2013square error. In particular, and as was shown in [4], generalized Vandermonde matrices play an important role in the minimum mean\u2013square\nerror estimation of vector ﬁelds, as might be measured in a sensor network. In such networks, the parameter d is the dimension of the ﬁeld being measured, L is the number of sensors and N can be taken as the approximate bandwidth of the measured signal per dimension. This asymptotic can be calculated as a random eigenvalue expectation, whose limit distribution depends on the signal dimension d. In the case d = 1 the limit is via random Vandermonde matrices. As d → ∞ the Marchenko\u2013Pastur limit distribution is shown to apply. Further applications were treated in [3], including source identiﬁcation and wavelength estimation.\nOne is typically interested in studying the behavior of these matrices as both N and L go to inﬁnity at a given ratio, lim N →∞ L N = β. In [3] important results were obtained for the case d = 1. In particular, the limit of the moments of V ∗ V was derived and a combinatorial formula for the asymp- totic moments was given under the hypothesis of continuous density. In [1] these results were extended to more general densities and it was also proved that these moments arise as the moments of a probability measure µ ν,β supported on [0, ∞). This measure depends of course on the measure ν, the distribution of the phases, and on the value of β. In [1] the behavior of the maximum singular value was studied and tight upper and lower bounds for the maximum eigenvalue of V ∗ V were obtained. Moreover, in [2], these results were extended to d-fold generalized Vandermonde matrix.\nA natural question is to examine the behavior of the smallest singular value as N → ∞, and this paper is one of the ﬁrst to address this question. Here we restrict to the case d = 1. The matrix V ∗ V is an L × L positive deﬁnite random matrix with eigenvalues\nV ∗ V. Therefore, s i (N ) = λ i (N ). On one hand, it is clear that if L > N then the matrix V ∗ V is of size L × L and rank N . Therefore, if β > 1 the asymptotic limit measure has an atom at zero of size at least β −1 and in particular λ 1 (N ) = 0. On the other hand, if L = N , then with probability 1 the\n(2) This determinant is zero if and only if there exist distinct p and q such that θ p = θ q . This is an event of zero probability if the probability measure has a density. Therefore, the mini- mum singular value s 1 (N ) is positive with probability 1 and converges to zero as N increases. In this work, we show that with high probability s 2 1 (N ) = λ 1 (N ) ≤ N 2 exp(−C\nAs a consequence of our argument, we show that with high probability\nwhere, as before, the phases {θ 1 , . . . , θ N } are i.i.d on [0, 1]. Moreover, we explicitly determine the constant C. We believe that this may prove to be of independent mathematical inter- est. Additionally, we show that the moments for the matrix (V ∗ V) −1 are not ﬁnite.\nThe rest of the paper proceeds as follows. In Section II, we set up some notation and terminology and present some known results for random Vandermonde matrices. In Section III, we prove the absence of ﬁnite moments for the matrix M ∗ M where M = V −1 . In Section IV, we study the behavior of the minimum singular value of V. Finally, in Section V we present some numerical results.\nThroughout the paper we denote by A ∗ the complex conjugate transpose of the matrix A and by I N the N × N identity matrix. We let Tr(A) := N i=1 a ii be the non\u2013normalized trace for square matrices, where a ii are the diagonal elements of the matrix A. We also let tr N (A) = 1 N Tr(A) be the normalized trace.\nConsider an N × L random Vandermonde matrix V with unit complex entries, as given in equation (1). The variables θ i are called the phase distributions and ν their probability distribution. It was proved in [3] that if dν = f (x) dx for f (x) continuous in [0, 1], then the matrices V ∗ V have ﬁnite asymptotic moments. In other words, the limit\nwhere K ρ,ν are positive numbers indexed by the partition set. We call these numbers Vandermonde expansion coefﬁcients.\nThe fact that all the moments exist is not enough to guarantee the existence of a limit probability measure having these moments. However, it was proved in [1] that the eigenvalues\nof V ∗ V converge in distribution to a probability measure µ β,ν supported on [0, ∞) where β = lim N →∞ L N . More precisely,\nIn [1] the class of functions for which the limit eigenvalue distribution exists was enlarged to include unbounded densi- ties, and lower bounds and upper bounds for the maximum eigenvalue were found. We suggest that the interested reader look at [3] and [1] for more properties on the Vandermonde expansion coefﬁcients K ρ,ν , as well as methods and formulas to compute them.\nGiven a vector x in C N , we deﬁne σ m r (x) to be the sum of all r-fold products of the components of x not involving the m-th coordinate. In other words,\nwhere ρ m r is a subset of {x 1 , x 2 , . . . , x m−1 , x m+1 , . . . , x N } , of cardinality r.\n   \nx 1 \t x 2 \t . . . x N .. . \t .. . \t . . . .. .\n   \nwith no zero entries. Then its inverse M := V −1 is the matrix with entries\nRemark 1. Let ν 1 ≤ ν 2 ≤ . . . ≤ ν N be the eigenvalues of M ∗ M and let λ 1 ≤ λ 2 ≤ . . . ≤ λ N be the corresponding eigenvalues of V ∗ V, which are the same as for VV ∗ . Note that\nand in particular ν N = λ −1 1 . Therefore, to understand the behavior of λ 1 it is enough to understand the behavior of ν N . Theorem 2. Let V be a square N × N random Vandermonde matrix. Then for every N ≥ 2, the matrix V ∗ V is invertible with probability 1 and\nProof: It is enough to prove the case p = 1 since the other cases follow from this. We ﬁrst observe that\n1 N\nIn this Section we focus on the behavior of the mini- mum eigenvalue λ 1 . Given a square N × N complex ma- trix M, we have the following matrix norms ||M|| 1 := sup j \t N k=1 |M (k, j)| and ||M|| 2 := λ N (M ∗ M). The following inequality is well known (see [8] for more details),\nLemma 1. Let A(z) = a 0 z n +a 1 z n−1 +. . .+a n be a complex polynomial and let A ∗ := max |z|=1 |A(z)| be its maximum on the unit circle. Then\nThe second inequality follows immediately from the triangle inequality and the ﬁrst one follows by applying the Cauchy\u2019s integral Theorem and using the fact that |z|=1 z −i dz = 0 for all i = 1.\nIn the following steps we ﬁnd a bound on λ 1 (N ) in terms of the maximum of a polynomial with roots on the unit circle. We begin with some deﬁnitions. Let z k = e 2πiθ k be the values determining the random Vandermonde matrix as in equation (1). Let P (z) be the polynomial deﬁned as\nLet M = V −1 be the inverse of the random Vandermonde matrix and let M (p, q) denote its entries. Deﬁne\nfor all p = 1, 2, . . . , N . The following Lemma is a direct consequence of Hadamard\u2019s inequality.\nLemma 2. Let z 1 , . . . , z N be distinct points on the unit circle. Then there exists p 0 ∈ {1, . . . , N } such that,\nWe are now in a position to prove the following Lemma, which provides upper and lower bounds on the minimum singular value of a Vandermonde matrix, in terms of the polynomial T p , deﬁned in (10).\nLemma 3. Let T p (z) be as deﬁned above. Then, 1\nProof: Since ||M|| 1 = max {β p : p = 1, . . . , N }, it fol- lows that\nfrom which we can deduce that 1\n1 N\nThis argument was previously showed in [2]. Before stating our upper bound for the minimum eigenvalue, we introduce the following deﬁnitions. First, we deﬁne a random sequence via a realization of the Brownian bridge W o on [0, 2π], which satisﬁes W o (0) = W o (2π) = 0. A shift phase ϕ of the bridge is deﬁned by\nif 2π − ϕ ≤ θ < 2π. Given a realization of the Brownian bridge and ϕ ∈ [0, 2π] we deﬁne the following function,\nNote that it is not clear that the above integral is well deﬁned, since it may not exist as the fraction sin θ 1−cos θ behaves like θ −1 near 0 and 2π. However, this is the case almost surely. Furthermore, it can be shown that I(ϕ) is continuous on the interval [0, 1]. Therefore, there exists a value ϕ ∗ which determines the maximum value of I(ϕ), which we denote as I ∗ . More precisely,\nWe are now in a position to state our main result for an upper bound on λ 1 (N ).\nTheorem 3. Assume that the phases θ 1 , . . . , θ N are i.i.d. and drawn accordingly to the uniform distribution on [0, 1]. Then given > 0,\n(21) where I ∗ is deﬁned in (19).\nIn this Section, we present an analytical and elementary argument for the upper bound on the minimum eigenvalue. Let z 1 , z 2 , . . . , z N be complex numbers in the unit circle and let P (z) = N i=1 (z − z i ) be the polynomial with these roots. We want to estimate max |z|=1 |P (z)| when the roots {z i } N i=1 are i.i.d uniformly distributed random variables on the unit circle.\nLemma 4. Given P (z) as before, there exists |w| = 1 such that |P (w)P (−w)| = 1.\nProof: Consider the function Ψ(z) = log |P (z)| + log |P (−z)|. This function is continuous except at the values {z 1 , −z 1 , . . . , z N , −z N } where it has a vertical asymptote going to −∞. Therefore, we can consider this function as a continuous function from the unit circle to [−∞, ∞) with the usual topology. On the other hand, it is clear that\nΨ(z) = 0. Therefore, there exist w such that Ψ(w) = 0 and hence |P (w)||P (−w)| = 1.\nConsider the following construction. We randomly choose the points {z i } N i=1 and consider the set of pairs P := {(z 1 , −z 1 ), . . . , (z N , −z N )}. Note that changing z i to −z i does not affect the value of the point w in the previous Lemma. Hence the set P determines the point w. Now we ﬁx this point and consider α i := |w − z i | and β i := |w + z i |. Since |P (w)P (−w)| = 1 we see that N i=1 α i β i = 1. It is also clear that β i = 4 − α 2 i .\nLet y be the random variable deﬁned as y : {1, −1} N → R with\ntaking signs i.i.d. at random with probability 1/2. It is not difﬁcult to see that E(y) = 0 where the average is taken over the set {1, −1} N . Note that\nand w is as in Lemma 4. Since |P (v 1 ,...,v N ) (−w)| = |P (v 1 ,...,v N ) (w)| −1 , we see that\nTheorem 4. Let γ = log cos(π/8) sin(π/8) . For every > 0 the following holds\nThe proof of this fact uses elegant techniques from additive combinatorics as the Littlewood\u2013Offord theory which have to be omitted for space purposes. The next Theorem presents a lower bound for the maximum magnitude of the random polynomial P (z).\nProof: As we mentioned before we start by randomly gen- erating N pairs of diametrically opposite points (z i , −z i ), and\nthen ﬁnd w as in Lemma 4. We ﬁnally ﬁx the z i by N indepen- dent coin ﬂips (v 1 , . . . , v N ) and condition on this event. We observed before that |P (v 1 ,...,v N ) (−w)| = |P (v 1 ,...,v N ) (w)| −1 . Hence,\na(w) = log |P (v 1 ,...,v N ) (w)| − log |P (v 1 ,...,v N ) (−w)| = log |P (v 1 ,...,v N ) (w)| 2 .\nIn this Section we present some numerical results for the behavior of the maximum of a random polynomial on the unit circle in the context of Theorem 5. In Figure 1 we show the graphs of 2 log max |z|=1 |P (z)| and √ γπ\nN /2 as a function of N . These graphs suggests that Theorem 5 could be slightly improved."},"refs":[{"authors":[{"name":"G. H. Tucc"},{"name":"P. A. Whitin"}],"title":{"text":"Eigenvalue Results for Large Scale Vandermonde Matrices with Unit Complex Entries , IEEE Trans"}},{"authors":[{"name":"G. H. Tucc"},{"name":"P. A. Whitin"}],"title":{"text":"Asymptotic Results on Generalized Vandermonde Matrices and their Extreme Eigenvalues , Proceedings of the 49th Annual Allerton Conference on Communication, Control, and Computing, USA, 2011"}},{"authors":[{"name":"M. Debba"}],"title":{"text":""}},{"authors":[{"name":"A. Nordi"},{"name":"F. Chiasserin"},{"name":"E. Viterb"}],"title":{"text":"C"}},{"authors":[{"name":"T. Anderso"}],"title":{"text":"Asymptotic Theory for Principal Component Analysis, Annals of Mathematical and Statistics, vol"}},{"authors":[{"name":"B. Pors"},{"name":"B. Friedlande"}],"title":{"text":"Analysis of the relative efﬁciency of the MUSIC algorithm , IEEE Transactions Acoustic Speech and Signal Pro- cessing, vol"}},{"authors":[{"name":"L. Sampai"},{"name":"M. Kobayash"},{"name":"M. Debba"}],"title":{"text":""}},{"authors":[{"name":"R. Hor"},{"name":"R. Johnso"}],"title":{"text":"C"}},{"authors":[{"name":"R. Norber"}],"title":{"text":"On the Vandermonde Matrix and its application in Math- ematical Finance , Working Paper No"}},{"authors":[{"name":"N. Maco"},{"name":"A. Spitzbar"}],"title":{"text":"Inverses of Vandermonde Matrices, The American Mathematical Monthly, vol"}},{"authors":[{"name":"T. Strohme"},{"name":"T. Binde"},{"name":"M. Sussne"}],"title":{"text":"How to Recover Smooth Object Boundaries from Noisy Medical Images , IEEE ICIP\u201996 Lausanne, pp"}},{"authors":[{"name":"Y. Che"},{"name":"D. S. Lubinsk"},{"name":"J. Math"}],"title":{"text":"Smallest eigenvalues for Hankel matrices for exponential weights ,  Anal"}},{"authors":[{"name":"C. Ber"},{"name":"Y. Che"},{"name":"M. E. H. Ismai"}],"title":{"text":"Small eigenvalues of large Hankel matrices: The indeterminate case , Mathematica Scandinavica, vol"}},{"authors":[{"name":"Y. Che"},{"name":"N. D. Lawrenc"},{"name":"J. Phys"}],"title":{"text":"Small eigenvalues of large Hankel matrices ,  A"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566091.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T9.4","endtime":"16:00","authors":"Gabriel H. Tucci, Philip Whiting","date":"1341502800000","papertitle":"Behavior of the Minimum Singular Value of a Random Vandermonde Matrix","starttime":"15:40","session":"S13.T9: Fourier Subsampling","room":"Stratton West Lounge (201)","paperid":"1569566091"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
