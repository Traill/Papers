{"id":"1569553909","paper":{"title":{"text":"On the Heegard-Berger Problem with Common Reconstruction Constraints"},"authors":[{"name":"Behzad Ahmadi"},{"name":"Ravi Tandon"},{"name":"Osvaldo Simeone"},{"name":"H. Vincent Poor"}],"abstr":{"text":"Abstract\u2014In lossy source coding with side information at the decoder (i.e., the Wyner-Ziv problem), the estimate of the source obtained at the decoder cannot be generally reproduced at the encoder, due to its dependence on the side information. In some applications this may be undesirable, and a Common Reconstruction (CR) requirement, whereby one imposes that encoder and decoder be able to agree on the decoder\u2019s estimate, may be instead in order. The rate-distortion function under the CR constraint has been recently derived for the point-to- point (Wyner-Ziv) problem. In this paper, this result is extended to the Heegard-Berger (HB) problem and to its variant with cooperating decoders. Speciﬁcally, for the HB problem, the rate- distortion function is derived under the assumption that the side information sequences at the two decoders are stochastically degraded. The rate-distortion function is also calculated explicitly for the special case of binary source and erased side information with Hamming distortion metric. The rate-distortion function is then characterized also for the HB problem with cooperating decoders and physically degraded side information."},"body":{"text":"In source coding problems with side information at a single decoder, such as in the Wyner-Ziv problem, or at multiple decoders, such as in the Heegard-Berger (HB) problem [1], the side information sequences are, in general, used in two different ways. The ﬁrst is as a means to reduce the rate required for communication between encoder and decoders via binning. The second is, instead, as an additional observation that the decoders can leverage, along with the bits received from the encoder, in order to improve their local estimates. Leveraging the side information in this latter way, while advantageous in terms of rate-distortion trade-off, may have unacceptable consequences for some applications. In fact, this use of the side information entails that the reconstruction ˆ X at a decoder cannot be reproduced at the encoder. In applications such as transmission of sensitive medical information, this may not be desirable. Instead, one may want to add the constraint that the reconstruction at the decoder be reproducible by the encoder [2].\nThis idea, referred to as the Common Reconstruction (CR) constraint, was ﬁrst proposed in [2], where it is shown that for the Wyner-Ziv problem the rate-distortion function under the CR constraint is given by\nwhere the minimum is taken over all probability mass func- tions (pmfs) p (ˆx|x) such that E[d(X, ˆ X )] ≤ D. Comparing\n(1) with the conventional Wyner-Ziv rate-distortion function, namely R W Z X|Y (D) = minI(X; U|Y ) with minimum overall all pmfs p (u|x) and deterministic functions ˆx(u, y) such that E [d(X, ˆx(U, Y ))] ≤ D, it can be seen that the additional CR constraint prevents the decoder from using the side information as a means to improve its estimate ˆ X.\nIn this paper, we extend the characterization of the rate- distortion function under the CR constraint of [2] from the point-to-point setting to the HB problem [1] (Fig. 1, switch open), and its variant, studied in [3], in which decoder cooper- ation is enabled by a limited capacity link from one decoder, Decoder 1, to the other, Decoder 2 (Fig. 1, switch closed). We recall that [1] derived the rate-distortion function for the HB problem (without CR constraints) under the assumption that the side information sequences are stochastically degraded versions of the source X n . Instead, for the case with decoder cooperation, inner and outer bounds on the rate distortion region for this problem are obtained in [3] (without CR constraints) under the assumption that the side information of Decoder 2 is physically degraded with respect to that of Decoder 1.\nFor the HB problem with the CR constraint, in Sec. II, we derive the rate-distortion function under the assumption that the side information sequences are stochastically degraded. We also calculate this function explicitly for binary source and erased side information with the Hamming distortion metric. Moreover, for the HB problem with the CR constraint and decoder cooperation, we derive the rate-distortion region\nunder the assumption that the side information sequences are (physically) degraded in either direction (Sec. III-A and Sec. III-B). We emphasize that the corresponding problem without the CR constraint is still open as per the discussion above.\nIn this section, we ﬁrst detail the system model for the HB source coding problem in Fig. 1 (switch open) with CR in Sec. II-A. Next, the characterization of the corresponding rate- distortion performance is derived under the assumption that one of the two side information sequences is a stochastically degraded version of the other in the sense of [1]. Finally, an example with binary sources is worked out in Sec. II-C. The case of Gaussian sources under quadratic distortion is tackled in [4]. The proofs of the results presented in the paper are omitted due to space limitations and can be found in [4].\nIn this section the system model for the HB problem with CR is detailed. The system is deﬁned by the pmf p XY 1 Y 2 (x, y 1 , y 2 ) and discrete alphabets X , Y 1 , Y 2 , ˆ X 1 , and ˆ\nX 2 as follows. The source sequence X n and side information sequences Y n 1 and Y n 2 , with X n ∈ X n , Y n 1 ∈ Y n 1 , and Y n 2 ∈ Y n 2 are such that the tuples (X i , Y 1i , Y 2i ) for i ∈ [1, n] are independent and identically distributed (i.i.d.) with joint pmf p XY 1 Y 2 (x, y 1 , y 2 ). The encoder observes a sequence X n and encodes it into a message J of nR bits, which is delivered to the decoders. Decoders 1 and 2 wish to reconstruct the source sequence X n within given distortion requirements, to be discussed below, as ˆ X n 1 ∈ ˆ X n 1 and ˆ X n 2 ∈ ˆ X n 2 , respectively. The estimated sequence ˆ X n j is obtained as a function of the message J and the side information sequence Y n j for j = 1, 2. The estimates are constrained to satisfy distortion constraints deﬁned by per-symbol distortion metrics d j (x, ˆx j ) : X × ˆ X j → [0, D max ] with 0 < D max < ∞. The reconstructions ˆ X n 2 and ˆ X n 2 are also required to satisfy the CR constraints, as formalized below.\nDeﬁnition 1. An (n, R, D 1 , D 2 , ) code for the HB problem with CR consists of an encoding function\ng: X n → [1, 2 nR ], \t (2) which maps the source sequence X n into a message J ; a decoding function for Decoder 1,\nh 1 : [1, 2 nR ] × Y n 1 → ˆ X n 1 , \t (3) which maps the message J and the side information Y n 1 into the estimated sequence ˆ X n 1 ; a decoding function for Decoder 2\nh 2 : [1, 2 nR ] × Y n 2 → ˆ X n 2 \t (4) which maps message J and the side information Y n 2 into the estimated sequence ˆ X n 2 ; and two reconstruction functions\nψ 1 : X n → ˆ X n 1 \t (5a) and ψ 2 : X n → ˆ X n 2 , \t (5b)\nwhich map the source sequence into the estimated sequences at the encoder, namely ψ 1 (X n ) and ψ 2 (X n ), respectively; such that the distortion constraints are satisﬁed, i.e.,\n1 n\nGiven distortion pairs (D 1 , D 2 ), a rate pair R is said to be achievable if, for any > 0 and sufﬁciently large n, there a exists an (n, R, D 1 + , D 2 + , ) code. The rate-distortion function R (D 1 , D 2 ) is deﬁned as R(D 1 , D 2 ) =inf{R : the triple (R, D 1 , D 2 ) is achievable}.\nIn this section, a single-letter characterization of the rate- distortion function for the HB problem with CR is derived, under the assumption that the joint pmf p (x, y 1 , y 2 ) is such that there exists a conditional pmf ˜p(y 1 |y 2 ) for which\nIn other words, the side information Y 1 is a stochastically degraded version of Y 2 .\nProposition 2. If the side information Y 1 is stochastically degraded with respect to Y 2 , the rate-distortion function for the HB problem with CR is given by\nwhere the mutual information terms are evaluated with respect to the joint pmf\np (x, y 1 , y 2 , ˆx 1 , ˆx 2 ) = p(x, y 1 , y 2 )p(ˆx 1 , ˆx 2 |x), (10) and minimization is performed with respect to the conditional pmf p (ˆx 1 , ˆx 2 |x) under the constraints\nThe proof of the converse can be found in [4]. Achievability follows as a special case of Theorem 3 of [1] and can be easily shown using standard arguments. In particular, the encoder randomly generates a standard lossy source code ˆ X n 1 for the source X n with rate I (X; ˆ X 1 ) bits per source symbol. Random binning is used to reduce the rate to I (X; ˆ X 1 |Y 1 ). By the Wyner-Ziv theorem, this guarantees that both Decoder 1 and Decoder 2 are able to recover ˆ X n 1 (since Y 1 is a degraded version of Y 2 ). The encoder then maps the source X n into the reconstruction sequence ˆ X n 2 using a codebook that is generated conditional on ˆ X n 1 with rate I (X; ˆ X 2 | ˆ X 1 ) bits per source symbol. Random binning is again used to reduce the rate to I (X; ˆ X 2 |Y 2 ˆ X 1 ). From the Wyner-Ziv theorem, and the fact that Decoder 2 knows the sequence ˆ X n 1 , it follows that Decoder 2 can recover the reconstruction ˆ X n 2 as well.\nNote that, since the reconstruction sequences ˆ X n 1 and ˆ X n 2 are generated by the encoder, functions ψ 1 and ψ 2 that guarantee the CR constraints (7) exist by construction.\nRemark 3. If we remove the CR constraint, then the rate- distortion function under the assumption of Proposition 2 is given by [1]\nwhere the mutual information terms are evaluated with respect to the joint pmf\nand minimization is performed with respect to the con- ditional pmf p (u 1 , u 2 |x) and the deterministic functions ˆx j (u j , y j ), for j = 1, 2, such that distortion constraints E[d j (X, ˆx j (U j , Y j ))] ≤ D j , for j = 1, 2 are satisﬁed. Com- parison of (9) with (12) reveals that, similar to the discussion for the point-to-point set-up, the CR constraint permits the use of side information only to reduce the rate via binning, but not to improve the decoder\u2019s estimates via the use of the auxiliary codebooks represented by variables U 1 and U 2 , and functions ˆx j (u j , y j ), for j = 1, 2, in (13).\nRemark 4. Consider the case in which the side information sequences are available in a causal fashion in the sense of [5]; that is, the decoding functions (3)-(4) are modiﬁed as h ji : [1, 2 nR ] × Y i j → ˆ X ji , for i ∈ [1, n] and j = 1, 2, respectively. Following similar steps as in [5], it can be concluded that the rate-distortion function in this case is the same as if the two side information sequences were not available at the decoders, and is thus given by (9) upon removing the conditioning on the side information. Note that this is true irrespective of the joint pmf p (x, y 1 , y 2 ) and hence it holds also for non-degraded side information. This result can be explained by noting that, as explained in [5], causal side information prevents the possibility of reducing the rate via binning. Since the CR constraint also prevents the side information from being used to improve the decoders\u2019 estimates, it follows that the side information is useless in terms of rate-distortion performance, if used causally.\nC. Binary Source with Erased Side Information and Hamming or Erasure Distortion\nIn this section, we consider a binary source X ∼ Ber( 1 2 ) with erased side information sequences Y 1 and Y 2 . The source Y 2 is an erased version of the source X with erasure probabil- ity p 2 and Y 1 is an erased version of X with erasure probability p 1 > p 2 . This means that Y j = e, where e represents an erasure, with probability p j and Y j = X with probability 1−p j . Note that, with these assumptions, the side information Y 1 is stochastically degraded with respect to Y 2 . In fact, we have the factorization (8), where additional distributions p (y 2 |y 1 ) and ˜p(y 1 |y 2 ) are illustrated in Fig. 2. As seen in Fig. 2, the pmf ˜p(y 1 |y 2 ) is characterized by the probability ˜p 1 that satisﬁes the equality ˜p 1 = p 2 + ˜p 1 (1 − p 2 ). We focus on Hamming and erasure distortions. For the Hamming distortion,\nthe reconstruction alphabets are binary, ˆ X 1 = ˆ X 2 = {0, 1}, and we have d j (x, ˆx j ) = 0 if x = ˆx j and d j (x, ˆx j ) = 1 otherwise for j = 1, 2. Instead, for the erasure distortion the reconstruction alphabets are ˆ X 1 = ˆ X 2 = {0, 1, e}, and we have for j = 1, 2: d j (x, ˆx j ) = 0 if ˆx j = x, d j (x, ˆx j ) = 1 if ˆx j = e and d j (x, ˆx j ) = ∞ otherwise.\nIn [4, Appendix C], it is proved that for the point-to-point set-up with X ∼ Ber( 1 2 ) and erased side information Y with erasure probability p, the rate-distortion function with CR under Hamming distortion is given by\nfor D > 1/2, (14)\nwhere H (x) denotes the binary entropy function. Note that the rate-distortion function with erased side information and Hamming distortion without the CR constraint is derived in [7].\nProposition 5. The rate-distortion function for the HB prob- lem with CR for the binary source with the stochastically degraded erased side information sequences illustrated in Fig. 2 under Hamming distortion is given by\n⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩\nif D 1 ≥ 1/2 and D 2 ≥ 1/2 R CR B (D 1 , p 1 )\nif D 1 ≤ 1/2 and D 2 ≥ min(D 1 , 1/2) R CR B (D 2 , p 2 )\nif D 1 ≥ 1/2 and D 2 ≤ 1/2 ˜ R CR HB (D 1 , D 2 )\n2 1\n2 1\nMoreover, for the same source under erasure distortion the rate-distortion function is given by (16) by substituting R CR BE (D j , p j ) as deﬁned in (15) for R CR B (D j , p j ) for j = 1, 2 and by substituting ˜ R CR HB,E (D 1 , D 2 ) = p 1 (1−D 1 )+p 2 (D 1 − D 2 ) for (17).\nCharacterization of the rate distortion function (16) re- quires different considerations for the four subregions of the (D 1 , D 2 ) plane sketched in Fig. 3. In fact, for D 1 ≥ 1/2 and D 2 ≥ 1/2, the required rate is zero, since the distor- tion constraints are trivially met by setting ˆ X 1 = ˆ X 2 = 0 in the achievable rate (9). For the case D 1 ≥ 1/2 and D 2 ≤ 1/2, it is sufﬁcient to cater only to Decoder 2 by setting ˆ X 1 = 0 and X = ˆ X 2 ⊕ Q 2 , with Q 2 ∼ Ber(D 2 ) independent of X, in the achievable rate (9). That this rate cannot be improved upon is a consequence of the trivial converse\nwhich follows by cut-set arguments. The same converse suf- ﬁces also for the regime D 1 ≤ 1/2 and D 2 ≥ min(D 1 , 1/2). For this case, achievability follows by setting X = ˆ X 2 ⊕ Q 2 and ˆ X 1 = ˆ X 2 in (9), where Q 2 ∼ Ber(D 2 ) is independent of X. In the remaining case, namely D 2 ≤ D 1 ≤ 1/2, the rate-distortion function does not follow from the point-to-point result (14) as for the regimes discussed thus far. The analysis of this case can be found in [4, Appendix D]. Similar arguments apply also for the erasure distortion metric.\nWe now compare the rate-distortion function above with the following related settings: (i) the Kaspi model [8], in which the encoder knows the side information, and for which the rate-distortion function R Kaspi (D 1 , D 2 ) for the example at hand was calculated in [7]; and (ii) the HB setting with no CR constraint, whose rate-distortion function R HB (D 1 , D 2 ) for the example at hand was derived in [6]. We clearly have the inequalities\nwhere the ﬁrst inequality in (19) accounts for the impact of the availability of the side information at the encoder, while the second reﬂects the potential performance loss due to the CR constraint.\nFig. 4 shows the aforementioned rate-distortion functions with p 1 = 1 and p 2 = 0.35, which corresponds to the case where Decoder 1 has no side information, for two values of the distortion D 2 versus the distortion D 1 . For D 2 ≥ p/2 = 0.175, the given settings reduce to one in which the encoder needs to communicate information only to Decoder 1. Since Decoder 1 has no side information, the Kaspi and HB settings yield the same performance i.e., R Kaspi (D 1 , D 2 ) = R HB (D 1 , D 2 ). Moreover, if D 1 is sufﬁciently smaller than D 2 , the operation of the encoder is limited by the distortion requirements of Decoder 1. In this case, Decoder 2 can in fact reconstruct as ˆ X 1 = ˆ X 2 while still satisfying its distortion constraints. Therefore, we obtain the same performance in all of the three settings, i.e., R Kaspi (D 1 , D 2 ) = R HB (D 1 , D 2 ) = R CR HB (D 1 , D 2 ). We also note the general performance loss due to the CR constraint, unless, as discussed above, distortion D 1 is sufﬁciently smaller than D 2 .\nThe system model for the HB problem with CR and decoder cooperation is similar to the one provided in Sec. II-A with the following differences. Here, in addition to encoding function given in (2) which maps the source sequence X n into a mes- sage J 1 of nR 1 bits, there is an encoder at Decoder 1 given by g 1 : [1, 2 nR 1 ] × Y n 1 → [1, 2 nR 2 ], which maps message J 1 and the source sequence Y n 1 into a message J 2 . Moreover, instead of the decoding function given in (3), we have the decoding function for Decoder 2, h 2 : [1, 2 nR 1 ] × [1, 2 nR 2 ] × Y n 2 → ˆ X n 2 , which maps the messages J 1 and J 2 and the side information Y n 2 into the estimated sequence ˆ X n 2 .\nIn this section, a single-letter characterization of the rate- distortion region is derived under the assumption that the joint pmf p (x, y 1 , y 2 ) is such that the Markov chain relationship X − Y 1 − Y 2 holds.\nProposition 6. The rate-distortion region R CR (D 1 , D 2 ) for the HB source coding problem with CR and cooperative decoders under the assumption that X − Y 1 − Y 2 forms a Markov chain is given by the union of all rate pairs (R 1 , R 2 ) that satisfy the conditions\nR 1 ≥ I(X; ˆ X 1 ˆ X 2 |Y 1 ) \t (20a) and R 1 + R 2 ≥ I(X; ˆ X 2 |Y 2 ) + I(X; ˆ X 1 |Y 1 , ˆ X 2 ),(20b)\nwhere the mutual information terms are evaluated with respect to the joint pmf\np (x, y 1 , y 2 , ˆx 1 , ˆx 2 ) = p(x, y 1 )p(y 2 |y 1 )p(ˆx 1 , ˆx 2 |x), (21) for some pmf p (ˆx 1 , ˆx 2 |x) such that the constraints (11) are satisﬁed.\nThe proof of the converse can be found in [4]. As for the achievability, it follows as a straightforward extension of [3, Sec. III] to the setup at hand where Decoder 2 has side information as well. It is worth emphasizing that the reconstruction ˆ X 2 for Decoder 2, which has degraded side information, is conveyed by using both the direct link from the Encoder, of rate R 1 , and the path Encoder-Decoder 1- Decoder 2. The latter path leverages the better side information at Decoder 1 and the cooperative link of rate R 2 .\nRemark 7. If we remove the CR constraint, the problem of determining the rate-distortion region for the setting of Fig. 1 under the Markov assumption X − Y 1 − Y 2 is still open [3].\nIn this section, a single-letter characterization of the rate- distortion region is derived under the assumption that the joint pmf p (x, y 1 , y 2 ) is such that the Markov chain relationship X − Y 2 − Y 1 holds.\nProposition 8. The rate-distortion region R CR (D 1 , D 2 ) for the HB source coding problem with CR and cooperative decoders under the assumption the Markov chain relationship X − Y 2 − Y 1 is given by the union of all rate pairs (R 1 , R 2 ) that satisfy the conditions\nand R 2 ≥ 0, \t (22b) where the mutual information terms are evaluated with respect to the joint pmf\np (x, y 1 , y 2 , ˆx 1 , ˆx 2 ) = p(x, y 2 )p(y 1 |y 2 )p(ˆx 1 , ˆx 2 |x), (23) for some pmf p (ˆx 1 , ˆx 2 |x) such that the constraints (11) are satisﬁed.\nThe proof of achievability follows immediately by neglect- ing the link of rate R 2 and using rate R 1 as per the HB\nscheme of Proposition 2. The converse follows by considering an enhanced system in which Decoder 2 is provided with the side information of Decoder 1. In this system, link R 2 becomes useless since Decoder 2 possesses all the information available at Decoder 1. It follows that the system reduces to the HB problem with degraded sources studied in the previous section and the bound (22a) follows immediately from Proposition 2. Remark 9. In the case without CR, the rate-distortion function is given similarly to (22), but with the HB rate-distortion function (12) in lieu of the rate-distortion function of the HB problem with CR in (22a).\nThe Common Reconstruction requirement [2], substantially modiﬁes the problem of source coding in the presence of side information at the decoders. A general subject of theoretical interest is identifying those models for which the CR require- ments enables a solution of problems that have otherwise resisted solutions for some time. For instance, reference [4] extends the result of this paper to cascade models in the sense of [9]. Other examples that are worth investigating include the Heegard-Berger and cascade source coding problems with no assumptions on side information degradedness and the one-helper lossy source coding problem. Applications of the generalized CR constraint of [10] are also of interest (see [4]).\nThe work of O. Simeone was supported by the U.S. National Science Foundation under grant CCF-0914899, and the work of H. V. Poor and R. Tandon was supported in part by the U.S. Air Force Ofﬁce of Scientiﬁc Research under MURI Grant FA9550-09-1-0643 and in part by the U.S. National Science Foundation under Grant CNS-09-05398."},"refs":[{"authors":[{"name":"C. Heegard"},{"name":"T. Berger"}],"title":{"text":"Rate distortion when side information may be absent"}},{"authors":[{"name":"Y. Steinberg"}],"title":{"text":"Coding and common reconstruction"}},{"authors":[{"name":"D. Vasudevan"}],"title":{"text":"On the Heegard-Berger/Kaspi problem with decoder cooperation"}},{"authors":[{"name":"B. Ahmadi"},{"name":"R. Tandon"},{"name":"O. Simeone"},{"name":"H. V. Poor"}],"title":{"text":"Heegard-Berger and cascade source coding problems with common reconstruction con- straints"}},{"authors":[{"name":"T. Weissman"},{"name":"A. El Gamal"}],"title":{"text":"Source coding with limited-look-ahead side information at the decoder"}},{"authors":[{"name":"R. Tandon"},{"name":"S. Mohajer"},{"name":"H. V. Poor"}],"title":{"text":"Cascade source coding with erased side information"}},{"authors":[{"name":"E. Perron"},{"name":"S. N. Diggavi"},{"name":"E. Telatar"}],"title":{"text":"Lossy source coding with Gaussian or erased side-information"}},{"authors":[{"name":"A. H. Kaspi"}],"title":{"text":"Rate-distortion function when side-information may be present at the decoder"}},{"authors":[{"name":"Y. K. Chia"},{"name":"H. Permuter"},{"name":"T. Weissman"}],"title":{"text":"Cascade, triangular and two way source coding with degraded side information at the second user"}},{"authors":[{"name":"A. Lapidoth"},{"name":"A. Malar"},{"name":"M. Wigger"}],"title":{"text":"Constrained Wyner-Ziv coding"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569553909.pdf"},"links":[{"id":"1569566381","weight":12},{"id":"1569566527","weight":4},{"id":"1569566485","weight":8},{"id":"1569565383","weight":8},{"id":"1569565223","weight":4},{"id":"1569566725","weight":12},{"id":"1569565663","weight":4},{"id":"1569565377","weight":4},{"id":"1569566385","weight":4},{"id":"1569564635","weight":8},{"id":"1569565867","weight":12},{"id":"1569565691","weight":4},{"id":"1569559617","weight":4},{"id":"1569566981","weight":4},{"id":"1569566683","weight":4},{"id":"1569559259","weight":4},{"id":"1569566597","weight":4},{"id":"1569552245","weight":8},{"id":"1569560833","weight":4},{"id":"1569566415","weight":8},{"id":"1569565355","weight":4},{"id":"1569565931","weight":4},{"id":"1569566373","weight":4},{"id":"1569566765","weight":8},{"id":"1569565461","weight":4},{"id":"1569564731","weight":4},{"id":"1569564227","weight":8},{"id":"1569566671","weight":4},{"id":"1569566119","weight":4},{"id":"1569564233","weight":8},{"id":"1569559541","weight":4},{"id":"1569558459","weight":8},{"id":"1569565291","weight":20},{"id":"1569564203","weight":4},{"id":"1569556713","weight":12},{"id":"1569566751","weight":4},{"id":"1569566467","weight":4},{"id":"1569565771","weight":4},{"id":"1569566999","weight":8},{"id":"1569564249","weight":4},{"id":"1569566843","weight":12},{"id":"1569566579","weight":4},{"id":"1569566089","weight":4},{"id":"1569565455","weight":20},{"id":"1569566709","weight":25},{"id":"1569564989","weight":8},{"id":"1569566523","weight":16},{"id":"1569551763","weight":4},{"id":"1569564189","weight":4},{"id":"1569565907","weight":20},{"id":"1569566239","weight":4},{"id":"1569563981","weight":8},{"id":"1569566905","weight":4},{"id":"1569566753","weight":12},{"id":"1569566311","weight":4},{"id":"1569563307","weight":4},{"id":"1569566063","weight":4},{"id":"1569558681","weight":4},{"id":"1569559995","weight":4},{"id":"1569565213","weight":12},{"id":"1569566643","weight":4},{"id":"1569566511","weight":8},{"id":"1569565841","weight":4},{"id":"1569566581","weight":4},{"id":"1569565833","weight":12},{"id":"1569566325","weight":16},{"id":"1569566423","weight":4},{"id":"1569566437","weight":4},{"id":"1569566851","weight":4},{"id":"1569559111","weight":4},{"id":"1569553537","weight":25},{"id":"1569552251","weight":4},{"id":"1569553519","weight":8},{"id":"1569566231","weight":4},{"id":"1569566513","weight":4},{"id":"1569554881","weight":4},{"id":"1569554971","weight":4},{"id":"1569565655","weight":4},{"id":"1569558985","weight":8},{"id":"1569566473","weight":4},{"id":"1569564333","weight":4},{"id":"1569566629","weight":4},{"id":"1569565033","weight":16},{"id":"1569563897","weight":12},{"id":"1569565887","weight":4},{"id":"1569555879","weight":8},{"id":"1569565219","weight":4},{"id":"1569558509","weight":12},{"id":"1569554759","weight":4},{"id":"1569564851","weight":4},{"id":"1569566553","weight":4},{"id":"1569566043","weight":4},{"id":"1569565029","weight":8},{"id":"1569565357","weight":4},{"id":"1569561245","weight":4},{"id":"1569566505","weight":4},{"id":"1569562207","weight":4},{"id":"1569567033","weight":4},{"id":"1569565527","weight":8},{"id":"1569565363","weight":4},{"id":"1569566051","weight":4},{"id":"1569565467","weight":8},{"id":"1569566655","weight":4},{"id":"1569566673","weight":4},{"id":"1569565441","weight":4},{"id":"1569566233","weight":4},{"id":"1569566667","weight":4},{"id":"1569564097","weight":8},{"id":"1569566407","weight":8},{"id":"1569566501","weight":4},{"id":"1569566387","weight":4},{"id":"1569560503","weight":12},{"id":"1569562551","weight":4},{"id":"1569563395","weight":8},{"id":"1569551347","weight":4},{"id":"1569565415","weight":12},{"id":"1569555367","weight":33},{"id":"1569566383","weight":16},{"id":"1569565571","weight":4},{"id":"1569565885","weight":8},{"id":"1569566293","weight":4},{"id":"1569566479","weight":16},{"id":"1569565397","weight":4},{"id":"1569565765","weight":8},{"id":"1569565215","weight":4},{"id":"1569565919","weight":8},{"id":"1569565181","weight":4},{"id":"1569566267","weight":4},{"id":"1569566737","weight":4},{"id":"1569566917","weight":4},{"id":"1569566253","weight":4},{"id":"1569564305","weight":4},{"id":"1569566691","weight":8},{"id":"1569566651","weight":8},{"id":"1569566823","weight":8},{"id":"1569566137","weight":4},{"id":"1569565013","weight":4},{"id":"1569565375","weight":4},{"id":"1569566713","weight":4},{"id":"1569565293","weight":8},{"id":"1569566641","weight":4},{"id":"1569551905","weight":8},{"id":"1569556759","weight":12},{"id":"1569561185","weight":12},{"id":"1569566301","weight":4},{"id":"1569558779","weight":8},{"id":"1569565669","weight":4},{"id":"1569565233","weight":4},{"id":"1569560235","weight":4},{"id":"1569566817","weight":8},{"id":"1569566435","weight":4},{"id":"1569566299","weight":16},{"id":"1569564769","weight":4},{"id":"1569565805","weight":4},{"id":"1569563919","weight":4},{"id":"1569557851","weight":20},{"id":"1569566147","weight":4},{"id":"1569565537","weight":4},{"id":"1569566847","weight":4},{"id":"1569559597","weight":4},{"id":"1569567013","weight":4},{"id":"1569560459","weight":4},{"id":"1569550425","weight":37},{"id":"1569565889","weight":4},{"id":"1569565635","weight":8},{"id":"1569566375","weight":4},{"id":"1569565143","weight":4},{"id":"1569564257","weight":4},{"id":"1569564931","weight":4},{"id":"1569564141","weight":4},{"id":"1569564509","weight":4},{"id":"1569551751","weight":4},{"id":"1569564419","weight":8},{"id":"1569566067","weight":8},{"id":"1569566825","weight":4},{"id":"1569566609","weight":12},{"id":"1569563007","weight":4},{"id":"1569566727","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T1.2","endtime":"12:10","authors":"Behzad Ahmadi, Ravi Tandon, Osvaldo Simeone, H. Vincent Poor","date":"1341229800000","papertitle":"On the Heegard-Berger Problem with Common Reconstruction Constraints","starttime":"11:50","session":"S2.T1: Network Source Coding with Side Information","room":"Kresge Rehearsal B (030)","paperid":"1569553909"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
