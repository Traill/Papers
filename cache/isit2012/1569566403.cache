{"id":"1569566403","paper":{"title":{"text":"Bounds on the Minimum Energy-Per-Bit for Bursty Trafﬁc in Diamond Networks"},"authors":[{"name":"Ilan Shomorony \u2020"},{"name":"Raúl Etkin ∗"},{"name":"Farzad Parvaresh ∗"},{"name":"A. Salman Avestimehr \u2020"}],"abstr":{"text":"Abstract\u2014When data trafﬁc in a wireless network is bursty, small amounts of data sporadically become available for trans- mission, and the energy cost associated with synchronizing the network nodes prior to each communication block is not negligi- ble. Therefore, designing energy-efﬁcient communication schemes for such asynchronous scenarios is of particular importance. In this paper, we show that, for symmetric diamond networks, by performing the tasks of synchronization and communication separately, it is possible to achieve the minimum energy-per-bit to within a factor that ranges from 2 in the synchronous case to 1 in the highly asynchronous regime."},"body":{"text":"Traditional wireless communication models assume that transmitters and receivers are synchronized, in the sense that the receiver knows when data transmission is about to start. In applications such as Wi-Fi and cellular networks, where large amounts of data are to be transmitted, this is justiﬁed by the fact that the time and energy required for synchro- nization are negligible when compared to what is required for data communication. However, in certain applications such as wireless sensor networks, small amounts of time-sensitive data are sporadically available for transmission, at times that are unknown to the receivers. In such scenarios, the receiver is constantly listening to the output of a noisy channel in an attempt to identify a message. An extra amount of energy is then spent at the transmitter to make sure that the message is not missed and the noise is not mistaken for the message. In the sporadic data model, this extra energy represents a signiﬁcant part of the total energy spent and becomes a relevant quantity. There is a large body of work treating synchronization from a practical perspective with the goal of minimizing overheads and synchronization errors [1, 2]. However, these studies lack a fundamental characterization of the energy and bandwidth costs of synchronization.\nEarly work on the fundamental limits of asynchronous communication involved characterizing the data rates that can be achieved when the receiver does not know the beginning of the communication block [3]. Later, in [4], a similar model was considered, but the performance metric was instead the energy (or, in general, the cost) per bit required for reliable communication. In wireless sensor networks, sensors are often battery-operated. Thus, in the case of short and sporadic transmissions, i.e., bursty trafﬁc, when synchronization costs may dominate the communication costs, the characterization of the minimum energy-per-bit is very relevant.\nIn this work we start studying the fundamental limits of bursty communication in relay networks. We consider the symmetric diamond network shown in Figure 1, and we follow the bursty communication model from [4]. We assume that B bits of data become available at the source at a random arrival time ν B , and must be communicated to the destination with a maximum delay d B 1 . The arrival time ν B of the data at the source is assumed to be drawn uniformly at random from {1, ..., A B }, independent of the data bits. Moreover, ν B is unknown to both relays and the destination, and unknown to the source until time t = ν B . Under a similar setting, the asynchronous minimum energy-per-bit for point-to-point channels was characterized in [4].\nh g\nBy considering the diamond network, the main question we wish to address is \u201chow should relays facilitate the com- munication between source and destination when they do not know the beginning of the transmission block?\u201d. The natural approach is to consider a separation-based coding scheme, i.e., performing the tasks of synchronization and communication separately. Thus, as soon as the message arrives (at time ν B ) the source uses a synchronization signal in order to inform the relays that the message is about to be transmitted. The relays can then do the same, making the destination aware of the beginning of the transmission block. If this synchronization procedure succeeds, communication can then take place as if we were in the synchronous setting.\nSeparation-based schemes are important due to their ease of design and implementation. However, they are potentially wasteful, since, in principle, relays do not need to know the beginning of the transmission block precisely. In essence, we would like to know whether the relays should be synchronized and whether separation-based schemes perform well. We for-\nmalize the notion of relay synchronization by saying that a coding scheme synchronizes relay i if the signals received by relay i during times 1, 2, ..., A B , A B + 1, ..., A B + d B , represented by Y A B +d B i \t , reveal a signiﬁcant amount of infor- mation about ν B ; i.e., if H(ν B | Y A B +d B i \t ) is small. We then show that any scheme for the symmetric diamond network that achieves a ﬁnite energy-per-bit must synchronize both relays. The main idea of the proof is that, in any coding scheme with small error probability, the relays must spend a signiﬁcant amount of energy between times ν B and ν B + d B . Therefore, each relay can construct a short list of \u201cguesses\u201d for the true arrival time based on where most of its output energy is spent, and that list contains ν B with high probability, implying that H(ν B | Y A B +d B i \t ) is small.\nThe fact that the relays need to be synchronized suggests that there is a certain energy penalty associated with using the relays in the asynchronous setting. This idea allows us to derive a lower bound for the asynchronous minimum energy-per-bit. This bound is then shown to be within a constant fraction of the energy-per-bit achieved by a simple separation-based scheme. This fraction is 1/2 in the worst- case, but it approaches 1 as (log A B )/B increases, implying that separation-based schemes are nearly optimal in the high- asynchronism regime.\nWe consider the symmetric diamond network, shown in Figure 1. We assume a discrete-time model where, at time t , each transmitter node u ∈ {S, 1, 2} transmits a real- valued signal X u [t] , each relay i, for i ∈ {1, 2}, receives Y i [t] = √gX S [t] + Z i [t], and the destination D receives Y D [t] =\nwhere Z 1 [t], Z 2 [t] and Z D [t] are independent i.i.d. N (0, N 0 ) noise terms.\nOur bursty trafﬁc model follows the asynchronous commu- nication model introduced in [4]. The source receives a B-bits message m at some random time ν ∈ [1 : A], where, for a < b, we deﬁne [a : b]  {a, a + 1, ..., b}. The source then needs to communicate this message to the destination with a delay of at most d time-steps.\nIn order to formally deﬁne reliable communication, we consider the asymptotic regime of B → ∞. Thus, we consider a sequence of arrival distributions {ν B } ∞ B=1 , where ν B is uniform on [1 : A B ] and A B = 2 βB , for B = 1, 2, ... and some β > 0 . Notice that, as B → ∞, B/A B → 0, thus capturing the idea of short and sporadic messages. Once the B bits arrive at the source at time ν B , they must be communicated to the destination within a delay d B . Notice that, in order for the problem to be meaningful, d B should be small in comparison to A B . Otherwise, it would be possible to devise a strategy where the source only starts its trasmission at pre-deﬁned time- steps separated by d B time-steps, and the trafﬁc would not be actually bursty. Thus, since A B is exponential in B, we will require the delay d B to be subexponential in B.\nAn asynchronous code C for the symmetric diamond net- work is designed to communicate a speciﬁc number of bits B\nwith a delay of d B , assuming an arrival distribution ν B . This code is comprised of\n\u2022 an encoding function for the source f : [1 : 2 B ] × [1 : A B ] → R d B +1 , which deﬁnes the source transmit signals for [ν B : ν B + d B ] , given the B message bits and their arrival time ν B ;\n\u2022 relaying functions ρ i,t : R t −1 → R, which deﬁne relay i \u2019s transmit signal at time t given its received signals in times 1, ..., t − 1, for t = 1, ..., A B + d B ;\n\u2022 a sequential decoder (τ, ˆ m) , which, at time t, decides to either decode the message (in which case it sets τ = t and outputs a decoded message ˆ m ) or to wait (in which case τ > t).\nNotice that, outside the interval [ν B : ν B + d B ] , the source is not allowed to transmit. Thus, for relay i ∈ {1, 2} and time t / ∈ [ν B : ν B + d B ] , Y i [t] = Z i [t] .\nDeﬁnition 1. Energy-per-bit e b is achievable if we can ﬁnd a sequence of codes {C k } ∞ k=1 and a sequence {B k } ∞ k=1 , with B k → ∞ as k → ∞, where code C k can transmit B k bits with a maximum delay of d B k , assuming the input distribution is ν B k , and we have\n= 0 3. lim inf k →∞ E[ E C k ] B\nwhere E C k   A k +d Bk t=1  X S [t] 2 + X 1 [t] 2 + X 2 [t] 2  is the total energy used by code C k , and A k  2 βB k , and error (C k ) is the event {m = ˆ m } ∪ {τ > ν B k + d B k } for code C k . The asynchronous minimum energy-per-bit is the inﬁmum over all achievable energy-per-bit values.\nOur main result is to ﬁnd upper and lower bounds on the asynchronous minimum energy-per-bit for the symmetric dia- mond network. The achievability scheme for the upper bound uses a separation-based code. The lower bound is obtained by formalizing the notion of relay synchronization, and showing that, for any sequence of coding schemes that achieve ﬁnite energy-per-bit, both relays must be synchronized.\nTheorem 1. The asynchronous minimum energy-per-bit for the symmetric diamond network in Figure 1 satisﬁes\nwhere γ = 2N 0 ln 2 is the minimum energy-per-bit of an AWGN channel in the synchronous setting.\nTherefore, separation-based schemes achieve to within a factor of (1 + β)/( 1 2 + β) from the minimum energy-per-bit. This\nratio equals 2 when β = 0 (i.e., in the synchronous case) but it decreases towards 1 as β increases. We conclude that separation-based coding schemes are nearly optimal in high- asynchronism regimes.\nOur upper bound in Theorem 1 is achieved with a simple separation-based scheme; i.e., a scheme where we perform the tasks of synchronization and communication separately. Synchronization will be achieved through pulses, and, for communication, we will use a simple decode-and-forward scheme. Notice that several relaying schemes that outperform decode-and-forward are known [5]. However, decode-and- forward is simpler to analyze and, as we will see, performs nearly optimally.\nTheorem 2. Separation-based coding schemes can achieve energy-per-bit\nProof: We construct a sequence of codes {C k } ∞ k=1 , where C k transmits B k bits assuming arrival distribution ν B k , for any sequence {B\n, where B k → ∞ as k → ∞. Our scheme is based on having the source send a pulse as soon as the message arrives. This pulse is detected by the relays, which send another pulse to the destination, taking advantage of beamforming. After relays and destination correctly detect their pulses, the network is in the synchronous setting, and we may employ decode-and-forward to communicate the B k bits.\nMore precisely, upon receiving the message, at time ν B k , the source will transmit a pulse of magnitude\nfor δ > 0. Relay i declares that the pulse is detected at time t if Y i [t] is the ﬁrst received signal larger than (1+δ/2) √ γβB k . We let L 1 be the event that relay i does not detect the pulse, and L 2 be the event that relay i incorrectly detects noise as the pulse before the pulse is sent. The probability of error in detecting the pulse can be upper bounded as Pr(L 1 ∪ L 2 ) ≤ Pr(L 1 ) + Pr(L 2 ) , and we have\nIf the relays correctly detect the pulse, they can transmit pulses to the destination in the next time slot. Since they can use beamforming to reduce the total energy required, at time ν B k + 1 , each relay will send a pulse of magnitude\nThen by following similar steps as before, it can be shown that the probability that the destination does not decode the pulse\ncorrectly also tends to 0 as k → ∞. The total energy-per-bit consumed in the synchronization phase is\nThe main ingredient that is necessary to prove our lower bound on the minimum asynchronous energy-per-bit is the fact that a relay can only be helpful in a coding scheme (from the energy-per-bit point of view) if it is synchronized. In this work, we will deﬁne synchronization as follows.\nDeﬁnition 2. We say that relay i is synchronized in the sequence of codes {C k } ∞ k=1 if\nwhere Y ˜ A k i is the length- ˜ A k vector of received signals of relay i when using code C k , where ˜ A k  A k + d B k .\nWe show that, for any sequence of codes {C k } ∞ k=1 that achieves a ﬁnite energy-per-bit e b according to Deﬁnition 1, both relays must be synchronized.\nLemma 1. Suppose we have a sequence of asynchronous codes {C k } ∞ k=1 for the symmetric diamond network that achieves a ﬁnite energy-per-bit. Then, relay i ∈ {1, 2} can create a list Λ (i) k ⊂ [1 : A k ] based on its received signals that contains ν B k with vanishing error probability, and has a size |Λ (i) k | that is subexponential in B k .\nProof Sketch: Here, we describe the steps to prove that relay i ∈ {1, 2} can create a list Λ (i) k with subexponential size, such that lim k →∞ Pr  ν B k / ∈ Λ (1) k ∪ Λ (2) k  = 0 . In [6], we show that this result can be strengthened and we can in fact have have lim k →∞ Pr  ν B k / ∈ Λ (i) k  = 0 for i = 1, 2.\nThe intuition behind the proof is simple. If a code C k has small error probability, then, in the block [ν B k : ν B k + d B k ] , at least one of the two relays should consume a signiﬁcant amount of energy. Moreover, if the sequence of codes {C k } ∞ k=1 achieves a ﬁnite energy-per-bit, the relays should not be spending too much energy outside of [ν B k : ν B k + d B k ] . Thus, by only looking at the times when the relays consume the most energy, one should be able to estimate the arrival time ν B k .\nRelay i builds Λ (i) k by adding to it the ﬁrst d B k E [ E C k ] /α time-steps t ∈ [1 : A k ] for which it consumes a total energy of at least αB k in the time window [t : t + d B k ] , for some α > 0 to be determined. We show that there must be an α for which the probability that ν B k / ∈ Λ k  Λ (1) k ∪Λ (2) k tends to 0 as k → ∞. The main idea of the argument is as follows. Fix some α > 0 , and notice that, if one of the relays uses a total energy of at least αB k in the \u201ccorrect window\u201d, i.e., [ν B k : ν B k +d B k ] , then with high probability ν B k will be included in Λ k . This is the case since, from Markov\u2019s inequality, the probability that the relays consume a total energy of at most E [E C k ] B k is at least 1 − 1/B k , and, in this case, there cannot be more than d B k E [ E C k ] /α windows [t : t + d B k ] where one of the relays uses energy at least αB k . Therefore, it sufﬁces to ﬁnd an α > 0 for which\n= 0, (1) where E (r 1 ,r 2 ) C k [ν B k : ν B k + d B k ] is the energy spent by the relays in the window [ν B k : ν B k + d B k ] . By contradiction, we suppose that no such α exists, which means that for any ﬁxed α , the limit inferior in (1) equals some δ(α) > 0. But then we notice that, since the error probability of our original sequence of codes {C k } ∞ k=1 tends to 0 as k → ∞, for large k, the error probability can be arbitrarily smaller than δ(α). Intuitively, this means that, conditioned on the event E (r 1 ,r 2 ) C k [ν B k : ν B k + d B k ] < 2αB k , the probability of error is still going to 0, as k → ∞. Moreover, this should hold for any small α > 0 . To obtain a contradiction, we show that the sequence of codes {C k } ∞ k=1 can be used to construct another sequence of codes {C  k } ∞ k=1 for the second hop of the diamond network in the synchronous setting (i.e., the two-input one-output channel from Figure 2), where the transmitters (which correspond to the relays in the diamond network) use energy at most 2αB k and transmit B k − o(B k ) bits with vanishing error probability. This implies that the transmitters spend a total energy-per-\nbit of at most 2α + o(1), where α can be chosen arbitrarily small. But this is clearly a contradiction, since the two-input one-output channel considered has a positive (synchronous) minimum energy-per-bit.\nFinally, from Deﬁnition 1, E [E C k ] is linear in B k and d B k is subexponential in B k . Thus |Λ (i) k | = d B k E [ E C k ] /α must be subexponential in B k .\nTo see that Lemma 1 implies that both relays must be synchronized, consider a sequence of codes {C k } ∞ k=1 that achieves a ﬁnite energy-per-bit, and assume that relay i creates\na list Λ k as described. If 1 ν Bk ∈Λ k is an indicator function for the event ν B k ∈ Λ k , we will have\nwhich tends to 0 as k → ∞, because |Λ k | is subexponential in B k , and Pr(ν B k / ∈ Λ k ) → 0 as k → ∞, which implies that relay 1 is synchronized according to Deﬁnition 2. Therefore, as a corollary of Lemma 1, we have shown the following.\nLemma 2. In any sequence of asynchronous codes {C k } ∞ k=1 for the symmetric diamond network that achieves a ﬁnite energy-per-bit, both relays are synchronized.\nNext, we will let C(P ) be the capacity region of a degraded BC X ↔ Y 1 ↔ Y 2 . Recall that this capacity region consists of all pairs (R\nfor some n and some distribution p(u, x n ) such that E  X n  2  ≤ nP . An important quantity for us will be the (1 : ρ) -capacity of this BC, which we deﬁne as\nfor some ρ > 0. Using the multi-letter description of the capacity (2), it is easy to see that we have\nTheorem 3. The asynchronous minimum energy-per-bit e async b for the symmetric diamond network is lower bounded as\nProof: Suppose we have a sequence of codes {C k } ∞ k=1 that achieves a ﬁnite energy-per-bit. We consider using code C k on the BC in Figure 3, in the synchronous setting. Notice that, for this BC, Y 2 = √gX + Z 2 is a scalar, while Y 1 = (√gX + Z 1,1 , √gX + Z 1,2 ) is a vector, and Z 1,1 , Z 1,2 and Z 2 are independent i.i.d. N (0, N 0 ) noise terms. To use code C k on this channel in the synchronous setting, we have the source choose an arrival time ν B k uniformly at random from [1 : 2 βB k ] and transmit the message as if we were in the asynchronous setting. Since it has two antennas, destination D 1 can then simulate what the relays would have received and transmitted and what the destination would have received\nin the diamond network. This guarantees that, with probability 1 −  k , where  k → 0, destination D 1 can decode m correctly and output a list [τ − d B k : τ ] containing ν B k .\nLet X ˜ A k be the the random vector corresponding to the transmit signals of the source when using code C k on the BC, and Y ˜ A k 1 and Y ˜ A k 2 the outputs at D 1 and D 2 respec- tively. Since, from Lemma 2, we may assume that relay 2 is synchronized in the diamond network, destination D 2 will be synchronized in this BC, which implies that\n/B k = 0. \t (4) Now, using (3) with U = ν B k , we obtain\n/ ˜ A k , (5)\nwhere (i) follows from Fano\u2019s inequality, and E (s) C k is the energy consumed by the source in code C k . Notice that the capacity region C(P ) of the Gaussian degraded BC is known in closed-form, and in the case of the BC from Figure 3, it consists of all non-negative pairs (R 1 , R 2 ) satisfying\nfor some α ∈ [0, 1]. It is then not difﬁcult to see that the (1 : β) -capacity of our BC can be expressed as\n2 log (1 + α2gP/N 0 ) , 1\n. Hence we have\n \n/ ˜ A k E[ E (s) C k ]/ ˜ A k\nBy taking lim sup when k → ∞ and using (4), we obtain 2g\n. (7) Next we apply code C k to the network in Figure 2. This time, the source simulates the transmit signals of the source and the received signals at the relays in Figure 1. Then it computes the transmit signals of the relays in Figure 1 and transmits them, one on each antenna. By viewing the channel from Figure 2 as a point-to-point channel, from Theorem 3 in [4], we have\n/B k ≥ (1 + β) γ 2h . \t (8) Therefore, by combining (7) and (8), we obtain\n, which concludes the proof of Theorem 3.\nIn this work, we found asymptotically tight bounds for the asynchronous minimum energy-per-bit of the symmetric diamond network. In [6], we extend these results to the asymmetric case. This is done by showing that any relay that is used (i.e., does not stay silent) must be synchronized, which yields bounds similar to those in Theorem 1.\nThe research of A. S. Avestimehr and I. Shomorony was supported in part by the NSF CAREER award 0953117, NSF Grant CCF-1144000, and NSF TRUST Center."},"refs":[{"authors":[{"name":"D. Warne"},{"name":"C. Leung"}],"title":{"text":"W"}},{"authors":[{"name":"M. Spet"},{"name":"D. Daeck"},{"name":"H. Meyr"}],"title":{"text":"Minimum overhead burst syn- chronization for ofdm based broadband transmission"}},{"authors":[{"name":"A. Tchamkerte"},{"name":"V. Chanda"},{"name":"W. Wornell"}],"title":{"text":"G"}},{"authors":[{"name":"V. Chanda"},{"name":"A. Tchamkerte"},{"name":"D. Tse"}],"title":{"text":"Asynchronous capacity per unit cost"}},{"authors":[{"name":"F. Parvares"},{"name":"R. Etkin"}],"title":{"text":"Relaying information by low duty cycle signals in gaussian diamond networks"}},{"authors":[{"name":"I. Shomoron"},{"name":"R. Etki"},{"name":"F. Parvares"},{"name":"A. S. Avestimehr"}],"title":{"text":"Asyn- chronous diamond networks: Bounds on the minimum energy-per-bit"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566403.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S5.T3.2","endtime":"10:30","authors":"Ilan Shomorony, Raul Etkin, Farzad Parvaresh, Salman Avestimehr","date":"1341310200000","papertitle":"Bounds on the Minimum Energy-Per-Bit for Bursty Traffic in Diamond Networks","starttime":"10:10","session":"S5.T3: Energy-Efficient Communication","room":"Stratton S. de P. Rico (202)","paperid":"1569566403"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
