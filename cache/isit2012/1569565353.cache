{"id":"1569565353","paper":{"title":{"text":"Analysis and Design of Irregular Graphs for Node-Based Veriﬁcation-Based Recovery Algorithms in Compressed Sensing"},"authors":[{"name":"Yaser Eftekhari"},{"name":"Amir H. Banihashemi"},{"name":"Ioannis Lambadaris"}],"abstr":{"text":"Abstract\u2014In this paper, we present a probabilistic analysis of iterative node-based veriﬁcation-based (NB-VB) recovery algorithms over irregular graphs in the context of compressed sensing. Veriﬁcation-based algorithms are particularly inter- esting due to their low complexity (linear in the signal dimen- sion n). The analysis predicts the average fraction of unveriﬁed signal elements at each iteration ℓ where the average is taken over the ensembles of input signals and sensing matrices. The analysis is asymptotic (n → ∞) and is similar in nature to the well-known density evolution technique commonly used to analyze iterative decoding algorithms. Compared to the existing technique for the analysis of NB-VB algorithms, which is based on numerically solving a large system of coupled differential equations, the proposed method is much simpler and more accurate. This allows us to design irregular sensing graphs for such recovery algorithms. The designed irregular graphs outperform the corresponding regular graphs substantially. For example, for the same recovery complexity per iteration, we design irregular graphs that can recover up to about 40% more non-zero signal elements compared to the regular graphs. Simulation results are also provided which demonstrate that the proposed asymptotic analysis matches the performance of recovery algorithms for large but ﬁnite values of n."},"body":{"text":"Consider a signal v ∈ R n with only k non-zero elements. Let m be a positive integer so that k < m ≪ n. The main idea in compressed sensing is to represent v with measurements c ∈ R m (measuring process), and to be able to recover back the original signal v from the measurements c (recovery process) [1], [2].\nThe measuring process is essentially a linear transforma- tion that can be represented by the matrix multiplication c = Gv, or equivalently characterized by a bipartite graph [3]. In these representations, G is referred to as the sensing matrix and the bipartite graph as the sensing graph, respectively. The recovery process is essentially estimating v based on the knowledge of c and G and is considered successful if v is estimated correctly.\nIf the density of edges in the sensing graph is high, the computational complexity of ﬁnding the measurements and that of the recovery is considerably higher compared to the cases where the sensing graph is sparse. The high complex- ity of recovery for dense graphs hinders their application to high-dimensional signal recovery (signals with large n). Moreover, in certain compressed sensing applications such as computer networks [4]\u2013[6], channel coding [7], spectrum sensing [8], and identiﬁcation of linear operators [9], the nature of the problem results in a formulation with a sparse\nsensing graph. The main focus of this paper is on such problems. More speciﬁcally, our main interest is in a sub- class of message-passing recovery algorithms, called Node- Based Veriﬁcation-Based (NB-VB) algorithms [10]\u2013[13], and the performance of these algorithms over irregular sparse graphs (matrices). The VB recovery algorithms, in general, are iterative and have computational complexity O(n), which makes them suitable for applications involving recovery of signals with large n. Moreover, if certain conditions are satisﬁed, the performance of VB algorithms is not sensitive to the distribution of non-zero elements in the sensing matrix and the original signal [12], [13]. Another interesting feature of VB algorithms is that their performance can be analyzed in the asymptotic case ( n → ∞) [10]\u2013[15]. These properties make the VB algorithms a suitable choice for low-complexity recovery of sparse signals. For a comprehensive study on the VB algorithms, we refer the interested readers to [12], [16].\nThe VB algorithms are, however, sensitive to the pres- ence of noise in the measured data. The authors in [12] discussed the use of a thresholding technique to deal with noisy measurements. This technique is very effective in the high signal to noise ratio (SNR) regime (such as the scenario in [4]). Having said that, some compressed sensing applications (see [5], [6] for some examples) are formulated as noiseless problems with sparse measurement matrices. Furthermore, the noise-free analysis of recovery algorithms serves as an upper bound for the performance of the noisy versions. All of the above highlight the importance of noise- free analysis of the recovery algorithms in compressed sensing, in general, and in compressed sensing with sparse measurement matrices, in particular.\nThe main focus of this paper is to analyze NB-VB recovery algorithms for compressed sensing problems with irregular sensing graphs and to design sensing graphs that perform well with these recovery algorithms. Our results are derived in the asymptotic regime ( n → ∞). In this regime, we assume a probabilistic model for the input signal, in which a signal element is zero with probability 1 − α or takes a value from a continuous distribution with probability α. Henceforth, the parameter α is referred to as the density factor. Let α (ℓ) denote the probability that a signal element is non-zero and unknown at iteration ℓ over the ensemble of all sensing graphs and all inputs of interest. In the asymptotic regime, the recovery algorithm is called successful for the initial density factor α (0) = α if\nand only if lim ℓ→∞ α (ℓ) = 0. Indeed, if the initial density factor is smaller than a certain threshold, referred to as the success threshold , then the recovery algorithm is successful as n → ∞ and ℓ → ∞ [10]\u2013[15]. Fixing the compression ratio m/n, it is desirable to devise sensing graphs with the highest success threshold possible.\nAn asymptotic analysis of NB-VB algorithms was ﬁrst presented in [10], where a system of coupled differential equations had to be solved. To cope with the high complex- ity of solving such a systems, the authors used numerical methods to solve the system for ﬁnite values of n, and thus obtained an approximation of the asymptotic result by choosing a large value of n. The numerical approximation in [10] translates to long running times and the possibility of numerical errors propagating through the iterations in the analysis. The latter would compromise the accuracy of the obtained success thresholds [12], [13].\nIn [12], [13], the authors developed a low-complexity framework for the asymptotic analysis of NB-VB algo- rithms over sparse random regular sensing graphs. The analysis presented in [12], [13] was signiﬁcantly faster and more robust against numerical errors compared to the approach of [10].\nIn this paper, we extend the analysis presented in [12], [13] to irregular graphs. Our simulations show that for a given compression ratio m/n, irregular graphs can provide up to 40% larger success thresholds compared to regular graphs. In this comparison, since the number of edges in both graphs is the same, the recovery complexity remains almost the same. Just like the analysis in [12], [13], the pro- posed analysis is developed for noiseless measurements and its computational complexity increases only linearly with the number of iterations. Moreover, the analysis is simple to perform, requiring only additions and multiplications. This makes it possible to use the analysis at the core of a process to design degree distributions for irregular sensing graphs that perform well with NB-VB algorithms. The performance measure considered in this work is the success threshold.\nLet G(V ∪ C, E) denote a bipartite graph or a bigraph with the node set V ∪ C and the edge set E, so that every edge in E connects a node in V to a node in C. Further, let A (G) denote the biadjacency matrix of graph G; the entry a ij in A is 1 if there exists an edge connecting the nodes c i ∈ C and v j ∈ V . Following the coding terminology, we refer to the sets V and C as variable nodes and check nodes , respectively.\nIn general, a bigraph can be weighted and irregular. In the weighted bigraph G \u2032 (V ∪ C, W (E)) a weight w ij := w(e ij ) ∈ R\\{0} is associated with each edge e ij ∈ E. The weight w ij also appears in the (i, j)th entry of the biadjacency matrix A (G \u2032 ) corresponding to the weighted bigraph G \u2032 .\nIn a bigraph, a node in V (C) has degree i if it is neighbor (connected) to i nodes in C (V ). Let λ i ∈ R + and ρ i ∈ R + denote the fraction of nodes in V and C with\ndegree i, respectively. The polynomials λ(x) = i λ i x i and ρ(x) = i ρ i x i are referred to as degree distributions corresponding to nodes in V and C, respectively. Clearly, λ(1) = ρ(1) = 1. For mathematical convenience, we deﬁne\n¯ d v := i iλ i and ¯ d c := j jρ j and we refer to them as the average variable degree and the average check degree, respectively.\nFor given λ(x), ρ(x) and n, let G n (λ(x), ρ(x)) (G n (λ, ρ) for short) denote the ensemble of all irregular bigraphs with n variable nodes and degree distributions λ(x) and ρ(x). Further, let W m×n f \t be the ensemble of all m × n (m = n ¯ d v / ¯ d c ) matrices with i.i.d. entries w drawn according to a distribution f (w). Now, for any irregular bigraph G(V ∪ C, E) ∈ G n (λ, ρ) and any weight matrix W ∈ W m×n f , we form the corresponding (n, λ, ρ)-weighted irregular bigraph G \u2032 (V ∪ C, W (E)) as follows. Let us assume an arbitrary, but ﬁxed, labeling scheme for node sets V and C over the ensemble G. To every edge e ij ∈ E, 1 ≤ i ≤ m, 1 ≤ j ≤ n, connecting c i ∈ C and v j ∈ V , we assign the weight in row i and column j of the weight matrix W ; i.e., w(e ij ) = w ij . Thus, we construct the ensemble of all (n, λ, ρ)-weighted irregular bigraphs, denoted by G n f (λ, ρ), by freely combining elements in G n (λ, ρ) and W m×n f .\nTo describe the inputs of interest, let α ∈ [0, 1] be a ﬁxed real number and v be a vector of length n with elements v i drawn i.i.d. according to Pr[v i = v] = αg(v) + (1 − α)δ(v), where δ(·) and g(·) are the Kronecker delta and a probability density function, respectively. We denote the ensemble of all such vectors by V n g (α). 1\nTo build the compressed sensing setup, let G(V ∪ C, W (E)) be a weighted irregular bigraph drawn uniformly at random from the ensemble G n f (λ, ρ) with G as its biadjacency matrix. Moreover, let v be a signal vector drawn uniformly at random from the ensemble V n g (α). Also, let c = Gv. The sets of signal elements v and measurements c are respectively mapped to the vertex sets V and C (|V | = n, |C| = m) with the sensing matrix being the biadjacency matrix G. Henceforth, we refer to the graph G as the sensing graph.\nAs a class of iterative recovery algorithms, the VB algorithms ﬁnd the value of a set of signal elements in each iteration based on the knowledge of the measurements, the sensing graph and the previously veriﬁed signal elements. In [11]\u2013[13], [17], [18], it was demonstrated that the continuity of at least one of the distributions f or g (non-zero weights of the sensing graph or non-zero signal elements), is a sufﬁcient condition for the assigned value to a variable node at a certain iteration to be its true value with probability one (zero probability of false veriﬁcation). In this paper also, we assume that the probability of false veriﬁcation throughout the recovery algorithm is zero.\nThe algorithm discussed in [17], which is the same as the LM2 algorithm of [11], performs the best among all known VB algorithms in the context of compressed sensing [10], [12], [13]. We refer to this algorithm as SBB. The analysis of SBB is the focus in this work. The proposed analytical framework is, however, general and applicable to the analysis of other NB-VB algorithms. In what follows, we discuss the veriﬁcation rules of the SBB algorithm.\nWhen a variable node is veriﬁed at an iteration of an NB- VB algorithm, its value is subtracted from the value of all its neighboring check nodes. Then, the variable node and all its adjacent edges are removed from the sensing bigraph. Consequently, all the check nodes neighbor to the veriﬁed variable node face a reduction in their degree by one. The algorithm stops at an iteration if the set of veriﬁed variable nodes remains unchanged for two consecutive iterations or when all the variables are veriﬁed. A variable node in SBB is veriﬁed based on the following veriﬁcation rules.\nZero Check Node (ZCN): All variable nodes neighbor to a zero-valued check node are veriﬁed with a value equal to zero.\nDegree One Check Node (D1CN): If a variable node is neighbor to a check node of degree 1, it is veriﬁed with the value of the check node.\nEqual Check Nodes (ECN): Let C denote a set of check nodes with the same non-zero value. Also, let V denote the set of all variable nodes neighbor to at least one check node in C. Then, 1) a variable node in V which is not connected to all check nodes in C is veriﬁed with a value equal to zero; 2) if there exists a unique variable node in V that is neighbor to all check nodes in C, then it is veriﬁed with the common value of the check nodes.\nIn order to introduce the asymptotic analysis of NB-VB algorithms and prove the concentration results, the authors in [12], [13] developed a message passing representation of VB algorithms. In this paper, we use the same representa- tion and refer the interested reader to the aforementioned references for more details.\nLet the probability distributions f and g, the degree distributions λ and ρ, and the density factor α be ﬁxed. It can be shown that the fraction of unveriﬁed non-zero variable nodes at each iteration ℓ of the SBB algorithm ( α (ℓ) ) over a realization of the sensing graph G ∈ G n f (λ, ρ) and a realization of the input signal V ∈ V n g (α) concentrates around the average of α (ℓ) taken over all the elements in the ensemble G n f (λ, ρ) × V n g (α), as n tends to inﬁnity. 2 The deterministic analysis presented here is to track the evolution of this average as n goes to inﬁnity. In the language of coding, the analysis is similar to the density evolution analysis of iterative decoding algorithms over irregular LDPC code ensembles, with the main difference\nbeing that the NB-VB algorithms do not conform to the principle of extrinsic message passing which signiﬁcantly simpliﬁes the density evolution analysis in the context of coding.\nThe mathematical framework for the analysis is similar to the one used in [12], [13], however with two extra variables d v and d c which represent the degree of a variable and a check node, respectively. These variables take different values for irregular graphs while for a regular graph they each have a ﬁxed value. This makes the derivations more tedious. Due to the lack of space, in the following, we only provide a sketch of the analysis.\nAt the beginning of each iteration ℓ, the analysis par- titions the set of all unveriﬁed variable nodes into two (disjoint) sets: non-zero variable nodes ( K (ℓ) ), zero-valued variable nodes ( ∆ (ℓ) ). Should the fraction of variable nodes in the set K (ℓ) tend to zero as iterations proceed, the fraction of variable nodes in the set ∆ (ℓ) will also tend to zero and consequently the analysis declares a successful recovery [12].\nEach iteration in the SBB algorithm is divided into two rounds ( R), each consisting of two half-rounds (HR). In the ﬁrst and second rounds, veriﬁed variable nodes belong to the sets K (ℓ) and ∆ (ℓ) , respectively. The conﬁguration of the sets at the end of each half-round is speciﬁed using the superscript (ℓ, Rx, y), where ℓ, x ∈ {1, 2} and y ∈ {1, 2} denote the iteration, round and half-round numbers, respectively.\nWe partition the set of all check nodes with the same degree (say d c ) into sets N (ℓ) i,j (d c ), 0 ≤ i ≤ d c , 0 ≤ j ≤ d c − i, where i and j indicate the number of neighboring variable nodes in the sets K (ℓ) and ∆ (ℓ) , respectively.\nLet K (ℓ) (d v ) and ∆ (ℓ) (d v ) denote the set of all non- zero and zero-valued unveriﬁed variable nodes with the same degree d v , respectively. Then, the set K (ℓ) (d v ) is further divided into subsets K (ℓ) i (d v ), 0 ≤ i ≤ d v , where i denotes the number of neighboring check nodes in the set N (ℓ) 1 := d\nN (ℓ,R1,1) 1,j \t (d c ). Also, we divide the set ∆ (ℓ) (d v ) into subsets ∆ (ℓ) i (d v ), 0 ≤ i ≤ d v , with the following deﬁnition: a variable node in ∆ (ℓ) i has i neighboring check nodes which became zero-valued after HR1 of R2. Table I summarizes the sets affected in each half-round of each round at any iteration.\nTheorems 1 and 2 below, characterize the veriﬁcation of unveriﬁed non-zero ( K (ℓ) ) and zero-valued ( ∆ (ℓ) ) variable nodes at HR2-R1 and HR2-R2 in each iteration ℓ of the SBB algorithm, respectively. The proofs of the theorems\nare very similar to the ones presented in [12] and therefore omitted.\nTheorem 1. In the ﬁrst round of any iteration ℓ, a non- zero variable node of degree d v is veriﬁed if and only if it belongs to the set d v i =2 K (ℓ,R1,2) i \t ∪ ˆ K (ℓ,R1,2) 1 \t , where the set ˆ K (ℓ,R1,2) 1 \t consists of all variable nodes in the set K (ℓ,R1,2) 1\nTheorem 2. In the second round of any iteration ℓ, a zero- valued variable node of degree d v is veriﬁed if and only if it belongs to the set d v i =1 ∆ (ℓ) i .\n∆ (ℓ−1,R2,2) i \t fully describe the state of the algorithm at the beginning of iteration ℓ. The probability that a variable node belongs to the set K (ℓ) is α (ℓ) .\nThe asymptotic analysis tracks the probability that a node (variable node or check node) belongs to a certain set at each half-round, round, or iteration. The recovery is successful if and only if the probability α (ℓ) tends to zero, as ℓ tends to inﬁnity. The analysis is based on the derivation of recursive equations that relate the probabilities described above for two consecutive iterations. The complexity of the analysis thus scales linearly with the number of iterations.\nTo verify the asymptotic results obtained based on the analysis of Section IV, we perform some ﬁnite-length simulations for large values of n. The input signal in all simulations follows the probabilistic model described in Section II. Also, each non-zero signal element is drawn from a standard Gaussian distribution (zero-mean with variance one). The graphs are constructed randomly with no parallel edges and all edge weights are chosen to be 1. Each simulation point is generated by averaging over 1000 random instances of the input signal. In simulations, the recovery is successful if and only if the input signal is recovered perfectly. For the analytical results, based on the fact that α (ℓ) is a non-increasing function of iteration number ℓ, we consider the following stopping criteria:\nTo calculate the success threshold, a binary search is performed within a certain range of initial density factors which includes the threshold. The search continues until the search region is smaller than 10 − 5 .\nTo motivate the use of irregular graphs for the purpose of sparse signal recovery, we ﬁrst present some comparison with regular graphs. In Table II, we compare the success threshold of the SBB algorithm over regular, left-regular (all variable nodes have the same degree), right-regular (all check nodes have the same degree) and bi-irregular graphs, when the average variable and check degrees are ﬁxed at ¯ d v = 4, ¯ d c = 5, respectively. The success thresholds reported for the left- and right-regular graphs are the highest thresholds obtained by optimizing right and left degree distributions with maximum degree 20 and\nwith up to four non-zero components, respectively. For the bi-irregular case, however, we restricted the search to only two degrees (bimodal distribution) both less than 20 for both variable and check nodes. The optimized degree distributions (λ(x), ρ(x)) are: (0.9310x 3 + 0.0350x 17 + 0.0340x 18 , x 5 ), (x 4 , 0.7100x 3 +0.1830x 5 +0.1070x 20 ), and (0.9000x 3 + 0.1000x 13 , 0.9375x 4 + 0.0625x 20 ) for right- regular, left-regular, and bi-irregular graphs, respectively. As expected, the bi-irregular graphs achieve the highest success threshold, almost 37% higher than that of the regular graphs.\nTo investigate the degree of agreement between our asymptotic analysis and ﬁnite-length simulations, we have presented in Fig. 1 the evolution of α (ℓ) (for the theoret- ical results) and the average unveriﬁed non-zero variable nodes normalized by n (for the ﬁnite-length results) with iterations ℓ for the SBB algorithm. The sensing graph is a randomly constructed bi-irregular graph with the optimized degree distributions λ(x) = 0.9000x 3 + 0.1000x 13 and ρ(x) = 0.9375x 4 +0.0625x 20 with 10 5 variable nodes. Two values of α (0) are selected: one above the success threshold ( 0.595 > 0.5795) and one below it (0.575 < 0.5795). The theoretical results are shown by dotted lines while simulations for n = 10 5 are presented with solid lines. As one can see, the two sets of results are in close agreement particularly for the cases where α (0) is above the threshold and also for smaller values of ℓ.\nIn Figure 2, we have plotted the average normalized number of unveriﬁed variables (success ratio) of SBB over\n5 0.931x 3 + 0.035x 17 + 0.034x 18 0.5319 0.4225 6 0.917x 3 + 0.082x 15 + 0.001x 19 0.4137 0.3387 7 0.906x 3 + 0.034x 13 + 0.06x 14 0.3369 0.2811 8 0.896x 3 + 0.04x 12 + 0.064x 13 0.2831 0.2394\nthe graphs with optimized right-regular and bi-irregular degree distributions of Table II vs. the initial density factor. Each graph has n = 10 5 variable nodes. We note that the success threshold for each graph, demonstrated by a vertical line on the ﬁgure, matches the waterfall region of the corresponding ﬁnite-length simulations.\nMore optimization results for right-regular graphs with ¯ d v = 4 and different d c values are presented in Table\nIII. For comparison, the threshold values α ∗ R of the cor- responding regular graphs are also given in the table. An inspection of the threshold values reveals an improvement of about 18% to 26% in the threshold of irregular graphs in comparison with that of regular graphs.\nTo reduce the design complexity of irregular graphs, we also investigate the effect of reducing the number of non- zero components in the left degree distribution of right- regular graphs. The results for some optimal bimodal left degrees are presented in Table IV. It can be seen from the table that the difference between the thresholds α ∗ B of bimodal left degrees and the thresholds α ∗ of left degrees with up to 4 nonzero components are negligible, i.e., only two different degrees on the variable side of a right-regular sensing graph sufﬁces to provide very good performance."},"refs":[{"authors":[{"name":"D. Donoho"}],"title":{"text":"Compressed sensing"}},{"authors":[{"name":"E. Cand`es"},{"name":"J. Romberg"},{"name":"T. Tao"}],"title":{"text":"Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency infor- mation"}},{"authors":[{"name":"W. Xu"},{"name":"B. Hassibi"}],"title":{"text":"Efﬁcient compressive sensing with determin- istic guarantees using expander graphs"}},{"authors":[{"name":"A. Abdelkeﬁ"},{"name":"Y. Jiang"},{"name":"W. Wang"},{"name":"A. Kvittem"}],"title":{"text":"Robust trafﬁc anomaly detection with principal component pursuit"}},{"authors":[{"name":"Y. Lu"},{"name":"A. Montanari"},{"name":"B. Prabhakar"}],"title":{"text":"Counter braids: Asymp- totic optimality of the message passing decoding algorithm"}},{"authors":[{"name":"Y. Lu"},{"name":"A. Montanari"},{"name":"B. Prabhakar"},{"name":"S. Dharmapurikar"},{"name":"A. Kab- bani"}],"title":{"text":"Counter braids: A novel counter architecture for per-ﬂow measurement"}},{"authors":[{"name":"E. Cand`es"},{"name":"T. Tao"}],"title":{"text":"Decoding by linear programming"}},{"authors":[{"name":"J. Meng"},{"name":"W. Yin"},{"name":"H. Li"},{"name":"E. Houssain"},{"name":"Z. Han"}],"title":{"text":"Collaborative spectrum sensing from sparse observations using matrix completion for cognitive radio networks"}},{"authors":[{"name":"R. Heckel"},{"name":"H. Bolcskei"}],"title":{"text":"Compressive identiﬁcation of linear operators."}},{"authors":[{"name":"F. Zhang"},{"name":"H. D. Pﬁster"}],"title":{"text":"Analysis of veriﬁcation-based decoding on the q-ary symmetric channel for large q"}},{"authors":[],"title":{"text":"On the iterative decoding of high rate LDPC codes with applications in compressed sensing."}},{"authors":[{"name":"Y. Eftekhari"},{"name":"A. Heidarzadeh"},{"name":"A. Banihashemi"},{"name":"I. Lambadaris"}],"title":{"text":"An efﬁcient approach toward the asymptotic analysis of node-based veriﬁcation-based algorithms in compressed sensing"}},{"authors":[],"title":{"text":"An efﬁcient approach toward the asymptotic analysis of node- based veriﬁcation-based algorithms in compressed sensing"}},{"authors":[{"name":"M. Luby"},{"name":"M. Mitzenmacher"}],"title":{"text":"Veriﬁcation-based decoding for packet-based low-density parity-check codes"}},{"authors":[{"name":"F. Zhang"},{"name":"H. D. Pﬁster"}],"title":{"text":"List-message passing achieves capacity on the q-ary symmetric channel for large q"}},{"authors":[{"name":"R. Berinde"},{"name":"A. Gilbert"},{"name":"P. Indyk"},{"name":"K. Strauss"}],"title":{"text":"Combining geometry and combinatorics: A uniﬁed approach to sparse signal recovery"}},{"authors":[{"name":"S. Sarvotham"},{"name":"D. Baron"},{"name":"R. Baraniuk"}],"title":{"text":"Sudocodes - fast mea- surement and reconstruction of sparse signals"}},{"authors":[{"name":"F. Zhang"},{"name":"H. D. Pﬁster"}],"title":{"text":"Compressed sensing and linear codes over real numbers"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565353.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S10.T9.5","endtime":"13:10","authors":"Yaser Eftekhari, Amir Banihashemi, Ioannis Lambadaris","date":"1341406200000","papertitle":"Analysis and Design of Irregular Graphs for Node-Based Verification-Based Recovery Algorithms in Compressed Sensing","starttime":"12:50","session":"S10.T9: Compressive Sensing and Algorithms","room":"Stratton West Lounge (201)","paperid":"1569565353"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
