{"id":"1569566715","paper":{"title":{"text":"Sparse Signal Recovery in Hilbert Spaces"},"authors":[{"name":"Graeme Pope"},{"name":"Helmut Bölcskei"}],"abstr":{"text":"Abstract\u2014This paper reports an effort to consolidate numerous coherence-based sparse signal recovery results available in the literature. We present a single theory that applies to general Hilbert spaces with the sparsity of a signal deﬁned as the number of (possibly inﬁnite-dimensional) subspaces participating in the signal\u2019s representation. Our general results recover uncertainty relations and coherence-based recovery thresholds for sparse signals, block-sparse signals, multi-band signals, signals in shift- invariant spaces, and signals in ﬁnite unions of (possibly inﬁnite- dimensional) subspaces. Moreover, we improve upon and gener- alize several of the existing results and, in many cases, we ﬁnd shortened and simpliﬁed proofs."},"body":{"text":"The sparse signal recovery literature is vast and has evolved along several threads with recent focus mostly on probabilistic results. This paper constitutes an attempt to consolidate the numerous coherence-based recovery results available in the literature. More speciﬁcally, we formulate a single theory that applies to ﬁnite- and inﬁnite-dimensional Hilbert spaces, in combination with sparsity deﬁned as the (ﬁnite) number of (possibly inﬁnite-dimensional) subspaces participating in a signal\u2019s representation. The general coherence-based re- covery thresholds we ﬁnd contain the known thresholds in the following settings as special cases: (i) sparse signals in ﬁnite-dimensional spaces [1]\u2013[4], (ii) block-sparse signals [5], [6], (iii) multi-band signals [7]\u2013[9], (iv) signals in shift- invariant spaces [10], and (v) signals in ﬁnite unions of ﬁnite or inﬁnite-dimensional subspaces [11]\u2013[13]. In addition, we improve upon the thresholds in [5] and we generalize the uncertainty relation in [10]. We introduce suitable generaliza- tions of P0-minimization [2], basis pursuit [2], and orthogonal matching pursuit [14]. Finally, we indicate how the results on signal separation reported in [15], [16] can be extended to the general Hilbert space setting considered here.\nKey to our results are deﬁnitions of coherence [2] and mutual coherence [3], [16] that work for our general setting. Based on these deﬁnitions, we obtain a general kernel uncer- tainty relation which is then used to establish general recovery thresholds. Similarly our deﬁnition of mutual coherence paves the way to a general uncertainty relation that yields fundamen- tal limits on how sparse a signal in a general Hilbert space can be under two different representations. All theorems in this paper are given without proof.\nNotation: Lowercase boldface letters stand for column vectors and uppercase boldface letters designate matrices. For a vector a, the kth element is written a k . For the matrix A,\nA H is its conjugate transpose, its kth column is written a k , and the entry in the kth row and th column is denoted by A k, . The spectral norm of A is A 2→2 , σ min (A) and σ max (A) are the minimum and maximum singular value of A, respectively.\nH and G are Hilbert spaces equipped with the norm · H and · G , respectively, and H has direct sum decom-\nposition [17, Ch. 5.20] H = n i=1 H (i) where n < ∞. We deﬁne v (i) to be the canonical projection of v onto H (i) . For v ∈ H , v H ,0 \t {i : v (i) H > 0} and\nand v (S) to be the projection of v onto H (S) . We say that a signal v ∈ H is ε S -concentrated to the set S if\nv (S) H ,1 \t (1 − ε S ) v H ,1 , where 0 \t ε S \t 1. We deﬁne e i ∈ C N to be the all zero vector with a one in the ith position. For an operator ϕ : H → G with ad- joint ϕ H , ω min (ϕ) \t inf v∈ H ϕ(v) G / v H , ω max (ϕ)\nsup v∈ H ϕ(v) G / v H , and ker(ϕ) {v ∈ H : ϕ(v) = 0}. For α ∈ R, we set [α] + max{0, α}. The cardinality of a set S is denoted as |S|. The Fourier transform operator is written F .\nLet H and G be Hilbert spaces, with dimensions N and M, respectively, possibly inﬁnite. Assume that H = n i=1 H (i) , n < ∞, and set d i = dim( H (i) ). We describe the sampling of signals in H through the application of a bounded linear operator Φ : H → G , which we call a sampling operator. With Φ we associate the operators ϕ i : H (i) → G , for i = 1, ..., n, obtained by restricting the action of Φ to the subspace H (i) . It follows from the linearity of Φ that Φ(v) = n i=1 ϕ i (v (i) ). We require that each ϕ i be injective.\nFor N = n i=1 d i < ∞, the action of Φ can be represented through a matrix D ∈ C M ×N according to Φ(v) = Dv, v ∈ C N . Taking D[i] = [ d i 1 · · · d i di ] to be the set of columns of D that correspond to H (i) we have ϕ i (v (i) ) = D[i] v (i) , for i = 1, ..., n.\nKey to our results are deﬁnitions of coherence, mutual coherence, and spark for general sampling operators.\nDeﬁnition 1 (Hilbert space coherence): Let H and G be Hilbert spaces and let Φ : H → G be a sampling operator. We deﬁne the Hilbert space coherence of Φ as 1\nWe can interpret µ H (Φ) as a measure of closeness of the subspaces H (i) under the action of Φ.\nDeﬁnition 2 (Mutual Hilbert space coherence): Let H 1 , H 2 , and G be Hilbert spaces and let Φ: H 1 → G and Ψ : H 2 → G be sampling operators. We deﬁne the mutual Hilbert space coherence of Φ and Ψ as\nω min (ϕ i ) ω min (ψ j ) . \t (2) The mutual Hilbert space coherence extends the deﬁnition of mutual coherence in [3], [16]. The setting of [3], [16] is recovered as follows. Let H 1 = C N 1 , H 2 = C N 2 , and G = C M . Represent the sampling operators Φ : H 1 → G and Ψ : H 2 → G by the matrices A and B, respectively, so that Φ(v) = Av and Ψ(u) = Bu. Then, we have\nwhere µ m is the mutual coherence as speciﬁed in [16], and (a) follows since in [16] A and B are assumed to have columns with unit 2 -norm.\nDeﬁnition 3 (Hilbert space spark): Let H and G be Hilbert spaces and let Φ : H → G be a sampling operator. Then\nThe spark of a sampling operator is the smallest number of subspaces that a non-zero signal v ∈ H in ker(Φ) can occupy.\nWith our general deﬁnitions of coherence and spark, the general recovery thresholds below follow without difﬁculties. We start with a general kernel uncertainty relation.\nTheorem 1 (Kernel uncertainty relation): Let Φ : H → G be a sampling operator with Hilbert space coherence µ H (Φ). Let v ∈ H be ε S -concentrated to S. If Φ(v) = 0, then\nWe next deﬁne two optimization problems for the recovery of a signal v ∈ H from its measurements z = Φ(v) ∈ G . The ﬁrst one, H -P0, aims to ﬁnd the signal that explains the given measurements while occupying the fewest subspaces:\nRecovery thresholds for H -P0 and H -BP can now be derived from the kernel uncertainty relation in Theorem 1.\nIn addition, we have the following bound, spark(Φ) 1 + (µ H (Φ)) −1 , which combined with Theorem 2 allows us to conclude that H -P0 returns the correct solution if\nTheorem 3: If v ∈ H satisﬁes Φ(v) = z and (8) holds, then H -BP applied to z returns the correct solution v.\nA commonly used alternative to BP is orthogonal matching pursuit (OMP) [14], [19]. We next present a Hilbert-space ver- sion of OMP, which we call H -OMP. This algorithm works by iteratively identifying the subspaces H (i) participating in the representation of v and computes an approximation to v, denoted as v i , in the ith iteration. The corresponding residual in the ith iteration is given by r i z −Φ(v i ). The algorithm is initialized with r 0 ← z and i ← 1, and performs the following steps until r i G = 0:\n2) Update \t the \t list \t of \t participating \t sub- spaces: S i ← S i−1 ∪ { }.\n3) Find the best approximation to v with support S i : v i ← arg min\nTheorem 4: Let Φ : H → G be a sampling operator. Then H -OMP applied to z = Φ(v) returns the correct solution v if (8) is satisﬁed and will require exactly v H ,0 iterations.\nNote that implementing the algorithms mentioned above, when H is inﬁnite-dimensional, is non-trivial. Some alter- natives to H -BP and H -OMP, such as SBR2/4, have been proposed for blind multi-band sampling [9], which is a special case of our setup. It is an interesting open problem to extend these algorithms to the general framework in this paper.\nWe next show how the recovery thresholds in [1]\u2013[5], [7]\u2013 [9], [11] follow from the general recovery threshold (8). The results in [6], which pertain to a generalization of [5] allowing for different subspace dimensions, can be recovered following the same methodology, but this will not be detailed here due to space constraints.\nThe (coherence-based) thresholds in [1]\u2013[4] are recovered as follows. Set H = C N and G = C M . Take the sampling operator Φ to be represented by the matrix D ∈ C M ×N , with unit 2 -norm columns d i . Take H (i) to be the 1-dimensional subspace spanned by e i ∈ C N , so that N = n. The action of ϕ i : H (i) → G is represented by ϕ i (v (i) ) = d i v (i) = d i v i . Since ω min (ϕ i ) = d i 2 = 1 and ω max ϕ H i ϕ j = | d i , d j |, we get µ H = max i=j | d i , d j |, which is exactly the deﬁnition of coherence as introduced in [2]\u2013[4]. The recovery threshold (8) for H -P0, H -BP, and H -OMP (which then reduce to P0, BP, and OMP, respectively) is thus equal to the\ncorresponding thresholds in [2]\u2013[4]. As an aside the general result (8) shows how dictionaries with unnormalized columns should be treated, speciﬁcally what the appropriate measure of coherence is, and what the selection criterion in Step 1 of ( H -)OMP should be.\nThe results for the block-sparse setting considered in [5] are recovered as follows. Set H = C N , G = C M , and N = nd, where d is the block size and n is the number of blocks (and hence the number of subspaces H (i) ). As before, the sampling operator Φ is represented by the matrix D ∈ C M ×N with unit 2 -norm columns. Let H (i) be the subspace spanned by {e (i−1)d+1 , ..., e id }, and set D[i] = [ d (i−1)d+1 · · · d id ], so that ϕ i (v (i) ) = D[i] v (i) . From (1) the Hilbert space coherence is\nσ 2 min (D[i]) \t . \t (9) We next show how the recovery threshold (8) improves upon that reported in [5, Thms. 2 and 3], which states that recovery using (L-OPT) [5, Eq. 32] and BOMP [5, Sec. IV- A] (our H -BP and H -OMP, respectively), is successful if\nσ max (D[i]) H D[j] d\nand D[ ] i is the ith column of D[ ]. The following steps establish that µ H ˆ µ, thereby proving our claim 2\nwhere we applied the Geršgorin disc theorem [20, Th. 6.1.1] in (a). When (D[i]) H D[i] = I d , for all i, we have µ H = ˆ µ, but one can easily ﬁnd examples where the strict inequality µ H < ˆ µ holds.\nWe next show how our results apply to sparse multi-band signals as considered in [8], [9], [21], [22]. Let H be the space of functions band-limited to the interval [0, 1/T ) and for a signal v ∈ H , let V be its Fourier transform. For\nsimplicity of exposition, assume that the interval [0, 1/T ), is divided into n disjoint intervals I 1 , ..., I n , with I i = [(i − 1)/(nT ), i/(nT )), i = 1, ..., n. Deﬁne the subspaces H (i) = {v ∈ L 2 (R) : V (f ) = 0, for all f / ∈ I i }. Thus, for a signal v ∈ H , the sparsity level v H ,0 is the number of frequency bands I i occupied by V .\nWe next demonstrate how the multi-coset sampling scheme of [7], [8] can be analyzed in our framework. Multi-coset sampling maps the signal v to m \t n sequences z (k) as follows:\nTo obtain an explicit characterization of the corresponding sampling operator Φ we will work in the frequency domain. The Fourier transform of z (k) is given by\nwhere λ k, = (nT ) −1 exp(2πik /n) and V ( ) (f ) = V (f + /(nT )). Then, the action of the sampling operator, Φ : H → G , can be represented in terms of the continuously parametrized linear system of equations\n \n \n \n \n \n \nfor f ∈ [0, 1/(nT )). We have thus established a ﬁnite- dimensional continuously indexed matrix representation of Φ [17]. Based on this insight, we next show that\nwhich means that we can reduce the computation of Hilbert space spark and Hilbert space coherence of an inﬁnite- dimensional operator to that of a ﬁnite matrix that does not depend on f . Since (10) holds for all f ∈ [0, 1/(nT )), for v to lie in the kernel of Φ, V (f ) must be in ker(Λ) for each f ∈ [0, 1/(nT )). One can then show that this implies that spark(Φ) = spark(Λ). The second equality in (11) follows since Λ consists of the ﬁrst m rows of the n × n DFT matrix and hence spark(Λ) = m [21].\nTo prove (12), note that for u ∈ H (i) with Fourier trans- form U , ϕ i : H (i) → G is given by the matrix representation\n \n \n \n \n \n \n \n \nwhere λ j is the jth column of Λ. Since (13) holds for all U , it follows that\nFrom [7], [9] we know that to recover a multi-band signal with bandwidth s/(nT ) (and with unknown spec- tral occupancy), it is necessary to sample at a rate f s = m/(nT ) 2s/(nT ). Theorem 2 implies that uniqueness of H -P0 recovery is guaranteed for multi-band coset sampling if spark(Φ)/2 = m/2 > s. Hence, sampling at rate at least 2s/(nT ) is also sufﬁcient to recover an s-sparse signal and recovery of the (multi-coset sampled) signal can be achieved through H -P0.\nTheorem 2 in this paper implies [11, Prop. 4] and [11, Eq. (23)] with the observation that the generalized Gram matrix in [11, Eq. (17)] plays the role of the sampling operator Φ in our framework. Our Theorem 2 also implies [12, Th. 2.2].\nAnother thrust in the sparse signal recovery literature deals with the recovery of sparsely corrupted signals [16]. The main tool underlying this line of work is an uncertainty relation that sets a limit on how sparsely a given signal can be represented concurrently in two different dictionaries [1], [15], [16]. We next formulate a Hilbert space version of this uncertainty relation, which is then used to recover and generalize results in [10] and [16].\nTheorem 5 (Uncertainty relation): Let H 1 , H 2 , and G be Hilbert spaces and let Φ : H 1 → G and Ψ: H 2 → G be sampling operators. Let u ∈ H 1 and v ∈ H 2 be signals that\nare ε U - and ε V -concentrated to the sets U and V, respectively, and assume that Φ(u) = Ψ(v). Then, we have\nRemark: [16, Th. 1] can be recovered from Theorem 5 by noting that Φ and Ψ play the role of the dictionaries A and B, respectively, as used in [16]. Then Φ(u) = Ψ(v) becomes Au = Bv and [16, Th. 1] follows since µ H (Φ, Ψ) = µ m , µ H (Φ) = µ a , and µ H (Ψ) = µ b , with µ m , µ a , and µ b as deﬁned in [16].\nWe next show how Theorem 5 can be used to recover [10, Th. 1]. Consider the shift-invariant space\n  \n  \n(15) with n 1 generators φ i ∈ L 2 (R) and φ i 2 = 1, for all i. Set H 1 to be the space of vector sequences\n \n \nwith adjoint ϕ H i : S φ → \t 2 given by ϕ H i (z) = { z(·), φ i (· − T ) } ∈Z . The sampling operator 3 Φ : H 1 → S φ is then given by\nA signal v ∈ H is s-sparse if at most s of the sequences v (i) in (18) are non-zero, i.e., if v H ,0 s, and in the terminology of [10], v H ,0 is the number of active generators.\nNow let us consider a set of n 2 generators θ i ∈ L 2 (R) where θ i 2 = 1, for all i, and the space\n  \n \n  \n \nLet H 2 be the space of vector sequences, as in (16), but with n 1 replaced by n 2 , and deﬁne the operators ϑ i : 2 → S θ and Θ : H 2 → S θ as in (17) and (18), respectively, with φ i replaced by θ i . Suppose that z = Φ(v) = Θ(u). We now establish a limit on the sparsity of u and v.\n= 1 if i = j and k = 0 otherwise.\nThen ϕ i (v (i) ) 2 = v (i) 2 , for all i, and for all v (i) ∈ 2 , hence ω min (ϕ i ) = 1, for all i, and similarly ω min (ϑ ) = 1, for all . For i = j and v (j) ∈ 2 , we have\nand similarly ϑ H i ϑ j u (j) 2 = 0, for all u (j) ∈ 2 . Therefore, µ H (Φ) = max i=j ω max (ϕ H i ϕ j ) = 0 and similarly µ H (Θ) = 0. This gives\nwhere we assume perfect concentration (since this is the case considered in [10]), i.e., ε U = ε V = 0. We now show that (19) is the uncertainty relation in [10, Th. 1], which, in our notation, is given by (19) but with µ H (Φ, Θ) replaced by\nIt therefore sufﬁces to prove that ω max ϕ H ϑ r \t = ess sup ξ∈[0,2π) R φ ,θ r e iξ . For v (r) ∈ 2 , we have\nSince Λ is a doubly inﬁnite Toeplitz matrix, its operator norm Λ 2→2 is given by the essential supremum of the Fourier transform of a row of Λ [23, p. 62]. We therefore\nhave ω max ϕ H ϑ r = ess sup ξ∈[0,2π) R φ ,θ r e iξ , which con- cludes the proof.\nWe ﬁnally note that our Theorem 5 also applies to nonorthogonal generator sets {φ i } and {θ j } with potentially different shift parameters, thereby extending the uncertainty relation in [10]."},"refs":[{"authors":[{"name":"D. L. Donoho"},{"name":"P. Stark"}],"title":{"text":"Uncertainty principles and signal recovery"}},{"authors":[{"name":"D. L. Donoho"},{"name":"X. Huo"}],"title":{"text":"Uncertainty principles and ideal atomic decomposition"}},{"authors":[{"name":"M. Elad"},{"name":"A. M. Bruckstein"}],"title":{"text":"A generalized uncertainty principle and sparse representation in pairs of bases"}},{"authors":[{"name":"D. L. Donoho"},{"name":"M. Elad"}],"title":{"text":"Optimally sparse representation in general (nonorthogonal) dictionaries via 1 minimization"}},{"authors":[{"name":"Y. C. Eldar"},{"name":"P. Kuppinger"},{"name":"H. Bölcskei"}],"title":{"text":"Block-sparse signals: Uncertainty relations and efﬁcient recovery"}},{"authors":[{"name":"P. T. Boufounos"},{"name":"G. Kutyniok"},{"name":"H. Rauhut"}],"title":{"text":"Sparse recovery from combined fusion frame measurements"}},{"authors":[{"name":"P. Feng"},{"name":"Y. Bresler"}],"title":{"text":"Spectrum-blind minimum-rate sampling and reconstruction of multiband signals"}},{"authors":[{"name":"Y. Bresler"}],"title":{"text":"Spectrum-blind sampling and compressive sensing for continuous-index signals"}},{"authors":[{"name":"M. Mishali"},{"name":"Y. C. Eldar"}],"title":{"text":"Blind multiband signal reconstruction: Compressed sensing for analog signals"}},{"authors":[{"name":"Y. C. Eldar"}],"title":{"text":"Uncertainty relations for shift-invariant analog signals"}},{"authors":[{"name":"Y. M. Lu"},{"name":"M. N. Do"}],"title":{"text":"A theory for sampling signals from a union of subspaces"}},{"authors":[{"name":"T. Blumensath"},{"name":"M. E. Davies"}],"title":{"text":"Sampling theorems for signals from a union of ﬁnite-dimensional linear subspaces"}},{"authors":[{"name":"Y. C. Eldar"},{"name":"M. Mishali"}],"title":{"text":"Robust recovery of signals from a structured union of subspaces"}},{"authors":[{"name":"J. A. Tropp"}],"title":{"text":"Greed is good: Algorithmic results for sparse approxima- tion"}},{"authors":[{"name":"P. Kuppinger"},{"name":"G. Durisi"},{"name":"H. Bölcskei"}],"title":{"text":"Uncertainty relations and sparse signal recovery for pairs of general signal sets"}},{"authors":[{"name":"C. Studer"},{"name":"P. Kuppinger"},{"name":"G. Pope"},{"name":"H. Bölcskei"}],"title":{"text":"Recovery of sparsely corrupted signals"}},{"authors":[{"name":"A. W. Naylo"},{"name":"G. R. Sel"}],"title":{"text":"Linear Operator Theory in Engineering and Science "}},{"authors":[{"name":"R. Gribonval"},{"name":"M. Nielsen"}],"title":{"text":"Sparse decompositions in \"incoherent\" dictionaries"}},{"authors":[{"name":"G. Davis"},{"name":"S. Mallat"},{"name":"M. Avellaneda"}],"title":{"text":"Adaptive greedy approxima- tions"}},{"authors":[{"name":"R. A. Hor"},{"name":"C. Johnso"}],"title":{"text":"Matrix Analysis"}},{"authors":[{"name":"R. Venkataramani"},{"name":"Y. Bresler"}],"title":{"text":"Sub-Nyquist sampling of multiband signals: Perfect reconstruction and bounds on aliasing error"}},{"authors":[{"name":"M. Mishali"},{"name":"Y. C. Eldar"}],"title":{"text":"From theory to practice: Sub-Nyquist sampling of sparse wideband analog signals"}},{"authors":[{"name":"U. Grenande"},{"name":"G. Szeg˝"}],"title":{"text":"Toeplitz forms and their applications"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566715.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T9.1","endtime":"17:00","authors":"Graeme Pope, Helmut Bölcskei","date":"1341333600000","papertitle":"Sparse Signal Recovery in Hilbert Spaces","starttime":"16:40","session":"S8.T9: Sampling and Signaling","room":"Stratton West Lounge (201)","paperid":"1569566715"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
