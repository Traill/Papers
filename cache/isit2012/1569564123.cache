{"id":"1569564123","paper":{"title":{"text":"On a Construction of Universal Network Code using LDPC Matrices"},"authors":[{"name":"Shigeki Miyake"},{"name":"Jun Muramatsu"}],"abstr":{"text":"Abstract\u2014An LDPC matrix is used as a local encoding kernel at each link to construct a universal code to address network coding problems. It is also shown that at each terminal node the global encoding kernel that constructs a decoder becomes an LDPC matrix. This provides the perspective that decoding complexity can be reduced to a linear order of a block length by using an efﬁcient decoding algorithm such as the sum-product algorithm."},"body":{"text":"The theory of network coding [1] provides the bound of transmission rate (\u201cmax-ﬂow bound\u201d) with which a source node multicasts a message to terminal nodes. A signiﬁcant property of network coding is the transmission of information after being encoded at each intermediate node, which is different from the ordinary store and forward scheme. The problem of how to construct an encoder at each node or decoder at each terminal node has been investigated by many researchers. Li et al. [2] showed that linear codes that assign matrices to each node attain the max-ﬂow bound. Using the random coding technique, Ho et al. [3] showed that a linear code constructed by randomly selected matrices also attains the max-ﬂow bound and established the theory of random linear network coding.\nRegarding channel coding problems, on the other hand, since the 1990\u2019s it has been known that using linear codes constructed from LDPC matrices in combination with an ef- ﬁcient decoding algorithm such as the sum-product algorithm enables decoding complexity to be reduced to O(n) of the block length n. As for the lossless source coding problem, Caire et al. [4] proposed an efﬁcient variable-length universal code using multiple LDPC matrices. It is quite natural that many researchers have tried to construct network codes using LDPC or sparse matrices to reduce encoding and decoding complexity. By constructing each local encoding kernel [10] using sparse matrices, Jaggi et al. [5] reduced encoding complexity to O(n). Li et al. [6] derived a condition with which a square sparse matrix is not non-singular. Note that in [5], since the decoding process adopts an ordinary inverse matrix computation, computational complexity of the process is not reduced compared with ordinary linear network coding.\nIn this paper, by constructing local encoding kernels using LDPC matrices, constructed code is shown to have a universal property that does not depend on the statistical property of the\nsource. Since it is also shown that the global encoding kernel at each terminal node becomes an LDPC matrix, it can be expected that using an efﬁcient decoding algorithm such as the sum-product algorithm will enable decoding complexity to be reduced to O(n).\nG = ( V, E) denotes a directed acyclic graph, where V is a vertex set and E is a link set whose element is described by an ordered pair of vertices (i, j) i, j ∈ V. At each link (i, j) ∈ E, a rate constraint R ij is assigned. Network coding handles the problem of multicasting from the source node s ∈ V to the set of terminal nodes T ⊂ V (Figure 1). The\nnetwork code consists of an encoder f ij and a decoder g t that are assigned at each link (i, j) ∈ E or at a terminal node t ∈ T . Messages and codewords are assumed to be binary sequences of 0 and 1, which are elements of binary ﬁeld F 2 . Let a message transmitted from the source node s be x nω ∈ F nω 2 , which is generated from the discrete memoryless probability distribution P X . Parameters n and ω are the number of link usage and transmission rate, respectively. The nω-length binary sequence x nω can be interpreted as ω-juxtapositions of n-length binary sequences. When we deﬁne encoder and\ndecoder as mappings f ij : F k i 2 → F k ij 2 , and g t : F k t 2 → F nω 2 , the rate constraints at each link (i, j) ∈ E can be denoted as\nNote that if we let z i be an information (or row) vector entering into node i, then decoding error can be described as an event x nω ̸= g t (z t ) for a terminal node t ∈ T . The multicasting problem treated here is the following:\nAssume that message x nω is generated according to the discrete memoryless probability distribution P X and sent out from the source node s. Then construct a network code using LDPC matrices that attains the maxﬂow bound and at the same time makes decoding error at each terminal node arbitrarily small asymptotically with the block length n.\nA universal network code is constructed using LDPC ma- trices.\nAfter showing the construction of LDPC matrices, encoders and decoders are described. For integers i < j, [i : j] is deﬁned as [i : j] def = {i, i + 1, ..., j}, and let H b ( ·) be a binary entropy function: For 0 < γ < 1,\nwhere 1[(Proposition)] takes a value 1 if the proposition is true and 0 otherwise.\nLet c be an even number which is greater than 6, and d be an odd number, and nc = kd is satisﬁed [7]. A bipartite graph constructed by a variable node set labeled [1 : n] and a check node set labeled [1 : k] is considered.\nStep 1. From each node in variable node set c hands are stretched, and from each node in check node set d hands are stretched.\nStep 2. With the condition nc = kd, since the number of hands stretched from both sides of the bipartite graph is equal, the hands from each side can be connected 1 : 1 at random.\nStep 3. If the number of connections between variable node i ∈ [1 : n] and check node j ∈ [1 : k] is even, set a ij = 0, otherwise set a ij = 1.\n[Construction of encoders] For (i, j) ∈ E,\nwhere z i is k i -dimensional row vector, and A ij is a k i × k ij LDPC matrix.\nLet an information (or row) vector that is received by a terminal node t be z t . Then\n˜ A t in the above deﬁnition (6) represents the global encoding kernel [10] at the terminal node t: When the transmitted message is x nω , z t , the information received by the terminal node t is represented by\nFor the network conﬁguration shown in Figure 1, ˜ A t 1 is an nω × k t 1 matrix, and represented by\nRemark 1: Since in the binary alphabet case, the sequence that attains minimum entropy in (6) corresponds to the se- quence that has the least number of 1\u2019s or 0\u2019s under the given linear constraints, which is the maximum likelihood estimator with an appropriate probability parameter, the decoder can be approximately implemented using, e. g. , the sum-product algorithm.\nLemma 1 (Modiﬁed version of Theorem 3 in [7]): Let A be an n × k LDPC matrix, and 0 < γ < 1/2 be a weight parameter satisfying\nwhere K = 6n ln(d) kd . If w(x n ) ≥ nγ and n is sufﬁciently large, then\n2 k \t (10) holds, where\nLemma 2 (Modiﬁed version of arguments at Section V-B [7]): Let A be an n × k LDPC matrix with k = nR for a constant R, and d min (A) def = min x n ̸=0 n :x n A=0 k w(x n ). Then for any 0 < ξ < 1,\nNote that in the above lemma, from the assumption c ≥ 6, β n → 0 (n → ∞) holds [7].\nThe next lemma refers to the universality of a code. Let P n be a type set [8] constructed by n-length sequences, and for each e ∈ E,\nIni(e) def = (origin of a directed link e), Err A,t (x nω ) denotes an event of decoding error at a terminal node t for a message x nω , and H(Q) is an entropy function of a type Q.\n \n} ∨   \nTheorem 1: Suppose that a message x nω is generated ac- cording to a discrete memoryless distribution P X . When a di- rected acyclic graph G and rate constraints R = {R ij } (i,j) ∈E are given, let a weight parameter γ be taken which satisﬁes\nIf ωH(P X ) < min t ∈T maxﬂow(s, t), then for sufﬁciently large d there exist LDPC matrices {A e } e ∈E with high prob- ability and decoding error at each terminal node can be arbitrarily small asymptotically with the block length n, where H(P X ) is an entropy of the source P X , and maxﬂow(s, t) denotes the max-ﬂow [1] between the source node s and the terminal node t.\nNote that (18) denotes a condition with which Lemma 1 and 2 hold on a given graph.\n(Proof of Theorem 1) If Lemma 3 holds, then with the probability of more than 1 − β(n) − ξ, for ∀t ∈ T and ∀Q ∈ P nω , LDPC matrices {A e } e ∈E can be taken that satisfy\nwhere at (a), (19) is used. \t (End of Proof of Theorem 1) From Theorem 1 and its proof, it can be easily seen that if\nholds. And when the weight parameter γ satisﬁes the condition given in the theorem, LDPC matrices with which the decoding error can be arbitrarily small asymptotically with the block length n can be taken with high probability.\nRemark 2: The code constructed here is also a static code [10]. When some links are broken and disconnected, at unbro- ken links the same LDPC matrices can be used for encoding. The proof can be shown applying the union bound to (19), using the fact that the number of disorder patterns is upper- bounded by 2 |E| .\nWhile local encoding kernels A e (e ∈ E) are LDPC matrices, in which the number of 1\u2019s of any row or column is constant with respect to the block length n, it is not obvious whether the global encoding kernel ˜ A t (t ∈ T ) is also an LDPC matrix or not. If ˜ A t is an LDPC matrix, to approximately implement the decoder g t the sum-product algorithm can be applied. The next lemma states that ˜ A t becomes an LDPC matrix:\nLemma 4: For each global encoding kernel ˜ A t (t ∈ T ), the number of 1\u2019s of any row or column is upper-bounded by a constant that does not depend on the block length n\n(Proof of Lemma 4) Assume that n × l matrix A and l × k matrix B are LDPC matrices with parameters (c 1 , d 1 ) and (c 2 , d 2 ), respectively. Let row vectors of B be b 1 , ..., b l . Then the i-th row of the product matrix AB can be described as\nFrom the construction of matrices, since the number of non- zero elements among a i1 , ..., a il is at most c 1 and the number of non-zero elements in k-dimensional row vectors b j (j ∈ [1 : l]) is at most c 2 , it can be seen that the number of non- zero elements of the i-th row of n × k matrix AB is at most c 1 c 2 . From a similar argument, it can be seen that the number of non-zero elements of each column of the matrix AB is at most d 1 d 2 .\nIf we suppose that the length of the longest path from the source node s to the terminal node t is h, since the global encoding kernel ˜ A t is constructed by multiplying matrices that are at most |V| juxtapositions of LDPC matrices, whose parameters are (c, d), at most h times, it can be seen that the number of 1\u2019s of each column is upper-bounded by d h and the number of 1\u2019s of each row is upper-bounded by (c |V|) h . These upper-bounds are constants with respect to the block length n. \t (End of Proof of Lemma 4)\nRemark 3: If d i (i = 1, 2) is O(log n) with respect to the block length n, since d 1 d 2 ≃ O\nand 2 d 1 d 2 can not be upper-bounded by a polynomial of n, a known decoding algorithm such as the sum-product algorithm can not be applied efﬁciently in this case.\nSumming up the above arguments, the following should be noted: If the parameters of LDPC matrices are chosen ap- propriately, the computational complexity of encoding at each node becomes O(n). Furthermore, if we apply a known efﬁ- cient decoding algorithm such as the sum-product algorithm, the decoding complexity at each terminal node can be expected to become O(n).\nIn this paper, it was shown that by using an LDPC matrix as a local encoding kernel at each link, the global encoding kernel also becomes an LDPC matrix at each terminal node. With this fact and by using an efﬁcient decoding algorithm such as the sum-product algorithm, we can expect that the decoding can be approximately implemented with computational complexity of O(n).\nWhile the code shown here is constructed using random selection, there exist deterministically constructed network codes such as the Jaggi-Sanders algorithm [9]. In the latter case, n does not denote block length but the extension degree of the ﬁeld that comprises the alphabet. When in the case of a deterministic algorithm we denote the extension degree as n 0 , the magnitude of n 0 is ordinary about 2 n 0 ≤ 100. Since in the random selection case the magnitude of n can be about nω ≃ 10 4 , when we want to send data of magnitude\nC at transmission rate ω the data is divided into large C nω packets, while in the deterministic case it is divided into small C n\npackets. If we assume that decoding complexity in the former case is O(nω) per packet, the total decoding time is about C nω × O(nω) ≃ C. In the latter case if we adopt FFT for multiplication of the elements of extension ﬁeld GF(2 n 0 ) whose computation complexity is O(n 0 log n 0 ), since the computation complexity of multiplication of the ω- vector and ω × ω matrix is O(ω 2 ), the total decoding time is about C n\n× O ( ω 2 n 0 log n 0 ) ≃ ω log n 0 × C. This argument shows that the network code constructed by LDPC matrices can be expected to be smaller decoding complexity than that of deterministically constructed network code. It should be noted that deterministic algorithms can decode with decoding error of exactly 0, while algorithms constructed with a random selection manner (such as the code constructed in this paper) can decode only with arbitrarily small error. The type of algorithm adopted should be determined according to the situation in which it is applied.\nholds, where β(n) is deﬁned at (17), and the condition in Theorem 1 is necessary to make β(n) → 0 (n → ∞).\nThe ﬁrst half of the following proof is similar to that in [1]. Let the transmitted message be x nω ∈ {0, 1} nω . The probability that at a ﬁxed terminal node t there exists another message ˜ x nω ∈ {0, 1} nω that provides the same codeword as that of transmitted message x nω is evaluated. Note that from Lemma 2, with high probability we can select A e that provides only the case w(x nω + ˜ x nω ) ≥ nγ, and the case\nIn the following, we sometimes use the notations z i def = z i (x nω ) and ˜ z i def = z i (˜ x nω ) as appropriate. Let a random variable A be A def = {A e } e ∈E . Since each A e is selected independently, from the deﬁnition of D e in (14) and Lemma 1, for any (i, j) ∈ E it holds that\nwhere D ij denotes a complement of D ij . Note that the left hand side of (23) becomes 0 for w(z i − ˜ z i ) < k i γ. At the terminal node t, if z t (x nω ) = z t (˜ x nω ) occurs, there exists U ⊂ V such that for any i ∈ U z i ̸= ˜z i holds, and at the same time, between node i in U and node j outside U with (i, j) ∈ E\nholds. From the above observation, since U 0 = U holds, it can be seen that\n \nAt (a), we use the fact that when U 0 ⊃ U, for any l ∈ U z l ̸= ˜ z l holds, and the fact that when U 0 = U , for (i, j) ∈ E U z i A ij = ˜ z i A ij holds. At (b), we use the fact that {A e } that is associated with the event\n{z l ̸= ˜ z l } is selected independently from A ij that satisﬁes z i A ij = ˜ z i A ij , and the fact that for e ̸= ˜e A e is selected independently from A ˜ e . At (c), (23) is used.\nTo consider a code whose transmission rate is near the rate constraint, for a given ε > 0 let k ij be satisﬁed by\nAt (d), the max-ﬂow min-cut theorem [1] is used. Considering U ⊂ V, since\nwhere at (e), (29) is used and at (f), n is assumed to be sufﬁciently large to satisfy"},"refs":[]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564123.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T1.1","endtime":"17:00","authors":"Shigeki Miyake, Jun Muramatsu","date":"1341333600000","papertitle":"On a construction of universal network code using LDPC matrices","starttime":"16:40","session":"S8.T1: Network Coding:  Code Design and Resource Allocation","room":"Kresge Rehearsal B (030)","paperid":"1569564123"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
