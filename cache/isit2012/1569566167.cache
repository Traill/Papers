{"id":"1569566167","paper":{"title":{"text":"Performance Analysis of 1 -synthesis with Coherent Frames"},"authors":[{"name":"Yulong Liu ∗"},{"name":"Shidong Li \u2020\u2021"},{"name":"Tiebin Mi \u2020"},{"name":"Hong Lei ∗"},{"name":"Weidong Yu ∗"}],"abstr":{"text":"Abstract\u2014Signals with sparse representations in frames com- prise a much more realistic model of nature, it is therefore highly desirable to extend the compressed sensing methodology to redundant dictionaries (or frames) as opposed to orthonormal bases only. In the generalized setting, the standard approach to recover the signal is known as 1 -synthesis (or Basis Pursuit). In this paper, we present the performance analysis of this approach in which the dictionary may be highly - and even perfectly - correlated. Our results do not depend on an accurate recovery of the coefﬁcients. We demonstrate the validity of the results via several experiments."},"body":{"text":"Compressed sensing is a new data acquisition theory which allows that sparse or compressible signals of interest can be recovered from a small number of linear, non-adaptive, and usually randomized measurements [5], [6], [10]. By now, compressed sensing has attacked abundant applications in signal and image processing, see e.g., the two special issues [1], [2] and references therein. Formally, one considers the following measurement model:\nwhere Φ is an m × n sensing matrix with m n (indicating some signiﬁcant undersampling) and z ∈ R m is a noise term modeling measurement error. The goal is to reconstruct the unknown signal f ∈ R n based on available measurements y ∈ R m .\nIn standard compressed sensing scenarios, it is usually assumed that the signal f has a sparse (or nearly sparse) representation in an orthonormal basis. However, a large number of applications in signal and image processing point to problems where f is sparse with respect to an overcomplete dictionary or a frame rather than an orthonormal basis, see, e.g., [19], [8], [4], and references therein. Examples include, e.g., signal modeling in array signal processing (oversampled array steering matrix), reﬂected radar and sonar signals (Gabor frames), and images with curves (curvelets), etc. The ﬂexibility of frames is the key characteristic that empowers frames to become a natural and concise signal representation tool. Therefore, it is highly desirable to extend the compressed sensing methodology to redundant dictionaries as apposed to orthnormal bases only. In the generalized setting, the signal f is now expressed as f = Dx where D ∈ R n ×d ( n < d) is\na matrix of frame 1 vectors (as columns) that are often rather coherent in applications, and x ∈ R d is a sparse coefﬁcient vector. The linear measurements of f then can be written as\nSince x is assumed sparse, the standard way of recovering f from (2) is known as 1 -synthesis [8], [13], [7]. From the measurements, one ﬁrst ﬁnds the sparsest possible coefﬁcient x by solving an 1 minimization problem\nwhere x p (p = 1, 2) denotes the standard p -norm of the vector x and is an upper bound of the noise. Then the solution to f is derived via a synthesis operation, i.e., ˆ f = Dˆ x.\nAlthough empirical studies show that 1 -synthesis often achieves good recovery results, the theoretical performance of this method is far from satisfactory. The analytical results in [20] essentially require that the frame D has columns that are extremely uncorrelated such that the compound matrix ΦD satisﬁes the requirements imposed by the traditional compressed sensing assumptions. However, these requirements are often infeasible when D is highly coherent. For example, consider a simple case in which Φ ∈ R m ×n is a Gaussian matrix with i.i.d. entries, then Φ ∼ N (0, I n ⊗ I m ), where ⊗ denotes the Kronecker product and I m is an identity matrix of the size m. It is now well known that with very high probability Φ satisﬁes the restricted isometry property (RIP) provided that m is on the order of s log(n/s) [3], [5]. Let us now examine ΦD. It is not hard to show that ΦD ∼ N (0, D ∗ D⊗I m ), where (·) ∗ denotes the transpose operation. If D is unitary, then ΦD has the same distribution as Φ and satisﬁes the RIP. However, if D is a coherent frame, then ΦD may no longer obey the common RIP since the entries of ΦD\nare correlated. Meantime, the mutual incoherence property (MIP) [11] may not apply either, as it is very hard for ΦD to satisfy the MIP as well when D is highly correlated.\nThe perspective of the results in [20] is that some sufﬁcient conditions are put on the compound matrix ΦD such that x can be recovered accurately, which leads to a good estimate of f . However, if one is only interested in reconstructing the signal f , then it may be unnecessary to care about obtaining a good recovery of x. As pointed out in [7], when the dictionary D has two identical columns, it seems impossible to recover a unique sparse coefﬁcient vector x from the measurements, but we may certainly be able to reconstruct the signal f accurately. In other words, a good recovery of x may be unnecessary to guarantee an accurate reconstruction of f .\nIn this paper, we present a performance analysis for the 1 - synthesis approach in which the dictionary D may be highly - and even perfectly - correlated. Also, our results do not depend on a good recovery of the coefﬁcients. Our basic idea is to establish the equivalence between the 1 -synthesis approach and the optimal-dual-based 1 -analysis approach recently proposed in [17]. Then the recovery error bound for the latter will naturally lead to that for the former.\nAlongside the 1 -synthesis approach, there is a counterpart that takes an analysis point of view, see e.g., [12], [13], [7]. This alternative ﬁnds an estimate of f directly by solving the problem\nwhere ¯ D denotes the canonical dual frame of D, i.e., ¯ D = (DD ∗ ) −1 D. If D is a Parseval frame, then we have ¯ D = D.\nIt is well known by now [13] that when D is a square and invertible dictionary, the 1 -analysis and 1 -synthesis ap- proaches are equivalent. However, when D is an overcomplete frame, the gap between them is unexplored.\nA performance study of the 1 -analysis approach (4) in the case of Parseval frames ( ¯ D = D) was given in [7]. It was shown that, under suitable conditions on the sensing matrix Φ, the solution to (4) is very accurate provided that D ∗ f has rapidly decreasing coefﬁcients. In other words, when the frame coefﬁcient vector D ∗ f is reasonably sparse, 1 -analysis can be the right method to use.\nHowever, the fact that f is sparse in terms of D does not imply D ∗ f is necessarily sparse. In fact, as the canonical dual frame expansion in the case of Parseval frames, D ∗ f = D ∗ Dx has the minimum 2 -norm by the frame property, see, e.g., [9] and is usually fully populated which is also pointed out in [20]. Put differently, the canonical dual frame of D may be ineffective in sparsifying f since 2 -norm tends to spread the coefﬁcients into a large number of small coefﬁcients.\nTo overcome this difﬁculty, the standard 1 -analysis ap- proach (4) has recently been extended to a more general case in which the analysis operator can be any dual frame\nof D [17]. This leads to the following general-dual-based 1 - analysis approach\nwhere columns of ˜ D form a general (and any) dual frame of D. The performance analysis of the general-dual-based 1 - analysis approach was also given in [17]. In order to introduce the results, we require the concept of D-RIP [7]: An m × n sensing matrix Φ is said to satisfy the restricted isometry property adapted to D (abbreviated D-RIP) with constant δ s ∈ (0, 1) if\nholds for all v ∈ Σ s , where Σ s is the union of all subspaces spanned by all subsets of s columns of D. The validity of the D-RIP was discussed in e.g., [7], [15]. It was shown in [7] that any m × n matrix Φ obeying for any ﬁxed ν ∈ R n\n( γ, c are positive constants) will satisfy the D-RIP with overwhelming probability provided that m is on the order of s log(d/s). Many types of random matrices satisfy (7), some examples include matrices with Gaussian, subgaussian, or Bernoulli entries. It has also been shown in [15] that randomizing the column signs of any matrix that satisﬁes the standard RIP results in a matrix which satisﬁes the Johnson- Lindenstrauss lemma. Such a matrix would then satisfy the D-RIP via (7). Consequently, partial Fourier matrix (or partial circulant matrix) with randomized column signs will satisfy the D-RIP since these matrices are known to satisfy the RIP.\nWith these preliminaries, we now restate the results in [17] as follows.\nTheorem 1. [17] Let D be a general frame of R n with frame bounds 0 < A ≤ B < ∞. Let ˜ D be an alternative dual frame of D with frame bounds 0 < ˜ A ≤ ˜ B < ∞, and let ρ = s/b. Suppose\nholds for some positive integers a and b satisfying 0 < b−a ≤ 3a. Then the solution ˆf to (5) satisﬁes\nwhere C 0 and C 1 are some constants and ( ˜ D ∗ f ) s denotes the vector consisting the largest s entries of ˜ D ∗ f in magnitude (and setting the other to zero).\nTheorem 1 shows that if Φ satisﬁes some proper conditions, then the solution to (5) is very accurate provided that ˜ D ∗ f has rapidly decreasing coefﬁcients. By the deﬁnition of the D- RIP, the condition (8) is independent of the coherence of the dictionary D. For differently chosen a and b, (8) will give rise to different conditions on the D-RIP constant. For instance, if\nD is a Parseval frame and ˜ D is its canonical dual frame, i.e., B ˜ B = 1, then (8) is satisﬁed whenever δ 2s < 0.1398 [17].\nWith the error bound (9), we can easily see the potential superiority of using alternative dual frames as analysis opera- tors. For clarity, we consider a simple case in which the noise is free, i.e., = 0. Then the error bound (9) reduces to\n(10) is measured in terms of how effective ˜ D ∗ f is in spasifying the signal f with respect to the dictionary D. As discussed before, the canonical dual frame expansion of f has the mini- mum 2 -norm, i.e., ¯ D ∗ f 2 = min\n˜ x 2 , and is ineffective in promoting sparsity in general. On the other hand, when the analysis operator can be any dual frame of D, it is not hard to imagine that there should be some dual frame of D, denoted by ˜ D S , such that ˜ D ∗ S f = x. This is due to the fact that all coefﬁcients of a frame expansion of f in D should correspond to some dual frame of D, which really is the spirit of frame expansions. Generally, ˜ D S is much more effective in sparsifying the signal f than the canonical dual frame does. Therefore, one may expect a better recovery performance by taking some \u201cproper\u201d alternative dual frame as the analysis operator.\nThe important question then is how to choose some ap- propriate dual frame such that the corresponding analysis coefﬁcients are as sparse as possible. Since the true signal f is never known before hand in practice, it seems impossible to explicitly construct some proper dual frame ˜ D such that ˜ D ∗ f is sparse without additional priori knowledge about f . One approach proposed in [17] is by the method of optimal- dual-based 1 -analysis:\nwhere the optimization is performed simultaneously over both all dual frames of D and the feasible signal set. This seemingly complicated optimization problem can be reformulated into a simpliﬁed form. Note that the class of all dual frames for D is given by [16]\n(12) where P ≡ I d − D ∗ (DD ∗ ) −1 D denotes the orthogonal projection onto the null space of D and W ∈ R d ×n is an arbitrary matrix. Plug (12) into (11), we obtain\n(13) where we have used the fact that when ˜ f = 0, g ≡ W˜f can be any vector in R d due to the fact that W is free. If we simply set Pg ≡ 0, then (13) reduces to the standard 1 - analysis approach (4). In [17], an iterative algorithm based on the split Bregman iteration [14] was developed to solve the optimization problem (13) efﬁciently.\nClearly, the solution to (11) deﬁnitely corresponds to that of (5) with some \u201coptimal\u201d dual frame, say ˜ D o as the analysis operator. The optimality here is in the sense that ˜ D ∗ o ˆf 1 achieves the smallest ˜ D ∗ ˜f 1 in value among all dual frames of D and feasible signals satisﬁed the constraint in (11). Once ˆf and ˆg are obtained (through solving (13)), it follows from (12) that the analysis operator ˜ D ∗ o is given by\nEvidently, the optimal dual frame ˜ D o depends on the solutions of (13). By utilizing the fact that vec (ABC) = (C ∗ ⊗ A )vec(B), the above equation (15) is equivalent to\nwhere vec (W o ) denotes the vectorization of the matrix W o by stacking the columns of W o into a single vector. The solution to (16) is non-unique in general since this equation is highly underdetermined (with d equations but nd unknowns). The class of solutions to (16) is given by\nwhere A \u2020 denotes the pseudo-inverse of A and w ∈ R nd ×1 is an arbitrary vector. In deriving (17), we have used the two facts that (A⊗B) \u2020 = A \u2020 ⊗B \u2020 and (A⊗B)(C⊗D) = AC⊗BD,\nsee e.g., [18]. Let w = 0, then (17) reduces to the least square solution of W o\nWhen f is sparse with respect to the redundant frame D, it is highly desirable that ˜ D o may promote high sparsity in the frame expansion of the true signal f . It then follows from (9) that an accurate recovery of f may be achieved by the solution of (11). Indeed, we have seen that the signal recovery via (11) is much more effective than that of the standard 1 - analysis approach (4) which uses the canonical dual frame as the analysis operator.\nIn this section, we present the performance analysis of the 1 -synthesis approach. We begin by showing that the 1 - synthesis and the optimal-dual-based 1 -analysis approaches are equivalent.\nTheorem 2. 1 -synthesis and optimal-dual-based 1 -analysis are equivalent.\nProof: We start with the optimal-dual-based 1 -analysis approach as posed in (13). Let ˜ x = ¯ D ∗ ˜f + Pg, then we have\nD ˜ x = ˜f. Since the columns of [ ¯ D ∗ , P] span the whole d- dimensional space and both ˜ f and g are free, then ˜ x ∈ R d . Put the two facts into (13), we obtain the 1 -synthesis method (3). On the other hand, we start from the 1 -synthesis formulation. For any ˜ x ∈ R d , the following decomposition always holds\n˜ x = ˜ x R + ˜ x N = D ∗ (DD ∗ ) −1 D ˜ x + P˜ x = ¯ D ∗ D ˜ x + P˜ x ,\nwhere ˜ x R and ˜ x N are the components of ˜ x belonging to the row space and the null space of D, respectively. By the deﬁnition of 1 -synthesis, we have ˜ f = D˜ x ∈ R n . Let g = ˜ x ∈ R d , we can arrive at the optimal-dual-based 1 - analysis approach and the two methods are equivalent.\nRemark 1: By taking a geometrical description, it was shown in [13] that any 1 -analysis problem (with full-rank analysis operator) may be reformulated as an equivalent 1 -synthesis one. Our results indicate that the reverse is also true. For a given 1 -synthesis problem, there exist some appropriate analysis operators (e.g., optimal dual frames of D) such that the corresponding 1 -analysis problem is equivalent to the 1 - synthesis one.\nWith this equivalence, we now establish the error bound for the 1 -synthesis approach. Since ˜ D o is some alternative dual frame of D, i.e., D ˜ D ∗ o = I, a direct application of Theorem 1 leads to the following results.\nTheorem 3. Let D be a general frame of R n with frame bounds 0 < A ≤ B < ∞. Let ˜ D o be some optimal dual frame of D deﬁned in (14) with frame bounds 0 < ˜ A o ≤ ˜ B o < ∞, and let ρ = s/b. Suppose\nholds for some positive integers a and b satisfying 0 < b−a ≤ 3a. Then the solution ˆf to (3) (or to (11)) satisﬁes\nwhere C 0 and C 1 are some constants and ( ˜ D ∗ o f ) s denotes the vector consisting the largest s entries of ˜ D ∗ o f in magnitude.\nTheorem 3 shows that, under suitable conditions on the sensing matrix, the recovered signal ˆ f by 1 -synthesis is very accurate provided that ˜ D ∗ o f has rapidly decreasing coefﬁcients. By the optimality of ˜ D o , one may expect that ˜ D o will promote high sparsity in the frame expansion of the true signal f . Indeed, as we shall see in the numerical experiments, ˜ D o is much more effective in sparsifying f than the canonical dual frame does. Consequently, a better signal recovery is often achieved by 1 -synthesis.\nSince the class of optimal dual frames is signal-dependent, one might naturally question whether the condition (20) is satisﬁed when ˜ D ∗ o is used as the analysis operator. We have seen that, when we choose ˜ D ∗ o = ¯ D ∗ + (ˆf ∗ ⊗ P ˆ g )/ ˆf 2 2 , B ˜ B o is reasonably small and hence the condition (20) is satisﬁed.\nIn this section, we present some numerical experiments to demonstrate the validity of the results obtained in this paper. In these experiments, we use two types of frames: Gabor frames and a concatenation of the coordinate and Fourier bases. The sensing matrix Φ is a Gaussian matrix with m = 32, n = 128. Since the dependence on the noise in the error bound (21) is optimal and for the purpose of clarity, we only consider the noise-free case 2 . Both 1 -analysis and 1 -synthesis problems are solved by the algorithm developed in [17] because the returned auxiliary variable (Pg) by this algorithm can be used to construct the optimal dual frame ˜ D o (19). We set λ = µ = 1, tol = 10 −12 , nInner = 5, and nOuter = 100 in this algorithm for all experiments.\nExample 1: Gabor Frames. Recall that for a window function g and positive time-frequency shift parameters α and β, the Gabor frame is given by\nFor many practical applications such as radar and sonar, the received signal f often has the form\nEvidently, f is sparse with respect to a Gabor frame. In this experiment, we construct a Gabor dictionary with Gaussian windows, oversampled by a factor of 30 so that d = 30 × n = 3840. The tested signal f is sparse with respect to the constructed Gabor frame with sparsity s = ceil(0.2 × m) = 7. The positions of the nonzero entries of the coefﬁcient vector x are selected uniformly at random, and each nonzero value is sampled from standard Gaussian distribution.\nFigure 1 (a) shows that when D is highly coherent with coherence 3 µ(D) = 0.9934, the recovered coefﬁcients by\n1 -synthesis are disappointing (with a relative error ˆ x − x 2 / x 2 = 0.9039). However, the signal recovered by 1 - synthesis is very accurate (with a relative error equal to 0.0845), see Figure 1 (b). This example also illustrates that a good recovery of the coefﬁcients may be unnecessary to guarantee an accurate reconstruction of the signal. Figure 1 (b) also shows that the signal recovery via 1 -synthesis is much better than that of 1 -analysis (relative error: 0.0845 vs. 0.3445). This is because the optimal dual frame ˜ D o is much more effective in promoting sparsity in the frame expansion of f than the canonical dual frame ¯ D does, see Figure 1 (c), where ˜ D ∗ o is determined by (19).\nExample 2: Concatenations. When signals of interest are sparse over several orthonormal bases (or frames), it is nat- ural to use a dictionary D consisting of a concatenation of these bases (or frames). In this experiment, we consider a\ndictionary consisting of the coordinate and Fourier bases, i.e., D = [I, F]/\n2. The tested signal f is a linear combination of spikes and sinusoids, i.e., f = f 1 + f 2 = x 1 + Fx 2 . The sparsity of both x 1 and x 2 is equal to 4. Again, the positions of the nonzero entries of both x 1 and x 2 are selected uniformly at random, and each nonzero value is sampled from standard Gaussian distribution.\nFigure 1 (d) and (e) show that when D is incoherent (with coherence µ(D) = 1/\n1 -synthesis not only recover the signal accurately but also achieves a good recovery for the coefﬁcients. Figure 1 (e) also shows that 1 -analysis almost fails in recovering the signal with a relative error at 0.8143. Such a failure is not surprising since ¯ D = D is ineffective in sparsifying the true signal f , see Figure 1 (f). By contrast, ˜ D ∗ o f decays very quickly, which guarantees the good recovery for the signal by 1 -synthesis.\nThis work has provided a theoretical analysis for 1 - synthesis when the dictionary may be highly coherent. Our approach was to show the equivalence between 1 -synthesis and optimal-dual-based 1 -analysis. With this equivalence, the signal recovery error bound for both could be established by using the results in [17]. Lastly, the results obtained in this paper were validated via numerical experiments.\nY. Liu would like to thank the School of Information Sciences, Renmin University of China for support during his visit."},"refs":[{"authors":[{"name":"R. G. Baraniuk"},{"name":"E. J. Cand`es"},{"name":"R. Nowak"}],"title":{"text":"Sensing, sampling, and compression"}},{"authors":[{"name":"R. G. Baraniuk"},{"name":"E. J. Cand`es"},{"name":"M. Elad"},{"name":"Y. Ma"}],"title":{"text":"Applications of sparse representation and compressed sensing"}},{"authors":[{"name":"R. G. Baraniuk"},{"name":"M. Davenport"},{"name":"R. DeVore"},{"name":"M. Wakin"}],"title":{"text":"A simple proof of the restricted isometry property for random matrices"}},{"authors":[{"name":"A. M. Bruckstein"},{"name":"D. L. Donoho"},{"name":"M. Elad"}],"title":{"text":"From sparse solutions of systems of equations to sparse modeling of signals and images"}},{"authors":[{"name":"E. J. Cand`es"},{"name":"T. Tao"}],"title":{"text":"Near optimal signal recovery from random projections: Universal encoding strategies?"}},{"authors":[{"name":"E. J. Cand`es"},{"name":"J. Romberg"},{"name":"T. Tao"}],"title":{"text":"Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency informa- tion"}},{"authors":[{"name":"E. J. Cand`es"},{"name":"Y. C. Eldar"},{"name":"D. Needell"},{"name":"P. Randall"}],"title":{"text":"Compressed sensing with coherent and redundant dictionaries"}},{"authors":[{"name":"S. S. Chen"},{"name":"D. L. Donoho"},{"name":"M. A. Saunders"}],"title":{"text":"Atomic decomposition by basis pursuit"}},{"authors":[{"name":"O. Chiristense"}],"title":{"text":"An Introduction to Frames and Riesz Bases"}},{"authors":[{"name":"D. L. Donoho"}],"title":{"text":"Compressed sensing"}},{"authors":[{"name":"D. L. Donoho"},{"name":"M. Elad"},{"name":"V. N. Temlyakov"}],"title":{"text":"Stable recovery of sparse overcomplete representations in the presence of noise"}},{"authors":[{"name":"M. Elad"},{"name":"J. L. Starck"},{"name":"P. Querre"},{"name":"D. L. Donoho"}],"title":{"text":"Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA)"}},{"authors":[{"name":"M. Elad"},{"name":"P. Milanfar"},{"name":"R. Rubinstein"}],"title":{"text":"Analysis versus synthesis in signal priors"}},{"authors":[{"name":"T. Goldstein"},{"name":"S. Osher"}],"title":{"text":"The split Bregman algorithm for L1- regularized problems"}},{"authors":[{"name":"F. Krahmer"},{"name":"R. Ward"}],"title":{"text":"New and improved Johnson-Lindenstrauss embeddings via the Restricted Isometry Property"}},{"authors":[{"name":"S. Li"}],"title":{"text":"On general frame decompositions"}},{"authors":[{"name":"Y. Liu"},{"name":"T. Mi"},{"name":"S. Li"}],"title":{"text":"Compressed sensing with general frames via optimal-dual-based 1 -analysis"}},{"authors":[{"name":"H. L¨utkepoh"}],"title":{"text":"Handbook of Matrices"}},{"authors":[{"name":"S. Mallat"},{"name":"Z. Zhang"}],"title":{"text":"Matching pursuits with time-frequency dic- tionaries"}},{"authors":[{"name":"H. Rauhut"},{"name":"K. Schnass"},{"name":"P. Vandergheynst"}],"title":{"text":"Compressed sensing and redundant dictionaries"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566167.pdf"},"links":[{"id":"1569559617","weight":2},{"id":"1569566981","weight":2},{"id":"1569566321","weight":14},{"id":"1569552245","weight":2},{"id":"1569565227","weight":7},{"id":"1569567005","weight":2},{"id":"1569564469","weight":9},{"id":"1569564897","weight":2},{"id":"1569565837","weight":2},{"id":"1569565123","weight":2},{"id":"1569558483","weight":2},{"id":"1569566497","weight":9},{"id":"1569566795","weight":2},{"id":"1569564337","weight":9},{"id":"1569563981","weight":2},{"id":"1569561085","weight":2},{"id":"1569566991","weight":2},{"id":"1569552251","weight":2},{"id":"1569565559","weight":12},{"id":"1569566913","weight":7},{"id":"1569566809","weight":2},{"id":"1569564353","weight":2},{"id":"1569566115","weight":2},{"id":"1569558401","weight":2},{"id":"1569565739","weight":2},{"id":"1569566297","weight":2},{"id":"1569566245","weight":2},{"id":"1569565439","weight":2},{"id":"1569557715","weight":4},{"id":"1569566983","weight":4},{"id":"1569566873","weight":4},{"id":"1569552037","weight":2},{"id":"1569565353","weight":4},{"id":"1569565177","weight":2},{"id":"1569552025","weight":14},{"id":"1569565829","weight":2},{"id":"1569566715","weight":14},{"id":"1569566755","weight":14},{"id":"1569566713","weight":2},{"id":"1569565425","weight":9},{"id":"1569565529","weight":4},{"id":"1569561185","weight":2},{"id":"1569558779","weight":2},{"id":"1569566001","weight":7},{"id":"1569566817","weight":2},{"id":"1569564923","weight":2},{"id":"1569565367","weight":2},{"id":"1569565805","weight":2},{"id":"1569567691","weight":4},{"id":"1569566457","weight":2},{"id":"1569564961","weight":2},{"id":"1569564253","weight":2},{"id":"1569566635","weight":7},{"id":"1569566611","weight":36},{"id":"1569564505","weight":2},{"id":"1569566125","weight":7},{"id":"1569564419","weight":2},{"id":"1569566825","weight":7},{"id":"1569566443","weight":14},{"id":"1569560581","weight":2},{"id":"1569559233","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T9.3","endtime":"10:50","authors":"Yulong Liu, Shidong Li, Tiebin Mi, Lei Hong, Yu Weidong","date":"1341484200000","papertitle":"Performance Analysis of l1-synthesis with Coherent Frames","starttime":"10:30","session":"S11.T9: L1-Regularized Least Squares and Frames","room":"Stratton West Lounge (201)","paperid":"1569566167"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
