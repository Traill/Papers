{"id":"1569566575","paper":{"title":{"text":"Index Coding: An Interference Alignment Perspective"},"authors":[{"name":"Hamed Maleki"},{"name":"Viveck Cadambe"},{"name":"Syed Jafar \u2020"}],"abstr":{"text":"Abstract\u2014The index coding problem is a multiple unicast wire- line communication network where the network is represented by a directed graph having exactly one link with ﬁnite capacity (also known as the bottleneck link). There are K independent sources which share the ingress of this bottleneck link. Correspondingly there are K destinations which are on the receiving end of the bottleneck link, with each destination intending to decode the message of one (unique) corresponding source. Each destination can have apriori side-information of a (different) subset of the original source messages. In this paper, we study the capacity of such a network from the perspective of interference alignment, and derive information theoretically optimal schemes for a class of networks. In our ﬁrst main result, we identify the set of graphs where each user can achieve half rate in the index coding problem. In a second result, we derive the capacity for a class of symmetric index coding networks."},"body":{"text":"Much progress in network information theory can be at- tributed to the pursuit of capacity of simple-to-describe canon- ical network communication models. Simplicity in the network communication models often affords a clear formulation of techniques involved in the communication system. The focus of this paper is the index coding problem, which is, arguably, the simplest open multi-source (non-multicast) wireline net- work capacity problem, because it has only one link with ﬁnite capacity. We begin by describing the index coding problem.\nIn the index coding problem (See Fig. 2 for an example which is analogous to the deterministic broadcast channel depicted in Fig 1), there are K independent discrete source messages W 1 , W 2 , . . . W K . There are K destinations, with destination i intending to decode source W i for i ∈ K, where K = {1, 2, . . . , K}. We assume that each destination has side information of a certain set of messages apriori. The set of side information present at receiver i, also referred to as the set of antidotes, is denoted by A i ⊂ K − {i}. We denote the set of messages present as side information at receiver i as W A i = {W i : i ∈ A i }. Each destination receives a common (broadcast) symbol S ∈ S from a ﬁnite alphabet S that can be chosen arbitrarily. The goal of the index coding problem is to design the broadcast alphabet S and the broadcast symbol S using the messages as S = f (W 1 , W 2 , . . . , W K ), where the function f is often referred to as the (index) code. An index coding scheme is said to be achievable 1 if each destination is able to decode its intended message successfully, i.e., if\nwhere H(.) is the entropy function. For a given achievable coding scheme, rate of transmission for message i is deﬁned as R i = H(W i ) H(S) . The capacity region of the index coding problem is deﬁned as the set of all achievable rate tuples (R 1 , R 2 , . . . , R K ) and is denoted by C. In this paper, we are speciﬁcally interested in the highest symmetric achievable rate in this system, i.e.,\nImportantly, it is worth noting that the index coding problem can be described in terms of multi-source network capacity of a directed graph as shown in Figure 2. In this network, there is exactly one (directed) link of ﬁnite capacity, since all the antidotes links can be thought of links with inﬁnite capacities.\nRemark: Note that a trivial achievable scheme in the index coding problem - routing - achieves a symmetric rate of 1/K. However, as demonstrated by the butterﬂy network (which is a 2 user index coding problem), the antidotes can indeed enable a higher achievable rate.\nLinear Schemes: For a given antidote set, an achievable coding scheme is said to be linear if S = F T , and\n\u2022 F is a ﬁnite ﬁeld, and F T represents the T -time Cartesian product of the ﬁeld,\n\u2022 X i ∈ F L is a L × 1 vector representing W i such that H(W i ) = L|F|.\n\u2022 V i is a T × L linear pre-coding vector over F, chosen independent of the messages.\nA coding scheme is said to be a scalar linear encoding scheme if L = 1. The index code is said to be a binary scalar linear encoding scheme if S = F 2 and L = 1. A rate tuple (R 1 , R 2 , . . . , R K ) is said to be achievable using (scalar/binary scalar) linear coding if there exists some (scalar/binary scalar) linear coding scheme that achieves the rate tuple.\nRemark: As is common in network coding and wireline network capacity literature, note that the index coding problem can be deﬁned without explicit mention of the alphabet set S, since we are only interested in the H(S). However, we explicitly identify this set because the deﬁnition of a linear index code is closely connected to this alphabet.\nThe index coding problem was introduced by Birk and Kol in [1]. Since then, the index coding problem has been studied from different perspectives [2], [3], [4], [5] . A primary theme in the pursuit of the index coding problem has been the applicability of linear coding. References [2], [3] have characterized the best possible rate achievable with scalar linear network coding. In particular, they have shown that the best achievable rate is related to a functional on the network communication graph known as the minrank. An important observation was made in [6], where it was shown that this quantity is sub-optimal because of the possibilty of vector linear coding. Further, it has been shown in [7] that even vector linear coding is not sufﬁcient for the index coding problem. This means that the insufﬁciency of linear network coding shown previously in [8] in the context of general networks,\nholds even for the specialized context of the index coding problem 2\nIn the context of the index coding problem, there remain two important unanswered questions. The ﬁrst is a characterization of the best possible rate achievable using a vector linear index code. The second question of interest is an identiﬁcation of the index coding scenarios where vector linear coding is op- timal. Reference [10] made progress in addressing these open questions by obtaining information theoretic outer bounds for the index coding rate through a linear programming approach. The formulation of the outer bounds enabled the authors to identify certain scenarios where (vector) linear coding is tight, in an information theoretic sense. In this paper, we make further progress in this direction by studying the problem from perspective of interference alignment.\nInterference alignment is an important tool that has recently emerged out of the pursuit of capacity of wireless interfer- ence networks. The representative example is the wireless interference channel with K transmitter-receiver pairs where, because of interference alignment, each user is simultaneously able to send at a data rate equal to half of his interference- free channel capacity to his desired receiver [11]. Interference alignment is useful, not only to wireless communications, but also for wireline communication networks [12], [13], [14]. In this paper, we study the index coding problem from the perspective of interference alignment. In particular, we present two main results in the paper.\n1) In a result that has parallels to [11], we will identify sce- narios in the index coding problem where each user gets half the \u201cinterference-free\u201d channel capacity, i.e., each user can send a (symmetric) rate of 1/2. In particular, we uniquely identify the side-information graphs where a rate of 1/2 is feasible in the index coding problem.\n2) We solve the index coding problem for a class of cyclically symmetric side information graphs.\ntheoretic outer bounds for the index coding set up which are of interest in and of themselves. Achievability is shown by intuitive interference alignment schemes. (See Fig. 3.)\nTo begin, it is worth examining the role of interference alignment in the index coding problem. Consider a linear index coding achievable scheme, i.e., we assume that the transmitted broadcast symbol S has a form as in (2). We use the following notation here.\ni.e., V is the set of all column vectors of [V 1 V 2 . . . V K ] . Similarly, V A is the set of all column vectors which belong to at least one matrix V i : i ∈ A.\nNow, note that receiver i has, as antidotes, messages W A i and can cancel the effect of these messages from S. The interference that remains at receiver i after this cancellation lies in the span of V A c\n. For receiver i to resolve the message from W i from this the resolvability of message W i at receiver i can be expressed as\n−{i} ) = {0} \t (3) Since we operate in a T dimensional space and we want resolvability of an L dimensional vector V i , this means that the dimension of span (V A c\n−{i} ) should be smaller than T − L (because the vectors are all observed in an T dimensional space). Clearly, if T < |A c i |L, then, these interfering vectors need to align in an T − L dimensional space. This scenario is demonstrated in Figure 3, where K = 3, T = 2 and each user sends L = 1 vector. Because of alignment of V 2 and V 3 , user 1 is able to resolve x 1 . Indeed, our ﬁrst main result generalizes this scenario by explicitly identifying the set of all index coding problems where a rate of 1/2 is achievable.\nThe ﬁrst issue we investigate is the achievability of a symmetric rate of 1 2 for each user which we denote as the half- rate-feasibility problem. The following terminology is useful for an explicit description of the solution of this problem.\nj as follows. W i k ↔ W j iff W i / ∈ A k , W j / ∈ A k for distinct indices i, j, k ∈ K. We may occasionally use the notation W i ↔ W j when the identity of the destination is not important.\n\u2022 Alignment Subsets: The set of messages W is par- titioned into alignment subsets, created as follows. If W i ↔ W j , then both W i , W j belong to the same alignment subset. Further, if W i ↔ W j and W j ↔ W m then W i , W j , W m all belong to the same alignment subset.\nFor the example of Fig. 3 the alignment relations are W 2 1 ↔ W 3 and the alignment subsets are { W 2 , W 3 }, {W 1 }. We are now ready to present our main result.\nTheorem 1: The rate tuple R with R 1 = R 2 = ... = R K = 0.5 is not achievable in a single bottleneck network if and only if there exist distinct indices i, j ∈ K such that W i , W j belong to the same alignment subset and W i / ∈ A j .\nRemark: The statement of Theorem 1 is intuitively inter- preted as follows. If messages W i , W j belong to the same alignment set then they should overlap almost perfectly in half the dimensions of the bottleneck link so as to leave the remaining half of the dimensions for the desired message W k . Because of their overlap, it is not possible to recover one message unless the other message is removed by using an antidote. If such an antidote is not available then the achievability of half rate for every user becomes infeasible. Note that the converse bounds all possible coding schemes and not just linear schemes.\nA second main result of this paper is a characterization of (symmetric) rate of index coding problems where the antidote sets have a cyclically symmetric property.\nDeﬁnition 1: Consider an arbirary set ∆ \t ⊆ {±1, ±2, . . . , ±K/2 }. A cyclically symmetric index coding problem deﬁned on ∆ is characterized by its antidotes as\nTheorem 2: The information theoretically optimal symmet- ric rate of a cyclically symmetric index coding problem characterized by antidote generator set\nWe choose S = F 2 q , where q is chosen to be sufﬁciently large. We partition { 1, 2, . . . , K} into alignment subsets as per Theorem 1. Let us denote the partitions by P 1 , P 2 , . . . , P M . Then, we assign a 2 × 1 coding vector for each subset denoted by V P i , such that the M vectors V P 1 , V P 2 , . . . , V P M are pairwise linearly independent. The linear coding vectors are chosen as V i = V P m if i ∈ P m . As per Theorem 1, we need to show that the following conditions imply the resolvability of message W i at receiver i.\nwhere the ﬁnal equation follows because all elements of {i : i / ∈ A r , i = r} belong to the same alignment subset by deﬁnition; this subset is denoted by P m . From the above equations, it is clear that after cancelling the second term above, receiver r can obtain\nFurther, r / ∈ P m , because if r ∈ P m , then, the condition (4) is violated. This is because j, r ∈ P m → j ∈ A r → j / ∈ P m which is a contradiction. This means that V P m and V r are linearly independent. Since we are operating in a T = 2 dimensional space, x r is linearly resolvable at receiver r as required. This proves achievability.\nFirst, note that if | ∆| = U + D = K − 1, then it is obvious that each source can achieve a rate of 1. If |∆| = K − 2, then, it is easy to verify that a rate of 1 2 is achievable using Theorem 1. Here we are trying to show achievability for | ∆| ≤ K − 3. Using linear coding, we show that each user can send L = (U + 1) symbols in a T = (K − (D − U )) dimensional space F T q . Let z 1 , z 2 , . . . , z K , be K vectors of size T × 1 where any T of them are linearly independent over F q . Note that over a sufﬁciently large ﬁeld, the vectors z i , i = 1, 2, . . . , K can be chosen to satisfy this property. Our construction for V i - the linear coding co-efﬁcients for user i - is as follows.\nwhere a ⊕ b denotes [((a − 1) + b) mod K] + 1. With this construction, we intend to show that (3) is satisﬁed. First, note that the U + 1 columns of V i are linearly independent since U + 1 < K − (D − U ). In particular, denoting X i = [x i,0 x i,1 . . . , x i,U ], we have\nNow, because of the symmetric nature of the problem, we only need to show that W 1 is linearly resolvable at X 1 . This ensures resolvability at all other receivers. Note that receiver 1 has side information of x i,j for all i ∈ {K − U + 1, K −\nU + 2, . . . , K, 2, 3, . . . , D + 1}. Cancelling the effect of these messages above, the receiver can obtain\nNote that the above is the linear combination of K − (D − U ) vectors z 1 , z 2 , . . . , z U +1 , z D+2 , z D+3 , . . . , z K . Since we operate in a K − (D − U ) dimensional space, it is easy to see these vectors are linearly independent and therefore the desired scalars x 1,j , j = 0, 1, . . . , U are resolvable at receiver i. This completes the proof. See Figure 4 for an example.\nWe (brieﬂy) describe the outerbound for networks which are valid in general and are tight for the half rate feasibility problem. Detailed outer bounds for Theorems 1 and 2 can be found in [15].\nTheorem 3: For any N +1 distinct indices i 0 , i 1 , ..., i N ∈ K and N indices j 1 , ..., j N ∈ K if there is the following alignment chain\nRemark: It worths mentioning the difference between the above alignment chain and directed acyclic side information graphs presented in [3]. In the the above alignment chain, all the messages can be perfectly aligned except the ﬁrst and the last messages in the chain, i.e., W i 0 and W i N , which leads to the derived outerbound in Theorem 3. However, in a directed\nacyclic side information graph, none of the messages can be aligned which leads to the sum rate outerbound of 1.\nCorollary 1: The rate tuple R with R 1 = R 2 = ... = R K = 0.5 is not achievable in a single bottleneck network if there exist distinct indices i, j ∈ K such that W i , W j belong to the same alignment subset and W i / ∈ A j .\nProof of Corollary: If W i , W j belong to the same align- ment subset, there must exist a chain of alignment relations connecting W i , W j as\nwhere N is the length of the chain. If W i / ∈ A j then from the result of Theorem 3 shown later in this paper we have an explicit rate bound\nClearly, R i = R i 1 = R i 2 = . . . = R i N = R j 1 = R j n = 0.5 does not satisfy the above bound. This proves the corollary.\nProof of Theorem 3: Theorem 3 affords a simple proof for N = 1 which can be found in [15]. Here, we consider the case where N = 2, since it captures all the ideas required for proving the theorem for an arbitrary value of N . In what follows we show that for any 3 distinct indices i, j, k ∈ K and indices l, m ∈ K if W i l ↔ W j m ↔ W k and W i / ∈ A k then R i + R j + R k + R l + R m ≤ 2 (see Fig. 4). Below, we denote H(S) = n.\nH(W l ) = nR l = I(W l ; S, W A l ) + o(n) \t (9) ≤ I(W l ; S, W − {W i , W j , W l }) + o(n) = H(S | W − {W i , W j , W l })\nnR k ≤ I(W k ; S, W A k ) + o(n) \t (12) ≤ I(W k ; S, W − {W i , W k }) + o(n) \t (13)\n≤ H(S | W − {W i , W k }) − nR i + o(n) \t (14) ≤ H(S | W − {W i , W j }) + H(S | W − {W j , W k })\n−H(S | W − {W j }) − nR i + o(n) \t (15) = H(S | W − {W i , W j }) + H(S | W − {W j , W k })\n−nR j − nR i + o(n) \t (16) ≤ n(1 − R l ) + n(1 − R m ) − nR i − nR j + o(n)(17) ⇒ R k ≤ 2 − R i − R j − R l − R m \t (18)\nwhere (14) follows from the fact that R i ≤ H(S|W − {W i }) because of (1), (15) follows from Lemma 1 which is proved in the Appendix. (17) follows from (11).\nProof: Because of submodularity of the entropy function, for two sets C , D we have\nChoosing C = {S, W −{W i , W j }}, D = {S, W −{W i , W k }} we have\nH(S | W − {W i , W j }) + H(S | W − {W i , W k }) ≥ H(S | W − {W i }) + H(S | W − {W i , W j , W k }) ≥"},"refs":[{"authors":[{"name":"Y. Birk"},{"name":"T. Kol"}],"title":{"text":"Informed-source coding-on-demand (ISCOD) over broadcast channels"}},{"authors":[{"name":"Y. Birk"},{"name":"T. Kol"}],"title":{"text":"Coding on demand by an informed source (ISCOD) for efﬁcient broadcast of different supplemental data to caching clients"}},{"authors":[{"name":"Z. Bar-Yossef"},{"name":"Y. Birk"},{"name":"T. S. Jayram"},{"name":"T. Kol"}],"title":{"text":"Index Coding With Side Information"}},{"authors":[{"name":"I. Haviv"},{"name":"M. Langberg"}],"title":{"text":"On linear index coding for random graphs"}},{"authors":[{"name":"Y. Berliner"},{"name":"M. Langberg"}],"title":{"text":"Index coding with outerplanar side information"}},{"authors":[{"name":"N. Alon"},{"name":"A. Hasidim"},{"name":"E. Lubetzky"},{"name":"U. Stav"},{"name":"A. Weinstein"}],"title":{"text":"Broad- casting with side information"}},{"authors":[{"name":"A. Blasiak"},{"name":"R. Kleinberg"},{"name":"E. Lubetzky"}],"title":{"text":"Lexicographic products and the power of non-linear network coding"}},{"authors":[{"name":"R. Dougherty"},{"name":"C. Freiling"},{"name":"K. Zeger"}],"title":{"text":"Insufﬁciency of linear coding in network information ﬂow "}},{"authors":[{"name":"S. Rouayheb"},{"name":"A. Sprintson"},{"name":"C. Georghiades"}],"title":{"text":"On the Index Coding Problem and Its Relation to Network Coding and Matroid Theory"}},{"authors":[{"name":"A. Blasiak"},{"name":"R. Kleinberg"},{"name":"E. Lubetzky"}],"title":{"text":"Index coding via linear programming"}},{"authors":[{"name":"V. Cadambe"},{"name":"S. Jafar"}],"title":{"text":"Interference alignment and the degrees of freedom of the K user interference channel"}},{"authors":[{"name":"V. R. Cadambe"},{"name":"S. A. Jafar"},{"name":"H. Maleki"}],"title":{"text":"Distributed data storage with minimum storage regenerating codes - exact and functional repair are asymptotically equally efﬁcient"}},{"authors":[{"name":"A. Das"},{"name":"S. Vishwanath"},{"name":"S. Jafar"},{"name":"A. Markopoulou"}],"title":{"text":"Network coding for multiple unicasts: An interference alignment approach"}},{"authors":[{"name":"A. Ramakrishnan"},{"name":"A. Das"},{"name":"H. Maleki"},{"name":"A. Markopoulou"},{"name":"S. Jafar"},{"name":"S. Vishwanath"}],"title":{"text":"Network Coding for Three Unicast Sessions: Interference Alignment Approaches"}},{"authors":[{"name":"H. Maleki"},{"name":"V. R. Cadambe"},{"name":"S. A. Jafar"}],"title":{"text":"Index coding - an interference alignment perspective"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566575.pdf"},"links":[{"id":"1569566485","weight":3},{"id":"1569564889","weight":6},{"id":"1569566725","weight":3},{"id":"1569567049","weight":9},{"id":"1569565067","weight":9},{"id":"1569566683","weight":3},{"id":"1569559259","weight":3},{"id":"1569564481","weight":3},{"id":"1569564805","weight":6},{"id":"1569567005","weight":3},{"id":"1569566647","weight":9},{"id":"1569566871","weight":3},{"id":"1569558325","weight":25},{"id":"1569565837","weight":6},{"id":"1569566119","weight":9},{"id":"1569565317","weight":3},{"id":"1569566319","weight":6},{"id":"1569558459","weight":3},{"id":"1569565859","weight":3},{"id":"1569565809","weight":3},{"id":"1569566843","weight":6},{"id":"1569558483","weight":9},{"id":"1569564903","weight":6},{"id":"1569566173","weight":3},{"id":"1569564387","weight":6},{"id":"1569566795","weight":31},{"id":"1569561679","weight":9},{"id":"1569566015","weight":9},{"id":"1569566895","weight":6},{"id":"1569566985","weight":3},{"id":"1569565321","weight":3},{"id":"1569566733","weight":6},{"id":"1569566759","weight":3},{"id":"1569565213","weight":6},{"id":"1569566511","weight":9},{"id":"1569566531","weight":9},{"id":"1569564611","weight":9},{"id":"1569566423","weight":3},{"id":"1569567015","weight":3},{"id":"1569566811","weight":9},{"id":"1569558901","weight":3},{"id":"1569566139","weight":46},{"id":"1569553519","weight":3},{"id":"1569564209","weight":3},{"id":"1569566445","weight":28},{"id":"1569566209","weight":3},{"id":"1569566371","weight":9},{"id":"1569566909","weight":3},{"id":"1569564857","weight":9},{"id":"1569566357","weight":9},{"id":"1569558509","weight":9},{"id":"1569566003","weight":3},{"id":"1569566553","weight":9},{"id":"1569562207","weight":3},{"id":"1569566191","weight":6},{"id":"1569565527","weight":6},{"id":"1569566695","weight":15},{"id":"1569566297","weight":18},{"id":"1569564097","weight":6},{"id":"1569566407","weight":9},{"id":"1569566481","weight":3},{"id":"1569566383","weight":9},{"id":"1569566097","weight":6},{"id":"1569566479","weight":6},{"id":"1569566129","weight":12},{"id":"1569566711","weight":6},{"id":"1569566887","weight":6},{"id":"1569564131","weight":3},{"id":"1569566595","weight":6},{"id":"1569566677","weight":6},{"id":"1569566137","weight":9},{"id":"1569566283","weight":3},{"id":"1569565293","weight":6},{"id":"1569563975","weight":46},{"id":"1569564861","weight":3},{"id":"1569566487","weight":3},{"id":"1569560235","weight":6},{"id":"1569564157","weight":6},{"id":"1569566389","weight":6},{"id":"1569564923","weight":3},{"id":"1569564281","weight":3},{"id":"1569564769","weight":3},{"id":"1569566601","weight":3},{"id":"1569557851","weight":3},{"id":"1569566847","weight":9},{"id":"1569567013","weight":12},{"id":"1569565165","weight":3},{"id":"1569565113","weight":3},{"id":"1569566973","weight":6},{"id":"1569566987","weight":6},{"id":"1569565579","weight":15},{"id":"1569566615","weight":3},{"id":"1569566609","weight":9},{"id":"1569560581","weight":21}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T1.2","endtime":"15:20","authors":"Hamed Maleki, Viveck Cadambe, Syed Ali Jafar","date":"1341500400000","papertitle":"Index Coding: An Interference Alignment Perspective","starttime":"15:00","session":"S13.T1: Index Coding","room":"Kresge Rehearsal B (030)","paperid":"1569566575"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
