{"id":"1569566787","paper":{"title":{"text":"Rank Modulation for Translocation Error Correction"},"authors":[{"name":"Farzad Farnoud (Hassanzadeh)"},{"name":"Vitaly Skachek"},{"name":"Olgica Milenkovic"}],"abstr":{"text":"Abstract\u2014We consider rank modulation codes for ﬂash memo- ries that allow for handling arbitrary charge drop errors. Unlike classical rank modulation codes used for correcting errors that manifest themselves as swaps of two adjacently ranked elements, the proposed translocation codes account for more general forms of errors that arise in storage systems. Translocations represent a natural extension of the notion of adjacent transpositions and as such may be analyzed using related concepts in combinatorics and rank modulation coding. Our results include deriving the asymptotic capacity of translocation rank codes, construction techniques for asymptotically good codes and a simple decoding algorithm."},"body":{"text":"Permutation codes and permutation arrays are collections of suitably chosen codewords from the symmetric group, used in applications as varied as single user communication over Gaussian channels [1], reduction of impulsive noise over power-lines [2] and coding for storage [3]. Many instances of permutation-based codes were studied in the coding theory literature, with special emphasis on permutation arrays under the Hamming distance and rank modulation codes under the Kendall τ distance [4], [5, Chapter 6B]. The distances used for code construction in storage devices have mostly focused around two families of combinatorial measures: adjacent trans- positions and measures obtained via embeddings into the Hamming space [2], [3]. This is due to the fact that such distance measures capture the displacement of symbols in retrieved messages that arise in modern storage systems.\nOne emerging application of permutation codes in storage is rank modulation. Rank modulation is an encoding scheme that may improve the lifespan, storage efﬁciency and reliability of future generations of ﬂash memory storage devices [3], [6]. The idea behind the modulation scheme is that information should be stored in the form of rankings of cells charges, rather than in terms of the absolute values of the charges. This simple conceptual coding framework may reduce the problem of cell block erasures as well as potential cell over-injection issues [6], [7]. In their original formulation, rank-modulation codes represent a family of codes capable of handling errors of the form of adjacent transpositions. Such transposition errors represent the most likely errors in a system where the cells\nhave nearly-uniform leakage rates. Leakage rates depend not only on the charge and position of the cells, but also on a number of external factors, the inﬂuence of which may not be adequately captured by adjacent transposition errors. For example, if a cell for a variety of reasons has a higher leakage rate than other cells, given sufﬁcient time, the charge of this cell may drop below the charge of a number of other cells. Using Kendall\u2019s τ distance, this process may be modeled as a sequence of adjacent transposition errors [3], [8]. However, as this type of error is the result of a single error event, for the purpose of error correction it should be modeled as one error only. This is reminiscent of the scenario when one models a sequence of individual symbol errors as a single burst error.\nIn what follows, we present a novel approach to rank modulation coding which allows for correcting a more varied class of errors when compared to classical schemes. The focal point of the study that follows is the notion of a translocation error, a concept that can be viewed as a generalization of the notion of an adjacent transposition in a permutation. Roughly speaking, a translocation moves the ranking of one particular element in the permutation below the ranking of a certain number of closest-ranked elements. As such, translocations are suitable for modeling errors that arise in ﬂash memory systems where high leakage levels for subsets of cells are expected or possible. The study of translocations is also closely related to a number of problems in combinatorial theory, such as the longest common subsequence problem and permutation coding in the Levenshtein and Hamming metric [9], [10].\nThe rank modulation problem is by now fairly well under- stood from the perspective of code construction. The asymp- totic capacity of rank-modulated channel was derived in [8], while some practical code constructions were proposed in [3], [6] and [11]. Here, we complement the described work in terms of deriving upper and lower bounds on the capacity of translocation rank modulation codes, and in terms of presenting constructive, asymptotically good coding schemes. Our constructions are based on a novel idea of permutation interleaving, and are of independent interest in combinatorics and algebra.\nThe paper is organized as follows. In Section II we provide the motivation for studying translocations as well as basic deﬁnitions used in our analysis. The properties of permutations under translocations and bounds on the size of translocation\ncodes are studied in the same section. Code constructions and decoding are addressed in Sections III. Throughout the paper, we omit the proofs of the claimed results due to space limitations \u2013 the proofs can be found in the Arxiv preprint of this work [12].\nA permutation is a bijection σ [n] → [n], that is, for any i, j ∈ [n], i ≠ j, we have σ(i) ≠ σ(j). For any σ ∈ S n , we write σ = (σ(1),σ(2),⋯,σ(n)), where σ(i) is the image of i ∈ [n] under the permutation σ. Alternatively, we may write σ as [σ(1),σ(2),⋯,σ(n)] or as [σ(1)σ(2)⋯σ(n)] if doing so does not cause ambiguity. The identity permutation (1,2,⋯,n) is denoted by e, while σ −1 stands for the inverse of a permutation σ.\nWe let S n denote the set of all permutations of the set [n], i.e., the symmetric group of order n. Additionally, let\nS (P),P ⊆ [n], be deﬁned as the set of all permutations of elements of P .\nA permutation code of length n and minimum distance d in a metric d is subset C of S n such that for all distinct π, σ ∈ C, we have d (π,σ) ≥ d.\nDeﬁnition 1. We say that a permutation τ ∈ S n is a transposition if for i, j ∈ [n],\nAssume that 1 ≤ i, j ≤ n. A translocation φ (i,j) is a permutation deﬁned as follows. If i ≤ j, we have\nφ (i,j) = (1,⋯,i − 1,i + 1,i + 2,⋯,j,i,j + 1,⋯,n) and if i > j, we have\nSimply put, the product of a permutation σ and a transloca- tion φ (i,j) is the permutation obtained by moving σ(i) to the j th position and shifting all the elements between the ith and j th positions. Observe that the inverse of the a translocation φ (i,j) is the right translocation φ(j,i), and vice versa.\nOur interest in translocations in permutations is motivated by rank modulation coding. In classical multi-level ﬂash memories, each cell used for storing information is subject to leakage. As a result, classical error control schemes of non- zero rate can not be efﬁciently used in such systems. One solution to the problem is to encode the information in terms of rankings, rather than absolute values of the stored information sequences [3]. Hence, data is represented by permutations and errors manifest themselves via reordering of the ordered elements. The simplest model assumes that only adjacent ranks may be exchanged \u2013 or equivalently, that only adjacent positions in the inverse permutation may be exchanged.\nThis model has the drawback that it does not account for more general changes in ranks. With respect to this observation, consider the charge-drop model in Figure 1. Here, cell number 3, ranked second, experienced a leakage rate sufﬁciently high to move the cell\u2019s ranking to the seventh position. If other cells had signiﬁcantly more moderate leakage rates, the resulting ranking would be the result of a (right) translocation error. It is easy to note that in this framework, one translocation φ (i,j) of \u201clength\u201d i − j corresponds to i − j adjacent transpositions. Nevertheless, a translocation should be counted as one single error, and not a sequence of adjacent transposition errors. Furthermore, translocation errors of arbitrary length are suitable for modeling arbitrary charge drops of a given cell independently of the charge drops of other cells.\nDeﬁnition 2. Let σ, π ∈ S n . The translocation distance between σ and π is a function\nIn other words, d ○ (σ,π) equals the smallest m such that there exist a sequence of translocations φ 1 , φ 2 , ..., φ m for which π = σφ 1 φ 2 ⋯φ m .\nObserve that the function d ○ (⋅,⋅) is nonnegative and sym- metric. It also satisﬁes the triangle inequality, namely for any σ 1 , σ 2 and σ 3 in S n , one has\nd ○ (σ 1 , σ 3 ) ≤ d ○ (σ 1 , σ 2 ) + d ○ (σ 2 , σ 3 ) . Therefore, it is indeed a metric over the space S n .\nNote that a translocation may correspond to either a left or a right translocation. As seen from the example in Figure 1, right translocations correspond to general cell leakage models. On the other hand, left translocations assume that the charge of a cell is increased above the level of other cells, which corresponds to a phenomena not frequently encountered in ﬂash memories. The translocation distance is easier to analyze than the right translocation distance, and represents a natural lower bound for this distance.\nDeﬁnition 3. A subsequence of length m of σ = (σ(1),... ,σ(n)) is a sequence of the form σ(i 1 ),... ,σ(i m ),\nwith i 1 < i 2 < . . . i m . Let σ 1 , σ 2 ∈ S n . A longest common subsequence of σ 1 and σ 2 is a subsequence of both σ 1 and σ 2 of longest length. We denote this sequence by L (σ 1 , σ 2 ), and its length by l (σ 1 , σ 2 ).\nDeﬁnition 4. Let σ ∈ S n and let l (σ) = l (σ,e). The function l (σ) is termed the length of the longest increasing subsequence of σ.\nDeﬁnition 5. Let R + 0 denote the set of nonnegative real numbers. A metric d S n × S n → R + 0 is right-invariant if, for all π, σ, ω ∈ S n , we have d (π,σ) = d(πω,σω). Similarly, d is left-invariant if d (π,σ) = d(ωπ,ωπ).\nIt can be easily veriﬁed that the translocation distance and the length of the longest common subsequence are both left- invariant. Furthermore, it can be easily shown [12] that, for π, σ ∈ S n , the distance d ○ (π,σ) equals n − l (π,σ).\nFor π, σ ∈ S n , n−l (π,σ) is also known as the Ulam distance [5], frequently used in voting theory. The Ulam metric is closely connected to the edit (Leveshtein) distance between binary sequences, deﬁned as the number of deletions and insertions needed to transform one sequence to another [10]. Over the space of permutations, it is easy to see that Ulam\u2019s distance is half of Levenshtein\u2019s distance. Nevertheless, with the exception of two results \u2013 one pertaining to single-error correction codes [10], and another to a purely combinatorial analysis of substrings [13] that corresponds to zero-rate cod- ing, no results on multiple error-correcting codes in the Ulam metric are known.\nThere also exists an interesting relationship between the translocation distance and the Kendall\u2019s τ distance used for classical rank modulation coding. The Kendall\u2019s τ distance d τ (σ,π) between two permutations π and σ is deﬁned as the minimum number of adjacent transpositions required to change π into σ. Since a translocation requires at most n − 1 adjacent transpositions, and since an adjacent transposition is a translocation, it is easy to see that\nBoth the upper and lower bound are tight. Observe that the inequalities imply that the translocation distance is not within a constant factor from the Kendall\u2019s τ distance, so that code constructions and bounds speciﬁcally designed for the latter distance measure are not tight and sufﬁciently efﬁcient with respect to the translocation distance.\nA similar pair of bounds may be shown to hold for the translocation distance and the Hamming distance between two permutations. The Hamming distance d H (σ,π) between two permutations σ and π is deﬁned as n − F (σ, π) , where F (σ,π) denotes the set of ﬁxed points in σ under the ordering of π (and vice versa). The subsequence of σ that consists of elements of F (σ,π) is also a subsequence of π and thus d ○ (σ,π) = n − l(σ,π) ≤ n − F(σ,π) = d H (σ,π). Furthermore, since for any two permutations π, σ ∈ S n one has\nd H (π,σ) ≤ n, it follows that d H (π,σ) ≤ nd ○ (π,σ). Thus, 1\nLet A ○ (n,d) be the maximum size of a code of length n and minimum translocation distance d. Also, let C ○ (n) =\ndenote the rate of the code. The following results follow from a simple computation of the volume of spheres involving permutations.\nProposition 7. For all n, d ∈ Z with n ≥ d ≥ 1, A ○ (n,d) ≤ (n − d + 1)! .\nFrom the two previous propositions, we obtain (n − d + 1)!\nIn what follows, all limits are in n. The results below are stated for code families with length n, A ○ (n,d(n)) codewords, and minimum translocation distance d (n). The ratio d (n) / n is denoted by δ (n). Furthermore, limδ(n) and lim C ○ (n) are denoted by δ and C ○ , respectively.\nWe describe next constructions for single and t-translocation error-correcting codes. The ﬁrst construction is based on single transposition detecting codes, while the second construction involves codes in the Hamming metric and interleaving meth- ods.\nDeﬁnition 9. For vectors σ i , i ∈ [k], of lengths m i with m ≤ m k ≤ ⋯ ≤ m 1 ≤ m+1, the interleaved vector σ = σ 1 ○σ 2 ○⋯○σ k is deﬁned as\nA single-transposition error detecting code: For σ 1 , σ 2 ∈ S n , let d T (σ 1 , σ 2 ) denote the transposition distance between σ 1 and σ 2 , i.e., the number of transpositions needed to transform σ 1 to σ 2 . The parity of a transposition σ is deﬁned as the parity of d T (σ,e). It is well-known that applying a transposition to a permutation changes the parity of the permutation, and also that, for n ≥ 2, half of the permutations in S n are even and half are odd. Hence, the code containing all even permutations of S n is a single-transposition error detecting code of length n and cardinality S n /2.\nThe following construction leads to single-translocation error correcting codes. Assume that n = 3k. We start by partitioning [n] into three sets P 1 , P 2 , and P 3 , each of size k. We let C i be the set of all even permutations of elements of P i , for i = 1, 2, 3.\nProposition 10. The code C = C 1 ○ C 2 ○ C 3 corrects one translocation error.\nThe construction above can be easily extended to the case where n = 3k ± 1.\nIn what follows, we construct a family of codes with translocation distance 2t + 1, length n = s (2t + 1) for some integer s ≥ 4t + 1, and cardinality M = (A H (s,4t + 1)) 2t +1 , where A H (s,d) denotes the maximum size of a permutation code with length s and minimum Hamming distance d. The construction relies on the use of 2t+1 permutation codes, each with minimum Hamming distance at least 4t + 1.\nFor a given n and t, where n ≡ 0 (mod 2t + 1), partition the set [n] into 2t + 1 classes P i , each of size s, with\nP i = {j ∈ [n] j ≡ i (mod 2t + 1)} , \t i ∈ [2t + 1]. (3) For i ∈ [2t + 1], let C i be a permutation code over P i with minimum Hamming distance at least 4t + 1. The code C = C 1 ○ ⋯ ○ C 2t +1 is referred to as an interleaved code with 2t + 1 classes. The following theorem provides a lower-bound for the minimum translocation distance of C.\nTheorem 11. Consider positive integers s, t, n = s (2t+1), and a partitioning of [n] of the form of (3). If, for i ∈ [2t+1], C i is a permutation code over P i with minimum Hamming distance at least 4t+1, then C = C 1 ○⋯○C 2t +1 is a permutation code over [n] with minimum translocation distance greater than or equal to 2t + 1.\nThe rate of translocation correcting codes based on inter- leaving may be easily estimated as follows. The cardinality of the interleaved code of length n and minimum distance at least d is at least (A H (⌊ n d ⌋ ,2d − 1)) d , for odd d, and (A H (⌊ n d +1 ⌋ ,2d + 1)) d +1 , for even d. Assuming that Ham- ming codes with minimum distance d ∼ n β are used for interleaving, it can be shown that the asymptotic rate of the interleaved code equals 1 − β. In the next subsection we describe a simple modiﬁcation of the interleaving procedure, which, when applied recursively, improves upon the code rate 1 − β.\nThe interleaving approach described in the previous sub- section may be modiﬁed as follows. Rather than interleaving permutation codes with good Hamming distance, one may construct a code in the translocation metric by interleaving a code with good translocation distance and a code with\ngood Hamming distance. Furthermore, this approach may be implemented in a recursive manner.\nWe ﬁnd the following results useful for describing our recursive construction method.\nLemma 12. Let σ, π ∈ S n be two permutations, such that d ○ (σ,π) = 1. Then, there exist at most three locations i, i ∈ [n − 1], such that for some j = j(i) ∈ [n − 1]:\nCorollary 13. Let σ, π ∈ S n be two permutations, and assume that there exist a ≥ 0 different locations i, i ∈ [n − 1], such that σ (i) = π(j), but σ(i + 1) ≠ π(j + 1) for some j ∈ [n − 1]. Then, d ○ (σ, π) ≥ ⌈a/3⌉.\nFor an integer p ≥ 1, let µ = [12⋯p + 1] and let σ 1 , σ 2 ∈ S ({p + 2,⋯,2p + 1}). In this case, we have\nµ ○ σ 2 = (1,σ 2 (1),2,σ 2 (2),⋯,p,σ 2 (p),p + 1). (4) Lemma 14. For µ, σ 1 , and σ 2 described above, if\nAs a result, for odd n, the code {[12⋯p + 1] ○ σ σ ∈ C 1 }, where n = 2p + 1 and C 1 is permutation code with length p and minimum Hamming distance ⌈ 3d / 2 ⌉, is a translocation code with length n, minimum distance at least d, and size A H (p,⌈ 3d / 2 ⌉). This can be easily generalized for all n to obtain codes of size\nBy assuming that the permutation code in the Hamming metric is capacity achieving, the asymptotic rate of the con- structed code becomes 1 /2 − (3/2)δ. Therefore, this code construction incurs a rate loss of 1 /2(1 + δ) when compared to the capacity bound.\nLemma 15. For sets P and Q of sizes p + 1 and p respec- tively, let C \u2032 1 ⊆ S (P) be a code with minimum translocation distance d and C 1 ⊆ S (Q) a code with minimum Hamming distance 3d /2. The code C \u2032 1 ○C 1 = {σ ○ π σ ∈ C \u2032 1 , π ∈ C 1 } has minimum translocation distance d.\nWe now turn our attention to a recursive code construction based on the ﬁndings outlined above.\nLet α = 3 / 2 . For a given n, set P = {1,⋯,⌈ n 2 ⌉} and set Q = {⌈ n 2 ⌉ + 1,⋯,2 ⌈ n 2 ⌉ − 1}. Suppose C \u2032 1 ⊆ S (P) is a code with minimum translocation distance d and C 1 ⊆ S (Q) a code with minimum Hamming distance α d. Assuming that permutation codes with this given minimum Hamming distance exist, we only need to provide a construction for C \u2032 1 . An obvious choice for C \u2032 1 is a code with only one codeword, which leads to the case discussed above.\nThe gap to capacity may be signiﬁcantly reduced by ob- serving that C \u2032 1 may be constructed from shorter codes. To\nthis end, let C \u2032 1 = C \u2032 2 ○ C 2 where C \u2032 2 is a code of length ⌈ n 4 ⌉ with minimum translocation distance d, while C 2 is a code of length ⌈ n 4 ⌉ − 1 and minimum Hamming distance αd.\nBy repeating the same procedure k times we obtain a code of the form\nwhere each C i , i ≤ k, is a code with minimum Hamming distance αd and length ⌈ n 2 i ⌉−1 and C \u2032 k is a code with minimum translocation distance d and length ⌈ n 2 i ⌉. Since each C i is a permutation code in the Hamming metric with minimum distance αd, we must have ⌈ n 2 i ⌉ − 1 ≥ αd. To ensure that this condition is satisﬁed, in (5), we let k be the largest value of i satisfying n 2 i − 1 ≥ αd. It is easy to see that k = ⌊log n αd +1 ⌋. Furthermore, we choose C \u2032 k to consist of a single codeword.\nThe asymptotic rate of the recursively constructed codes equals 1 − 2 −⌊log 1 αδ ⌋ − αδ ⌊log 1 αδ ⌋. B. Decoding of Interleaved Codes\nAn efﬁcient decoder implementation for the general family of interleaved codes is not currently known. For the case of recursive codes, decoding may be accomplished with low com- plexity provided that the Hamming distance of the component permutation codes is increased from 3d / 2 to 2d.\nFor simplicity of exposition, we assume n to be odd, more precisely, of the form n = 2p + 1. The case of even n may be handled in the same manner, provided that one ﬁxes the last symbol of all codewords.\nAssume that C ⊆ S n is an interleaved code of the form C = C \u2032 1 ○ C 1 where C \u2032 1 is a permutation code over the set {1,⋯,p + 1} with minimum translocation distance 2t + 1 and C 1 is a permutation code over the set Q = {p + 2,⋯,2p + 1} with minimum Hamming distance 4t + 1. In what follows we present a decoding method where there are at most t translocation errors. We assume C \u2032 1 = {[1,2,⋯,p + 1]}. The general case follows by repeating the same argument for each layer of the recursive code.\nLemma 16. The permutation ˆ π differs from ˆ σ in at most 2d ○ (σ,π) positions.\nThe ﬁrst step of the decoding algorithm is to extract ˆ π from the permutation π. By Lemma 16, we have d H (ˆσ, ˆπ) ≤ 2t. Since C 1 has minimum Hamming distance 4t + 1, ˆ σ can be uniquely recovered from ˆ π . Thus, decoding is accomplished through Hamming distance decoding of permutation codes, for which a number of interesting algorithms are known in the literature, e.g., [14], [15].\nFinally, we brieﬂy comment on the rate loss introduced into the interleaved code construction in order to perform efﬁcient decoding. To compute the rate of the code C, note that\nln C 1 ln p!\nAssume that the Hamming code C 1 is capacity achieving, and that therefore it holds that\n1 2"},"refs":[{"authors":[{"name":"J. Karlof"}],"title":{"text":"Permutation codes for the gaussian channel"}},{"authors":[{"name":"I. F. Blake"},{"name":"G. Cohen"},{"name":"M. Deza"}],"title":{"text":"Coding with permutations"}},{"authors":[{"name":"A. Jiang"},{"name":"M. Schwartz"},{"name":"J. Bruck"}],"title":{"text":"Error-correcting codes for rank modulation"}},{"authors":[{"name":"H. Chadwick"},{"name":"L. Kurz"}],"title":{"text":"Rank permutation group codes based on kendall\u2019s correlation statistic"}},{"authors":[{"name":"P. Diaconis"}],"title":{"text":"Group representations in probability and statistics"}},{"authors":[{"name":"A. Jiang"},{"name":"M. Schwartz"},{"name":"J. Bruck"}],"title":{"text":"Correcting charge-constrained errors in the rank-modulation scheme"}},{"authors":[{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"Partial rank modulation for ﬂash memories"}},{"authors":[{"name":"A. Barg"},{"name":"A. Mazumdar"}],"title":{"text":"Codes in permutations and error correction for rank modulation"}},{"authors":[{"name":"J.-C. Chang"},{"name":"R.-J. Chen"},{"name":"T. Klove"},{"name":"S.-C. Tsai"}],"title":{"text":"On the maximum number of permutations with given maximal or minimal distance"}},{"authors":[{"name":"V. I. Levenshtein"}],"title":{"text":"On perfect codes in deletion and insertion metric"}},{"authors":[{"name":"A. Mazumdar"},{"name":"A. Barg"},{"name":"G. Zemor"}],"title":{"text":"Parameters of rank modulation codes: Examples"}},{"authors":[{"name":"F. Farnoud"},{"name":"V. Skachek"},{"name":"O. Milenkovic"}],"title":{"text":"Rank modulation for translocation error correction"}},{"authors":[{"name":"P. Beame"},{"name":"E. Blais"},{"name":"D. Huynh-Ngoc"}],"title":{"text":"Longest common subse- quences in sets of permutations"}},{"authors":[{"name":"T. Swart"},{"name":"H. Ferreira"}],"title":{"text":"Decoding distance-preserving permutation codes for power-line communications"}},{"authors":[{"name":"T. Wadayama"},{"name":"M. Hagiwara"}],"title":{"text":"Lp decodable permutation codes based on linearly constrained permutation matrices"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566787.pdf"},"links":[{"id":"1569564605","weight":3},{"id":"1569566605","weight":3},{"id":"1569565227","weight":3},{"id":"1569564805","weight":3},{"id":"1569564897","weight":3},{"id":"1569565317","weight":9},{"id":"1569564249","weight":3},{"id":"1569565809","weight":6},{"id":"1569566717","weight":3},{"id":"1569566015","weight":3},{"id":"1569566895","weight":6},{"id":"1569566343","weight":3},{"id":"1569564311","weight":3},{"id":"1569566733","weight":3},{"id":"1569563307","weight":3},{"id":"1569565199","weight":3},{"id":"1569566719","weight":3},{"id":"1569566423","weight":9},{"id":"1569559805","weight":3},{"id":"1569558901","weight":25},{"id":"1569565839","weight":3},{"id":"1569566139","weight":3},{"id":"1569564209","weight":3},{"id":"1569566909","weight":3},{"id":"1569564857","weight":6},{"id":"1569566809","weight":3},{"id":"1569565847","weight":6},{"id":"1569565521","weight":3},{"id":"1569556671","weight":3},{"id":"1569565393","weight":3},{"id":"1569565933","weight":3},{"id":"1569566603","weight":3},{"id":"1569561123","weight":3},{"id":"1569565739","weight":3},{"id":"1569566501","weight":3},{"id":"1569565961","weight":3},{"id":"1569565155","weight":3},{"id":"1569566831","weight":12},{"id":"1569565765","weight":3},{"id":"1569565385","weight":18},{"id":"1569566887","weight":3},{"id":"1569564919","weight":3},{"id":"1569564595","weight":9},{"id":"1569565177","weight":3},{"id":"1569566755","weight":3},{"id":"1569566713","weight":3},{"id":"1569563975","weight":3},{"id":"1569564861","weight":6},{"id":"1569567483","weight":3},{"id":"1569561713","weight":18},{"id":"1569566147","weight":3},{"id":"1569560785","weight":3},{"id":"1569565631","weight":3},{"id":"1569565565","weight":9},{"id":"1569565373","weight":9}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S17.T1.3","endtime":"16:00","authors":"Farzad Farnoud, Vitaly Skachek, Olgica Milenkovic","date":"1341589200000","papertitle":"Rank Modulation for Translocation Error Correction","starttime":"15:40","session":"S17.T1: Rank-Modulation Coding","room":"Kresge Rehearsal B (030)","paperid":"1569566787"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
