{"id":"1569566485","paper":{"title":{"text":"Partial Decode-Forward Binning for Full-Duplex Causal Cognitive Interference Channels"},"authors":[{"name":"Zhuohua Wu"},{"name":"Mai Vu"}],"abstr":{"text":"Abstract\u2014The causal cognitive interference channel (CCIC) is a four-node channel, in which the second sender obtains information from the ﬁrst sender causally and assists in the trans- mission of both. We propose a new coding scheme called Han- Kobayashi partial decode-forward binning (HK-PDF-binning), which combines the ideas of Han-Kobayashi coding, partial decode-forward relaying, conditional Gelfand-Pinsker binning and relaxed joint decoding. The second sender decodes a part of the message from the ﬁrst sender, then uses Gelfand-Pinsker binning to bin against the decoded codeword. When applied to the Gaussian channel, this HK-PDF-binning essentializes to a correlation between the transmit signal and the state, which encompasses the traditional dirty-paper-coding binning as a special case when this correlation factor is zero. The proposed scheme encompasses the Han-Kobayashi rate region and achieves both partial decode-forward relaying rate for the ﬁrst user and interference-free rate for the second user."},"body":{"text":"The causal Cognitive Interference Channel (CCIC) is a practically-oriented cognitive channel, in which the second (cognitive) sender obtains information from the ﬁrst (primary) sender causally, then uses that to assist the transmissions of the ﬁrst sender and its own message. This is different from the traditional cognitive channel in which the cognitive user knows the primary user\u2019s message non-causally.\nCoding for the traditional (non-causal) CIC is mainly based on combining Gelfand-Pinsker binning technique [1] with Han-Kobayashi coding [2], [3] for the interference channel. Since the cognitive user has the primary user\u2019s message non- causally, the fact that it relays this message is implicit. In the causal-CIC, however, the cognitive user has to relay explicitly. Speciﬁcally in this paper, we apply partial decode-forward relaying [4], in which the cognitive user ﬁrst decodes the primary user\u2019s message causally, then transmits the decoded message and its own message cognitively.\nThe CCIC can also be considered as a special case of the interference channel with source cooperation (IC-SC) in which both senders exchange information. Several coding schemes have been proposed for the IC-SC by applying different ways of rate splitting, block Markov encoding and/or Gelfand- Pinsker binning [5]\u2013[8]. These existing schemes may encom- pass the Han-Kobayashi rate region or the partial decode- forward (PDF) relaying rate, but none achieve both.\nIn this paper, we propose a new coding scheme for the CCIC based on block Markov encoding, partial decode-forward relaying, Gelfand-Pinsker binning and Han-Kobayashi coding by splitting the ﬁrst user\u2019s message into 3 parts and the second user\u2019s into 2 parts. The proposed scheme achieves both the Han-Kobayashi region and the PDF rate for the primary user.\nThis scheme therefore brings a new way of coding and can be combined with existing schemes for the IC-SC to improve rates further. We then apply our scheme to the Gaussian channel and show that introducing a correlation between the state and the transmit signal can enlarge the rate region by allowing both state nullifying and forwarding at the cognitive user.\nThe full-duplex causal cognitive interference channel con- sists of two input alphabets X 1 , X 2 , and three output alphabets Y 1 , Y 2 , Y. The channel is characterized by a channel transi- tion probability p(y 1 , y 2 , y|x 1 , x 2 ), where x 1 and x 2 are the transmit signals of S 1 and S 2 , y 1 , y 2 and y are the received signals of D 1 , D 2 and S 2 . Figure 1 illustrates the channel model, where W 1 and W 2 are the messages of S 1 and S 2 .\nx n 1 (w 1 ) ∈ X n 1 , and one maps w 2 and each received sequence y k−1 into a symbol x 2k (w 2 , y k−1 ) ∈ X 2 .\n\u2022 Two decoders: one maps y n 1 into ˆ w 1 ∈ W 1 ; one maps y n 2 into ˆ w 2 ∈ W 2 .\nThe deﬁnitions for the error probability, achievable rates and capacity region follow the standard ones in [9]. B. Full-duplex Gaussian CCIC model\nThe standard full-duplex Gaussian causal cognitive interfer- ence channel is shown in Figure 2 as\nY 1 = X 1 + bX 2 + Z 1 , Y 2 = aX 1 + X 2 + Z 2 ,\nwhere Z 1 , Z 2 , Z ∼ N (0, 1) are independent Gaussian noises, and a, b and c are cross-channel gains. If the original channel\nis not in this standard form, we can always transform it into the standard form using a procedure similar to the interference channel [10]. The transmit signals X 1 and X 2 are subject to power constraints P 1 and P 2 , respectively.\nFigure 3 illustrates the idea of the full-duplex Han- Kobayashi PDF-binning scheme. Message w 1 is split into three parts: w 10 , w 11 , w 12 , corresponding to the common (forward- ing), public and private parts, and message w 2 is split into two parts: w 21 , w 22 , corresponding to the public and private parts. Take the transmission in block i as an example. At S 1 , the current common message w 10i is superimposed on the previous commons message w 10[i−1] ; message w 11i is encoded independently of both w 10[i−1] and w 10i ; message w 12i is then superimposed on all three messages w 10[i−1] , w 10i and w 10i . S 2 decodes ˜ w 10[i−1] of the previous block and uses conditional binning to bin the codeword for its private part w 22[i] against ˜ w 10[i−1] , conditionally on knowing the public part w 21[i] . At the end of block i, D 1 uses joint decoding over two consecutive blocks to decode a unique tuple ( ˆ w 10[i−1] , ˆ w 11[i−1] , ˆ w 12[i−1] ) for some ˆ w 21[i−1] without requiring this message part to be correct. D 2 treats the codeword for w 10[i−1] as the state and searches for a unique pair ( w 21i , w 22i ) for some w 11i .\nTheorem 1. The convex hull of the following rate region is achievable for the CCIC using HK-PDF-binning:\n⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩\nR 1 \t ≤ min{I 2 + I 5 , I 6 } R 2 \t ≤ I 12\nR 1 + R 2 ≤ min{I 2 + I 7 , I 8 } + I 13 R 1 + R 2 ≤ min{I 2 + I 3 , I 4 } + I 14\nR 1 + R 2 ≤ min{I 2 + I 9 , I 10 } + I 11 2R 1 + R 2 ≤ min{I 2 + I 3 , I 4 }\nP 1 =p(t 10 )p(u 10 |t 10 )p(u 11 )p(x 1 |t 10 , u 10 , u 11 )p(u 21 ) (3) p(u 22 |u 21 , t 10 )p(x 2 |t 10 , u 21 , u 22 )p(y 1 , y 2 , y|x 1 , x 2 ),\nand I 2 \u2014 I 14 are deﬁned as I 2 = I(U 10 ; Y |T 10 )\nI 4 = I(U 10 , X 1 ; Y 1 |T 10 , U 11 , U 21 ) + I(T 10 ; Y 1 ) I 5 = I(U 11 , X 1 ; Y 1 |T 10 , U 10 , U 21 )\nI 6 = I(U 10 , U 11 , X 1 ; Y 1 |T 10 , U 21 ) + I(T 10 ; Y 1 ) I 7 = I(X 1 , U 21 ; Y 1 |T 10 , U 10 , U 11 )\nI 8 = I(U 10 , X 1 , U 21 ; Y 1 |T 10 , U 11 ) + I(T 10 ; Y 1 ) I 9 = I(U 11 , X 1 , U 21 ; Y 1 |T 10 , U 10 )\nI 11 = I(U 22 ; Y 2 |U 21 , U 11 ) − I(U 22 ; T 10 |U 21 ) I 12 = I(U 21 , U 22 ; Y 2 |U 11 ) − I(U 22 ; T 10 |U 21 ) I 13 = I(U 11 , U 22 ; Y 2 |U 21 ) − I(U 22 ; T 10 |U 21 )\nProof: Fix a joint probability distribution as in (3). 1) Codebook generation: For each block i: \u2022 Independently generate 2 nR 10 sequences t n 10 (w 10 ) ∼ n\n\u2022 For each t n 10 (w 10 ), independently generate 2 nR 10 se- quences u n 10 (w 10 |w 10 ) ∼ n k=1 p(u 10k |t 10k ), w 10 ∈ [1, 2 nR 10 ]. w 10 and w 10 are the common (forwarding) messages of the previous and current blocks, respectively.\n\u2022 For each t n 10 (w 10 ), u n 10 (w 10 |w 10 ) and u n 11 (w 11 ), independently \t generate \t 2 nR 12 \t sequences\nw 12 ∈ [1, 2 nR 12 ]. \u2022 Independently generate 2 nR 21 sequences u n 21 (w 21 ) ∼ n\n\u2022 For each u n 21 (w 21 ), independently generate 2 n(R 22 +R 22 ) sequences u n 22 (w 22 , v 22 |w 21 ) ∼ \t n k=1 p(u 22k |u 21k ), w 22 ∈ [1, 2 nR 22 ] and v 22 ∈ [1, 2 nR 22 ].\n\u2022 For each t 10 (w 10 ), u n 21 (w 21 ) and u n 22 (w 22 , v 22 |w 21 ), generate one sequence x n 2 (w 10 , w 21 , w 22 , v 22 ) ∼ n\n2) Encoding: \t Let \t ( w 10i , w 11i , w 12i , w 21i , w 22i ) be the new messages to be sent in block i, and\n\u2022 S 1 transmits x n 1 (w 12i |w 11i , w 10i , w 10[i−1] ). \u2022 S 2 searches for a v 22i such that\nS 2 then transmits x n 2 (w 10[i−1] , w 21i , w 22i , v 22i ). 3) Decoding: At the end of block i:\n\u2022 S 2 knows w 10[i−1] and declares message ˆ w 10i was sent if it is the unique message such that\n\u2022 D 1 knows w 10[i−2] and searches for a unique tuple ( ˆ w 10[i−1] , ˆ w 11[i−1] , ˆ w 12[i−1] ) for some ˆ w 21[i−1] such that\nand (t n 10 ( ˆ w 10[i−1] ), y n 1 (i)) ∈ A (n) (P T 10 Y 1 ). \t (6) \u2022 D 2 treats T n 10 (w 10[i−1] ) as the state and searches for a\nunique ( ˆ w 21i , ˆ w 22i ) for some ( ˆ w 11i , ˆv 22i ) such that (u n 11 ( ˆ w 11i ), u n 21 ( ˆ w 21i ), u n 22 ( ˆ w 22i , ˆv 22i | ˆ w 21i ), y n 2 (i))\nApplying standard error analysis and Fourier Motzkin elimi- nation, we obtain rate region (2). For details see [11].\nRemark 1. Even though at S 2 we use standard Gelfand-Pinsker binning technique, but depending on the joint distribution between the binning auxiliary random variable ( U 22 ) and the state ( T 10 ), S 2 can also forward a part of the state (i.e. message w 10 of the previous block) to D 1 .\nRemark 2. In the binning step (5) at S 2 , we use conditional binning instead of unconditional binning. The binning is only between the codeword for Han-Kobayashi private message part U 22 (w 22 ) and the state T 10 (w 10 ), conditionally on knowing the Han-Kobayashi public messsage part w 21 . This conditional binning is possible since w 21 is decoded at both destinations. Remark 3. In the decoding step (7) at D 2 , we use joint de- coding of both the Gelfand-Pinsker auxiliary random variable ( u 22 ) and the Han-Kobayashi public message parts ( w 11 and w 21 ), instead of decoding Gelfand-Pinsker and Han-Kobayashi codewords separately. This joint decoding is possible since the codewords for w 11 and w 21 (i.e. U n 11 and U n 21 ) are independent of the state in Gelfand-Pinsker coding (i.e. T n 10 ). Joint decoding at both D 1 (6) and D 2 (7) help achieve the largest rate region for this coding structure.\nRemark 4. Inclusion of Han-Kobayashi rate region and the maximum rate for each user\n\u2022 The HK-PDF-binning scheme becomes the Han- Kobayashi scheme if T 10 = U 10 = ∅ and X 2 = U 22 .\n\u2022 S 1 achieves the partial decode-forward relaying rate if we set U 11 = U 21 = U 22 = ∅, and X 2 = T 10 .\nmin \t (8) {I(U 10 ; Y |X 2 ) + I(X 1 ; Y 1 |U 10 , X 2 ), I(X 1 , X 2 ; Y 1 )}\n\u2022 S 2 achieves the maximum rate as in Gelfand-Pinsker coding if we set U 11 = U 21 = ∅, T 10 = U 10 = X 1 .\nThe interference channel with source cooperation (IC-SC) is a 4-node channel in which both S 1 and S 2 can receive signal from each other and use that cooperatively in sending messages to D 1 and D 2 . This channel therefore includes the CCIC as a special case (when S 2 sends no information to S 1 ).\n1) Host-Madsen\u2019s scheme [5]: This scheme for Gaussian IC-SC is based on dirty paper coding and block Markov en- coding; it includes the rate for decode-forward relaying but not the Han-Kobayashi region. However, since both senders must decode the cooperative message from the other sender in order to apply dirty paper coding, the scheme cannot be applied to the CCIC which has only uni-directional cooperation.\n2) Prabhakaran-Viswanath\u2019s scheme [6]: This scheme is based on 4-part rate splitting and block Markov superposition coding. It may not contain the Han-Kobayashi region or the PDF rate, depending on channel parameters. The ideas in this scheme, however, can be combined with our scheme to further improve the rate region.\n3) Cao-Chen\u2019s scheme [7]: This scheme is quite close to our proposed scheme. It is also based on 3-part message splitting, block Markov encoding, Gelfand-Pinkser binning and random binning, and achieves the Han-Kobayashi region. But this scheme cannot achieve the decode-forward relaying rate because of no block Markovity between the current and the previous cooperative messages, hence no coherent transmission between source and relay.\n4) Yang-Tuninetti\u2019s scheme [8]: This scheme combines ideas in previous schemes by doing 4-part message splitting, block Markov superposition coding, Marton double binning and Gelfand-Pinsker binning. It achieves the Han-Kobayashi region but not the partial decode-forward relaying rate as in (8). In this scheme, destination 2 decodes the cooperative- common part of user 1, thus limits rate R 1 to be below the decode-forward relaying rate. In our proposed scheme, the forwarding part of user 1 is not decoded at destination 2. (In [8], it is claimed to achieve the partial decode-forward relaying rate but only by setting Y 1 = Y 2 , which is not necessary in our scheme for the CCIC.)\nFurthermore, in both [7] and [8], joint decoding of both the state and the binning auxiliary variables is used at the destinations, but this joint decoding is invalid as it results in a rate region larger than is possible. In our proposed scheme, all message parts that are jointly decoded with the binning auxiliary variable are encoded independently of the state.\nHence none of the existing schemes for the IC-SC include both the HK rate region and the decode-forward relaying rate as our proposed scheme (see Remark 4). More detailed analysis can be found in [11].\nIn the Gaussian channel, input signals for the HK-PDF- binning scheme in Section III-A can be represented as\nT 10 = αS 10 (w 10 ), \t (10) U 10 = αS 10 (w 10 ) + βS 10 (w 10 ), U 11 = γS 11 (w 11 ),\nX 1 = αS 10 (w 10 ) + βS 10 (w 10 ) + γS 11 (w 11 ) + δS 12 (w 12 ), U 21 = θS 21 (w 21 ),\nwhere S 10 , S 10 , S 11 , S 12 , S 21 , S 22 are independent N (0, 1) random variables to encode w 10 , w 10 , w 11 , w 12 , w 21 , w 22 , respectively. U 22 is the auxiliary random variable for binning that encodes w 22 . X 1 and X 2 are the transmit signals of S 1 and S 2 . The parameters α, β, γ, δ, θ and μ are power allocation factors satisfying power constraints\nAn important feature of the signaling design in (10) is ρ ( −1 ≤ ρ ≤ 1), the correlation factor between the transmit signal ( X 2 ) and the state ( S 10 ) at S 2 . In traditional dirty paper coding, the transmit signal and the state are independent. Here, we introduce correlation between them, which includes dirty paper coding as a special case when ρ = 0. This correlation allows both signal forwarding and traditional binning at the same time. λ is the partial decode-forward binning parameter which will be optimized later.\nCorollary 1. The achievable rate region for the full- duplex Gaussian-CCIC using the Han-Kobayashi PDF- binning scheme is the convex hull of all rate pairs ( R 1 , R 2 ) satisfying (2) with\nwith C(x) = 1 2 log(1 + x), α, β, γ, δ, θ and μ satisfy the power constraints (11) and −1 ≤ ρ ≤ 1.\nProof: Applying Theorem 1 with the signaling in (10), we obtain the rate region in Corollary 1.\n2 , we obtain the maximum R 1 as in partial decode-forward relaying:\n2 , we obtain the maximum R 2 as in dirty paper coding:\nProof: λ ∗ is obtained by maximizing I 11 in (2). The detailed proof is omitted and can be seen in [11]. Remark 6. Effect of ρ:\n\u2022 If ρ = 0, λ ∗ becomes the optimal λ for traditional dirty paper coding [12], which achieves R max 2 as in (14).\n\u2022 If ρ = ±1, λ ∗ differs from the λ in traditional dirty paper coding and achieves R max 1 as in (13).\n\u2022 The effect of ρ is shown in Figure 4. The dashed line represents the rate region for DPC-binning ( ρ = 0), while the solid line represents the region for HK-PDF-binning when we adapt ρ ∈ [−1, 1]. Figure 4 illustrates that the correlation factor ρ can enlarge the rate region.\nIn this section, we provide numerical comparison among the proposed HK-PDF-binning scheme, the original Han- Kobayashi scheme, and an outer bound combining the capacity for the (non-causal) CIC [13], [14] and the outer bound for the IC with user cooperation (IC-UC) [15]. Figure 5 shows an example for weak interference and Figure 6 for strong interference. We can see that the proposed HK-PDF-binning scheme contains the Han-Kobayashi region, partial decode- forward relaying rate for user 1 as in (13) and interference-free rate for user 2 as in (14). The outer bound is the intersection of the two bounds drawn and is loose as this bound is not achievable. However, we observe that as b decreases, the HK- PDF-binning rate region becomes closer to the outer bound.\nIn this paper, we have proposed a new coding scheme for the full-duplex causal cognitive interference channel based on partial decode-forward relaying, Gelfand-Pinsker binning and Han-Kobayashi coding. For the Gaussian channel, we introduce a correlation between the transmit signal and the state, which enlarges the rate region by allowing both state nullifying and forwarding. We also derive the optimal binning\nparameter for the coding scheme. Results show that the Han- Kobayashi PDF-binning scheme for the CCIC contains both the Han-Kobayashi region and partial decode-forward relaying rate. Thus cognitive communication is also beneﬁcial even in causal setting."},"refs":[{"authors":[{"name":"S. Gel\u2019fand"},{"name":"M. Pinsker"}],"title":{"text":"Coding for channels with random param- eters"}},{"authors":[{"name":"T. Han"},{"name":"K. Kobayashi"}],"title":{"text":"A new achievable rate region for the interference channel"}},{"authors":[{"name":"H.-F. Chong"},{"name":"M. Motani"},{"name":"H. Garg"},{"name":"H. El Gamal"}],"title":{"text":"On the Han- Kobayashi region for the interference channel"}},{"authors":[{"name":"T. Cover"},{"name":"A. El Gamal"}],"title":{"text":"Capacity theorems for the relay channel"}},{"authors":[{"name":"A. Host-Madsen"}],"title":{"text":"Capacity bounds for cooperative diversity"}},{"authors":[{"name":"V. Prabhakaran"},{"name":"P. Viswanath"}],"title":{"text":"Interference channels with source cooperation"}},{"authors":[{"name":"Y. Cao"},{"name":"B. Chen"}],"title":{"text":"An achievable rate region for interference channels with conferencing"}},{"authors":[{"name":"S. Yang"},{"name":"D. Tuninetti"}],"title":{"text":"Interference channel with generalized feed- back (a.k.a. with source cooperation): Part I: Achievable region"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory"}},{"authors":[{"name":"A. Carleial"}],"title":{"text":"Interference channels"}},{"authors":[{"name":"Z. Wu"},{"name":"M. Vu"}],"title":{"text":"Partial decode-forward binning schemes for the causal cognitive relay channels"}},{"authors":[{"name":"M. Costa"}],"title":{"text":"Writing on dirty paper (corresp.)"}},{"authors":[{"name":"I. Maric"},{"name":"R. Yates"},{"name":"G. Kramer"}],"title":{"text":"Capacity of interference channels with partial transmitter cooperation"}},{"authors":[{"name":"W. Wu"},{"name":"S. Vishwanath"},{"name":"A. Arapostathis"}],"title":{"text":"Capacity of a class of cognitive radio channels: Interf. channels with degraded message sets"}},{"authors":[{"name":"R. Tandon"},{"name":"S. Ulukus"}],"title":{"text":"Dependence balance based outer bounds for Gaussian networks with cooperation and feedback"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566485.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T2.3","endtime":"17:40","authors":"Zhuohua Wu, Mai Vu","date":"1341336000000","papertitle":"Partial Decode-Forward Binning for Full-Duplex Causal Cognitive Interference Channels","starttime":"17:20","session":"S8.T2: Relay Strategies for Network Communications","room":"Kresge Auditorium (109)","paperid":"1569566485"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
