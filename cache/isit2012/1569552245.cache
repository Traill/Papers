{"id":"1569552245","paper":{"title":{"text":"Moderate-Deviations of Lossy Source Coding for Discrete and Gaussian Sources"},"authors":[{"name":"Vincent Y. F. Tan"}],"abstr":{"text":"Abstract\u2014We study the moderate-deviations (MD) setting for lossy source coding of stationary memoryless sources. More speciﬁcally, we derive fundamental compression limits of source codes whose rates are R(D) ± n , where R(D) is the rate- distortion function and n is a sequence that dominates 1/n. This MD setting is complementary to the large-deviations and central limit settings and was studied by Altug and Wagner for the channel coding setting. We show, for ﬁnite alphabet and Gaussian sources, that as in the central limit-type results, the so-called dispersion for lossy source coding plays a fundamental role in the MD setting for the lossy source coding problem."},"body":{"text":"Rate-distortion theory [1] consists in ﬁnding the optimal compression rate for a source X ∼ P subject to the condition that there exists a code which can reproduce the source to within a distortion level D. The optimal compression rate for the distortion level D is known as the rate-distortion function R(P, D). This function can be expressed as the minimization of mutual information over test channels [1].\nIt is also of interest to study the excess distortion probability for codes at rate R > R(P, D). This is the probability that the average distortion between X n and its reconstruction\nˆ X n exceeds D. The exact exponential rate of decay of this probability was derived by Marton [2] for discrete memoryless sources (DMSs). This was extended to Gaussian [3] and general sources [4]. These results belong to the theory of large- deviations (LD) and are reviewed in Section II.\nWith the revival of interest in second-order coding rates and dispersion analysis [5]\u2013[7], various researchers have also studied the fundamental limit of lossy compression subject to the condition that the probability of excess distortion is no larger than > 0. In particular, it was shown in [8] and independently in [9], [10] that\nwhere R(n, D, ) is the optimal rate of compression of a memoryless source at blocklength n and V (P, D) is known as the dispersion of the source. Eq. (1) holds true for both discrete and Gaussian sources and belongs to the realm of central limit theorem (CLT)-style results. It is similar to the pointwise redundancy results in lossy source coding [11].\nIn this paper, we operate in a moderate-deviations (MD) regime [12, Section 3.7] that \u201cinterpolates between\u201d the LD\nand CLT regimes. In particular, we study the performance of source codes of rates R n = R(P, D) ± n where n is a sequence that is asymptotically larger than 1/n (cf. (1)). Our results apply to both ﬁnite alphabet and Gaussian sources but do not reduce to the LD or CLT settings. Moreover, neither the LD nor CLT results specialize to our setting. We show that the dispersion V (P, D) also plays a fundamental role in this MD setting. Besides studying the excess distortion probability, we also study the complementary probability (also termed the probability of correct decoding) for codes whose rates are below the rate-distortion function. Similarly, the fundamental nature of the dispersion is revealed.\nThis work is inspired by the work on MD in the context of channel coding [13], [14]. It was shown in [13] that for positive discrete memoryless channels (i.e., W (y|x) > 0 for all x, y), the dispersion also governs the \u201cMD exponent\u201d\nThe direct part was proved by considering the Taylor ex- pansion of Gallager\u2019s random coding exponent. We also use this proof strategy. In [14], several assumptions in [13] were relaxed and the relations between the MD and CLT were clariﬁed. Concurrent to this work, Sason [15] studied MD for binary hypothesis testing. Finally, we mention that He et al. [16] studied the redundancy of the Slepian-Wolf problem which is also related to [8]\u2013[10] and to the current problem.\nLet P(X ) be the set of probability mass functions supported on the ﬁnite alphabet X . Let P n (X ) ⊂ P(X ) be the set of n- types. For a type Q ∈ P n (X ), let T n Q be the set of sequences x n of type Q, i.e., the type class. The reproduction alphabet is denoted as ˆ X . In addition, let d : X × ˆ X → R + be a distortion measure such that for every x ∈ X , there exists an ˆ x 0 ∈ ˆ X for which d(x, ˆ x 0 ) = 0. The average distortion is d(x n , ˆ x n ) := 1 n n i=1 d(x i , ˆ x i ). For a function f : A → B, the notation f := |f (A)| denotes the cardinality of its range.\nA DMS X n ∼ n i=1 P (x i ) is described at rate R by an encoder. The decoder receives the description index over a noiseless link and generates a reconstruction sequence ˆ X n ∈\nDeﬁnition 1. A rate-distortion code consists of (i) an encoder f n : X n → M n and (ii) a decoder ϕ n : M n → ˆ X n . The rate\nThe rate-distortion function R(P, D) is deﬁned as the inﬁmum of all numbers R for which there exists codes {(f n , ϕ n )} n∈N for which the probability of excess distortion\nis arbitrarily small for sufﬁciently large blocklengths n. The rate-distortion function [1] can be expressed as\nwhere E[d(X, ˆ X)] := x,ˆ x P (x)W (ˆ x|x)d(x, ˆ x). Another fundamental quantity introduced by Ingber and Kochman [8] is the dispersion for lossy source coding\nwhere R (x; P, D) = ∂ ∂P (x) R(P, D) for x ∈ X is the partial derivative of the rate-distortion function w.r.t. P (x) (assuming it exists). In (5), the variance is taken w.r.t. the distribution P and R (X; P, D) is a function of the random variable X. In fact, the term dispersion is usually an operational one but since it was shown in [8] that the operational deﬁntion coincides with the one in (5), we will abuse terminology and use the generic term dispersion for both quantities.\nWe analyze e(f n , ϕ n , P, D) in the so-called MD regime where the rate of the code R n := 1 n log f n = R(P, D) + n for some sequence n . Clearly, if n → 0, then R n → R(P, D). When the rate of the code R is a constant strictly above R(P, D), Marton [2] showed that\nn log e(f n , ϕ n , P, D) = −F (P, R, D), \t (6) where Marton\u2019s exponent is deﬁned as\nThe exponent is positive for R > R(P, D). One can also con- sider the probability of correct decoding 1 − e(f n , ϕ n , P, D). In [17, pp. 156], it was shown that:\nn log (1 − e(f n , ϕ n , P, D)) = −G(P, R, D), \t (8) where the exponent for correct decoding is\nThe exponent is positive for R < R(P, D). These limits and exponents are Sanov-like LD results [12]. We present MD versions of Marton\u2019s and Iriyama\u2019s results where the normalizations in (6) and (8) need not be 1 n .\nOur main result for a DMS with bounded distortion measure (i.e. d : X × ˆ X → [0, d max ]) is stated as follows:\nThat is, n = ω(( log n n ) 1/2 ) ∩ o(1). Assume that R(Q, D) is twice differentiable w.r.t. Q in a neighborhood of P and V (P, D) > 0. There exists a rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≤ R(P, D) + n such that\nFurthermore, every rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≤ R(P, D) + n must satisfy\nThough somewhat ungainly, the log factor in (10) appears to be essential because the proof hinges on the method of types. So our analysis does not completely close the gap between the CLT and LD regimes. This log factor is unnecessary in the Gaussian case as will be seen in Theorems 5 and 6. Theorem 1 means that if the dispersion V (P, D) is small, the \u201cMD exponent\u201d (2V (P, D)) −1 is large, corresponding to a faster decay in the excess distortion probability. This has the same interpretation as in the CLT regime (1). As an example, for the Bernoulli source with Hamming distortion, the dispersion can be computed as\nV (Bern(α), D) = α(1 − α) log 2 1 − α α\nThe parameter that maximizes (resp. minimizes) V (P, D) is α ≈ 0.0832 (resp. α = 0, 0.5). Thus, the \u201cMD exponent\u201d is maximized when the source is deterministic or has maximum entropy. The proof uses the following lemma, whose proof is essentially identical to that of [18, Theorem 8], where the divergence and the constraint set in (7) are approximated by a quadratic and an afﬁne subspace respectively.\nIn the sequel, we assume that the limit in (14) exists. Otherwise, the results are modiﬁed accordingly by considering the upper and lower limits in (14) and replacing the dispersion by its upper and lower limit versions. We ﬁrst prove the direct part of Theorem 1 in (11) followed by the converse in (12).\nProof: The code construction proceeds along the lines of that in [8]. Fix a sequence n satisfying (10). From the reﬁned type covering lemma by Berger (stated in [19]), for every type Q ∈ P n (X ) there exists a set C Q that completely D-covers T n Q (i.e., for every x n ∈ T n Q there exists an ˆ x n ∈ C Q such that d(x n , ˆ x n ) ≤ D) and C Q has rate\nwhere J is some function of the size of the alphabets. Consider the set C that that is the union of all sets that D-cover the types Q ∈ U n (D, n ), deﬁned as\nwhere n := n − J (|X |, | ˆ X |) log n n − |X | log(n+1) n . The second constraint on the 1 distance of the type Q to the true distribution P is to ensure that R( · , D) is differentiable. This is also done in [16, Theorem 4]. Note that if n satisﬁes (10) so does n . Now, consider the size of C:\nThe ﬁrst inequality applies (15) and the type counting lemma. Furthermore, Q ∗ is the dominating type. The second inequality applies the deﬁnitions of U n and n . Take f n to be the function that maps a sequence x n ∈ X n with type P x n to a predeﬁned index in C = ∪ Q∈U n C Q and take ϕ n to be the function that maps the index to the reproduction sequence in C P xn that D- covers x n . Now, we evaluate the error probability, which is the P n -probability of the types not in U n (D, n ). Consider,\nwhere we applied the type counting lemma and the deﬁnition of Marton\u2019s exponent in the last line. Next, from [20],\nwhere we invoked Lemma 2 with n = o(1) in the role of δ. Now, we take the logarithm and normalize by n 2 n to assert the achievability part of the theorem in (11). Note that we used the fact that log n n 2\nNow for the converse, we ﬁx a code {(f n , ϕ n )} n∈N of rate R n = 1 n log f n ≤ R(P, D) + n and observe that\nwhere the event E Ψ n := {R(P X n , D) ≥ R n + Ψ n } and P X n is the type of X n . From the converse of the type covering lemma [21, Lemma 3], for any type Q ∈ P n (X ) such that R(Q, D) > R, the fraction of T n Q that is covered by any set is no greater than exp[−n(R(Q, D) − R + K(|X |, | ˆ X |) log n n )]. Hence, the ﬁrst term above can be bounded as\n1 n\nwhere the ﬁrst inequality is from the deﬁnition of R n ≤ R(P, D) + n and in the last inequality we deﬁned the type Q (n) := arg min Q∈P\nD(Q || P ). In the appendix, we prove the following key continuity statement.\nLet η > 0. For n large enough, the ratio in (24) is smaller than 1 + η. Uniting (20) \u2013 (24) yields\nThe last inequality is an application of Lemma 2 with n = o(1) in the role of δ. Now, we take the logarithm and normalize by n 2 n to establish the converse noting that η is arbitrary,\n→ 0. The latter allows us to assert that n / n → 1.\nNote that the multiplicative nature of (24) is necessary to establish Theorem 1. The analysis for the probability of correct decoding 1 − e(f n , ϕ n , P, D) in the MD regime is analogous and is stated in the following:\nTheorem 4. Let n be any positive sequence satisfying (10). Assume that R(Q, D) is twice differentiable w.r.t. Q in a neigh- borhood of P and V (P, D) > 0 There exists a rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≥ R(P, D) − n such that\nFurthermore, every rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≥ R(P, D) − n must satisfy\nWe now turn our attention to the quadratic Gaussian setting where X n is a length-n vector whose entries are identically distributed as zero-mean Gaussians with variance σ 2 . The distortion measure is d(x, ˆ x) := (x − ˆ x) 2 . It is known [1] that in this case, the rate-distortion function takes the form\nFurthermore, Ihara and Kubo [3] showed that the analogue of Marton\u2019s exponent in (7) also holds in the Gaussian setting. Indeed, it is shown that the excess distortion exponent is\n1 2\nwhenever R > R(σ 2 , D) and zero otherwise. The exponent for correct decoding G(σ 2 , R, D) takes the same form as in (28) when R < R(σ 2 , D) and zero otherwise. In this case, it is easy to show by direct differentiation of F (σ 2 , R, D) (or G(σ 2 , R, D)) that the dispersion for lossy source coding is\nfor all σ 2 and all D. In analogy to Theorem 1, we have the following in the quadratic Gaussian setting:\nTheorem 5. Let n be any positive sequence satisfying lim\nFurthermore, every rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≤ R(P, D) + n must satisfy\nIn contrast to the DMS case, the dispersion for the quadratic Gaussian case (29) is constant. Hence, the exponents in (31) and (32) are also constant. Also note from (30) that the requirement on n is less stringent than in the DMS case (10). In particular, the log factor is no longer required. This is because the method of types is not used in the proof.\nProof: Fix the sequence n . For the direct part, let us consider the set of \u201cempirical variances\u201d\nwhere n := n − 5 log n 2n − log 6 n . By using the deﬁnition of R(σ 2 , D) in (27), it is easy to see that ˆ σ 2 ∈ U n if and only if e −2 n < ˆ σ 2 /σ 2 < e 2 n . We now use a result by Verger- Gaugry [22, Theorem 1.2], which in our context, says that 6n 5/2 (σ 2 e 2 n /D) n/2 reconstruction points sufﬁce to D-cover length-n vectors x n whose empirical variance 1 n i x 2 i ∈ U n . Hence, the size of the code is bounded as\nwhere we used the deﬁnition of n . Hence, the rate R n ≤ R(σ 2 , D) + n as required. For the probability of excess distortion, we have\ne(f n , ϕ n , σ 2 , D) = P 1 n\nThe ﬁrst inequality is by the deﬁnition of U n and the union bound. The second is an application of the upper bound of Cram´er\u2019s theorem [12] applied to the χ 2 1 -random variables X 2 i /σ 2 . Now note from Taylor\u2019s theorem that e 2 n −1−2 n = 2 2 n + o( 2 n ). Taking the logarithm, normalizing by n 2 n and taking the upper limit of (35) yields the desired result in (31).\nWe now turn our attention to the converse. The gist of the proof follows from the converse in [3] but, as we shall see, the error probability analysis is more intricate. Fix codes of rates R n = 1 n log f n ≤ R(σ 2 , D) + n . Let the repro- duction sequences be denoted as ˆ x n (m), m ∈ M n . Also, let A n := ∪ m∈M n B n (ˆ x n (m),\nD) where B n (c n , r) is the n-dimensional ball centered at c n with radius r. Now, let γ n > 0 be such that Vol(B n (0, γ n )) = Vol(A n ). Clearly, Vol(A n ) ≤ |M n | Vol(B n (0,\nVol(A n ) Vol(B n (0,\nVol(B n (0, γ n )) Vol(B n (0,\nNow deﬁne the random variables Y i := X 2 i /σ 2 and note that the Y i \u2019s are χ 2 1 -distributed. With this notation, and using (36),\ne(f n , ϕ n , σ 2 , D) ≥ P 1 n\nRecall that for the χ 2 1 -distribution, the cumulant generating function is Λ(θ) = − 1 2 log(1 − 2θ) and the rate function is I(y) = max θ {θy − Λ(θ)} = 1 2 (y − 1) − 1 2 log y. Furthermore, θ ∗ (y) := 1 2 (1− 1 y ) is the maximizer. Using the standard change of measure technique for the lower bound in Cram´er\u2019s theorem (see proof of [12, Theorem 2.2.3]),\ne(f n , ϕ n , σ 2 , D) ≥ β n exp −nI(e 2 n ) − n 2\nwhere β n := P( 1 n n i=1 ˜ Y i ∈ (e 2 n , e 2 n + τ n )) and τ n is a sequence to be chosen. The random variables ˜ Y i have (tilted) distribution q(˜ y) := exp[θ ∗ (e 2 n )˜ y − Λ(θ ∗ (e 2 n ))]p(˜ y) where\np( · ) is the χ 2 1 distribution of the Y i \u2019s. By the choice of q( · ), E q [ ˜ Y i ] = e 2 n . Put τ n := ζ n for some small ζ > 0. Then,\n˜ Y i ≤ e 2 n +P 1 n\n≤ 1 2\n= 1 2\nwhere in the second inequality, we applied the Berry-Ess´een theorem to the ﬁrst term (the third moment of ˜ Y i is 15e −7 n ) and Chebyshev\u2019s inequality to the second. By (30), β n → 1 2 from below. With this choice of τ n , for n sufﬁciently large,\ne(f n , ϕ n , σ 2 , D) ≥ 1 4\nbecause I(e 2 n ) = 2 n +o( 2 n ) and 1−e −2 n = 2 n +o( n ). The converse in (32) follows by taking the logarithm, normalizing by n 2 n , taking n → ∞, and ﬁnally taking ζ → 0.\nThe MD setting for the probability of correct decoding of Gaussian sources can also analyzed analogously:\nTheorem 6. Let n be any positive sequence satisfying (30). There exists a rate-distortion code {(f n , ϕ n )} n∈N with rates\nFurthermore, every rate-distortion code {(f n , ϕ n )} n∈N with rates 1 n log f n ≥ R(σ 2 , D) − n must satisfy\nIn this paper, we analyzed the MD regime for lossy source coding. In analogy to (2), we showed for discrete sources that\nand for Gaussian sources the RHS of (40) is equal to −1 independent of σ 2 and D. As in [8]\u2013[11], this reveals that the fundamental nature of the dispersion in the lossy source coding context. There are at least three avenues for future research: (i) Can the results be applied to, for instance, general sources as in [4]? (ii) Can similar analysis of the MD setting be applied to lossy source coding problems with side information, e.g., the Wyner-Ziv problem? (iii) What is the exact relationship between the MD and CLT regimes cf. [14]?\nProof: The rate-distortion function is uniformly continu- ous. Speciﬁcally, R(Q, D)−R(P, D) = O( Q−P 1 log Q− P 1 ) [23]. Also, min Q∈P n (X ) Q − P 1 ≤ |X |/n for any P ∈ P(X ) [12, Lemma 2.1.2] so min Q∈P n (X ) R(Q, D) − R(P, D) = O( log n n ) which is asymptotically dominated by\n= ω(( log n n ) 1/2 ). Thus, there exist n-types in the regular- closed set {Q ∈ P(X ) : R(Q, D) − R(P, D) ≥ n }\nfor n large. Let Marton\u2019s exponent be D(Q (n) M || P ) = F (P, R(P, D) + n , D). Then, notice that\nD(Q (n) || P ) D(Q (n) M || P )\n|| P ) D(Q (n) M || P )\nThe numerator of the ﬁrst term on the RHS in (41) is O( 1 n ) because |D(Q (n) || P ) − D(Q (n) M || P )| = O( Q (n) − Q (n) M 1 ) and Q (n) −Q (n) M 1 = O( 1 n ). From Lemma 2, the denominator (Marton\u2019s exponent) scales as 2 n /(2V (P, D)) = ω( log n n ). Thus, the ﬁrst term in (41) tends to zero and the ratio of the divergence in (23) and Marton\u2019s exponent tends to one."},"refs":[{"authors":[{"name":"C. E. Shannon"}],"title":{"text":"Coding theorems for a discrete source with a ﬁdelity criterion"}},{"authors":[{"name":"K. Marton"}],"title":{"text":"Error exponent for source coding with a ﬁdelity criterion"}},{"authors":[{"name":"S. Ihara"},{"name":"M. Kubo"}],"title":{"text":"Error exponent of coding for memoryless gaussian sources with a ﬁdelity criterion"}},{"authors":[{"name":"K. Iriyama"}],"title":{"text":"Probability of error for the ﬁxed-length lossy source coding of general sources"}},{"authors":[{"name":"Y. Polyanskiy"},{"name":"H. V. Poor"},{"name":"S. Verd´u"}],"title":{"text":"Channel coding in the ﬁnite blocklength regime"}},{"authors":[{"name":"M. Hayashi"}],"title":{"text":"Information spectrum approach to second-order coding rate in channel coding"}},{"authors":[{"name":"V. Y. F. Tan"},{"name":"O. Kosut"}],"title":{"text":"On the dispersions of three network information theory problems"}},{"authors":[{"name":"A. Ingber"},{"name":"Y. Kochman"}],"title":{"text":"The dispersion of lossy source coding"}},{"authors":[{"name":"V. Kostina"},{"name":"S. Verd´u"}],"title":{"text":"Fixed-length lossy compression in the ﬁnite blocklength regime: Discrete memoryless sources"}},{"authors":[],"title":{"text":"Fixed-length lossy compression in the ﬁnite blocklength regime: Gaussian source"}},{"authors":[{"name":"I. Kontoyiannis"}],"title":{"text":"Pointwise Redundancy in Lossy Data Compression and Universal Lossy Data Compression"}},{"authors":[{"name":"A. Demb"},{"name":"O. Zeitoun"}],"title":{"text":"Large Deviations Techniques and Applica- tions , 2nd ed"}},{"authors":[{"name":"Y. Altug"},{"name":"A. B. Wagner"}],"title":{"text":"Moderate deviation analysis of channel coding: Discrete memoryless case"}},{"authors":[{"name":"Y. Polyanskiy"},{"name":"S. Verd´u"}],"title":{"text":"Channel dispersion and moderate devia- tions limits for memoryless channels"}},{"authors":[{"name":"I. Sason"}],"title":{"text":"On Reﬁned Versions of the Azuma-Hoeffding Inequality with Applications in Information Theory"}},{"authors":[{"name":"D.-K. He"},{"name":"L. A. Lastras-Monta˜no"},{"name":"E.-H. Yang"},{"name":"A. Jagmohan"},{"name":"J. Chen"}],"title":{"text":"On the redundancy of Slepian-Wolf coding"}},{"authors":[{"name":"I. Csisz´a"},{"name":"J. Korne"}],"title":{"text":"Information Theory: Coding Theorems for Discrete Memoryless Systems "}},{"authors":[{"name":"V. Y. F. Tan"},{"name":"A. Anandkumar"},{"name":"L. Tong"},{"name":"A. S. Willsky"}],"title":{"text":"A large- deviation analysis for the maximum likelihood learning of Markov tree structures"}},{"authors":[{"name":"B. Yu"},{"name":"T. P. Speed"}],"title":{"text":"A rate of convergence result for a universal d- semifaithful code"}},{"authors":[{"name":"T. Weissman"},{"name":"E. Ordentlich"},{"name":"G. Seroussi"},{"name":"S. Verdu"},{"name":"M. L. Wein- berger"}],"title":{"text":"Inequalities for the l 1 deviation of the empirical distribution"}},{"authors":[{"name":"Z. Zhang"},{"name":"E.-H. Yang"},{"name":"V. K. Wei"}],"title":{"text":"The redundancy of source coding with a ﬁdelity criterion: Known statistics"}},{"authors":[{"name":"J. L. Verger-Gaugry"}],"title":{"text":"Covering a ball with smaller equal balls in R n "}},{"authors":[{"name":"H. Palaiyanur"},{"name":"A. Sahai"}],"title":{"text":"On the uniform continuity of the rate- distortion function"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569552245.pdf"},"links":[{"id":"1569566381","weight":4},{"id":"1569566527","weight":2},{"id":"1569565383","weight":9},{"id":"1569565223","weight":2},{"id":"1569566725","weight":2},{"id":"1569565663","weight":2},{"id":"1569566385","weight":2},{"id":"1569567049","weight":2},{"id":"1569564635","weight":11},{"id":"1569565067","weight":2},{"id":"1569566875","weight":2},{"id":"1569559617","weight":9},{"id":"1569566981","weight":4},{"id":"1569566683","weight":2},{"id":"1569566227","weight":4},{"id":"1569566597","weight":2},{"id":"1569565551","weight":2},{"id":"1569566943","weight":4},{"id":"1569556029","weight":2},{"id":"1569566571","weight":2},{"id":"1569565227","weight":2},{"id":"1569564481","weight":2},{"id":"1569566415","weight":2},{"id":"1569566469","weight":6},{"id":"1569566081","weight":4},{"id":"1569565355","weight":4},{"id":"1569564469","weight":2},{"id":"1569565931","weight":6},{"id":"1569566373","weight":2},{"id":"1569551535","weight":2},{"id":"1569565461","weight":23},{"id":"1569564245","weight":2},{"id":"1569564731","weight":6},{"id":"1569564227","weight":2},{"id":"1569565837","weight":2},{"id":"1569566671","weight":2},{"id":"1569564233","weight":4},{"id":"1569563411","weight":2},{"id":"1569559541","weight":2},{"id":"1569565123","weight":6},{"id":"1569566941","weight":4},{"id":"1569565291","weight":4},{"id":"1569566821","weight":4},{"id":"1569556713","weight":2},{"id":"1569566467","weight":6},{"id":"1569565771","weight":4},{"id":"1569566903","weight":2},{"id":"1569566999","weight":9},{"id":"1569565859","weight":2},{"id":"1569566843","weight":6},{"id":"1569566579","weight":6},{"id":"1569558483","weight":2},{"id":"1569566089","weight":2},{"id":"1569565347","weight":2},{"id":"1569565455","weight":4},{"id":"1569566497","weight":2},{"id":"1569566795","weight":2},{"id":"1569566963","weight":2},{"id":"1569566709","weight":2},{"id":"1569564989","weight":6},{"id":"1569566523","weight":4},{"id":"1569565897","weight":2},{"id":"1569551763","weight":2},{"id":"1569566269","weight":2},{"id":"1569564189","weight":2},{"id":"1569564613","weight":4},{"id":"1569566095","weight":9},{"id":"1569565907","weight":2},{"id":"1569566167","weight":2},{"id":"1569563981","weight":11},{"id":"1569561085","weight":2},{"id":"1569566419","weight":2},{"id":"1569559565","weight":2},{"id":"1569566905","weight":11},{"id":"1569566753","weight":2},{"id":"1569566311","weight":2},{"id":"1569558681","weight":4},{"id":"1569565213","weight":2},{"id":"1569565841","weight":2},{"id":"1569566531","weight":2},{"id":"1569567665","weight":6},{"id":"1569561143","weight":13},{"id":"1569565833","weight":2},{"id":"1569566325","weight":2},{"id":"1569567015","weight":2},{"id":"1569566437","weight":16},{"id":"1569553909","weight":4},{"id":"1569566939","weight":4},{"id":"1569553537","weight":2},{"id":"1569565427","weight":2},{"id":"1569565915","weight":2},{"id":"1569552251","weight":34},{"id":"1569553519","weight":9},{"id":"1569554881","weight":4},{"id":"1569554971","weight":2},{"id":"1569566209","weight":2},{"id":"1569562821","weight":2},{"id":"1569565559","weight":4},{"id":"1569566909","weight":2},{"id":"1569565151","weight":2},{"id":"1569564333","weight":2},{"id":"1569566913","weight":2},{"id":"1569566809","weight":4},{"id":"1569566629","weight":13},{"id":"1569563897","weight":2},{"id":"1569566721","weight":2},{"id":"1569565055","weight":2},{"id":"1569555879","weight":4},{"id":"1569565219","weight":4},{"id":"1569558509","weight":2},{"id":"1569564851","weight":2},{"id":"1569566037","weight":4},{"id":"1569566553","weight":4},{"id":"1569566043","weight":2},{"id":"1569565357","weight":2},{"id":"1569561245","weight":2},{"id":"1569566505","weight":4},{"id":"1569565393","weight":2},{"id":"1569562207","weight":2},{"id":"1569567033","weight":9},{"id":"1569566603","weight":4},{"id":"1569565467","weight":4},{"id":"1569567235","weight":2},{"id":"1569565441","weight":2},{"id":"1569566233","weight":4},{"id":"1569566297","weight":2},{"id":"1569560997","weight":4},{"id":"1569560503","weight":6},{"id":"1569565463","weight":4},{"id":"1569565439","weight":9},{"id":"1569566133","weight":2},{"id":"1569562551","weight":11},{"id":"1569563395","weight":4},{"id":"1569566901","weight":4},{"id":"1569551347","weight":27},{"id":"1569565415","weight":4},{"id":"1569555367","weight":2},{"id":"1569566383","weight":2},{"id":"1569565571","weight":6},{"id":"1569565885","weight":2},{"id":"1569564411","weight":2},{"id":"1569566805","weight":2},{"id":"1569565665","weight":9},{"id":"1569566983","weight":4},{"id":"1569566779","weight":2},{"id":"1569566479","weight":2},{"id":"1569565397","weight":2},{"id":"1569566873","weight":4},{"id":"1569565765","weight":2},{"id":"1569565435","weight":6},{"id":"1569565093","weight":4},{"id":"1569565919","weight":4},{"id":"1569565181","weight":2},{"id":"1569566711","weight":2},{"id":"1569565865","weight":4},{"id":"1569566887","weight":2},{"id":"1569566267","weight":11},{"id":"1569565511","weight":2},{"id":"1569566917","weight":2},{"id":"1569566253","weight":2},{"id":"1569565421","weight":2},{"id":"1569566651","weight":2},{"id":"1569566595","weight":6},{"id":"1569566137","weight":2},{"id":"1569565013","weight":2},{"id":"1569565375","weight":2},{"id":"1569566639","weight":2},{"id":"1569566819","weight":2},{"id":"1569565541","weight":2},{"id":"1569566813","weight":2},{"id":"1569565293","weight":2},{"id":"1569566641","weight":6},{"id":"1569559035","weight":2},{"id":"1569563975","weight":2},{"id":"1569551905","weight":11},{"id":"1569565457","weight":2},{"id":"1569564787","weight":2},{"id":"1569565529","weight":2},{"id":"1569556759","weight":4},{"id":"1569566619","weight":4},{"id":"1569565271","weight":2},{"id":"1569561185","weight":11},{"id":"1569566397","weight":2},{"id":"1569558779","weight":6},{"id":"1569560235","weight":2},{"id":"1569566817","weight":4},{"id":"1569564923","weight":4},{"id":"1569566299","weight":4},{"id":"1569564281","weight":4},{"id":"1569566171","weight":2},{"id":"1569565805","weight":2},{"id":"1569563919","weight":4},{"id":"1569566577","weight":4},{"id":"1569557851","weight":6},{"id":"1569567691","weight":2},{"id":"1569565389","weight":4},{"id":"1569559919","weight":2},{"id":"1569566147","weight":9},{"id":"1569565537","weight":2},{"id":"1569562367","weight":2},{"id":"1569566457","weight":2},{"id":"1569555891","weight":2},{"id":"1569559597","weight":2},{"id":"1569564961","weight":2},{"id":"1569567013","weight":2},{"id":"1569565337","weight":2},{"id":"1569564253","weight":4},{"id":"1569560459","weight":2},{"id":"1569566807","weight":2},{"id":"1569565853","weight":2},{"id":"1569550425","weight":2},{"id":"1569566341","weight":2},{"id":"1569565889","weight":9},{"id":"1569563725","weight":2},{"id":"1569564505","weight":2},{"id":"1569565165","weight":2},{"id":"1569565113","weight":2},{"id":"1569566375","weight":23},{"id":"1569564257","weight":4},{"id":"1569566555","weight":2},{"id":"1569564931","weight":2},{"id":"1569564141","weight":9},{"id":"1569561579","weight":6},{"id":"1569566987","weight":2},{"id":"1569565031","weight":2},{"id":"1569564509","weight":4},{"id":"1569551751","weight":2},{"id":"1569564419","weight":4},{"id":"1569566067","weight":11},{"id":"1569566825","weight":2},{"id":"1569564807","weight":2},{"id":"1569563007","weight":2},{"id":"1569566113","weight":6},{"id":"1569566443","weight":6},{"id":"1569566417","weight":2},{"id":"1569560581","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S6.T1.3","endtime":"12:30","authors":"Vincent Tan","date":"1341317400000","papertitle":"Moderate-Deviations of Lossy Source Coding for Discrete and Gaussian Sources","starttime":"12:10","session":"S6.T1: Finite Blocklength Analysis for Source Coding","room":"Kresge Rehearsal B (030)","paperid":"1569552245"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
