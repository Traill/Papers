{"id":"1569566933","paper":{"title":{"text":"Key Agreement over Gaussian Wiretap Models with Known Interference at the Transmitter"},"authors":[{"name":"Ali Zibaeenejad"}],"abstr":{"text":"Abstract\u2014We investigate the (forward) key capacity of a Gaussian state-dependent wiretap channel (G-SWC) paralleled with a public channel having capacity C P ∈ [0, ∞). This model consists of a sender, a main receiver, and a wiretapper. The channel state information (CSI) is an additive white Gaussian interference (AWGI) which is non-causally known at the sender. A lower bound (LB) on the key capacity is achieved by using a generalized version of the dirty paper coding (DPC) in which the transmitted signal is correlated with the interference. The correlation coefﬁcient is to be determined by C P . The achievable scheme is asymptotically optimum as C P → ∞. This optimum key capacity is also asymptotically achievable for any C P ≥ 0 in high signal to interference ratio (SIR) regime. In this regime, the public channel has negligible contribution in key generation. Generally, the CSI enhances the key capacity such that it exceeds the main channel capacity of the G-SWC in low SIR regime."},"body":{"text":"In a wireless network, key agreement [1] between intended nodes is a challenging problem as propagated signals are accessible by unauthorized antennas. Using the wiretap coding strategy [2], the key agreement problem was formulated by Maurer [1] as well as Ahlswede and Csisz´ar [3] for a discrete memoryless\n(DM) channel-type model which consists of a DM wiretap channel and a parallel public channel [1]. Ahlswede and Csisz´ar [3] proved that the forward key capacity [3] of the DM channel-type model equals the secrecy capacity [2] of its wiretap channel, and thus the public channel is useless.\nThe key agreement problem from correlated Gaussian sources is studied in [4], [5]. In [4], a two-way public channel with unlimited capacity and rate limited quantization at the sources are modeled; while in [5], a rate limited public communication is considered, and the forward key capacity is calculated as a function of the public channel capacity.\nThe key agreement problem over a discrete memoryless state-dependent wiretap channel (DM-SWC) with non-causal channel state information (CSI) at the transmitter (Alice) was studied in [6]\u2013[10]. Zibaeenejad [9] assumed a discrete memoryless (DM) model in which the DM-SWC is parallel\ncapacity C P ∈ [0, ∞). He [9] investigated the (forward) key capacity of the DM model as a function of C P , i.e., C K (C P ). The author [9] established a lower bound (LB) and an upper bound (UB) on C K (C P ), where the LB is asymptotically tight as C P → ∞; further, for any DM-SWC there exists a ﬁnite capacity C ∗ P such that C K (C P ) = C K ( ∞) for C P ≥ C ∗ P .\nIn this paper, we study the key agreement problem over a Gaussian model: A Gaussian state-dependent wiretap channel (G-SWC) paralleled with a one-way public channel. Following [11], [12], the CSI is assumed to be an additive white Gaussian interference (AWGI), which is non-causally known at Alice. We explore the key capacity as a function of C P , i.e., C K (C P ).\nIn this paper, we examine if the results of the DM model [9] can be extended to the Gaussian model. In the DM model, the strong typicality [13, Sec. 10.6] is applied to the achievable coding scheme. However, this typicality is not valid for continuous signals. Hence, we require to use the generalized version of Markov lemma [14], which is only valid for Gaussian distributions based on weak typicality [13, Sec. 3.1]. Further, as alphabets of the CSI and auxiliary random variables (RVs) are ﬁnite in the DM model, the proofs of the LB and UB of the DM model have to be retreated for the Gaussian model.\nWe develop a novel achievable coding scheme in which the key is generated based on a random (vector) quantization of the interference at Alice. As C P grows, a ﬁner quantization at Alice improves the key capacity. For the key agreement, the interference can be helpful, and so our strategy is to enhance the additive interference of Bob\u2019s received signal through the transmitted signal (subject to the model parameters) such that the achievable key rate is maximized. Hence, we exploit a generalized version of the dirty paper coding (DPC) [11] in which correlation coefﬁcient between the transmitted signal and the interference is ρ. ρ is an increasing function of C P . When C P → ∞, C K ( ∞) is asymptotically achievable by an amplify-forward coding scheme in which the transmitter ampliﬁes the interference according to its maximum available power and forwards it to the channel, i.e., ρ → 1. Using simulations, we also show that the LB on C K (C P ) is a strictly increasing function of C P . This fact is an essential difference between the Gaussian model and the DM model [9].\nIn an independent and parallel work to [7], we learnt that Khisti et al. [6], [8] studied the key agreement problem over the Gaussian model for two special cases: no public channel, i.e., C P = 0, and a two-way public channel with unlimited capacity. Regarding the former which is related to this paper, they achieved an LB on C K (0) when SNR at the main channel is not negative (in dB). In high SIR (and high SNR) regime, this LB coincides our result in Corollary 1 when C P = 0 is relaxed. Our achievable scheme is a generalized form of their work as it is established for any SNR/SIR and C P ∈ [0, ∞). The authors [6], [8] also derived a UB on C K (0). This UB equals C K ( ∞), which is achieved in this paper. However, they [6], [8] directly extended/calculated the results of the DM model for their Gaussian model.\nThe rest of this paper is organized as follows. In Section II, we will present the problem deﬁnitions. In Section III, we will state our main results. We will justify the sketch of the proofs in Section IV. In Section V, we will simulate and compare the results for a sample Gaussian model. In the last section, we will conclude this paper.\nN and R are reserved for the set of natural numbers and that of real numbers, respectively. A subset of R which contains its positive elements is denoted by R + . Other sets are also represented by blackboard bold letters, e.g., A. The cardinality of a set is denoted by |.|, e.g., |A|; however, |.| returns the absolute value of a real-valued argument. Deﬁne A ℓ A × . . . × A\nn is reserved for the length of block codes. Greek letters are reserved for publicly known parameters, e.g., Λ is interference power. Random variables (RVs) are represented by capital narrow Latin letters as well, e.g., X. An element of a vector is speciﬁed by its time instant shown by a subscript, e.g., X 1 . Random vectors with length n are represented by small bold Latin letters for simplicity, e.g., x = (X 1 , . . . , X n ). Super- script \u201c t\u201d above a random vector stands for its transposition.\nP {.} and are reserved for the probability (of an event) and the differential entropy function [13], respectively. Other functions are denoted by calligraphic letters, e.g., functions I, N , and E represent the mutual information, the (multivariate) normal distribution, and the expectation [13], respectively. Any other symbols will be deﬁned as they appear in the paper.\nAs depicted in Fig. 1, a Gaussian model consists of two parallel channels from Alice to Bob and Eve: A G-SWC and an (authenticated) public channel according to the following deﬁnitions.\ny = x + s + g 1 , \t (2a) z = x + s + g 2 ; \t (2b)\n( ⌈2 nR K ⌉, n) such that 2 Reliability Condition : \t lim\nP error (n) = 0 , (5a) Security Condition : \t lim\nR L (n) = 0 , \t (5b) Randomness Condition : lim\n. (6)\nThe detailed proofs can be found in [10, Sec. 3.4.2]. The sketch of the proofs is as follows. 1) The Proof of Theorem 1:\nFor any ǫ ∈ (0, 1), select real numbers Γ 0 = Γ − ǫ, γ ∈ [0, 1], and ρ ∈ (−1, 1). Let\nAlso, assume auxiliary Gaussian RV T ∼ N (0, Γ 0 − β 2 Λ) such that E(T S) = 0, where S ∼ N (0, Λ). Let\nX = T + βS , \t (12a) U = T + αS . \t (12b)\nFrom (11b) and (12), we have U = X + γS, where the correlation coefﬁcient between X and S is ρ. Also, let Y = X +S+G 1 , Z = X +S+G 2 , where both G 1 ∼ N (0, σ 2 1 )\nand G 2 ∼ N (0, σ 2 2 ) are independent of (X, S). Hence, from [13, Thm. 8.4.1], we have\nE(U 2 ) = Γ 0 + γ 2 Λ + 2ρ γ Γ 0 Λ , \t (13a) E(US) = ρ Γ 0 Λ + γΛ , \t (13b)\nE(Y 2 ) = Γ 0 + 2ρ Γ 0 Λ + Λ + σ 2 1 , \t (13c) E(UY ) = Γ 0 + ρ(1 + γ) Γ 0 Λ + γΛ , \t (13d)\nE(Z 2 ) = Γ 0 + 2ρ Γ 0 Λ + Λ + σ 2 2 , \t (13e) E(UZ) = Γ 0 + ρ(1 + γ) Γ 0 Λ + γΛ . \t (13f)\nand I(U; Z) is the same as I(U; Y ) if σ 1 is replaced by σ 2 . The key generator, encoding and decoding functions of the\nGaussian model are similar to those of the DM model [9] with the difference that the strongly typical property [13, Sec. 10.6] used in those functions is to be replaced by the weakly typical property [13, Sec. 3.1]. On the other hand, the proof of [9, Thm. 1] relies on the Markov lemma [13, Sec. 15.8.1], which is only valid for strong typicality. However, if we prove that the channel input is a Gaussian signal which satisﬁes power constraint (1), the generalized version of the Markov lemma [14], which is based on the weak typicality, guarantees the extension of the proof of [9, Thm. 1] to the Gaussian model.\nNow, we revise the achievable coding scheme of the DM model [9, Thm. 1] for the Gaussian model in this paper. Codebook C consists of N = 2 n (I(U;S)+ǫ 0 ) code- words u generated i.i.d. according to U ∼ N (0, Γ 0 + (α 2 − β 2 )Λ). The codewords are uniformly partitioned into 2 n (I(U;S)−I(U;Y )+ǫ 0 +ǫ 1 ) enumerated bins such that each bin contains 2 n (I(U;Y )−I(U;Z)−ǫ 1 +ǫ 2 ) enumerated sub-bins, where 0 < ǫ 2 < ǫ < ǫ 1 < ǫ 0 < 1.\nA revealed vector s is ǫ-weakly typical [13, Sec. 3.1] with high probability if n ≥ n 0 (ǫ). Hence [10, Appendix B]\n| 1 n ss t − Λ| ≤ ǫ \u2032 , \t (16) where ǫ \u2032 = 2 ln(2)Λ ǫ. Having s, ˜ u is selected randomly from sequences u ∈ C such that (u, s) is ǫ-weakly typical for n ≥ n 1 (ǫ). This typicality leads to [10, Appendix B]\nOnce codeword ˜ u is selected, the index of its bin is sent over the public channel, and the index of its sub-bin (within the bin) is kept as key K. Also, signal x is generated by\nx = t + βs = ˜ u + γs , \t (18) where (18) follows from (11b). From equations (12) and (18), we conclude that x is an i.i.d. Gaussian vector according to X ∼ N (0, Γ 0 ) as ˜ u and s are i.i.d. Gaussian vectors. Further, x is 2ǫ −weakly typical with high probability for n ≥ n 1 (ǫ), and [10, Appendix B]\n| 1 n xx t − Γ 0 | ≤ ǫ \u2032\u2032\u2032 \t (19) where ǫ \u2032\u2032\u2032 = 2 ln(2)Γ 0 ǫ. Because Γ 0 = Γ −ǫ, power constraint (1) is met due to (19). From equations (11), (16), (17), and (18), we also have\n| 1 n xs t − ρ Γ 0 Λ | ≤ ǫ \u2032\u2032\u2032 , \t (20) which shows an essential difference between our strategy with that of [11] in which x and s are asymptotically orthogonal.\nNow, the proof of [9, Thm. 1] can be applied to the Gaussian model.\nThe security condition (5b) can be also justiﬁed as follows. At the end of the transmissions, both Alice and Bob know the bin index of ˜ u . Now, the bin can be considered as a Gaussian wiretap codebook, which is designed for a Gaussian wiretap channel with no interference [15], with 2 n (I(U;Y )−ǫ 1 ) codewords. Hence, (5b) can be concluded from [15].\nLet γ = 1 and ρ = 1 − δ, where δ ∈ (0, 1). Then, (1, 1 − δ) ∈ O(C P ) holds only if condition\n(21) is met. To satisfy this condition, select C P large enough such that condition (21) is met for any given δ ∈ (0, 1). In other words, (1, 1 − δ) ∈ O(C P ) with δ → 0 as C P → ∞. Hence,\n1 ) σ 2 1 (Γ + Λ + 2(1 − δ)\n2 ) is an achievable key rate according to equation (7).\nb) The Converse Part: Let i ∈ {1, . . . , n} be the time instant and Υ i E((X i + S i ) 2 ). First, let state the following lemma which is proved in [10, Lem. 3.5].\n1 n\n\u2022 (23) follows from [9, Eq. 29], which is also valid for the Gaussian model, where U i = (K, W i ) and W i = ((Y 1 , . . . , Y i ), (Z i +1 , . . . , Z n ), P );\n\u2022 (24) follows from Markov chain W i → U i → (X i , S i ) → Y i → Z i and data processing inequality [13, Thm. 2.8.1];\n1 ) and G 2i ∼ N (0, σ 2 2 ) are independent from (X i , S i );\n[13]; also, the forward key capacity is unchanged if Eve receives a physically degraded version of Bob\u2019s signal Z i = Y i + G \u2032 i (similar to [13, Sec. 15.1.3]), where G \u2032 i is independent of Y i such that G \u2032 i ∼ N (0, σ 2 2 − σ 2 1 );\nlog(2πe(σ 2 2 − σ 2 1 )) [13, Thm. 8.4.1]; it also follows from (Y i ) ≤ 1 2 log(2πe E(Y 2 i )) due to [13, Thm. 8.6.5] with the equality when Y i ∼ N (0, E(Y 2 i ));\n\u2022 (29) holds by applying Jensen\u2019s inequality [13, Thm. 2.6.2] and using Lemma 1 for some −1 ≤ ρ ≤ 1;\nHence, the UB is proved as equation (29) is an increasing function of ρ provided σ 2 2 ≥ σ 2 1 .\n= 0.4. In our simulations σ 2 1 , σ 2 2 , Λ are ﬁxed, and the desired plots are sketched as a function of SIR, i.e., ( Γ Λ ) dB .\n\u2022 Fig. 2: Recalling Theorem 1, the LB on C K (C P ) is simulated in this ﬁgure for 5 different values of C P . The UB on the key capacity is also sketched in this ﬁgure according to Theorem 2. This UB is the maximum achievable key capacity over the Gaussian model for a given G-SWC which acquires for C P → ∞. According to this simulation, inequality\n(30) holds for any SIR. When Γ Λ = 1, we have R K (0) = .9478 and C K ( ∞) = .9491. Hence, we observe that R K (0) is just .137% less than C K ( ∞), which is the maximum achievable key capacity for the given G-SWC. This difference is even less for other values of C P according to equation (30). Moreover, |R K (0) − C K ( ∞)| → 0 as Γ Λ → ∞. In other words, the LB on C K (C P ) for any C P ≥ 0 asymptotically achieves\nThis fact is established in Corollary 1. Hence, the public channel has negligible contribution in key generation in high SIR regime.\n\u2022 Fig. 3: Assume the Gaussian model with C P = 0 (the G-SWC alone). In this ﬁgure, we compare the (ordinary) capacity of the main channel [11] ( C M ), the known LB on the secrecy capacity [12] ( R S ), and the LB on the key capacity given in Theorem 1 ( R K (0)). As it is illustrated in this ﬁgure, R K (0) exceeds the ordinary capacity of the G-SWC when ( Γ Λ ) dB < −8.5 dB. In this region, this means that R S ≤ C S ≤ C M < R K (0) ≤ C K (0) , where R S , C S , and C M\nare the LB on the secrecy capacity, the secrecy capacity and the main channel capacity of the G-SWC, respectively. In other words, the key capacity in low SIR regime is generally greater\nthan both the main channel capacity and the secrecy capacity as it can be generated with assistance of the interference.\n\u2022 Fig. 4 and Fig. 5: Assume (γ ∗ , ρ ∗ ) is the optimum value of pair (γ, ρ) in the sense that the supremum of equation (8) is obtained. Fig. 4 and Fig. 5 exhibit γ ∗ and ρ ∗ versus SIR, respectively, for 6 values of C P . According to these ﬁgures, both γ ∗ and ρ ∗ are increasing functions of C P for any SIR. Moreover, both γ ∗ and ρ ∗ are increasing functions of SIR ( Γ Λ ) for any C P ≥ 0, i.e., lim\nWe have shown that the positive effect of the interference on the key capacity is generally more than that of the secrecy capacity, because the interference, which is independent of messages in a secrecy problem, is a valuable resource in key generation. Hence, the key capacity of a Gaussian wiretap channel with interference is generally larger than its secrecy capacity. As C P grows, contribution of the interference in key generation is intensiﬁed specially in low SIR regime because a ﬁner quantization of the interference, which enhances the forward key capacity, can be applied."},"refs":[{"authors":[{"name":"U. Maurer"}],"title":{"text":"Secret key agreement by public discussion from common information"}},{"authors":[{"name":"A. D. Wyner"}],"title":{"text":"The wire-tap channel"}},{"authors":[{"name":"R. Ahlswede"},{"name":"I. Csisz´ar"}],"title":{"text":"Common randomness in information theory and cryptography \u2014 Part I: Secret sharing"}},{"authors":[{"name":"S. Nitinawarat"}],"title":{"text":"Secret key generation for correlated Gaussian sources"}},{"authors":[{"name":"S. Watanabe"},{"name":"Y. Oohama"}],"title":{"text":"Secret key agreement from vector Gaussian sources by rate limited public communication"}},{"authors":[{"name":"A. Khisti"}],"title":{"text":"Secret key agreement on wiretap channel with transmitter side information"}},{"authors":[{"name":"A. Zibaeenejad"},{"name":"A. K. Khandani"}],"title":{"text":"State-dependent wiretap models with side information"}},{"authors":[{"name":"A. Khisti"},{"name":"S. Diggavi"},{"name":"G. Wornell"}],"title":{"text":"Secret-key agreement with channel state information at the transmitter"}},{"authors":[],"title":{"text":"Key agreement over wiretap models with non-causal side in- formation"}},{"authors":[{"name":"M. Costa"}],"title":{"text":"Writing on dirty paper"}},{"authors":[{"name":"C. Mitrpant"},{"name":"A. J. Han Vinck"},{"name":"Y. Luo"}],"title":{"text":"An achievable region for the Gaussian wiretap channel with side information"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of information theory , 2nd ed"}},{"authors":[{"name":"Y. Oohama"}],"title":{"text":"The rate-distortion function for the quadratic Gaussian CEO problem"}},{"authors":[{"name":"S. K. Leung-Yan-Cheong"},{"name":"M. Hellman"}],"title":{"text":"The Gaussian wire-tap channel"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566933.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T4.2","endtime":"15:20","authors":"Ali Zibaeenejad","date":"1341500400000","papertitle":"Key Agreement over Gaussian Wiretap Models with Known Interference at the Transmitter","starttime":"15:00","session":"S13.T4: Gaussian Wiretap Channels","room":"Stratton 20 Chimneys (306)","paperid":"1569566933"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
