{"id":"1569565785","paper":{"title":{"text":"Joint Synchronization and Demodulation by Forward Filtering"},"authors":[{"name":"Murthy V. R. S. Devarakonda"},{"name":"Hans-Andrea Loeliger"}],"abstr":{"text":"Abstract\u2014In a typical receiver, symbol synchronization must be established before symbol demodulation. This paper discusses synchronization for an isolated symbol from a ﬁlter-bank type multicarrier system. It is shown that accurate symbol timing for a single multicarrier symbol can be obtained using forward- only processing. The proposed receiver computes continuous- time symbol likelihoods along with a timing metric and its time derivative. The timing metric shows a sharp concentration that is used to produce a trigger to sample the matched ﬁlter outputs. The paper proposes baseband processing using message passing algorithms derived from factor graphs. Suitable system parameters for which near-optimum synchronization is obtained are identiﬁed using computer simulations."},"body":{"text":"In a typical receiver, symbol synchronization must be es- tablished before symbol demodulation, which, in turn, must precede decoding. Synchronization is particularly challenging when isolated packets are transmitted at times unknown to the receiver. The established approaches in this case can be classiﬁed into two groups. In the ﬁrst approach, the data is pre- ceded by a preamble that enables the receiver to synchronize before demodulation. In the second approach, the whole block is ﬁrst sampled asynchronously and digitally stored, and then processed to ﬁgure out the symbol boundaries. Neither of these approaches is entirely satisfactory: the ﬁrst approach wastes transmission energy for the preamble, whereas the second approach requires much digital processing.\nIn this paper, we propose a new approach to this problem. For a suitably deﬁned multicarrier symbol format, we show that symbol synchronization (for an isolated symbol that arrives at an unknown time) can be obtained as a by-product of matched ﬁltering. The receiver in the proposed system has the general structure shown in Fig. 1: a time-invariant \u201cﬁlter\u201d produces, ﬁrst, a continuous-time likelihood vector L(t) and simultaneously, a timing signal L T 0 (t) and its derivative, from which a trigger signal is generated to sample the likelihood signal L(t) at an optimal moment. The \u201cﬁlter\u201d may be either a continuous-time analog circuit or a discrete-time digital processing unit with a free-running clock; the notation that we will use assumes the latter, but the proposed system is perfectly suitable for implementation in the former mode. Unlike OFDM, the proposed approach does not use a cyclic preﬁx, and the symbol does not need to arrive within a ﬁxed time window. For other approaches to the synchronization of multicarrier symbols see, e.g., [1] [2].\nThe paper is structured as follows. The system setup is in- troduced in Sec. II. Sec. III provides an overview of likelihood ﬁlters [3] based on linear Gaussian state-space models, mes- sage passing on Forney-style factor graphs, and puts together various ideas \u2013 in particular, localized models for pulses using glue factors \u2013 to deﬁne a framework for receiver processing. Synchronization and detection with forward processing are elaborated in Sec. IV and performance results are provided for different combinations of system parameters in Sec. V. The paper is concluded in Sec. VI. The description of the likelihood computations in Sec. III will assume some familiarity with Forney-style factor graphs as in [4].\nFig. 2 shows the system set up. The transmitter modulates an encoded block, (b 1 , . . . , b M ) ∈ {+1, −1} M , of M bits, on to binary antipodal pulses. The transmit signal is,\nwhere α m , m = 1, . . . , M are real and |α m | are known amplitudes, b m α m > 0, φ CB [j] is a complex baseband pulse, and the elementary pulses are located in adjacent frequency bands with Ω m = (m−1)Ω 0 . We assume orthogonality among the elementary pulses. We consider baseband processing, assuming perfect carrier recovery. The receiver sees a noisy version of the delayed signal: y j = φ[j − ν 0 ] + z j , where z j are i.i.d, zero mean Gaussian random variables with variance σ 2 and ν 0 is the delay unknown to the receiver. The received signal is passed through a bank of ﬁlters whose outputs are used to compute two statistics. At the outputs denoted as A , time-varying log-likelihood ratios for the symbols are produced. From the outputs denoted as B , the overall signal- to-noise log-likelihood ratio is computed which is used to detect the packet, and to provide a trigger to sample the symbol likelihoods. It is well known that the accuracy of pulse position\nestimation improves with the number of dimensions [5]. When M is sufﬁciently large, the likelihood for the received signal exhibits a sharp concentration around the ideal sampling time ν 0 . This phenomenon is fundamental to the scheme and is used to sample the bits on the ﬂy as the signal arrives and provide soft outputs (ˆ α 1 , . . . , ˆ α M ) to a decoder.\nWe are interested in computing the likelihood for a state- space model using the Forney style factor graph shown in Fig. 3 with observations y = (y 1 , . . . , y n ), and hidden state sequence X = (X 1 , . . . , X n ). While the following discussion applies to general state-space models, we restrict ourselves to autonomous (i.e., without input) linear models and Gaussian noise with scalar observations: X k = AX k−1 , S k = CX k , Y k = S k + Z k , Z k ∼ N (0, σ 2 ), where A,B, and C are matrices of suitable dimensions (our notation closely follows [4]). The graph imposes a constraint on the state vector at time n using a glue factor [3] labeled g. For example, for a pure sinusoid model, by choosing g(x n ) ∝ δ( x n − 1), the factor graph effectively models a subclass of sinusoids on the unit circle. By placing the glue factor always at the current time instance, n, we obtain a time-varying hypothesis, denoted as H(n, g). The graph represents the joint density p(y, X|H(n, g)). Using sum-product message passing, the likelihood of the observations under the hypothesis H(n, g) can be obtained as,\nwhere p(y|H(n)) is the likelihood of the unconstrained model ( g is absent), − → f X n (x n ) is the normalized forward message, − →\nµ X n (x n ), and g(x n , θ) is parametrized by θ. From (2) we note that the forward message is a sufﬁcient statistic for θ.\nWhen matrix A is non-singular, the choice of the glue factor g(x n , θ) = δ(x n − θ) completely determines the state\n( ·) E\ntrajectory. In this case, we obtain the likelihood for the known signal hypothesis. Message passing with this choice leads to many useful properties that enable us to derive algorithms with forward processing as highlighted below.\na) The known signal likelihood can be written as p(y|H(n, g)) = p(y|H(n)) − → f X n (x n = θ). By choosing different parameters θ 1 and θ 2 , likelihoods for different hypotheses, such as in a binary signaling scheme, can be obtained simultaneously using the same model.\nb) The noise only hypothesis can be obtained with θ = 0, as this implies an all zero solution for the state sequence.\nc) In some problems, the previous two results lead to like- lihood ratio computations using only forward messages because the unconstrained likelihood p(y|H(n)) cancels out. For example, the likelihood ratio between signal and noise hypotheses is − → f X n (x n = θ)/ − → f X n (x n = 0), that between two known signal hypotheses is\nX n (x n = θ 1 )/ − → f X n (x n = θ 2 ), and so on.\nd) ML parameter estimation can now be restated using (2) as θ ML = argmax θ − → f X n (θ).\ne) For a linear Gaussian model, the known signal-to-noise log-likelihood ratio is related to the inner product as (see [6] for details),\nwhere ˜ φ is the underlying known signal modeled by some glue factor parameter θ. It is important to note that, for glue factor at time n, the delay, κ, can be controlled by a suitable choice of θ. As we are going to show, this can be used to delay the computations to the end of a signal (a time-limited pulse in our case) until all energy has been received. We obtain this using forward computations and do not require the signal to be causal.\nThe description so far assumed a ﬁnite observation window. To obtain algorithms in a truly forward processing style, we introduce some approximations.\nGaussian message passing requires computation of the mean vector, − → m X n , and the covariance matrix, − → V X n . By modifying the message computations as shown in Fig. 4 for every edge X k , we introduce a \u201cforgetting\u201d with 0 < γ < 1. The update rule for the covariance matrix in this case typically has a steady state solution, V ∞ = lim n→∞ − → V X n . By using V ∞ , and by taking the lower limit of summation to X −∞ in (2), the message updates for − → m X n can be performed in the form of a stable ﬁlter. This has the effect of localizing the model to the immediate past with an exponential window, and is controlled by γ. From the likelihood ﬁlter, the two key parameters, − → m X n and V ∞ of the Gaussian message,\nare readily available for extracting various likelihoods. B. Modeling Pulses\nWe consider approximating a time-limited pulse as a sum of L sinusoids: φ[j] ≃ L\nα ℓ cos(Ω ℓ j +ψ ℓ ), − J 2 ≤ j ≤ J 2 . Many pulses of practical interest, viz. a root-raised cosine Nyquist pulse or a Gaussian pulse, are well approximated with L = 5. This decomposition can be written using a separate state-space model for each sinusoid: at time k, we have X ℓ,k = A ℓ X ℓ,k−1 , S k = L ℓ=1 C ℓ X ℓ,k . This leads to a loopy factor graph (due to the sum term). An approximation to message passing is to avoid the message iterations around the sum term (the details are omitted here). In other words, each model assumes the observations y k = C ℓ X ℓ,k + Z k (instead of y k = S k + Z k ) by ignoring the contribution from the other models. This approximation does not lead to substantial performance loss.\nWhen the pulse decomposition is combined with localized models, we obtain a bank of ﬁlters from which time-varying likelihoods can be computed. For a single pulse, LLR for a known signal-to-noise hypothesis can be written as,\nℓ is inverse of the steady state covariance matrix for the ℓ-th model.\nFor forward processing, the delay mentioned with respect to equation (3) is controlled by choosing, e.g., C ℓ = [1, 0], θ ℓ =\nα ℓ cos( Ω ℓ J 2 + ψ ℓ ), α ℓ sin( Ω ℓ J 2 + ψ ℓ ) T . The resulting LLR is depicted for two pulses in Fig. 5. The plots to the left show a transmitted RRC pulse in baseband (top) and the LLR in (4) delayed to the end of the pulse (bottom). The plots to the right correspond to another RRC pulse shifted in frequency. The optimum sampling time is at J 2 , where the models match the transmitted signals in each case.\nWhen the pulses are used in binary antipodal signaling as in (1), the LLR, L m [n], for each bit is,\nwhere the indices m = 1, . . . , M and ℓ = 1, . . . , L refer to the ℓ-th state-space model for the m-th transmit pulse, φ m . Parameters θ m,ℓ correspond to the bit hypothesis b m = +1. When the message passing approximation is combined with localized models, the uncoded BER for binary antipodal signaling (with perfect symbol timing) for a single RRC pulse is about 0.2dB worse compared to the theoretical limit. For the multicarrier system in (1), the uncoded BER suffers a further loss of about 0.3 to 0.5dB. This is due to the loss of orthogonality of the pulses arising out of the approximations.\nThe problem of receiving a single multicarrier symbol described in Section I is two fold: to detect the presence of the transmit signal, and to identify the unknown delay ν 0 to sample the matched ﬁlter outputs in Fig. 2 using forward\nprocessing. The problem of ﬁnding the best sampling time when the data is unknown (non-data aided synchronization) is equivalent to identifying the pulse position when the pulse parameters are unknown. For convenience we assume that the transmit pulse ends at time 0 and a noisy version is received with an unknown delay ν 0 . The maximum likelihood estimate of the pulse position, ν ML , can be obtained from the log-likelihood ratio of the total transmit pulse versus noise hypothesis, L T 0 [ν], with ν ML = argmax ν L T 0 [ν], and\nwhere ρ m \t (θ m,1 , . . . , θ m,L ) is the parameter vector for the hypothesis b m = +1 and the maximization is over {+ρ m , −ρ m }. The LLRs L m0 [ν, ρ m ] for individual pulses are computed by adapting (4) to each model. Sampling the bit LLRs at ν ML does not necessarily result in a well performing system unless the ML estimate is very good. In the following, we examine this from two angles. First, we examine how ν ML depends on M and the total pulse energy, E T . Second, we consider whether a reliable detection using a thresholding algorithm (for forward processing) is feasible. Throughout this section, we consider RRC pulses located in adjacent frequency bands as in (1).\ntime-varying LLR, L T 0 [ν] shows a sharp concentration around ν 0 for M > 64 as depicted in Fig. 7. These two properties can be used to achieve timing synchronization.\nWe would like to exploit the concentration depicted in Fig. 7 by sampling the bit-wise LLRs when L T 0 [ν] crosses a threshold L thr . This is shown in Fig. 8. If the threshold is low, shown as L thr 1 , an early detection occurs, resulting in the packet being dropped eventually by the receiver. The threshold can be raised, say, to L thr 2 to detect very close to ν ML , but this would increase the probability of missed detection. A feasible choice depends on the statistics of the LLR a little away from the peak, at L T 0 [ν ML − ǫ], and close to the peak, at L T 0 [ν ML ]. We introduce the term \u201cfalse detection\u201d in this context:\nDeﬁnition. False Detection. False detection is deﬁned as detecting a noisy pulse at a time outside a speciﬁed limit,\n∆ν max . Detection at time ˆ ν is classiﬁed as a false detection if |ˆ ν − ν 0 | > ∆ν max .\nFalse detects dominate the system performance and the false alarm condition (detecting a signal when none is present) is less important in this system. Two types of events contribute to false detects. Event E1 is caused by the ML timing estimation error, |ν ML − ν 0 | > ∆ν max . This error can be reduced only by increasing either M or E b or both. Event E2 is the LLR in the region away from the peak crossing the threshold as shown in Fig. 8. Another error condition is missed detections arising from L T 0 [ν ML ] falling below the threshold. A suitable operating point meets a given set of criteria for the timing error, and probabilities for false and missed detection.\nThe system parameters M , E b , and the receiver threshold L thr can be obtained as outlined below. As timing error affects sampling of the pulses placed higher up on the spectrum, we allow up to a certain phase error, θ max , in the state space model corresponding to the highest frequency, Ω max :\n|ν ML − ν 0 | ≤ ∆ν max , where ∆ν max = θ max /Ω max , (7) When M is large, the ML timing estimation error ∆ν = ν ML − ν 0 is nearly Gaussian. As an example, by choosing, ∆ν max > 4σ ∆ν , the probability of false detection (due to the timing error event E1 ) is upper bounded as, Pr {∆ν > ∆ν max } < Pr {∆ν > 4σ ∆ν } = 3.167 × 10 −5 . ∆ν max depends on M via Ω max . Table I shows design parameters for θ max = 2 degrees, and a minimum value of E b /N 0 that meets the criterion (7).\nWhen M is large, L T 0 [ν ML ] also tends to be nearly Gaus- sian. Given a probability of missed detection, p md , we can choose L thr such that\nPr {L T 0 [ν ML ] < L thr } < p md . \t (8) The above criterion is sufﬁcient because, L T 0 [ν ML ] ≥ L T 0 [ν], ∀ν. A feasible operating point (M and E b ) is one which meets (7) and (8). This implies in general a further increase in E T via either M , or E b , or both compared to the operating points given in Table I.\nWe compare the performance of two detection algorithms with the algorithm using ML position estimates. In the ﬁrst algorithm, a ﬁxed offset is added to the detected threshold to adjust for a bias:\n\u2022 Identify the time ˆ ν at which the LLR crosses a threshold: L T 0 [ˆ ν] = L thr .\n\u2022 Add a ﬁxed delay to ˆ ν: ν d = ˆ ν + ν off . ( ν off can be chosen as the mean of ν ML − ˆ ν.)\nThe second algorithm uses a ﬁrst threshold on L T 0 [ν] followed by a second threshold on the time derivative of L T 0 [ν] to locate the peak. The time derivative, dL T 0 dt , (or its discrete-time equivalent) is easily computed from the state space model: note that in equations (4) or (5), − → m X m ℓ,n is the only time- dependent quantity and its derivative can be obtained from the ﬁlter descriptions. A peak detection is feasible because L T 0 [ν] is nearly noise-free above the ﬁrst threshold.\n\u2022 Open a window (ν 1 , ν 2 ) when L T 0 stays above the threshold: L T 0 [ν] ≥ L thr , ν 1 ≤ ν ≤ ν 2 .\nTable II shows the performance for different values of M and E b /N 0 . Simulations were performed on 10, 000 samples for each set (except 1000 samples for M = 1024) The table shows the percentage of false detects, η fd , and the percentage of missed detects, η md , for each case. For η fd , false detects from both events (E1 and E2 ) are accounted for. The threshold and offset are manually ﬁxed for each set of system parameters. The algorithm \u201cTHR\u201d shows a high number of false detects, although η md reduces with either M or E b /N 0 . This method has a higher sensitivity to the choice of the offset ν off because the width of the spike gets narrower as M increases. Secondly, the threshold crossing times have a jitter. These two factors make the detection time, ν d , fall outside the allowed range more often, leading to a higher η fd . These errors are noticeable at higher values of E b /N 0 in Table II. Although improvements may be obtained by an accurate estimation of ν off , the algorithm \u201cTHRNPEAK\u201d offers a better alternative. The algorithm \u201cTHRNPEAK\u201d is less sensitive to the choice of the ﬁrst threshold and performs closer to \u201cML\u201d as M or E b /N 0 are increased. For each choice of E b /N 0 there exists a value of M above which the detection performance shows considerable improvement. Alternately, at higher values of M , even though the tolerance in (7) is tighter, a given detection performance is achieved at lower value of E b /N 0 . The uncoded BER performance due to timing errors incurs no signiﬁcant loss in this scheme and stays within the previously mentioned limits. Another observation (not shown in the table) is, the false detects are mostly dominated by the event E2 discussed before; otherwise ν d is equal to the true value ν 0 with high probability.\nWe have shown that near-optimal synchronization of iso- lated multicarrier symbols can be obtained as a by-product of matched ﬁltering. The method does not require the sub- carriers to be down-converted before sampling; however, if this is done, then the sensitivity to timing errors would signiﬁcantly reduce and operation at even lower SNRs may be feasible. Performance improvements are also possible by modulating some sub-carriers with known data. The approach of using glue factor constraints may be extended with some changes to non-binary signaling schemes as well. These are open for further work."},"refs":[{"authors":[{"name":"V. Lottici"},{"name":"M. Luise"},{"name":"C. Saccomando"},{"name":"F. Spalla"}],"title":{"text":"Non-data-aided timing recovery for ﬁlter-bank multicarrier wireless communications"}},{"authors":[{"name":"M. Carta"},{"name":"V. Lottici"},{"name":"R. Reggiannini"},{"name":"F. Cianchi"}],"title":{"text":"Receiver design for ﬁlter-bank multicarrier systems over time-frequency selective channels"}},{"authors":[{"name":"H.-A. Loeliger"},{"name":"L. Bolliger"},{"name":"C. Reller"},{"name":"S. Korl"}],"title":{"text":"Localizing, forgetting, and likelihood ﬁltering in state-space models"}},{"authors":[{"name":"H.-A. Loeliger"},{"name":"J. Dauwels"},{"name":"J. Hu"},{"name":"S. Korl"},{"name":"L. Ping"},{"name":"F. R. Kschischang"}],"title":{"text":"The factor graph approach to model-based signal processing"}},{"authors":[{"name":"J. M. Wozencraf"},{"name":"I. M. Jacob"}],"title":{"text":"Principles of Communication Engi- neering "}},{"authors":[{"name":"M. Devarakonda"}],"title":{"text":"Joint matched ﬁltering, decoding, and timing synchro- nization"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565785.pdf"},"links":[{"id":"1569565883","weight":5},{"id":"1569565867","weight":5},{"id":"1569566697","weight":5},{"id":"1569566761","weight":25},{"id":"1569565355","weight":5},{"id":"1569566999","weight":5},{"id":"1569566311","weight":5},{"id":"1569566425","weight":5},{"id":"1569564333","weight":5},{"id":"1569564677","weight":5},{"id":"1569567235","weight":20},{"id":"1569566133","weight":5},{"id":"1569559199","weight":25},{"id":"1569565665","weight":10},{"id":"1569566639","weight":5},{"id":"1569564923","weight":5},{"id":"1569566601","weight":5},{"id":"1569566797","weight":5},{"id":"1569558697","weight":10}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T7.5","endtime":"16:20","authors":"Murthy V.R.S. Devarakonda, Hans-Andrea Loeliger","date":"1341504000000","papertitle":"Joint Synchronization and Demodulation by Forward Filtering","starttime":"16:00","session":"S13.T7: Communication Systems","room":"Stratton (407)","paperid":"1569565785"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
