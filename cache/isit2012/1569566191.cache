{"id":"1569566191","paper":{"title":{"text":"The Compute-and-Forward Transform"},"authors":[{"name":"Or Ordentlich"},{"name":"Uri Erez"},{"name":"Bobak Nazer"}],"abstr":{"text":"Abstract\u2014We derive an achievable rate region for the Gaussian K-user multiple-access channel (MAC) where all users transmit codewords from a chain of nested lattices. For any set of channel coefﬁcients, this rate region contains points within a constant gap from the sum capacity boundary of the MAC. The main tool used is the recently proposed compute-and-forward framework. A new transformation of a MAC to a modulo-lattice multiple- input multiple-output (MIMO) channel is introduced based on this framework. Speciﬁcally, from one noisy linear combination of the transmitted signals the receiver attempts to decode K linearly independent equations with integer-valued coefﬁcients. While the individual rates at which these equations can be decoded are highly sensitive to the exact channel gains, their sum is always within a constant gap from the sum capacity boundary of the MAC. The transformation is then utilized for establishing the desired rate region."},"body":{"text":"transform , due to its close connection to the original compute- and-forward scheme for relay networks [8]. This technique can either be viewed as a building block for interference alignment for static channels or, more generally, as an approximately sum rate optimal multiple-access scheme that requires only a single layer of codewords.\nIn a relay network, the basic idea underlying compute-and- forward is that each relay should decode an integer combina- tion of the transmitted lattice points. The effective signal-to- noise ratio (SNR) is determined by how closely the integer coefﬁcients match the channel coefﬁcients. For the multiple- access setting with K users, the receiver should instead decode K linearly independent equations of the transmitted lattice points. Then, these equations can be solved for the lattice points transmitted by each user. This approach is connected to the integer-forcing receiver recently proposed for multiple- antenna point-to-point channels [9]. A striking phenomenon that, to the best of our knowledge, has gone unnoticed is that while the computation rate for each of the K equations is very sensitive to the exact channel gains, the sum of the rates is equal to the sum-capacity of the MAC up to a constant gap, independent of the channel gains and the SNR (see Figure 1). To achieve this sum rate, our scheme associates each of the computation rates to a speciﬁc transmitter and decodes the equations using a form of successive interference cancellation tailored to the modulo-lattice structure. Below, we develop the compute-and-forward transform within the context of a Gaussian MAC. Due to space limitations proofs are omitted and the reader is referred to [10] for the full details.\nIn this section we give some basic deﬁnitions and results that will be used in the sequel.\nwhere h = [h 1 · · · h K ] T ∈ R K is the vector of channel gains, x k ∈ R n , k = 1, · · · , K are the channel inputs, z ∈ R n is additive white Gaussian noise (AWGN) with zero mean and unit variance and y ∈ R n is the channel\u2019s output. Without loss of generality we assume all K users are subject to the\nΛ ⊆ Λ K ⊆ · · · ⊆ Λ 1 . From these lattices, we construct K codebooks, one for each user. Speciﬁcally, user k is allocated the codebook L k = Λ θ(k) ∩ V, where V is the Voronoi region of Λ and the function θ(k) : {1, . . . , K} → {1, . . . , K} maps between users and lattices. The rate of each codebook L k is R k = 1 / n log |Λ θ(k) ∩ V|.\nUser k encodes its message onto a lattice point from its codebook, t k ∈ L k . Each user also has a random 2 dither vector d k which is generated independently and uniformly over V. These dithers are made available to the decoder. The signal transmitted by user k is\nOur objective is to communicate over the MAC using the compute-and-forward scheme from [8]. To this aim, the receiver ﬁrst decodes a set of K lattice equations with linearly independent coefﬁcient vectors. Afterwards, it solves this set of equations for the transmitted lattice points. Assume the receiver is interested in decoding the lattice equation v = \t K k=1 a k t k mod Λ with coefﬁcient vector a = [a 1 · · · a K ] T ∈ Z K . Following the scheme of [8], the receiver scales the observation y by a factor β, removes the dithers, and reduces modulo Λ to get\nis effective noise. From [8], we have that z eff (h, a, β) is statistically independent of v and its effective variance 3 is\nLet θ ∗ = min k:a k =0 θ(k) be the index of the densest lattice participating in the lattice equation v. The receiver produces an estimate for v by applying to s the nearest neighbor lattice quantizer w.r.t. Λ θ ∗ ,\nLet V θ ∗ be the Voronoi region of Λ θ ∗ , and deﬁne the error probability\nThe next theorem summarizes and reformulates relevant re- sults from Sections IV.C, IV.D, and V.A of [8].\nTheorem 1: For any ǫ > 0 and n large enough there exists a chain of nested lattices Λ ⊆ Λ K ⊆ · · · ⊆ Λ 1 forming the\nare ordered with descending rates R 1 ≥ R 2 ≥ · · · ≥ R K , i.e., θ(k) = k for k = 1, . . . , K. The receiver, which sees a noisy real-valued linear combination of the transmitted codewords, begins by decoding the integer-valued linear combination v 1 = [ a 1m t m ] mod Λ which yields the highest computa- tion rate R comp ,1 . Using the compute-and-forward framework, this is possible if R 1 < R comp ,1 . Then, it proceeds to decode the equation v 2 = [ a 2m t m ] mod Λ which yields the second highest computation rate R comp ,2 . In general, t 1 participates in this equation and the condition for correct decoding of v 2 is therefore R 1 < R comp ,2 . Nevertheless, this condition can be relaxed using the ﬁrst equation v 1 that was already decoded. Speciﬁcally, after appropriate scaling of the channel\u2019s output and dithers removal, the receiver has a noisy observation\nof the desired equation v 2 . If t 1 participates in v 1 , it is possible to cancel out t 1 from the second equation by adding a scaled version of v 1 to s 2 . Namely, the re- ceiver adds r 21 v 1 to s 2 , where r 21 is an integer cho- sen such that [(a 11 + r 21 a 21 )] mod p = 0, which assures [(a 11 + r 21 a 21 )t 1 ] mod Λ = 0 for any t 1 ∈ L 1 . After reducing modΛ this yields\ns SI 2 = [v 2 + r 21 v 1 + z eff (h, a 2 )] mod Λ = [˜ v 2 + z eff (h, a 2 )] mod Λ,\nwhere t 1 does not participate in ˜ v 2 . Since the effective noise z eff (h, a 2 ) is unchanged by this process, the receiver can decode ˜ v 2 as long as R 2 < R comp ,2 . Now, the receiver can get v 2 by subtracting r 21 v 1 from ˜ v 2 and reducing modΛ. 4 The receiver decodes the remaining equations in a similar manner, i.e., before decoding the kth equation v k with computation rate R comp ,k the receiver adds to\nan integer-valued linear combination k−1 ℓ=1 r kℓ v ℓ mod Λ of the lattice equations that were already decoded. The coefﬁ- cients in the linear combination are chosen such that the effect of t 1 , . . . , t k−1 is canceled out from v k . Assuming that such coefﬁcients {r k1 , . . . , r k,k−1 } exist the receiver can decode ˜ v k = v k + k−1 ℓ=1 r kℓ v ℓ mod Λ as long as R k < R comp ,k .\nIn [10], we show that for any set of K linearly independent coefﬁcient vectors {a 1 , . . . , a K } there indeed always exist integer-valued coefﬁcients {r ij } such that in each kth decod- ing step the receiver can cancel out k−1 lattice points from the desired equation v k , using the previously decoded equations {v 1 , . . . , v k−1 }. The procedure for ﬁnding these coefﬁcients is reminiscent to the Gaussian elimination procedure of a full rank matrix. One of the basic operations in Gaussian\n.. . \t .. . \t .. .\n.. . \t .. . \t .. .\nThe next deﬁnition introduces the compute-and-forward transform of a multiple-access channel. This transform con- verts the output of a MAC into a set of K modulo Λ channels with lattice equations corrupted by effective noises. The coefﬁcient vectors of these equations are full rank.\nDeﬁnition 2: Let {a 1 , . . . , a K } be a set of optimal integer coefﬁcient vectors (see Deﬁnition 1), β 1 , . . . , β K the cor- responding optimal scaling factors, and R comp ,1 ≥ · · · ≥ R comp ,K the corresponding optimal computation rates. We deﬁne the compute-and-forward transform of the MAC with nested lattice codes as\n \n \n   \n   \n \n \n \n \nwhere we have written the channel output y, dithers d k , and lattice codewords t k as length- n row vectors. We also have\n0 − 1 2 , π = [1 2], or\nIn particular, since for any MAC the integer-valued matrix A from the compute-and-forward transform is full rank, it can always be pseudo-triangularized with at least one permutation vector π.\nTheorem 4: Consider the MAC (1). For any ǫ > 0 and n large enough there exists a chain of nested lattices Λ ⊆ Λ K ⊆ · · · ⊆ Λ 1 forming the set of codebooks L 1 , . . . , L K with rates R 1 , . . . , R K such that for all h ∈ R K , if:\n2) the integer-valued matrix from the compute-and-forward transform of the MAC (1) can be pseudo-triangularized with the permutation vector π, and the optimal computa- tion rates are R comp ,1 ≥ · · · ≥ R comp ,K ,\nthen all messages can be decoded with error probability smaller than ǫ.\nCombining Theorems 2, 3 and 4 gives the following theo- rems.\nTheorem 5: The sum rate achieved by the compute-and- forward transform has a gap of no more than K / 2 log K bits from the sum capacity of the MAC.\nTheorem 6: The DoF attained by each user in the K-user MAC under the compute-and-forward transform is 1/K for almost every h ∈ R K ."},"refs":[{"authors":[{"name":"U. Erez"},{"name":"R. Zamir"}],"title":{"text":"Achieving 1 2 log(1+ SNR ) on the AWGN channel with lattice encoding and decoding"}},{"authors":[{"name":"R. Zamir"},{"name":"S. Shamai (Shitz)"},{"name":"U. Erez"}],"title":{"text":"Nested linear/lattice codes for structured multiterminal binning"}},{"authors":[{"name":"G. Bresler"},{"name":"A. Parekh"},{"name":"D. Tse"}],"title":{"text":"The approximate capacity of the many-to-one and one-to-many Gaussian interference channels"}},{"authors":[{"name":"S. Sridharan"},{"name":"A. Jafarian"},{"name":"S. Vishwanath"},{"name":"S. A. Jafar"}],"title":{"text":"Capacity of symmetric K-user Gaussian very strong interference channels"}},{"authors":[{"name":"A. S. Motahari"},{"name":"S. O. Gharan"},{"name":"M. Maddah-Ali"},{"name":"A. K. Khan- dani"}],"title":{"text":"Real interference alignment: Exploiting the potential of single antenna systems"}},{"authors":[{"name":"O. Ordentlich"},{"name":"U. Erez"}],"title":{"text":"Interference alignment at ﬁnite SNR for time-invariant channels"}},{"authors":[{"name":"B. Rimoldi"},{"name":"R. Urbanke"}],"title":{"text":"A rate-splitting approach to the Gaussian multiple-access channel"}},{"authors":[{"name":"B. Nazer"},{"name":"M. Gastpar"}],"title":{"text":"Compute-and-forward: Harnessing inter- ference through structured codes"}},{"authors":[{"name":"J. Zhan"},{"name":"B. Nazer"},{"name":"U. Erez"},{"name":"M. Gastpar"}],"title":{"text":"Integer-forcing linear receivers"}},{"authors":[{"name":"O. Ordentlich"},{"name":"U. Erez"},{"name":"B. Nazer"}],"title":{"text":"The approximate sum capacity of the symmetric Gaussian K-user interference channel"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566191.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S17.T2.2","endtime":"15:40","authors":"Or Ordentlich, Uri Erez, Bobak Nazer","date":"1341588000000","papertitle":"The Compute-and-Forward Transform","starttime":"15:20","session":"S17.T2: Communication and Computation over Multiple Access Channels","room":"Kresge Auditorium (109)","paperid":"1569566191"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
