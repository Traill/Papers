{"id":"1569565029","paper":{"title":{"text":"Coordination via a Relay"},"authors":[{"name":"Farzin Haddadpour"},{"name":"Mohammad Hossein Yassaee"},{"name":"Amin Gohari"},{"name":"Mohammad Reza Aref"}],"abstr":{"text":"Abstract\u2014In this paper, we study the problem of coordinating two nodes which can only exchange information via a relay at limited rates. The nodes are allowed to do a two-round interactive two-way communication with the relay, after which they should be able to generate i.i.d. copies of two random variables with a given joint distribution within a vanishing total variation distance. We prove inner and outer bounds on the coordination capacity region for this problem. Our inner bound is proved using the technique of \u201coutput statistics of random binning\" that has recently been developed by Yassaee, et al."},"body":{"text":"Coordination is the problem of producing dependent random variables over a network [1]. This problem differs from traditional coding problems where the goal is to distribute explicit messages. The problem of coordination for a joint action has applications in distributed control and game theory [2], [4]. Two notions of coordination have been deﬁned in [1], namely empirical coordination and strong coordination. In empirical coordination we want the empirical joint distribution of the actions to be close to the desired distribution, whereas in the strong coordination we want the total variation distance between the joint probability distribution of the actions, and the i.i.d. copies of the given distribution to be negligibly small. In other words, the generated distribution and the i.i.d. distribution should be statistically indistinguishable. These are two different notions of coordination. In this paper we study the strong notion of coordination.\nAs discussed in [1], nodes in a network can cooperate arbitrarily without any communication if they are provided with sufﬁcient common randomness. However [1] argues that problem becomes nontrivial if the action of some of the nodes is speciﬁed by nature. We believe that this is not the only situ- ation where the problem becomes nontrivial. Consider a large network of users, connected to each other through a proxy (relay). The relay wants to make two nodes in the network to cooperate with each other while making sure they do not learn the identity of each other. Anonymity can be obtained through the proxy who can privately exchange messages with them. Since the two nodes cannot directly talk to each other (as they do not know the identity of each other), they will not be able to directly share randomness. However common randomness can be created indirectly through the relay. But the rate of this common randomness will be bounded from above by the communication rate constraints between the nodes and the relay. Furthermore creating common randomness for\nlater use may not be the optimal strategy if the ﬁnal goal is coordination. The communication links between the nodes and the relay are rate limited, and hence there may exist more economic ways of using this resource. Inspired by this discussion, we propose the following model as an attempt to understand the use of a relay in cooperation of two nodes whose actions are not speciﬁed by nature.\nAs shown in Fig. 1, we assume that there are four links between the relay (A 0 ) and the two nodes (A 1 and A 2 ). The noiseless forward links from the relay to the the ﬁrst and second nodes have rates R f 1 and R f 2 respectively. The back- ward links have rates R b 1 and R b 2 . As can be seen from the ﬁgure, the nodes use the backward links ﬁrst to communicate to the relay, after which the relay communicates back to the nodes using the forward links. The goal of the two parties is to generate i.i.d. copies of Y 1 and Y 2 jointly distributed according to a given p(y 1 , y 2 ) within a vanishing total variation distance. We don\u2019t assume any common randomness shared between A 1 and A 2 since the two nodes don\u2019t share any resources beyond private communication links with the proxy. However, private randomization is allowed at all the three nodes. Further we could have added a separate rate limited public forward link from the proxy to all the nodes, where all the bits put on this link will become available to all the parties. Adding this link would make our model to resemble the model proposed by Wyner [3] where a set of random bits were being simultaneously transmitted to two parties. However, we have excluded this from our model for simplicity.\nSince the two nodes are initially communicating at rates R b 1 and R b 2 , the nodes can use these only to generate pairwise common randomness between themselves and the proxy. Thus\none can reinterpret the model as a one-way communication problem from the relay to the two nodes in the presence of pairwise common randomness. This has been the motivation for naming R f 1 and R f 2 as forward links although they are being used in the second step of the protocol.\nIt is noteworthy that to see when R f 1 = 0 and R b 1 = ∞ our model reduces to the one considered by Cuff in [4]. If R f 1 = 0, the ﬁrst node does not receive any feedback and has to create the i.i.d. copies of Y n 1 by itself. Since R b 1 = ∞, the ﬁrst node can send Y n 1 completely to the relay. The relay is receiving R b 2 bits from the second node which can be understood as a common randomness shared between A 0 and A 2 . Thus, our problem reduces to the problem of [4]. If R f 1 = ∞, the problem reduces to a special case of the problem studied in [6]. In this case the relay is effectively coordinating with the second node because the relay can send its reconstruction of Y n 1 to the ﬁrst node using the forward link R f 1 of inﬁnite capacity. Thus this would be the problem of generating Y n 1 and Y n 2 using a two-round communication scheme when the two node share no common randomness. When R b 1 = R b 2 = ∞, the problem reduces to that of coordinating A 1 and A 2 when there are pairwise common randomness shared between (A 0 , A 1 ) and (A 0 , A 2 ) but no common randomness shared among the three. Finally when R b 1 = R b 2 = 0 the problem reduces to a problem that resembles Wyner\u2019s model [3].\nWe prove an inner and an outer bound on our model. We show that the inner and the outer bound match in certain special cases, two of which are of special interest: one is when R b 1 = R b 2 = ∞, i.e. an inﬁnite pairwise common randomness, the other is when R b 1 = R b 2 = 0, i.e. no pairwise common randomness. We show that when R b 1 = R b 2 = ∞, the capacity region is the one where R f 1 + R f 2 is greater than or equal to the mutual information between Y 1 and Y 2 . In the other extreme case both R f 1 and R f 2 have to be larger than Wyner\u2019s common information. This provides insights on the role of pairwise common randomness.\nThis paper is organized as follows: in Section II, we introduce the basic notations and deﬁnitions used in this paper. Section III contains the main results of the paper, and Section IV and V includes the proofs.\nIn this paper, we use p U A to denote the uniform distribution over the set A and p(x n ) to denote the i.i.d. pmf n i=1 p(x i ), unless otherwise stated. Also we use X S to denote (X j : j ∈ S). The total variation between two pmf\u2019s p and q on the same alphabet X , is denoted by p(x) − q(x) 1 . When a pmf itself is random, we use capital letter, e.g. P X . For simplicity of notation, we use P X ≈ Q X if E P X − Q X 1 < , where P X and Q X are random pmf\nConsider the problem of strong coordination over a network with a relay, as depicted in Figure 1. In this setting, there are\nthree nodes A 1 , A 0 and A 2 . They do not share any common randomness, but private randomization is allowed. Let M i be the private randomness at node A i . A (n, R f 1 , R b 1 , R f 2 , R b 2 ) coordination code consists of\n\u2022 Two encoders at nodes A k , k = 1, 2, that map M k to [1 : 2 nR bk ].\n\u2022 Two encoders at the relay node A 0 , that map M 0 × B 1 × B 2 to [1 : 2 nR fk ] for k = 1, 2.\n\u2022 Two decoders at nodes A k , k = 1, 2, that map M k × B k × F k to Y n k .\nDeﬁnition 1: A joint distribution q(y 1 , y 2 ) is said to be in the admissible region of the rate tuple (R f 1 , R b 1 , R f 2 , R b 2 ) if one can ﬁnd a sequence of (n, R f 1 , R b 1 , R f 2 , R b 2 ) coordina- tion codes for n = 1, 2, ... whose induced joint distributions have marginal distributions p(y n 1 , y n 2 ) that satisfy\nDeﬁnition 2: Given a joint distribution q(y 1 , y 2 ), the coor- dination rate region is the closure of the set of rate tuples (R f 1 , R b 1 , R f 2 , R b 2 ) that admit the channel q(y 1 , y 2 ).\nTheorem 1 (Inner bound): The following region forms an inner bound to the coordination rate region for q(y 1 , y 2 ): R in is the set of all non-negative rate tuples (R f 1 , R b 1 , R f 2 , R b 2 ), for which there exists p(u, v, w, y 1 , y 2 ) ∈ T in such that\nR b 1 + R f 1 + R b 2 + R f 2 ≥ I(Y 1 Y 2 ; V U W ) + I(U ; V |W ) + I(W ; Y 1 Y 2 ),\nR b 1 + R f 1 ≥ I(Y 1 Y 2 ; V W ), R b2 + R f 2 ≥ I(Y 1 Y 2 ; U W ),\nTheorem 2 (Outer bound): Take a desired distribution q(y 1 , y 2 ). Then the coordination rate region is contained in the region R out which is the closure of the set of all non- negative rate tuples (R f 1 , R b 1 , R f 2 , R b 2 ), for which there exists p(u, v, y 1 , y 2 ) ∈ T out such that\nR b 1 + R f 1 ≥ I(Y 1 Y 2 ; V ), R b 2 + R f 2 ≥ I(Y 1 Y 2 ; U ),\nT out = {p(u, v, y 1 , y 2 ) :(Y 1 , Y 2 ) ∼ q(y 1 , y 2 ), Y 2 − U − Y 1 , Y 2 − V − Y 1 ,\nCorollary 1: The inner bound and the outer bound match when R b 1 = R b 2 = ∞, both reducing to R f 2 + R f 1 ≥ I(Y 1 ; Y 2 ). This corresponds to the case of inﬁnite pairwise common randomness and has not been considered (to best of our knowledge) in the previous works. When R f 1 = ∞, the inner and outer bound reduce to R b 2 + R f 2 being greater than or equal to Wyner\u2019s common information. The inner and outer bound also match when R f 1 = 0 and R b 1 = ∞. To see this let V = Y 1 and W = cont. in the inner bound. On the other hand the optimal choice for V in the outer bound is V = Y 1 . Thus both regions reduce to the following region that matches the one given in [4].\nR b 2 + R f 2 ≥ I(Y 1 Y 2 ; U ), R f 2 ≥ I(U ; Y 1 ).\nAnother extreme case is when R b 1 = R b 2 = 0. Here we take U = V = cont. in the inner bound. It is easy to see that both the inner and outer bound reduce to R f 1 and R f 2 being greater than or equal to Wyner\u2019s common information. Comparing this case with Wyner\u2019s model, we see that an optimal strategy is to send the same message to both A 1 and A 2 (which is expected when R b 1 = R b 2 = 0). The inner and outer bound also match when Y 1 = (A, B), Y 2 = (A, C) for mutually independent random variable A, B and C.\nWe apply the techniques of [9] to prove the achievability of the theorem. We begin by a providing a summary of the lemmas we need. In the following subsection we provide the proof.\nA. Review on probability approximation via random binning [9]\nLet (X [1:T ] , Y ) be a DMCS distributed according to a joint pmf p X [1:T ] ,Y on a countably inﬁnite set T i=1 X i × Y. A distributed random binning consists of a set of random mappings B i : X n i → [1 : 2 nR i ], i ∈ [1 : T ], in which B i maps each sequence of X n i uniformly and independently to [1 : 2 nR i ]. We denote the random variable B t (X n t ) by B t . A random distributed binning induces the following random pmf on the set X n [1:T ] × Y n × T t=1 [1 : 2 nR t ],\nTheorem 3 ([9]): If for each S ⊆ [1 : T ], the following constraint holds\nWe now consider another region for which we can approx- imate a speciﬁed pmf. This region is the Slepian-Wolf region\nfor reconstructing X n [1:T ] in the presence of (B 1:T , Y n ) at the decoder. As in the achievability proof of the [7, Theorem 15.4.1], we can deﬁne a decoder with respect to any ﬁxed distributed binning. We denote the decoder by the random conditional pmf P SW (ˆ x n [1:T ] |y n , b [1:T ] ) (note that since the decoder is a function, this pmf takes only two values, 0 and 1). Now we write the Slepian-Wolf theorem in the following equivalent form. See [9] for details.\nLemma 1: If for each S ⊆ [1 : T ], the following constraint holds\nThe proof is divided into three parts. In the ﬁrst part we introduce two protocols each of which induces a pmf on a certain set of r.v.\u2019s. The ﬁrst protocol has the desired i.i.d. property on Y n 1 and Y n 2 , but leads to no concrete coding algorithm. However the second protocol is suitable for construction of a code, with one exception: the second protocol is assisted with an extra common randomness that does not really exist in the model. In the second part we ﬁnd conditions on R b 1 , R b 2 , R f 1 , R f 2 implying that these two induced distributions are almost identical. In the third part of the proof, we eliminate the extra common randomness given to the second protocol without disturbing the pmf induced on the desired random variables (Y n 1 and Y n 2 ) signiﬁcantly. This makes the second protocol useful for code construction.\nPart (1) of the proof: We deﬁne two protocols each of which induces a joint distribution on random variables that are deﬁned during the protocol.\nProtocol A. Let (W n , U n , V n , Y n 1 , Y n 2 ) be i.i.d. and dis- tributed according to p(w, v, u, y 1 , y 2 ) such that the marginal pmf of (Y 1 , Y 2 ) satisﬁes p(y 1 , y 2 ) = q(y 1 , y 2 ). Consider the following random binning:\n\u2022 To each sequence w n , assign a random bin index g 0 ∈ [1 : 2 n ˜ R 0 ].\n\u2022 We use a Slepian-Wolf decoder to recover ˆ w n 1 , ˆ v n from (g 0 , g 1 , b 1 , f 1 ), and another Slepian-Wolf decoder to re- cover ˆ w n 2 , ˆ u n from (g 0 , g 2 , b 2 , f 2 ). The rate constraints\nfor the success of these decoders will be imposed later, although these decoders can be conceived even when there is no guarantee of success.\nThe random 1 pmf induced by the random binning, denoted by P , can be expressed as follows:\nP (g 0 |w n )P (g 1 b 1 f 1 |w n v n )P (g 2 b 2 f 2 |w n u n )p(w n , v n , u n ) × P SW ( ˆ w n 1 , ˆ v n |g 0 , g 1 , b 1 , f 1 )P SW ( ˆ w n 2 , ˆ u n |g 0 , g 2 , b 2 , f 2 )×\nProtocol B. In this protocol we assume that the nodes have access to the extra common randomness (G 0 , G 1 , G 2 ) where G 0 , G 1 , G 2 are mutually independent random variables distributed uniformly over the sets [1 : 2 n ˜ R 0 ], [1 : 2 n ˜ R 1 ] and [1 : 2 n ˜ R 2 ], respectively. Now, we use the following protocol:\n\u2022 At the ﬁrst stage, the node A 1 chooses an index b 1 ∈ [1 : 2 nR b1 ] uniformly at random and sends it to the node A 0 . Also the node A 2 independently chooses an index b 2 ∈ [1 : 2 nR b2 ] uniformly at random and sends it to the node A 0 .\n\u2022 In the second stage, knowing (g 0 , g 1 , g 2 , b 1 , b 2 ), the node A 0 generates sequences (w n , v n , u n ) according to the conditional pmf P (w n , v n , u n |g 0 , g 1 , g 2 , b 1 , b 2 ) of the protocol A. Then it sends the bin indices f 1 (w n , v n ) and f 2 (w n , u n ) to the nodes A 1 and A 2 , respectively.\n\u2022 At the ﬁnal stage, the node A 1 , knowing (g 0 , g 1 , b 1 , f 1 ) uses the Slepian-Wolf decoder P SW ( ˆ w n 1 , ˆ v n |g 0 , g 1 , b 1 , f 1 ) to obtain an estimate of (w n , v n ). Then, it generates a sequence y n 1 according to p Y n |W n V n (y n 1 | ˆ w n 1 , ˆ v n ). The node A 2 proceeds in a similar way.\nThe random pmf induced by the protocol, denoted by ˆ P , factors as\np U (g [0:2] )p U (b 1 )p U (b 2 )P (w n , v n , u n , f [1:2] |g [0:2] b [1:2] )× P SW ( ˆ w n 1 , ˆ v n |g 0 , g 1 , b 1 , f 1 )P SW ( ˆ w n 2 , ˆ u n |g 0 , g 2 , b 2 , f 2 )×\nPart (2) of the proof: Sufﬁcient conditions that make the induced pmfs approximately the same : To ﬁnd the constraints that imply that the pmf ˆ P is close to the pmf P in total variation distance, we start with P and make it close to ˆ P in a few steps. The ﬁrst step is to observe that g 0 , (g 1 , b 1 ) and (g 2 , b 2 ) are the bin indices of w n , (w n , v n ) and (w n , u n ), respectively. Substituting T = 3, X 1 = W , X 2 = W V , X 3 = W U and Y = ∅ in Theorem 3, implies that if\n˜ R 0 < H(W ), ˜ R 0 + ˜ R 1 + R b\n< H(W V ), ˜ R 0 + ˜ R 2 + R b\n< H(W U ), ˜ R 0 + ˜ R 1 + ˜ R 2 + R b\n0 ≈ p U (g [0:2] )p U (b 1 )p U (b 2 ) = ˆ P (g [0:2] , b 1 , b 2 ). This implies\nThe next step is to see that for the Slepian-Wolf decoders of the ﬁrst protocol to work well, Lemma 1 requires imposing the following constraints:\n+ R f 1 ≥ H(V |W ), ˜ R 0 + ˜ R 1 + R b\n+ R f 1 ≥ H(W V ), ˜ R 2 + R b\n+ R f 2 ≥ H(U |W ), ˜ R 0 + ˜ R 2 + R b\nˆ P (g [0:2] , b 1 , b 2 , w n , v n , u n , ˆ w n 1 , ˆ v n , ˆ w n 2 , ˆ u n ) × p(y n 1 | ˆ w n 1 , ˆ v n )p(y n 2 | ˆ w n 2 , ˆ u n )\n× 1{ ˆ w n 1 = w n , ˆ v n = v n , ˆ w n 2 = w n , ˆ u n = u n } × p(y n 1 | ˆ w n 1 , ˆ v n )p(y n 2 | ˆ w n 2 , ˆ u n )\n× 1{ ˆ w n 1 = w n , ˆ v n = v n , ˆ w n 2 = w n , ˆ u n = u n } × p(y n 1 |w n 1 , v n )p(y n 2 |w n 2 , u n ).\nIn particular, the marginal pmf of (Y n 1 , Y n 2 ) of the RHS of this expression is equal to p(y n 1 , y n 2 ) which is the desired pmf.\nPart (3) of the proof: In the protocol we assumed that the nodes have access to an external randomness G [0:2] which is not present in the model. Nevertheless, we can assume that\nthe nodes agree on an instance g [0:2] of G [0:2] . In this case, the induced pmf ˆ P (y n 1 , y n 2 ) changes to the conditional pmf\n, y n 2 |g [0:2] ). But if G [0:2] is independent of (Y n 1 , Y n 2 ), then the conditional pmf ˆ P (y n 1 , y n 2 |g [0:2] ) is also close to the desired distribution. To obtain the independence, we again use Theorem 3. Substituting T = 3, X 1 = W , X 2 = W V , X 3 = W U and Y = Y 1 Y 2 in Theorem 3, asserts that if\n˜ R 0 + ˜ R 1 < H(W V |Y 1 Y 2 ), ˜ R 0 + ˜ R 2 < H(W U |Y 1 Y 2 ),\n, y n 2 ), for some van- ishing sequence (n) 2 . Using triangular inequality for total variation, we have ˆ P (y n 1 , y n 2 , g [0:2] ) (n) ≈ p U (g [0:2] )p(y n 1 , y n 2 ), where (n) = 2 i=0 (n) i . Thus, there exists a ﬁxed binning with the corresponding pmf ¯ p such that if we replace P with ¯ p in (6) and denote the resulting pmf with ˆ p, then ˆ p(y n 1 , y n 2 , g [0:2] ) (n) ≈ p U (g [0:2] )p(y n 1 , y n 2 ). Now, the second part of Lemma 2 shows that there exists an instance g [0:2]\nsuch that ˆ p(y n 1 , y n 2 |g [0:2] ) 2 (n) ≈ p(y n 1 , y n 2 ). Finally, eliminating ( ˜ R 0 , ˜ R 1 , ˜ R 2 ) from (7), (9) and (10) by using Fourier-Motzkin elimination results in the rate region (1).\nLet Q denote a uniform random variable over [1 : n] and independent of all previously deﬁned random variables. We choose single-letter auxiliary random variables as follows: U = (F 2 , B 2 , Y Q−1 1 , Q) and V = (F 1 , B 1 , Y Q−1 2 , Q). Using\nthe fact that I(B 2 ; B 1 ) = 0 that comes from the model (because A 1 and A 2 are creating these random variables at the beginning) we have:\n≥ I(F 2 ; F 1 B 1 | B 2 ) + I(B 2 ; F 1 | B 1 ) = I(F 2 B 2 ; F 1 B 1 ) ≥ I(F 2 B 2 ; Y n 1 )\n= nI(F 2 B 2 Y Q−1 1 ; Y 1,Q |Q) − ng 1 ( ), ≥ nI(F 2 B 2 Y Q−1 1 , Q; Y 1,Q )\n− ng 1 ( ) − ng 2 ( ) \t (12) = nI(U ; Y 1,Q ) − ng 1 ( ) − ng 2 ( ), \t (13)\nconverges to zero. Equations (11) and (12) hold, due to Lemma 20 and Lemma 21 of [5]. In the same way one can show that\nIn summary, we have proved that for every , any achiev- able rate tuple must belong to the set R out, deﬁned as the set of all tuples (R f 1 , R f 2 , R b 1 , R b 2 ) such that there exists p(u, v, y 1 , y 2 ) ∈ T out, for which (R f 1 , R f 2 , R b 1 , R b 2 ) satisﬁes the inequalities (13), (14) and (15) where T out, is the set of p(u, v, y 1 , y 2 ) satisfying the Markov relations as in the deﬁnition of T out and\nThe proof continues by showing that ∩ >0 R out, = R out . Note that the cardinality bounds can be proved using the standard Fenchel extension of the Caratheodory theorem [8]. This completes the proof for the converse."},"refs":[{"authors":[{"name":"P. Cuff"},{"name":"H. Permuter"},{"name":"T. M. Cover"}],"title":{"text":"Coordination capacity"}},{"authors":[{"name":"V. Anantharam"},{"name":"V. Borkar"}],"title":{"text":"Common Randomness and Distributed Control: A Counterexample"}},{"authors":[{"name":"A. Wyner"}],"title":{"text":"The Common Information of Two Dependent Random Variables"}},{"authors":[{"name":"P. Cuff"}],"title":{"text":"Communication requirements for generating correlated random variables"}},{"authors":[{"name":"P. Cuff. \u201cCommunication in networks for coordinating behavior"}],"title":{"text":"Communication in networks for coordinating behavior"}},{"authors":[{"name":"A. Gohari"},{"name":"V. Anantharam"}],"title":{"text":"Generating dependent random variables over networks"}},{"authors":[{"name":"T. M. Cover"},{"name":"J. A. Thomas"}],"title":{"text":"Elements of Information Theory"}},{"authors":[{"name":"A. El Gamal"},{"name":"Y.-H. Kim"}],"title":{"text":"Lecture notes on network information theory"}},{"authors":[{"name":"M. H. Yassaee"},{"name":"M. R. Aref"},{"name":"A. Gohari"}],"title":{"text":"Achievability proof via output statistics of random binning"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565029.pdf"},"links":[{"id":"1569566381","weight":23},{"id":"1569566485","weight":5},{"id":"1569565383","weight":5},{"id":"1569565223","weight":5},{"id":"1569566725","weight":5},{"id":"1569566385","weight":5},{"id":"1569565691","weight":5},{"id":"1569566943","weight":5},{"id":"1569566591","weight":5},{"id":"1569566415","weight":5},{"id":"1569566765","weight":5},{"id":"1569564227","weight":5},{"id":"1569563411","weight":11},{"id":"1569566941","weight":5},{"id":"1569565291","weight":5},{"id":"1569564203","weight":11},{"id":"1569556713","weight":17},{"id":"1569565859","weight":5},{"id":"1569566579","weight":5},{"id":"1569556091","weight":5},{"id":"1569565455","weight":11},{"id":"1569566709","weight":17},{"id":"1569551763","weight":11},{"id":"1569565953","weight":5},{"id":"1569564189","weight":5},{"id":"1569564647","weight":5},{"id":"1569565907","weight":5},{"id":"1569563981","weight":5},{"id":"1569566753","weight":5},{"id":"1569566063","weight":5},{"id":"1569558681","weight":5},{"id":"1569565213","weight":5},{"id":"1569566643","weight":5},{"id":"1569565833","weight":11},{"id":"1569561795","weight":5},{"id":"1569566423","weight":5},{"id":"1569553909","weight":11},{"id":"1569566939","weight":5},{"id":"1569553537","weight":11},{"id":"1569553519","weight":11},{"id":"1569566231","weight":5},{"id":"1569565655","weight":47},{"id":"1569558985","weight":5},{"id":"1569566473","weight":5},{"id":"1569566809","weight":5},{"id":"1569566257","weight":5},{"id":"1569565033","weight":17},{"id":"1569566447","weight":5},{"id":"1569565887","weight":5},{"id":"1569566721","weight":5},{"id":"1569565633","weight":5},{"id":"1569555879","weight":5},{"id":"1569566553","weight":11},{"id":"1569566043","weight":5},{"id":"1569565357","weight":5},{"id":"1569566505","weight":5},{"id":"1569565527","weight":5},{"id":"1569565363","weight":5},{"id":"1569566695","weight":5},{"id":"1569566051","weight":5},{"id":"1569566673","weight":11},{"id":"1569565441","weight":5},{"id":"1569565311","weight":5},{"id":"1569566297","weight":5},{"id":"1569566501","weight":11},{"id":"1569560503","weight":5},{"id":"1569565439","weight":5},{"id":"1569563395","weight":11},{"id":"1569565415","weight":17},{"id":"1569565397","weight":5},{"id":"1569566129","weight":5},{"id":"1569565385","weight":5},{"id":"1569565919","weight":5},{"id":"1569565181","weight":5},{"id":"1569561221","weight":11},{"id":"1569566691","weight":5},{"id":"1569566823","weight":11},{"id":"1569566237","weight":5},{"id":"1569566283","weight":5},{"id":"1569566641","weight":5},{"id":"1569564247","weight":5},{"id":"1569556759","weight":11},{"id":"1569561185","weight":11},{"id":"1569565669","weight":5},{"id":"1569565233","weight":11},{"id":"1569566299","weight":17},{"id":"1569564769","weight":11},{"id":"1569557851","weight":35},{"id":"1569565537","weight":23},{"id":"1569564961","weight":5},{"id":"1569559251","weight":5},{"id":"1569560459","weight":5},{"id":"1569566807","weight":5},{"id":"1569550425","weight":11},{"id":"1569565635","weight":64},{"id":"1569564931","weight":11},{"id":"1569551751","weight":17},{"id":"1569564419","weight":11}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S17.T4.1","endtime":"15:20","authors":"Farzin Haddadpour, Mohammad Hossein Yassaee, Amin Aminzadeh Gohari, Mohammad Reza Aref","date":"1341586800000","papertitle":"Coordination via a Relay","starttime":"15:00","session":"S17.T4: Communication Models","room":"Stratton 20 Chimneys (306)","paperid":"1569565029"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
