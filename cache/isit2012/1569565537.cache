{"id":"1569565537","paper":{"title":{"text":"On Marton\u2019s inner bound for broadcast channels"},"authors":[{"name":"Amin Gohari"},{"name":"Chandra Nair"},{"name":"Venkat Anantharam"}],"abstr":{"text":"Abstract\u2014Marton\u2019s inner bound is the best known achievable region for a general discrete memoryless broadcast channel. To compute Marton\u2019s inner bound one has to solve an optimization problem over a set of joint distributions on the input and auxiliary random variables. The optimizers turn out to be structured in many cases. Finding properties of optimizers not only results in efﬁcient evaluation of the region, but it may also help one to prove factorization of Marton\u2019s inner bound (and thus its optimality). The ﬁrst part of this paper formulates this factorization approach explicitly and states some conjectures and results along this line. The second part of this paper focuses primarily on the structure of the optimizers. This section is inspired by a new binary inequality that recently resulted in a very simple characterization of the sum-rate of Marton\u2019s inner bound for binary input broadcast channels. This prompted us to investigate whether this inequality can be extended to larger cardinality input alphabets. We show that several of the results for the binary input case do carry over for higher cardinality alphabets and we present a collection of results that help restrict the search space of probability distributions to evaluate the boundary of Marton\u2019s inner bound in the general case. We also prove a new inequality for the binary skew-symmetric broadcast channel that yields a very simple characterization of the entire Marton inner bound for this channel."},"body":{"text":"A broadcast channel [1] models a communication scenario where a single sender wishes to communicate multiple mes- sages to many receivers. A two-receiver discrete memoryless broadcast channel consists of a sender X and two receivers Y, Z . The sender maps a pair of messages M 1 , M 2 to a trans- mit sequence X n (m 1 , m 2 )( 2 X n ) and the receivers each get a noisy version Y n ( 2 Y n ), Z n ( 2 Z n ) respectively. Further |X |, |Y|, |Z| < 1 and p(y n 1 , z n |x n ) = Q n i=1 p(y i , z i |x i ) . For more details on this model and a collection of known results please refer to Chapters 5 and 8 in [2]. We also adopt most of our notation from this book.\nThe best known achievable rate region for a broadcast channel is the following inner bound due to [3]. Here we consider the private messages case.\nfor any triple of random variables (U, V, W ) such that (U, V, W ) ! X ! (Y, Z) is achievable. Further, to compute\nthis region it sufﬁces [4] to consider |W|  |X | + 4, |U|  |X |, |V|  |X |.\nIt is not known whether this region is the true capacity region since the traditional Gallager-type technique for proving converses fails to work in this case. This raises the question of whether Marton\u2019s inner bound has an alternative representation that is more amenable to analysis. For this it is important to understand properties of joint distributions p(u, v, w, x) corresponding to extreme points of Marton\u2019s inner bound. Our approach to this is twofold. In the ﬁrst part of this paper we ﬁnd sufﬁcient conditions on the optimizing distributions p(u, v, w, x) which would imply a kind of factorization of Marton\u2019s inner bound. Such a factorization would imply that Marton\u2019s region is the correct rate region. In the second part we ﬁnd necessary conditions on any optimizing p(u, v, w, x). Unfortunately the gap between these sufﬁcient and necessary conditions is still wide, but we discuss how the necessary conditions enhance our understanding of the maximizers of the expression I(U; Y ) + I(V ; Z) I(U ; V ) and may be useful in proving the factorization of Marton\u2019s inner bound.\nRemark 1. Due to page limitations we have to omit some of the proofs from this version. They can be found in the full version [5].\nThe question of whether Marton\u2019s inner bound matches one of the known outer bounds has been studied in several works recently [6], [7], [4], [8], [9]. Since we build upon these results in this work, a brief literature review is in order. It was shown in [7] that a gap exists between Marton\u2019s inner bound and the best-known outer bound [10] for the binary skew-symmetric (BSSC) broadcast channel (Fig. 1) if a certain binary inequality, (1) below, holds. A gap between the bounds was demonstrated for the BSSC in [4] without explicitly having to evaluate the inner bound. The conjectured inequality for this channel was established in [8] and hence Marton\u2019s sum-rate for BSSC was explicitly evaluated. The inequality was shown [9] to hold for all binary input broadcast channels thus giving an alternate representation to Marton\u2019s sum-rate for binary input broadcast channels.\nCorollary 1. [9] The maximum sum-rate achievable by Mar- ton\u2019s inner bound for any binary input broadcast channel is given by\nThis characterization is much simpler than that in Bound 1. Our results on the necessary conditions of an optimizer\nattempt to extend the new binary inequality to larger alphabets and to the entire rate region (rather than just the sum rate). B. Sufﬁcient conditions\nSuppose we have certain properties of p(u, v, w, x) that maximize Marton\u2019s inner bound. How can one use this to prove that Marton\u2019s inner bound is tight? The traditional Gallager-type technique requires us to consider the n-letter expression and to try to identify single-letter auxiliary random variables. If any such statement can be shown, it has to hold for n = 2 in particular. In [11], the authors studied Marton\u2019s inner bound (sum-rate) via a two-letter approach and presented an approach to test whether Marton\u2019s inner bound is indeed optimal. The crux of [11] is a certain factorization idea which if established would yield the optimality of Marton\u2019s inner bound for discrete memoryless broadcast channels. Further the authors used the same idea to show [12] an example of a class of broadcast channels where Marton\u2019s inner bound is tight and the best known outer bounds are strictly loose 1 . The converse to the capacity region of this class of broadcast channels was motivated by the factorization approach. The authors also showed that the factorization approach works if an optimizer p(u, v, w, x 1 x 2 ) for the two-letter Marton\u2019s inner bound satisﬁes certain conditions.\nIn this paper we provide more sufﬁcient conditions that imply factorization by forming a more reﬁned version of the two-letter approach [12]. Simulations conducted on randomly generated binary input broadcast channels indicate that per- haps the factorization stated below (Conjecture 1) is true; thus indicating that Marton\u2019s inner bound could be optimal. For any broadcast channel q(y, z|x), deﬁne\nNote that T (X) is a function of p(x) for a given broadcast channel. Similarly for any function 2 f (X) denote by\nthe upper concave envelope of f(X) evaluated at p(x). (Note that one can restrict the maximization to |V|  |X | by Fenchel- Caratheodory arguments.) A 2-letter broadcast channel is a\n; i.e. they can be considered as parallel non-interfering broadcast channels. For this channel the function T (X 1 , X 2 ) is deﬁned similarly as\nRemark 2. The above conjecture was not formally stated in [11] as the authors did not have enough numerical evidence at that point; however subsequently the evidence has grown enough for some of the authors to have reasonable conﬁdence in the validity of the above statement.\nIt was shown [11] that if Conjecture 1 holds then Marton\u2019s inner bound would yield the optimal sum-rate for a two- receiver discrete memoryless broadcast channel. Hence estab- lishing the veracity of the conjecture becomes an important direction in studying the optimality of Marton\u2019s inner bound.\nThe validity of Conjecture 1 was established [11] in the following three instances:\n3) In one of the components, say the ﬁrst, receiver Y 1 is more capable 3 than receiver Z 1 .\nNote that to establish the conjecture one needs to get a better handle on T (X). What inequality (1) shows is that when |X| = 2 then\nIn this work, we seek generalizations of the inequality (1) in two different directions:\n\u2022 To the entire private messages region: Maximizing I(U ; Y ) + I(V ; Z) I(U ; V ) for a given p(x) is related to the sum-rate computation of Marton\u2019s inner bound. If one is interested in the entire private messages region, one must deal with a slightly more general form and this is presented in Section I-B1.\n\u2022 Beyond binary input alphabets: The inequality (1) itself fails to hold where |X | = 3, for instance in the Blackwell channel 4 . Therefore, we attempt to establish properties of the optimizing distributions p(u, v|x) that achieve T (X), in Section III.\n1) A generalized conjecture: Much of the work in [11] focused on the sum-rate. If one is interested in proving the optimality of the entire rate-region (for the private mes- sage case) then establishing the following equivalent con- jecture would be sufﬁcient. For ↵ 1 deﬁne T ↵ (X) := max p(u,v |x) ↵I(U ; Y ) + I(V ; Z) I(U ; V ).\nRemark 3. The sufﬁciency of the conjecture in proving the optimality of Marton\u2019s inner bound follows from a 2-letter argument similar to that found in [11]. However this conjecture is not equivalent to proving the optimality of Marton\u2019s inner bound; indeed it is a stronger statement.\nA sufﬁcient condition beyond those established in [11] that imply factorization is the following: Claim 1. For some p(x 1 , x 2 ) and a product channel if we have a p(u, v|x\nand further P(X 2 = x 2 |U = u) 2 {0, 1} 8u, x 2 , then the factorization conjecture holds.\nRemark 4. The main purpose of this claim is to demonstrate that if the distributions p(u, v|x) that achieve T (X), we will refer to them as extremal distributions, satisfy certain properties, then we could employ these properties to establish the conjecture. In this paper we will establish some such properties of the extremal distributions.\nA. A conjecture for binary alphabets A natural guess for extending the inequality (1), so as to compute T\nHowever this inequality turns out to be false in general. A counterexample is presented in the full version.\nHowever the inequality is true in the following cases: 1) ↵  1: To see this let Y 0 be obtained from Y by erasing each received symbol with probability 1\n) = ↵I(U ; Y ) and I(X; Y 0 ) = ↵I(X; Y ) . Since\n1 and p(x) is such that I(X; Y ) I(X; Z) : The inequality holds since\nThe inequality in Equation (2) also holds for the binary skew-symmetric broadcast channel shown in Figure 1 (we assume p = 1 2 ); possibly the simplest channel whose capacity region is not known. The proof is presented in the full version.\nBy establishing Equation (2) for this channel, we are now able to precisely characterize Marton\u2019s inner bound region for this channel. In particular it is straightforward to see that for ↵ 1, if M represents Marton\u2019s inner bound, then\nA similar statement holds for when the roles of Y, Z are interchanged.\nBased on simulations and other evidence we propose the following conjecture.\nRemark 5. Clearly for a broadcast channel if Equation (2) holds then the conjecture holds. Even though we know that\nEquation (2) may fail at some p(x) for some channels, the conjecture states that Equation (2) holds for a sufﬁcient class of p(x) that is needed to compute the concave envelope.\n3 . To understand our approach, it is useful to have a quick recap of the proof of equation (1) for binary alphabets. The main idea behind the proof is to isolate the local maxima of the function p(u, v|x) by a perturbation argument, an extension of the ideas introduced in [4]. The following facts were established in [4]: for a ﬁxed broadcast channel q(y, z|x) to compute\n2) p(x|u, v) 2 {0, 1}, i.e. X is a function of (U, V ), say X = f (U, V ) .\nWhen X is binary, there are 16 possible functions from U, V to X. The proof [9] essentially boiled down to showing that the local maxima may only exist for the following two cases: U = X, V = ;; V = X, U = ;, leading to the terms I(X; Y ), I(X; Z) respectively. Indeed, in the proof, there were only two non-trivial cases to eliminate: these were (assume w.l.o.g. all alphabets of U, V, X are {0, 1}):\nHence we adopt the approach of eliminating classes of functions where the local maxima may exist and we present the generalizations of the AND case and the XOR cases in the next two sections.\nIn the following sections we assume that p(u, v|x) achieves T (X) and X = f(U, V ). Further we assume that q(y, z|x) > 0 8x, y, z, i.e. we are in a dense subset of channels with non- zero transition probabilities. In this case we can further assume that p(u, v) > 0 8u, v, [14].\nWe now present an extension of the AND case from the proof of the binary inequality [9]. It says that one cannot have one column and one row mapped to the same input symbol.\nTheorem 2. For any (U, V, X) such that X = f(U, V ) and p(uv |x) achieves T (X) one cannot ﬁnd x 0 , u 0 and v 0 such that f(u 0 , v) = f (u, v 0 ) = x 0 for all u 2 U and v 2 V.\nProof: Assume otherwise that f(u 0 , v) = f (u, v 0 ) = x 0 for all u 2 U and v 2 V. Consider the multiplicative perturbation q u,v,x = p u,v,x (1 + \"L u,v ) for some \" in some interval around zero. For this to be a valid perturbation, it has to preserve the marginal distribution of X, i.e. X\nwhere random variable L is deﬁned to take the value L u,v under the event that (U, V ) = (u, v). Routine calculations show that this condition can be rewritten as follows\nT x 1 ,x 2 ,v is deﬁned similarly. Equation (3) can be rewritten as X\nNow, let us deﬁne I u,v as follows: (a) I u,v = 0 when u 6= u 0 and v 6= v 0 , (b) I u 0 ,v = p u 0 ,v p v 0 when v 6= v 0 , (c) I u,v 0 =\np u,v 0 p u 0 when u 6= u 0 , and (d) I u 0 ,v 0 = p u 0 v 0 (p v 0 p u 0 ). Note that I u 0 ,v > 0 for all v 6= v 0 , and I u,v 0 < 0 for all u 6= u 0 since p u,v > 0 .\nNow, using Lemma 2 (a very similar result was used in [9]) one can see that T x 0 ,x 0 ,v p u0v0 p u0v p v0 , T x 0 ,x 0 ,v 0 1 p v0 , T x 0 ,x 0 ,u p u0v0 p uv0 p u0 and T x 0 ,x 0 ,u 0 \t 1 p u0 . Hence, observe that\nOne can verify that for our given choice of I u,v the right hand side of the equation (7) is equal to the left hand side of equation (6), i.e.\nThis implies that both equations (7) and (6) have to hold with equality for our choice of I u,v . Therefore all the inequal- ities in Lemma 2 have to hold with equality, which happens only if U is independent of Y , and V is independent of Z, i.e. I(U ; Y ) = I(V ; Z) = 0 . This is a contradiction.\nLemma 1. If there are u 1 6= u 2 such that f(u 1 , v) = f (u 2 , v) for all v 2 V, one can ﬁnd another optimizer p(u 0 , v |x), where I(U ; Y )+I(V ; Z) I(U ; V ) = I(U 0 ; Y )+I(V ; Z) I(U 0 ; V )\nand furthermore |U 0 | < |U|. A similar condition holds if one can ﬁnd v 1 6= v 2 such that f(u, v 1 ) = f (u, v 2 ) for all u 2 U.\nRemark 6. The proof can be found in the full version on arXiv. Lemma 2. Take arbitrary u 1 , u 2 , v, x such that f(u 1 , v) = x and f(u 2 , v) = x . Then any maximizing distribution must satisfy P y p 2 y |x p u2y \t p u1v p u2v p u1 . Equality implies that p y |x = p y |u 2 = p y |u 1 for all y.\nIn this section we provide an alternative proof for the binary XOR case, and its generalization to the non-binary case (another extension of the XOR case has been provided in [14]). Let U, V be binary random variables, and X = U\nDeﬁnition 1. Given p(u, x), let c p(u,x) denote the minimum value of c such that I(U; Y )  c·I(X; Y ) holds for all p(y|x) for all possible alphabets Y. Alternatively, c p(u,x) is the mini- mum value of c such that the function q(x) 7! H(U) cH(X) when p(u|x) is ﬁxed, matches its convex envelope at p(x).\nBy the data-processing inequality 0  c p(u,x)  1, and the minimum is well deﬁned.\nRemark 7. Note that here we are adopting a dual notion. We ﬁx the auxiliary channel p(u|x) and then ask for a minimizing c over all the forward channels.\nIf c p(u,x) + c p(v,x)  1 then note: I(U; Y ) + I(V ; Z)  c p(u,x) I(X; Y ) + c p(v,x) I(X; Z)  max(I(X; Y ), I(X; Z)).\nTheorem 3. For any binary U, V, X and p(u, v, x) such that X = U V it holds that c p(u,x) + c p(v,x)  1.\nwe claim that c p(u,x)  |↵ | and c p(v,x)  |↵ + 1 |. This will complete the proof since ↵, 2 [0, 1] implies\nTo show that c p(u,x)  |↵ |, it sufﬁces to show that q(x) 7! H(U ) |↵ |H(X) is convex at all q(x). The proof for c p(v,x)  |↵ + \t 1 | is similar. Note that H(U) |↵\n|H(X) = h(↵q(0) + q(1)) |↵ |h(q(0)) where h(·) is the binary entropy function. Thus, we need to look at the function x 7! h(↵x + (1 x)) |↵ |h(x) for x 2 [0, 1]. The second derivative is\nIt is not hard to verify that the above expression is non- negative, see the full version.\nWe propose a pathway for verifying the optimality of Marton\u2019s inner bound by trying to determine properties of the extremal distributions. We establish some necessary con- ditions, extending the work in the binary input case. We also add to the set of sufﬁcient conditions. We present a few conjectures whose veriﬁcations have immediate consequences for the optimality of Marton\u2019s region.\nAmin Gohari was partially supported by the Iranian Na- tional Science Foundation Grant 89003743. Chandra Nair was partially supported by the University Grants Committee of the Hong Kong Special Administrative Region, China Project No. AoE/E-02/08 and GRF Project 415810. He also acknowledges the support from the Institute of Theoretical Computer Sci- ence and Communications (ITCSC) at the Chinese University of Hong Kong. Venkat Anantharam gratefully acknowledges research support from the ARO MURI grant W911NF- 08-1- 0233, Tools for the Analysis and Design of Complex Multi- Scale Networks, from the NSF grant CNS- 0910702, from the NSF Science & Technology Center grant CCF-0939370, Science of Information, from Marvell Semiconductor Inc., and from the U.C. Discovery program."},"refs":[{"authors":[{"name":"T. Cover"}],"title":{"text":"Broadcast channels"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory"}},{"authors":[{"name":"K. Marton"}],"title":{"text":"A coding theorem for the discrete memoryless broadcast channel"}},{"authors":[{"name":"A. Gohari"},{"name":"V. Anantharam"}],"title":{"text":"Evaluation of Marton\u2019s inner bound for the general broadcast channel"}},{"authors":[{"name":"A. Gohari"},{"name":"C. Nair"},{"name":"V. Anantharam"}],"title":{"text":"On Marton\u2019s inner bound for broadcast channels"}},{"authors":[{"name":"C. Nair"},{"name":"A. El Gamal"}],"title":{"text":"An outer bound to the capacity region of the broadcast channel"}},{"authors":[{"name":"C. Nair"},{"name":"Z. V. Wang"}],"title":{"text":"On the inner and outer bounds for 2- receiver discrete memoryless broadcast channels"}},{"authors":[{"name":"V. Jog"},{"name":"C. Nair"}],"title":{"text":"An information inequality for the bssc channel"}},{"authors":[{"name":"C. Nair"},{"name":"Z. V. Wang"},{"name":"Y. Geng"}],"title":{"text":"An information inequality and evaluation of Marton\u2019s inner bound for binary input broadcast channels"}},{"authors":[{"name":"A. El Gamal"}],"title":{"text":"The capacity of a class of broadcast channels"}},{"authors":[{"name":"Y. Geng"},{"name":"A. Gohari"},{"name":"C. Nair"},{"name":"Y. Yu"}],"title":{"text":"On Marton\u2019s inner bound for two receiver broadcast channels"}},{"authors":[],"title":{"text":"The capacity region of classes of product broadcast channels"}},{"authors":[{"name":"J. K¨orner"},{"name":"K. Marton"}],"title":{"text":"Comparison of two noisy channels"}},{"authors":[{"name":"A. Gohari"},{"name":"A. El Gamal"},{"name":"V. Anantharam"}],"title":{"text":"On an outer bound and an inner bound for the general broadcast channel"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565537.pdf"},"links":[{"id":"1569566381","weight":12},{"id":"1569566485","weight":25},{"id":"1569566725","weight":6},{"id":"1569565691","weight":12},{"id":"1569566597","weight":6},{"id":"1569566943","weight":6},{"id":"1569566591","weight":6},{"id":"1569552245","weight":6},{"id":"1569564481","weight":12},{"id":"1569566415","weight":18},{"id":"1569566081","weight":18},{"id":"1569565931","weight":12},{"id":"1569565461","weight":6},{"id":"1569564203","weight":25},{"id":"1569556713","weight":6},{"id":"1569565859","weight":18},{"id":"1569558483","weight":6},{"id":"1569565347","weight":12},{"id":"1569566709","weight":18},{"id":"1569551763","weight":12},{"id":"1569565953","weight":12},{"id":"1569564189","weight":56},{"id":"1569566865","weight":6},{"id":"1569566095","weight":12},{"id":"1569565907","weight":6},{"id":"1569566239","weight":6},{"id":"1569566063","weight":6},{"id":"1569566643","weight":12},{"id":"1569561143","weight":6},{"id":"1569565833","weight":25},{"id":"1569553909","weight":6},{"id":"1569559111","weight":6},{"id":"1569566939","weight":6},{"id":"1569553537","weight":6},{"id":"1569553519","weight":12},{"id":"1569566231","weight":12},{"id":"1569554689","weight":6},{"id":"1569554881","weight":6},{"id":"1569565655","weight":18},{"id":"1569566473","weight":6},{"id":"1569566809","weight":6},{"id":"1569566629","weight":12},{"id":"1569565033","weight":6},{"id":"1569566447","weight":6},{"id":"1569565055","weight":6},{"id":"1569555879","weight":12},{"id":"1569566553","weight":6},{"id":"1569564969","weight":25},{"id":"1569566043","weight":6},{"id":"1569565029","weight":25},{"id":"1569565357","weight":6},{"id":"1569565527","weight":6},{"id":"1569565363","weight":6},{"id":"1569566695","weight":6},{"id":"1569566051","weight":6},{"id":"1569566673","weight":6},{"id":"1569565441","weight":6},{"id":"1569566297","weight":6},{"id":"1569563845","weight":6},{"id":"1569566501","weight":18},{"id":"1569566481","weight":6},{"id":"1569565463","weight":6},{"id":"1569565439","weight":18},{"id":"1569563395","weight":6},{"id":"1569565571","weight":6},{"id":"1569565665","weight":6},{"id":"1569565435","weight":6},{"id":"1569557275","weight":6},{"id":"1569565919","weight":6},{"id":"1569566711","weight":6},{"id":"1569565511","weight":12},{"id":"1569566035","weight":6},{"id":"1569566691","weight":6},{"id":"1569566547","weight":6},{"id":"1569566823","weight":6},{"id":"1569565375","weight":6},{"id":"1569566641","weight":12},{"id":"1569556759","weight":31},{"id":"1569558779","weight":6},{"id":"1569565669","weight":6},{"id":"1569565233","weight":6},{"id":"1569566817","weight":6},{"id":"1569566299","weight":18},{"id":"1569564769","weight":6},{"id":"1569557851","weight":12},{"id":"1569564961","weight":6},{"id":"1569560459","weight":6},{"id":"1569550425","weight":6},{"id":"1569565635","weight":18},{"id":"1569564931","weight":6},{"id":"1569564141","weight":18},{"id":"1569566973","weight":6},{"id":"1569551751","weight":18},{"id":"1569565139","weight":6},{"id":"1569564419","weight":31},{"id":"1569566825","weight":6},{"id":"1569565315","weight":6}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T2.1","endtime":"17:00","authors":"Amin Aminzadeh Gohari, Chandra Nair, Venkat Anantharam","date":"1341247200000","papertitle":"On Marton's inner bound for broadcast channels","starttime":"16:40","session":"S4.T2: Capacity of Broadcast Channels","room":"Kresge Auditorium (109)","paperid":"1569565537"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
