{"id":"1569566943","paper":{"title":{"text":"Nested Lattice Codes for Arbitrary Continuous Sources and Channels"},"authors":[{"name":"Aria G. Sahebi"},{"name":"S. Sandeep Pradhan"}],"abstr":{"text":"Abstract\u2014In this paper, we show that nested lattice codes achieve the capacity of arbitrary continuous channels with or without non-causal state information at the transmitter. We also show that nested lattice codes are optimal for source coding with or without non-causal side information at the receiver for arbitrary continuous sources. We show the optimality of lattice codes for the Gelfand-Pinsker and Wyner-Ziv problems in their most general settings."},"body":{"text":"Lattice codes for continuous sources and channels are the analogue of linear codes for discrete sources and channels and play an important role in information theory and communica- tions. Linear/lattice and nested linear/lattice codes have been used in many communication settings to improve upon the existing random coding bounds [2], [10]\u2013[13], [16], [18], [20].\nIn [2] and [12] the existence of lattice codes satisfying Shannon\u2019s bound has been shown. These results have been generalized and the close relation between linear and lattice codes has been pointed out in [13]. In [24], several results regarding lattice quantization noise in high resolution has been derived and the problem of constructing lattices with an arbitrary quantization noise distribution has been studied in [7].\nNested lattice codes were introduced in [26] where the concept of structured binning is presented. Nested linear/lattice codes are important because in many communication prob- lems, specially multi-terminal settings, such codes can be superior in average performance compared to random codes [11]. It has been shown in [25] that nested lattice codes are optimal for the Wyner-Ziv problem when the source and side information are jointly Gaussian. The dual problem of channel coding with state information has been addressed in [4]\u2013[6], [21] and the optimality of lattice codes for Gaussian channels has been shown. In [3], it was shown that random linear codes provide good binning schemes for general Slepian-Wolf coding.\nIn a recent work [17], it has been shown that nested linear codes are optimal for arbitrary discrete memoryless channels with state information at the transmitter. In this paper we focus on two problems: 1) The point to point channel coding with state information at the encoder (the Gelfand-Pinsker problem [8]) and 2) Lossy source coding with side information at the\ndecoder (the Winer-Ziv problem [22], [23]). We consider these two problems in their most general settings i.e. when the source and the channel are arbitrary but memoryless. We use nested lattice codes with joint typicality decoding/encoding rather than lattice decoding. We consider a lattice code en- semble with simpler random dithers and without modulo-Λ transformations as used in [25]. We show that in both settings, from an information-theoretic point of view, nested lattice codes are optimal.\nThe paper is organized as follows: in Section II we present the required preliminaries and introduce our notation. In Sec- tion III we show the optimality of nested lattice codes for chan- nels with state information (the Gelfand-Pinsker problem). We brieﬂy present the optimality of nested lattice codes for source coding with side information (the Wyner-Ziv problem) in Section IV and we conclude in Section V.\n1) Channel Model: We associate two sets X and Y with the channel as the channel input and output alphabets. The set of channel states is denoted by S and it is assumed that the channel state is distributed over S according to P S . When the state of the channel S is s ∈ S, the input-output relation of the channel is characterized by a transition kernel W Y |XS (y|x, s) for x ∈ X and y ∈ Y. We assume the state of the channel is known at the transmitter non-causally. The channel is speciﬁed by (X , Y, S, P S , W Y |XS , w) where w is the cost function.\n2) Source Model: The source is modeled as a discrete- time random process X with each sample taking values in a ﬁxed set X called alphabet. Assume X is distributed jointly with the random variable S according to the measure P XS over X × S where S is an arbitrary set. We assume that the side information S is known to the receiver non-causally. The reconstruction alphabet is denoted by U and the quality of reconstruction is measured by a single-letter distortion functions d : X × U → R + . We denote such sources by (X , S, U , P XS , d).\n3) Linear and Coset Codes Over Z p : For a prime number p, a linear code over Z p of length n and rate R = k n log p is a collection of p k codewords of length n which is closed under mod-p addition. Any such code can be characterized by its generator matrix G ∈ Z k×n p . The set of all message tuples for this code is Z k p and the set of all codewords is the range of the matrix G. The linear encoder maps a message\ntuple u ∈ Z k p to the codeword x where x = uG and the operations are done mod-p. A coset code over Z p is a shift of a linear code by a ﬁxed vector. A coset code of length n and rate R = k n log p is characterized by its generator matrix G ∈ Z k×n p and it\u2019s shift vector (dither) B ∈ Z n p . The encoding rule for the corresponding coset code is given by x = uG+B, where u is the message tuple and x is the codeword.\n4) Lattice Codes and Shifted Lattice Codes: A lattice code of length n is a collection of codewords in R n which is closed under real addition. A shifted lattice code is any translation of a lattice code by a real vector. In this paper, we use coset codes to construct (shifted) lattice codes as follows: Given a coset code C of length n over Z p and a step size γ, deﬁne Λ(C, γ, p) = γ(C − p−1 2 ). Then the corresponding mod-p lattice code ¯ Λ(C, γ, p) is the disjoint union of shifts of Λ by vectors in γp Z n . i.e. ¯ Λ(C, γ, p) =\nΛ(C, γ, p) ⊆ ¯ Λ(C, γ, p) is a scaled and shifted copy of the linear code C.\n5) Nested Linear Codes: A nested linear code consists of two linear codes, with the property than one of the codes (the inner linear code ) is a subset of the other code (the outer linear code ). For positive integers k and l, let the outer and inner codes C i and C o be linear codes over Z p characterized by their generator matrices G ∈ Z l×n p and G ∈ Z (k+l)×n p\nFurthermore, assume G = G ∆G for some ∆G ∈ Z k×n p and B = B. In this case,\nC o = aG + m∆G + B|a ∈ Z l p , m ∈ Z k p , \t (1) C i = aG + B|a ∈ Z l p \t (2)\nIt is clear that the inner code is contained in the outer code. Furthermore, the inner code induces a partition of the outer code through its shifts. For m ∈ Z k p deﬁne the mth bin of C i in C o as B m = aG + m∆G + B|a ∈ Z l p . The outer code is the disjoint union of all the bins and each bin index m ∈ Z k p is considered as a message. We denote a nested linear code by a pair ( C i , C o ).\n6) Nested Lattice Codes: Given a nested linear code (C i , C o ) over Z p and a step size γ, deﬁne\nThen the corresponding nested lattice code consists of an inner lattice code and an outer lattice code\n¯ Λ i (C i , γ, p) = ∪ v∈pZ n (γv + Λ i ) \t (5) ¯ Λ o (C o , γ, p) = ∪ v∈pZ n (γv + Λ o ) \t (6)\nIn this case as well, the inner lattice code induces a partition of the outer lattice code. For m ∈ Z k p , deﬁne B m = γ(B m − p−1 2 ) where B m is the mth bin of C i in C o . The mth bin of the inner lattice code in the outer lattice code is deﬁned by:\nThe set of messages consists of the set of all bins of ¯ Λ i in ¯ Λ o . We denote a nested lattice code by a pair ( ¯ Λ i , ¯ Λ o ).\n7) Achievability for Channel Coding: A transmission sys- tem with parameters (n, M, Γ, τ ) for reliable communication over a given channel (X , Y, S, P S , W Y |XS ) with cost function w : X → R + consists of an encoding mapping and a decoding mapping e : S n × {1, 2, . . . , M } → X n , f : Y n → {1, 2, . . . , M } such that for all m = 1, 2, . . . , M ,\nGiven a channel (X , Y, S, f S , f Y |XS ), a pair of non negative numbers (R, W ) is said to be achievable if for all > 0 and for all sufﬁciently large n, there exists a transmission system for reliable communication with parameters (n, M, Γ, τ ) such that 1 n log M ≥ R − , Γ ≤ W + and τ ≤ .\n8) Achievability for Source Coding: A transmission sys- tem with parameters (n, Θ, ∆, τ ) for compressing a given source (X , S, U , P XS , d(·)) consists of an encoding mapping e : X n → {1, 2, · · · , Θ} and a decoding mapping g : S n × {1, 2, · · · , Θ} → U n such that P (d(X n , g(e(X n ))) > ∆) ≤ τ where X n is the random vector of length n generated by the source. In this transmission system, n denotes the block length, log Θ denotes the number of channel uses, ∆ denotes the distortion level and τ denotes the probability of exceeding the distortion level ∆.\nGiven a source, a pair of non-negative real numbers (R, D) is said to be achievable if there exists for every > 0, and for all sufﬁciently large numbers n a transmission system with parameters (n, Θ, ∆, τ ) for compressing the source such that\n10) Typicality: We use the notion of weak* typicality with Prokhorov metric introduced in [14]. Let M ( R d ) be the set of probability measures on R d . For a subset A of R d deﬁne its\n-neighborhood by A = {x ∈ R d |∃y ∈ A such that x − y < } where · denotes the Euclidean norm in R d . The Prokhorov distance between two probability measures P 1 , P 2 ∈ M (R d ) is deﬁned as follows:\nConsider two random variables X and Y with joint distribution P XY (·, ·) over X × Y ⊆ R 2 . Let n be an integer and be a positive real number. For the sequence pair (x, y) belonging to X n × Y n where x = (x 1 , · · · , x n ) and y = (y 1 , · · · , y n ) deﬁne the empirical joint distribution by\n1 n\nfor Borel sets A and B. Let P x and P y be the corre- sponding marginal probability measures. It is said that the sequence x is weakly* -typical with respect to P X if π 1 (P X , P x ) < . We denote the set of all weakly* -typical sequences of length n by A n (X). Similarly, x and y are said to be jointly weakly* -typical with respect to P XY if π 2 (P xy , P XY ) < . We denote the set of all weakly* - typical sequence pairs of length n by A n (XY ). We deﬁne A n (Y |x) = {y ∈ Y n |(x, y) ∈ A n (X, Y ) }.\nWe show the achievability of the rate R = I(U ; Y ) − I(U ; S) for the Gelfand-Pinsker channel using nested lattice code for U .\nTheorem III.1. For the channel (X , Y, S, P S , W Y |XS ) where X , X , X ⊆ R, let w : X → R + be a continuous cost function. Let U be an arbitrary set and let SU XY be distributed over S × U × X × Y according to P S P U |S W X|U S W Y |SX where\nP U |S and W X|U S are such that E{w(X)} ≤ W . Then the pair (R, W ) is achievable using nested lattice codes where R = I(U ; Y ) − I(U ; S).\nIn this section we prove the theorem for the case when U = ˆ U takes values from the discrete set γ(Z p − p−1 2 ) where p is a prime and γ is a positive number. We use a random coding argument over the ensemble of mod-p lattice codes to prove the achievability. Let C o and C i be deﬁned as (1) and (2) where G is a random matrix in Z l×n p , ∆G is a random matrix in Z k×n p and B is a random vector in Z n p , all uniformly distributed over their respective domains. Deﬁne ¯ Λ i (C i , γ, p) and ¯ Λ o (C o , γ, p) accordingly. The ensemble of nested lattice codes consists of all lattices of the form (3) and (4). The set of messages consists of all bins B m indexed by m ∈ Z k p . The encoder observes the message m ∈ Z k p and the channel state s ∈ S n and looks for a vector u in the mth bin B m which is jointly weak* typical with s and encodes the message m to x according to W X|SU . The encoder declares error if it does not ﬁnd such a vector.\nAfter receiving y ∈ Y n , the decoder decodes it to m ∈ Z k p if m is the unique tuple such that the mth bin B m contains a sequence jointly typical with y. Otherwise it declares error.\n1) Encoding Error: Let S = [ −γp 2 , γp 2 ] n ∩ γZ n . For a ∈ Z k p , m ∈ Z l p , deﬁne\ng(a, m) = γ (aG + m∆G + B) − (p − 1) 2\nLemma III.2. For a ∈ Z l p and m ∈ Z k p , g(a, m) is uniformly distributed over S .\nProof: Follows from the fact that B is independent of G and ∆G and is uniformly distributed.\nLemma III.3. For a, ˜ a ∈ Z l p and m ∈ Z k p if a = ˜ a then g(a, m) and g(˜ a, m) are pairwise independent.\nFor message m ∈ Z k p and state s ∈ S n , the encoder declares error if there is no sequence in B m jointly typical with s. Deﬁne\nLemma III.4. Let P XY be a joint distribution on R 2 and P X and P Y denote its marginals. Let y be a sequence and Z n a random sequence drawn according to P n Z . If D(P XY P Z P Y ) is ﬁnite then for each δ > 0, there exist (δ) and ¯(δ) such that if < (δ), ¯ < ¯(δ) and y ∈ A n ¯ (P Y ) then\nProof: This lemma is a generalization of theorem 21 of [14]. The complete proof can be found in a more complete version of this work [19].\nLemma III.5. Let P XY be a joint distribution on R 2 and P X and P Y denote its marginals. Let y be a sequence and Z n a random sequence drawn according to P n Z . Then for each\nlim inf 1 n\nProof: This lemma is a generalization of theorem 22 of [14]. The complete proof can be found in [19].\nSimilarly, let Z n = g(a, m) and ˜ Z n = g(˜ a, m). Note that Z n and ˜ Z n are equal if a = ˜ a and are independent if a = ˜ a. We\nTherefore if l n log p > D(P ˆ U S P Z P S ) then the probability of encoding error goes to zero as the block length increases.\n2) Decoding Error: The decoder declares error if there is no bin B m containing a sequence jointly typical with the chan- nel output y or if there are multiple bins containing sequences jointly typical with y. Assume that the message m has been encoded to x according to W X|SU where u = g(a, m) and the channel state is s. The channel output y is jointly typical with u with high probability. It can be shown [19] that the probability of decoding error is upper bounded by\nlog p < D(P ˆ U Y P Z P Y ). If we choose l n log p sufﬁciently close to D(P ˆ U S P Z P S ) and k+l n log p sufﬁciently close to D(P ˆ U S P Z P S ) we can achieve the rate\nWe have shown in Section III-A that for discrete random variables the region given in Theorem III.1 is achievable. In this part, we make a quantization argument to generalize this result to arbitrary auxiliary random variables. Let S, U, X, Y\nbe distributed according to P S P U |S P X|U S W Y |X where in this case U is an arbitrary random variable. We start with the following theorem:\nTheorem III.6. Let F 1 ⊆ F 2 ⊆ · · · be an increasing sequence of σ-algebras on a measurable set A. Let F ∞ denote the σ-algebra generated by the union ∪ ∞ n=1 F n . Let P and Q be probability measures on A. Then\nwhere P | F denotes the restriction of P on F . Proof: Provided in [9] and [1].\nFor a prime p > 2 and a real positive number γ and for i = 0 · · · , p − 1 deﬁne a i = −γ(p−1) 2 \t + γi and deﬁne\nthe quantization Q γ,p as Q γ,p = {A 0 , A 2 , · · · , A p−1 } where A 0 = (−∞, a 0 ], A p−1 = (a p−2 , +∞) and A i = (a i−1 , a i ] for i = 1, · · · , p − 2. Let the random variable ˆ U γ,p take values from {a 0 , · · · , a p−1 } according to joint measure\nFor all Borel sets B ⊆ R 3 . For a ﬁxed γ, let p ≤ q be two primes. Then the σ-algebra induced by Q γ,p is included in the σ-algebra induced by Q γ,q . Therefore, for a ﬁxed γ, we can use the above theorem to get\nwhere U | F γ,∞ is a random variable over Q γ,∞ = {A i |i ∈ Z} where A i = γ 2 + (γi, γ(i + 1)] with measure P U | Fγ,∞ (A i ) = P U (A i ).\nLet γ 0 = 1 and deﬁne γ n = 1 2 n . Note that if m > n then F γ n ,∞ is included in F γ m ,∞ . Also, since dyadic intervals generate the Borel Sigma ﬁeld ( [15] for example), the restriction of U to the sigma algebra generated by ∪ ∞ n=1 F γ n ,∞ is U itself. We can use Theorem III.6 to get\nCombining (8) and (9) we conclude that for all > 0, there exist Γ and P such that if γ ≤ Γ and p ≥ Γ then\nSince quantization reduces the mutual information (X Q → X → Y ), we have\nTherefore I(U | F γ,p ; Y ) − I(U ; Y ) < . Also note that I(U | F γ,p ; Y ) = I( ˆ U γ,p ; Y ) since we deﬁne the joint measure to be the same. Therefore\nif we take the maximum of the two p\u2019s and the minimum of the two γ\u2019s, we can say for all > 0 there exist γ and p such that both (10) and (11) happen.\nconverges to P SU X in the weak* sense as p → ∞.\nProof: Provided in a more complete version [19]. The above lemma implies E P\n{w(X)} converges to E P SU X {w(X)} ≤ W since w is assumed to be bounded continuous.\nWe have shown that for arbitrary P U |S and W X|SU , one can ﬁnd P ˆ U |S and W X|S ˆ U induced from (7) such that ˆ U is a discrete variable and\nI( ˆ U ; Y ) − I( ˆ U ; S) ≈ I(U ; Y ) − I(U ; S) E P S ˆ U X {w(X)} ≈ E P SU X {w(X)}\nHence, using the result of section III-A, we have shown the achievability of the rate region given in Theorem III.1 for arbitrary auxiliary random variables when the cost function is bounded and continuous.\nFor a positive number l, deﬁne the bounded random variable ˆ X by ˆ X = sign(X) min(l, |X|) and let ˆ Y be distributed\nSince ˆ X is bounded and w is assumed to be continuous, w is also bounded. This completes the proof.\nWe show the achievability of the rate R = I(U ; X) − I(U ; S) for the Wyner-Ziv problem using nested lattice codes.\nTheorem IV.1. For the source (X , S, ˆ X , P XS , d(·)) assume X , S, ˆ X ⊆ R and d(·) is continuous. Let U be a random variable taking values from the set U jointly distributed with X and S according to P XS W U |X where W U |X (·|·) is a transition kernel. Further assume that there exists a measurable function f : S × U → ˆ X such that E{d(X, f(S, U))} ≤ D. Then the rate R ∗ (D) = I(X; U ) − I(S; U ) is achievable using nested lattice codes.\nHere we present a sketch of the proof of this theorem. The complete proof is similar to the channel coding problem and is provided in [19]. The ensemble of codes used for source coding is based on the parity check matrix representation of linear and lattice codes. For a prime number p, the linear code over Z p corresponding to the parity check matrix H ∈ Z k×n p is the kernel of the matrix H; i.e. C = u ∈ Z n p |Hu = 0 where the operations are done mod-p. The coset code corresponding to the parity check matrix H ∈ Z k×n p and the bias vector c ∈ Z k p is deﬁned as C = u ∈ Z n p |Hu = c .\nNested linear codes based on the parity check representation of linear codes can be deﬁned as follows\nwhere H ∈ Z k×n p and ∆H ∈ Z k×n p . The ensemble of lattice codes are then constructed using (1) and (4). The encoding and decoding rules are as follows: For m ∈ Z k p , Let B m be the mth bin of Λ i in Λ o . The encoder observes the source sequence x ∈ X n and looks for a vector u in the outer code Λ o which is typical with x and encodes the sequence x to the bin of Λ i in Λ o containing u. The encoder declares error if it does not ﬁnd such a vector.\nHaving observed the index of the bin m and the side infor- mation s, the decoder looks for a unique sequence u in the mth bin which is jointly typical with s and outputs f (u, s). Otherwise it declares error. Similar to the channel coding problem, this theorem is ﬁrst proved for discrete auxiliary random variables and then it is generalized to arbitrary sources.\nWe have shown that nested lattice codes are optimal for the Gelfand-Pinsker problem as well as the Wyner-Ziv problem."},"refs":[{"authors":[{"name":"A. R. Barron"}],"title":{"text":"Limits of Information, Markov Chains, and Projection"}},{"authors":[{"name":"R. De Buda"}],"title":{"text":"Some optimal codes have structure"}},{"authors":[{"name":"I. Csiszar"}],"title":{"text":"Linear Codes for Sources and Source Networks: Error Exponents, Universal Coding"}},{"authors":[{"name":"U. Ere"},{"name":"R. Zamir"}],"title":{"text":"Achieving 1 2 log(1 + SNR) on the AWGN Channel With Lattice Encoding and Decoding"}},{"authors":[{"name":"U. Ere"},{"name":"R. Zamir"}],"title":{"text":"Capacity and Lattice Strategies for Cancel- ing Known Interference"}},{"authors":[{"name":"U. Ere"},{"name":"R. Zamir"}],"title":{"text":"Lattices Which Are Good for (Almost) Everything"}},{"authors":[{"name":"T. Garib"},{"name":"U. Erez"}],"title":{"text":"On General Lattice Quantization Noise"}},{"authors":[{"name":"S. I. Gelfan"},{"name":"M. S. Pinsker"}],"title":{"text":"Coding for channel with random parameters"}},{"authors":[],"title":{"text":"P Harremos and K Khler Holst"}},{"authors":[{"name":"J. Korne"},{"name":"K. Marton"}],"title":{"text":"How to encode the modulo-two sum of binary sources"}},{"authors":[{"name":"D. Krithivasa"},{"name":"S. S. Pradhan"}],"title":{"text":"Distributed source coding us- ing abelian group codes"}},{"authors":[{"name":"T. Linde"},{"name":"C. Schlegel"}],"title":{"text":"Corrected Proof of de Buda\u2019s Theorem"}},{"authors":[{"name":"H. A. Loeliger"}],"title":{"text":"Averaging bounds for lattices and linear codes"}},{"authors":[{"name":"P. Mitran"}],"title":{"text":"Typical Sequences for Polish Alphabets"}},{"authors":[{"name":"P. Mrter"},{"name":"O. Schramm Y"},{"name":"W. Werner"}],"title":{"text":"Peres, and  Brownian Motion"}},{"authors":[{"name":"B. A. Naze"},{"name":"M. Gastpar"}],"title":{"text":"Computation over multiple-access channels"}},{"authors":[{"name":"A. Padakandl"},{"name":"S. S. Pradhan"}],"title":{"text":"Nested linear codes achieve martons inner bound for general broadcast channels"}},{"authors":[{"name":"T. Philoso"},{"name":"A. Kisht"},{"name":"U. Ere"},{"name":"R. Zamir"}],"title":{"text":"Lattice strategies for the dirty multiple access channel"}},{"authors":[{"name":"A. G. Saheb"},{"name":"S. Sandeep Pradhan"}],"title":{"text":"Nested lattice codes for arbitrary continuous sources and channels"}},{"authors":[{"name":"S. Sridhara"},{"name":"A. Jafaria"},{"name":"S. Vishwanat"},{"name":"S. A. Jafa"},{"name":"S. Shamai"}],"title":{"text":"A layered lattice coding scheme for a class of three user gaussian interference channels"}},{"authors":[{"name":"R. Urbank"},{"name":"B. Rimoldi"}],"title":{"text":"Lattice Codes Can Achieve Capacity on the AWGN Channel"}},{"authors":[{"name":"A. Wyner"}],"title":{"text":"The rate distortion function for source coding with side information at the decoder-ii"}},{"authors":[{"name":"A. Wyne"},{"name":"J. Ziv"}],"title":{"text":"The rate distortion function for source coding with side information at the decoder"}},{"authors":[{"name":"R. Zami"},{"name":"M. Feder"}],"title":{"text":"On lattice quantization noise"}},{"authors":[{"name":"R. Zami"},{"name":"S. Shamai"}],"title":{"text":"Nested linear/lattice codes for wyner-ziv encoding"}},{"authors":[{"name":"R. Zami"},{"name":"S. Shama"},{"name":"U. Erez"}],"title":{"text":"Nested linear/lattice codes for structured multiterminal binning"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566943.pdf"},"links":[{"id":"1569566381","weight":4},{"id":"1569565383","weight":4},{"id":"1569565883","weight":2},{"id":"1569566725","weight":2},{"id":"1569566385","weight":2},{"id":"1569567049","weight":9},{"id":"1569565867","weight":2},{"id":"1569565067","weight":7},{"id":"1569566605","weight":2},{"id":"1569566683","weight":12},{"id":"1569566855","weight":2},{"id":"1569566227","weight":2},{"id":"1569566697","weight":7},{"id":"1569565551","weight":2},{"id":"1569566591","weight":4},{"id":"1569552245","weight":4},{"id":"1569564481","weight":4},{"id":"1569566415","weight":4},{"id":"1569566469","weight":2},{"id":"1569566081","weight":4},{"id":"1569565355","weight":2},{"id":"1569565931","weight":2},{"id":"1569551535","weight":2},{"id":"1569565461","weight":9},{"id":"1569564245","weight":4},{"id":"1569564227","weight":4},{"id":"1569566119","weight":2},{"id":"1569564233","weight":9},{"id":"1569563411","weight":2},{"id":"1569559541","weight":4},{"id":"1569566319","weight":2},{"id":"1569565123","weight":2},{"id":"1569558459","weight":4},{"id":"1569565291","weight":2},{"id":"1569566821","weight":2},{"id":"1569556713","weight":2},{"id":"1569562685","weight":2},{"id":"1569566751","weight":2},{"id":"1569566467","weight":2},{"id":"1569565771","weight":2},{"id":"1569566157","weight":2},{"id":"1569566903","weight":2},{"id":"1569566999","weight":2},{"id":"1569565859","weight":7},{"id":"1569565347","weight":2},{"id":"1569565455","weight":7},{"id":"1569564989","weight":7},{"id":"1569566523","weight":2},{"id":"1569564189","weight":4},{"id":"1569566985","weight":2},{"id":"1569564613","weight":2},{"id":"1569566865","weight":2},{"id":"1569566095","weight":2},{"id":"1569564271","weight":2},{"id":"1569566905","weight":2},{"id":"1569566753","weight":2},{"id":"1569563307","weight":2},{"id":"1569558681","weight":4},{"id":"1569555999","weight":2},{"id":"1569565213","weight":2},{"id":"1569566511","weight":2},{"id":"1569565841","weight":2},{"id":"1569566531","weight":2},{"id":"1569567665","weight":2},{"id":"1569565833","weight":2},{"id":"1569564611","weight":4},{"id":"1569565667","weight":2},{"id":"1569561795","weight":4},{"id":"1569566423","weight":2},{"id":"1569567015","weight":2},{"id":"1569566811","weight":2},{"id":"1569566851","weight":2},{"id":"1569565735","weight":2},{"id":"1569559111","weight":2},{"id":"1569562285","weight":2},{"id":"1569566939","weight":4},{"id":"1569553537","weight":2},{"id":"1569565915","weight":2},{"id":"1569553519","weight":9},{"id":"1569566885","weight":12},{"id":"1569566231","weight":2},{"id":"1569554881","weight":2},{"id":"1569554971","weight":2},{"id":"1569566209","weight":2},{"id":"1569566371","weight":2},{"id":"1569565655","weight":2},{"id":"1569566909","weight":7},{"id":"1569565033","weight":4},{"id":"1569566357","weight":2},{"id":"1569566721","weight":2},{"id":"1569565633","weight":7},{"id":"1569566661","weight":2},{"id":"1569558509","weight":2},{"id":"1569566037","weight":4},{"id":"1569565095","weight":7},{"id":"1569564969","weight":2},{"id":"1569565029","weight":2},{"id":"1569561245","weight":2},{"id":"1569565393","weight":2},{"id":"1569566191","weight":9},{"id":"1569565527","weight":2},{"id":"1569566853","weight":2},{"id":"1569566655","weight":2},{"id":"1569566673","weight":2},{"id":"1569566667","weight":2},{"id":"1569564097","weight":2},{"id":"1569560997","weight":2},{"id":"1569566407","weight":2},{"id":"1569566481","weight":2},{"id":"1569560503","weight":2},{"id":"1569565439","weight":2},{"id":"1569563395","weight":2},{"id":"1569566901","weight":9},{"id":"1569565415","weight":2},{"id":"1569555367","weight":4},{"id":"1569566383","weight":2},{"id":"1569566805","weight":4},{"id":"1569566929","weight":2},{"id":"1569566983","weight":2},{"id":"1569566097","weight":2},{"id":"1569566479","weight":2},{"id":"1569566873","weight":2},{"id":"1569565435","weight":4},{"id":"1569566129","weight":9},{"id":"1569565093","weight":2},{"id":"1569565919","weight":2},{"id":"1569566711","weight":9},{"id":"1569565661","weight":9},{"id":"1569564131","weight":4},{"id":"1569565511","weight":4},{"id":"1569566737","weight":2},{"id":"1569561221","weight":2},{"id":"1569566651","weight":4},{"id":"1569566823","weight":4},{"id":"1569566137","weight":7},{"id":"1569565375","weight":7},{"id":"1569566639","weight":2},{"id":"1569566755","weight":4},{"id":"1569566819","weight":2},{"id":"1569566771","weight":4},{"id":"1569566641","weight":2},{"id":"1569559035","weight":2},{"id":"1569551905","weight":4},{"id":"1569566487","weight":7},{"id":"1569556759","weight":4},{"id":"1569566619","weight":12},{"id":"1569565271","weight":9},{"id":"1569566301","weight":2},{"id":"1569558779","weight":2},{"id":"1569566389","weight":2},{"id":"1569566435","weight":7},{"id":"1569566299","weight":2},{"id":"1569564281","weight":7},{"id":"1569563919","weight":2},{"id":"1569565537","weight":2},{"id":"1569562367","weight":2},{"id":"1569555891","weight":2},{"id":"1569566847","weight":2},{"id":"1569565997","weight":2},{"id":"1569567013","weight":2},{"id":"1569561861","weight":2},{"id":"1569565337","weight":2},{"id":"1569550425","weight":2},{"id":"1569563725","weight":4},{"id":"1569565165","weight":2},{"id":"1569565635","weight":4},{"id":"1569561397","weight":2},{"id":"1569566413","weight":2},{"id":"1569565113","weight":2},{"id":"1569564257","weight":7},{"id":"1569564141","weight":2},{"id":"1569566973","weight":2},{"id":"1569566987","weight":2},{"id":"1569565031","weight":7},{"id":"1569564509","weight":7},{"id":"1569551541","weight":2},{"id":"1569551751","weight":2},{"id":"1569566663","weight":2},{"id":"1569564419","weight":2},{"id":"1569566241","weight":2},{"id":"1569564807","weight":2},{"id":"1569566609","weight":2},{"id":"1569566113","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T4.2","endtime":"17:20","authors":"Aria Ghasemian Sahebi, Sandeep Pradhan","date":"1341248400000","papertitle":"Nested Lattice Codes for Arbitrary Continuous Sources and Channels","starttime":"17:00","session":"S4.T4: Structured Codes","room":"Stratton 20 Chimneys (306)","paperid":"1569566943"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
