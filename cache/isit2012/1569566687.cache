{"id":"1569566687","paper":{"title":{"text":"An Efﬁcient Algorithm to Calculate BICM Capacity"},"authors":[{"name":"Georg B¨ocherer ∗"},{"name":"Fabian Altenbach §"},{"name":"Alex Alvarado \u2021"},{"name":"Steven Corroy §"},{"name":"Rudolf Mathar §"}],"abstr":{"text":"Abstract\u2014Bit-interleaved coded modulation (BICM) is a prac- tical approach for reliable communication over the AWGN channel in the bandwidth limited regime. For a signal point constellation with 2 m points, BICM labels the signal points with bit strings of length m and then treats these m bits separately both at the transmitter and the receiver. BICM capacity is deﬁned as the maximum of a certain achievable rate. Maximization has to be done over the probability mass functions (pmf) of the bits. This is a non-convex optimization problem. So far, the optimal bit pmfs were determined via exhaustive search, which is of exponential complexity in m. In this work, an algorithm called bit-alternating convex concave method (B ACM ) is developed. This algorithm calculates BICM capacity with a complexity that scales approximately as m 3 . The algorithm iteratively applies convex optimization techniques. B ACM is used to calculate BICM capacity of 4, 8, 16, 32, and 64-PAM in AWGN. For PAM constellations with more than 8 points, the presented values are the ﬁrst results known in the literature."},"body":{"text":"Bit-interleaved coded modulation (BICM) [1]\u2013[3] is a de facto standard for wireless communications, and it is used in e.g., HSPA, IEEE 802.11a/g/n, and the latest DVB standards (DVB-T2/S2/C2).\nIn BICM, signal points from a ﬁnite constellation are labeled with bit strings. E.g., for 16-PAM, the signal points are labeled with log 2 16 = 4 bits each. The bits in the labels are then treated independently both at the transmitter and the receiver. According to [4], to determine BICM capacity, a certain achievable rate has to be maximized over the bit probability mass functions (pmf). We will make this statement precise later in this work. This maximization is a non-convex optimization problem [5, Fig. 1]. So far, BICM capacity has been calculated using exhaustive search only. For the AWGN channel, results are presented for 8-PAM in [6, Fig. 3] and [5, Fig. 1] and for 16-QAM in [4, Fig. 2]. The complexity of exhaustive search is exponential in the number of bits in the labels, and calculating BICM capacity becomes an intractable problem for large constellations. This motivates the present work.\nOur approach is as follows. We start by considering a discrete memoryless channel (DMC) operated by a BICM transceiver. To calculate BICM capacity, we develop a new algorithm called bit alternating convex-concave method (B ACM ), which combines two optimization techniques: ﬁrst, maximization is done sequentially over one bit pmf at a time, and second, the maximization over one bit pmf is done using the convex-concave procedure [7]. We then show how an average power constraint can be taken into account by B ACM . This allows us to use B ACM to calculate BICM capacity of PAM constellations in AWGN. We provide numerical results for 4 and 8-PAM and, for the ﬁrst time in the literature, for 16, 32, and 64-PAM. The results show that BICM capacity is close to AWGN capacity and signiﬁcantly larger than what can be achieved by operating BICM with uniform bit pmfs. Finally, we argue that the complexity of B ACM scales approximately as m 3 and logarithmically in the precision with which the optimal bit pmfs are calculated. An implementation of B ACM in Matlab is available on our website [8].\nConsider a DMC with 2 m input symbols X = {1, . . . , 2 m } and n output symbols Y = {1, . . . , n}. The channel is speciﬁed by a matrix of transition probabilities H ∈ R n×2 m , where R denotes the set of real numbers. The input of the channel is the random variable X, which takes values in X according to the pmf p. The channel output is the random variable Y , which takes values in Y according to the pmf r = Hp.\nWe denote the mutual information between X and Y either by I(X; Y ) or by I(p). The DMC capacity is [9, Eq. (7.1)]\nThe maximization is a convex optimization problem [10, Prob. 4.57] and it can be solved by the Blahut-Arimoto algorithm [11], [12] or by a software package such as CVX [13].\nIn BICM, the input symbols are represented by their m-bit binary expansion, i.e,\n0 · · · 00 2 ↔ 0 · · · 01\nEach bit position of the channel input is treated independently both at the transmitter and the receiver, see [3], [4] for details. This leads to the following constraint at the transmitter:\n\u2022 [4, Eq. (8)]: The bits B i in positions i of the channel input are stochastically independent, i.e., the channel input pmf p is given by\nwhere p i is the pmf of B i and where ⊗ denotes the Kronecker product, see [14, Def. 4.2.1].\nAccording to [15, Theorem 1], the following sum of mutual informations is an achievable rate for a BICM transceiver:\nFollowing [4, Eq. (19)], the \u201cBICM capacity\u201d C bicm is now given by\nUnfortunately, the maximization is a non-convex problem. This will become clear in Sec. III.\nSo far, BICM capacity has been calculated in literature via exhaustive search [4]\u2013[6]. To determine the optimal bit pmfs with a precision of ±d, I bicm has to be evaluated ( 1 d ) m times, so the complexity of this approach increases exponentially in the number of bit positions m and polynomially in the precision d. The objective of this work is to develop an algorithm that efﬁciently (compared to exhaustive search) calculates BICM capacity.\nThe goal of this section is to characterize the objective I bicm as a function of one bit pmf p i . By this characterization, it will become clear that I bicm is a non-convex function, and furthermore, we will see how we can maximize over p i . To this end, we pick an arbitrary bit position i and assume that for each j = i, B j is distributed according to a ﬁxed pmf and that B i is distributed according to a pmf that we interpret as a variable. To emphasize this distinction, we denote the pmfs\nfor j = i by ˆ p j and the pmf of B i by p i . The function I bicm can now be written as\nWe see that there are three kinds of terms that we need to express as functions of p i : the output entropy H(Y ), the conditional entropy H(Y |B i ), and the conditional entropy H(Y |B j ) for j = i.\nq i 0 := ˆ p 1 ⊗ · · · ⊗ ˆ p i−1 ⊗ 1 0 T ⊗ ˆ p i+1 ⊗ · · · ⊗ ˆ p m (8) q i 1 := ˆ p 1 ⊗ · · · ⊗ ˆ p i−1 ⊗ 0 1 T ⊗ ˆ p i+1 ⊗ · · · ⊗ ˆ p m . (9)\nwhere (x) k denotes the kth entry of the vector x. Since −x log x is concave in x, we conclude that the output entropy is concave in p i .\nThe output entropy conditioned on the ith bit can be written as\nwhere we index the rows of H i by 1, . . . , k and the columns by the binary values 0,1, e.g., (H i ) 10 is the entry of H i in the ﬁrst row and ﬁrst column. We conclude from (15) that H(Y |B i ) [and thereby − H(Y |B i ), which contributes to the objective function] is linear in p i .\nC. Conditional entropy H(Y |B j ) as a function of p p p i Deﬁne\n⊗ ˆ p i−1 ⊗ 1 0 T ⊗ ˆ p i+1 ⊗ · · · ⊗ ˆ p m (16) q ji 01 := ˆ p 1 ⊗ · · · ⊗ ˆ p j−1 ⊗ 1 0 T ⊗ ˆ p j+1 ⊗ · · ·\n0 p i . \t (21) Thus, the output entropy conditioned on the jth is\n(23) Since −x log x is concave in x, we conclude that H(Y |B j ) is concave in p i . As a consequence, the term − H(Y |B j ), which contributes to the objective function, is convex in p i .\nThe objective function as a function of p i can be charac- terized as follows:\nI bicm ( ˆ p 1 , . . . , ˆ p i−1 , p i , ˆ p i+1 , . . . , ˆ p m ) = m H(Y )\nAs a sum of convex and concave terms, I bicm is a non-convex function. However, as we detail in the next section, the convex- concave procedure [7] can be applied to maximize I bicm over p i .\nThe objective I bicm is a non-convex function of the pmfs p 1 , . . . , p m with potentially more than one local maximum. Thus, ﬁnding an efﬁcient algorithm that provably ﬁnds the global maximum is difﬁcult. Therefore, we resort to the simpler problem of ﬁnding a local maximum. With a good starting point, the global maximum is nevertheless found by such an approach. To ﬁnd local maxima, efﬁcient methods are available. For the problem at hand, we choose the combination of two methods.\nmaximize I bicm over p i see Alg. 2 update ˆ p i with the maximizing p i\ncalculate H i and H ji , j = i p i ← ˆ p i repeat\n\u2022 We maximize over one bit pmf p i at a time and then cycle through the i = 1, . . . , m until convergence. This approach goes under the name alternating maximization.\n\u2022 To maximize over one bit pmf p i , we iteratively approx- imate I bicm by a lower bound that is concave in p i and maximize this concave lower bound. After convergence, the maximum of the concave lower bound is also a local maximum of I bicm as a function of p i . This technique is known as the convex-concave procedure [7].\nWe call this approach the bit-alternating convex-concave method (B ACM ). The alternating maximization over the bit pmfs is displayed in Alg. 1. The maximization over one bit pmf is detailed next.\nAs the objective is the sum of concave and convex functions, it cannot be maximized directly. However, the convex-concave procedure as deﬁned in [16, slide 26] can be applied. Deﬁne the function h j (p i ) as the negative of the right-hand side of (23). This function is convex in p i . The convex-concave procedure is an iterative method and works as follows. Denote by ˆ p i the result for p i in the previous step. Then, in the current step, approximate h j (p i ) by its ﬁrst order Taylor expansion in ˆ p i , i.e., by\nNote that since h j (p i ) is convex in p i and the approximation ˆ h j (p i , ˆ p i ) is linear in p i , the approximation ˆ h j (p i , ˆ p i ) lower bounds h j (p i ) for any value of p i . By a calculation similar to [17, (7.61)\u2013(7.63)] it can be shown that ˆ h j is given by\nPutting all together, we have a concave lower bound of I bicm as a function of p i given by\n0 ˆ p i kb . (28)\nSince f i is a concave function of p i , it can be maximized efﬁciently over p i , as we will explain in detail in the next subsection. We iteratively update ˆ p i with the value of p i that maximizes f i (p i , ˆ p i ). Algorithm 2 illustrates this procedure. After convergence, the pmf p i locally maximizes I bicm over p i given the ﬁxed pmfs ˆ p j for j = i.\nNote that the problems (29) and (31) are equivalent and furthermore, by [10, Sec. 3.2.2], f i 0 is a concave function of p 0 . Thus, our problem reduces to ﬁnding the maximum of a concave function with a scalar argument. This can be done as follows.\nThe ﬁrst derivative of H(Y ), H(Y |B i ), and ˆ h j ( p i 0\n, ˆ p i ), j = i with respect to p i 0 are respectively given by\nwhere we index the rows of H ji by k = 1, . . . , n and the columns by the binary expansion b j b i = 00,01,10,11.\nE.g., (H ji ) 110 denotes the entry of H ji in the 1st row and the 3rd column. For notational convenience, we write\nPutting the expressions above together according to (27), we get the ﬁrst derivative of f i 0 . Since f i 0 is concave, df i 0 is monotonically decreasing in p i 0 . Consequently, we can maximize f i 0 over p i 0 ∈ [0, 1] as follows.\n  \n1 \t df i 0 (1 − , ˆ p i ) > 0 p i 0 : df i 0 (p i 0 , ˆ p i ) = 0 otherwise.\n(36) In our implementation [8], we use the bisection method to ﬁnd p i 0 in the third case. See Sec. VII for details.\nWe discuss how B ACM can be used to calculate BICM capacity when the bit pmfs are subject to an average cost constraint. Suppose we have a cost vector w ∈ R 2 m >0 , where R >0 denotes the set of positive real numbers. Then, the symbol costs seen by the ith bit are given by\nThe average cost can now be included by adding a weighted version of the average cost w iT p i to f i , i.e., the inner optimization problem in Alg. 2 now becomes\nThis simply adds another linear term and our algorithm works in exactly the same way as before. Denote by p i∗ the optimal pmfs found by this modiﬁed version of B ACM for some λ. Consider the resulting cost\nwhere p ∗ = p 1∗ ⊗ · · · ⊗ p m∗ . Then, it can be shown that the bit pmfs p 1∗ , . . . , p m∗ solve the optimization problem\nWe use B ACM to calculate BICM capacity of PAM con- stellations in AWGN. To calculate the BICM capacity of PAM constellations in AWGN, optimization has to be done over the labeling of the signal points, the scaling of the constellation, and the bit pmfs, see [6, Eq. (40)] for details. Here, we ﬁx the labeling to the binary reﬂected Gray code [6, Sec. II-B] and optimize over constellation scaling and bit pmfs. To be able to use B ACM , we discretize the channel output into 200 equally spaced points. For each scaling, the discretized AWGN channel with M = 2 m constellation points at the input can thus be represented by a DMC speciﬁed by a transition matrix H ∈ R 200×M . For this DMC, we\nuse the method proposed in Sec. V to calculate the BICM capacity. To achieve a target SNR, we iteratively adapt the weighting λ of the average power in (38). We repeat this for different constellation scalings and choose the scaling that yields the largest value for I bicm . This largest value is the BICM capacity and we denote it by C bicm (snr). Results for 4, 8, 16, 32, and 64-PAM are displayed in Fig. 1. For comparison, coded modulation (CM) capacity [6, Eq. (28)] of the corresponding constellation and I bicm for uniform bit pmfs are displayed. The values for CM capacity were obtained via CVX [13]. The BICM capacity signiﬁcantly outperforms uniform BICM and gets close to CM capacity. We calculated the optimal bit pmfs with a precision of d = 10 −5 .\nWe start by analyzing the complexity of the inner optimiza- tion problem. To cover the ﬁrst two cases in (36), we need to evaluate df i 0 two times. To ﬁnd the p i 0 in the third case we use the bisection method starting with the upper bound u = 1 and the lower bound = 0, and we terminate when u − ≤ 2d. After termination, we assign p i 0 = u+ 2 . Thus, we calculate p i 0 with a precision of ±d. According to [10, p. 146], the number of times we need to evaluate df i 0 until termination is given by\nlog 2 u − 2d\n= log 2 1 − 0 2d\nWhen evaluating df i , by (27), we need to evaluate ∂ˆ h j /∂p i 0 for each j = i, which results in a number of m − 1 or roughly m evaluations. Overall, the number of evaluations needed for solving the inner optimization problem once is roughly m log 2 1 2d . The sizes of the matrices involved in (28) are invariant under m, i.e., H ji ∈ R n×4 and H i ∈ R n×2 .\nTherefore, the number of iterations until convergence in Alg. 2 should be approximately invariant under m and we denote it by a constant K. For our AWGN simulations, this number was around K = 3, independent of m. The complexity of maximiz- ing I bicm over one bit pmf is thus approximately Km log 2 1 2d . This maximization has to be done for i = 1, . . . , m, i.e., m times, which adds another factor of m to the complexity. This procedure has to be repeated L times until convergence in the outer loop of Alg. 1. This number depends on m. For the AWGN simulations, we observed for m = 2, 3, 4, 5, 6, respectively, the values\nThe average for each m is taken separately over all values that were observed when executing B ACM . This value in- creases slightly with m. To have a rough bound on com- plexity, we assume that L increases at most linearly with m, which is consistent with the observed data (42). All together, we have a complexity that is approximately of the order LKm 2 log 2 1 2d ≤ Km 3 log 2 1 2d . In summary, B ACM scales as m 3 and logarithmically in the precision d."},"refs":[{"authors":[{"name":"E. Zehavi"}],"title":{"text":"8-PSK trellis codes for a Rayleigh channel"}},{"authors":[{"name":"G. Caire"},{"name":"G. Taricco"},{"name":"E. Biglieri"}],"title":{"text":"Bit-interleaved coded modula- tion"}},{"authors":[{"name":"A. Guill´en i F`abregas"},{"name":"A. Martinez"},{"name":"G. Caire"}],"title":{"text":"Bit-interleaved coded modulation"}},{"authors":[{"name":"A. Guill´en i F`abregas"},{"name":"A. Martinez"}],"title":{"text":"Bit-interleaved coded modula- tion with shaping"}},{"authors":[{"name":"A. Alvarado"},{"name":"F. Br¨annstr¨om"},{"name":"E. Agrell"}],"title":{"text":"High SNR bounds for the BICM capacity"}},{"authors":[{"name":"E. Agrell"},{"name":"A. Alvarado"}],"title":{"text":"Optimal alphabets and binary labelings for BICM at low SNR"}},{"authors":[{"name":"A. L. Yuille"},{"name":"A. Rangarajan"}],"title":{"text":"The concave-convex procedure"}},{"authors":[],"title":{"text":"BACM\u2013an algorithm for calculating BICM capacity."}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory, 2nd ed"}},{"authors":[{"name":"S. Boy"},{"name":"L. Vandenbergh"}],"title":{"text":"Convex Optimization"}},{"authors":[{"name":"R. Blahut"}],"title":{"text":"Computation of channel capacity and rate-distortion func- tions"}},{"authors":[{"name":"S. Arimoto"}],"title":{"text":"An algorithm for computing the capacity of arbitrary discrete memoryless channels"}},{"authors":[{"name":"M. Grant"},{"name":"S. Boyd"}],"title":{"text":"CVX: Matlab software for disciplined convex programming, version 1.21"}},{"authors":[{"name":"R. A. Hor"},{"name":"C. R. Johnso"}],"title":{"text":"Topics in Matrix Analysis"}},{"authors":[{"name":"A. Martinez"},{"name":"A. Guill´en i F`abregas"},{"name":"G. Caire"},{"name":"F. Willems"}],"title":{"text":"Bit- interleaved coded modulation revisited: A mismatched decoding per- spective"}},{"authors":[{"name":"S. Boyd"}],"title":{"text":"Convex optimization II, lecture 14: Sequential convex programming"}},{"authors":[{"name":"G. B¨ocherer"}],"title":{"text":"Capacity-achieving probabilistic shaping for noisy and noiseless channels"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566687.pdf"},"links":[{"id":"1569566381","weight":7},{"id":"1569566527","weight":3},{"id":"1569565223","weight":7},{"id":"1569565663","weight":7},{"id":"1569565377","weight":14},{"id":"1569566385","weight":3},{"id":"1569559665","weight":3},{"id":"1569559617","weight":7},{"id":"1569566683","weight":3},{"id":"1569566227","weight":3},{"id":"1569566761","weight":3},{"id":"1569556029","weight":10},{"id":"1569565495","weight":3},{"id":"1569565355","weight":17},{"id":"1569566765","weight":7},{"id":"1569565461","weight":7},{"id":"1569564227","weight":7},{"id":"1569566303","weight":10},{"id":"1569563411","weight":7},{"id":"1569559541","weight":3},{"id":"1569566821","weight":3},{"id":"1569562685","weight":25},{"id":"1569566751","weight":7},{"id":"1569565771","weight":7},{"id":"1569566157","weight":10},{"id":"1569560613","weight":7},{"id":"1569566999","weight":7},{"id":"1569558483","weight":7},{"id":"1569565347","weight":7},{"id":"1569566963","weight":7},{"id":"1569566709","weight":7},{"id":"1569566749","weight":14},{"id":"1569565321","weight":3},{"id":"1569566095","weight":3},{"id":"1569564311","weight":3},{"id":"1569566419","weight":14},{"id":"1569566905","weight":7},{"id":"1569566759","weight":3},{"id":"1569565213","weight":3},{"id":"1569566511","weight":7},{"id":"1569561143","weight":7},{"id":"1569566437","weight":3},{"id":"1569565427","weight":3},{"id":"1569566513","weight":3},{"id":"1569554971","weight":10},{"id":"1569562821","weight":28},{"id":"1569566649","weight":3},{"id":"1569558985","weight":14},{"id":"1569566473","weight":3},{"id":"1569566913","weight":3},{"id":"1569566257","weight":3},{"id":"1569566141","weight":3},{"id":"1569566721","weight":7},{"id":"1569555879","weight":7},{"id":"1569565219","weight":7},{"id":"1569556671","weight":7},{"id":"1569565095","weight":7},{"id":"1569566223","weight":7},{"id":"1569562207","weight":3},{"id":"1569566191","weight":7},{"id":"1569566051","weight":3},{"id":"1569566655","weight":3},{"id":"1569565441","weight":7},{"id":"1569565739","weight":3},{"id":"1569566857","weight":3},{"id":"1569566229","weight":3},{"id":"1569566949","weight":3},{"id":"1569566133","weight":7},{"id":"1569563395","weight":7},{"id":"1569551347","weight":7},{"id":"1569566383","weight":3},{"id":"1569565155","weight":3},{"id":"1569566177","weight":3},{"id":"1569566929","weight":7},{"id":"1569565549","weight":7},{"id":"1569565611","weight":7},{"id":"1569564175","weight":7},{"id":"1569566983","weight":10},{"id":"1569565397","weight":21},{"id":"1569565765","weight":7},{"id":"1569565435","weight":7},{"id":"1569565215","weight":3},{"id":"1569565181","weight":3},{"id":"1569566253","weight":7},{"id":"1569566651","weight":3},{"id":"1569566823","weight":3},{"id":"1569565013","weight":32},{"id":"1569565829","weight":21},{"id":"1569566237","weight":7},{"id":"1569565375","weight":3},{"id":"1569566715","weight":3},{"id":"1569566771","weight":7},{"id":"1569566641","weight":7},{"id":"1569559035","weight":3},{"id":"1569564247","weight":3},{"id":"1569551905","weight":7},{"id":"1569556759","weight":7},{"id":"1569565669","weight":7},{"id":"1569563721","weight":7},{"id":"1569564923","weight":7},{"id":"1569564769","weight":7},{"id":"1569565769","weight":10},{"id":"1569566933","weight":7},{"id":"1569565389","weight":7},{"id":"1569560785","weight":3},{"id":"1569565561","weight":10},{"id":"1569555891","weight":3},{"id":"1569566847","weight":3},{"id":"1569566583","weight":3},{"id":"1569560459","weight":7},{"id":"1569565853","weight":7},{"id":"1569565889","weight":7},{"id":"1569566611","weight":10},{"id":"1569564505","weight":7},{"id":"1569565165","weight":7},{"id":"1569564931","weight":3},{"id":"1569564141","weight":7},{"id":"1569561579","weight":3},{"id":"1569551541","weight":3},{"id":"1569558697","weight":3},{"id":"1569566067","weight":3},{"id":"1569566417","weight":3}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T7.4","endtime":"12:50","authors":"Georg Böcherer, Fabian Altenbach, Alex Alvarado, Steven Corroy, Rudolf Mathar","date":"1341232200000","papertitle":"An Efficient Algorithm to Calculate BICM Capacity","starttime":"12:30","session":"S2.T7: Capacity of Gaussian Channels","room":"Stratton (407)","paperid":"1569566687"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
