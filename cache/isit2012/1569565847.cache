{"id":"1569565847","paper":{"title":{"text":"Optimal Linear Codes with a Local-Error-Correction Property"},"authors":[{"name":"N. Prakash"},{"name":"Govinda M. Kamath"},{"name":"V. Lalitha"},{"name":"P. Vijay Kumar"}],"abstr":{"text":"Abstract\u2014Motivated by applications to distributed storage, Gopalan et al recently introduced the interesting notion of information-symbol locality in a linear code. By this it is meant that each message symbol appears in a parity-check equation associated with small Hamming weight, thereby enabling re- covery of the message symbol by examining a small number of other code symbols. This notion is expanded to the case when all code symbols, not just the message symbols, are covered by such \u201clocal\u201d parity. In this paper, we extend the results of Gopalan et. al. so as to permit recovery of an erased code symbol even in the presence of errors in local parity symbols. We present tight bounds on the minimum distance of such codes and exhibit codes that are optimal with respect to the local error-correction property. As a corollary, we obtain an upper bound on the minimum distance of a concatenated code."},"body":{"text":"In [1], Gopalan et al introduced the interesting and practi- cally relevant notion of locality of information. The i th code- symbol c i , 1 ≤ i ≤ n, of an [n, k, d] linear code C over the ﬁeld F q is said to have locality r if this symbol can be recovered by accessing at most r other code symbols of code C. Equivalently, for any coordinate i, there exists a row in the parity-check matrix of the code of Hamming weight at most r + 1, whose support includes i. An (r, d) code was deﬁned as a systematic linear code C having minimum distance d, where all k message symbols have locality r. It was shown that the minimum distance of an (r, d) code is upper bounded by\nA class of codes constructed earlier and known as pyramid codes [2] are shown to be (r, d) codes that are optimal with respect to this bound.\nThe concept of an (r, d) code was motivated by the prob- lem of designing efﬁcient codes for the distributed storage of data across nodes in a network. Since nodes are prone to failure, there is need to protect the data using an error- correcting code. A second important requirement in this setting, is the ability to efﬁciently bring up a failed node. Here, (r, d) codes offer the advantage that in the event of a single node failure, the node can be locally recovered by connecting to at most r other nodes.\nA natural extension to the concept of an (r, d) code, is a code that would allow local recovery of a failed node, even in the presence of failures in other nodes of the network. Multiple node failures are not uncommon in distributed data storage, and a number of coding schemes for tolerating\nsuch multiple node failures exist in practice [2][3][4]. This motivates the deﬁnition of the class of (r, d, δ) local-error- correction codes given below.\nDeﬁnition 1: The ith code symbol c i , 1 ≤ i ≤ n, in an [n, k, d] linear code C, will be said to have locality (r, δ) if there exists a punctured subcode of C with support containing i, whose length is at most r + δ − 1, and whose minimum distance is at least δ. Equivalently, there exists a subset S i ⊆ [n] = {1, . . . , n} such that\n\u2022 the minimum distance of the code C| S i obtained by deleting code symbols c i , i ∈ [n]\\S i , is least δ.\nSince the dual of a punctured code is a shortened code, this also implies that we may regard the parity-check matrix H of the code as containing for some ν i , 1 ≤ ν i ≤ n − k, a (ν i × n) submatrix H i having rank ν i , support S i , and the property that any δ − 1 columns of H i with indices drawn from S i , are linearly independent.\nA systematic [n, k, d] linear code C will be said to be an (r, δ) i code, if all k message (or information) symbols have locality (r, δ). We will also refer to such a code as having information locality (r, δ). It is clear that if we employ an (r, δ) i code for the distributed storage of data, a systematic node can be locally repaired by connecting to r other nodes, even if δ − 2 other nodes fail. An additional advantage of an (r, δ) i code is that even when the other nodes are intact, the code provides multiple options for locally repairing a failed systematic node, which in a network setting, can be used to balance trafﬁc across the network 1 . The (r, d) codes introduced by Gopalan et al correspond to (r, 2) i codes in the present notation.\nBy using properties of the generalized Hamming weights [5] of a code (also known as minimum support weights [6]), we will show that the minimum distance of an (r, δ) i code is upper bounded (Theorem 2) by\nk r\nAs was the case with the (r, d) codes introduced in [1], a class of pyramid codes turns out to provide examples of optimal (r, δ) i codes, i.e., (r, δ) i codes in which the bound in (2) is achieved with equality. For the special case when r|k, we\nwill identify conditions that the parity check matrix of an optimal (r, δ) i code must necessarily satisfy.\nWe will term a code in which all the n symbols of an [n, k, d] code have locality (r, δ) as codes as having all- symbol locality (r, δ) and denote such codes as (r, δ) a codes. Thus, whenever we speak of either an (r, δ) i or else an (r, δ) a code, it will be assumed that the length, dimension and minimum distance of the linear code are understood from the context and are typically denoted by n, k, d respectively. Clearly, codes with all-symbol locality are a subset of the set of codes with just information locality. Nevertheless, it turns out that when (r + δ − 1)|n, one can show the existence of codes with all-symbol locality (r, δ), which satisfy the upper bound on minimum distance given in (2). We will also present an explicit code having all-symbol locality, for the case when the code length n is of the form n = k r (r + δ − 1).\nThrough out this write up, we will assume without loss of generality, that the [n, k, d] code C under study, is systematic, with information symbols present in the ﬁrst k coordinates. For a codeword c ∈ C, we will use Supp(c) to denote the support {i ∈ [n] | c i = 0 } of the codeword. The support of a subcode D of C, is deﬁned by Supp(D) ∪ c∈D Supp(c). For a set S ⊂ [n], we will use C| S and C S to denote respectively, the punctured and shortened codes of C associated with the coordinate set S. By this we mean that under either the puncturing or shortening operation, the coordinates of the code lying in [n]\\S are suppressed. Also, for any set S, the cardinality of the set will be denoted by |S|.\nSection II presents background on generalized Hamming weights, while codes with information and all-symbol locality are treated in Sections III and IV respectively. In the ﬁnal section V, we present as a corollary, an upper bound on the minimum distance of a concatenated code.\nIn this section, we review the deﬁnition of the generalized Hamming weight (GHW) of a code [5], [7] and see how the GHWs of a code are related to those of its dual. We introduce the notion of a gap which will play an important role in our subsequent proofs.\nDeﬁnition 2: The i th , 1 ≤ i ≤ k, generalized Hamming weight of a code C is deﬁned by\nwhere D < C, is used to denote a subcode D of C. It is well known that\nWe will call the complement of the set {d i , 1 ≤ i ≤ k}, in [n], as the set of gap numbers (more simply, gaps) of the code C and denote them by the set {g i , 1 ≤ i ≤ n − k}, where {g i , 1 ≤ i ≤ n − k} = [n] \\ {d i , 1 ≤ i ≤ k}. Similarly, let the sets {d ⊥ j , 1 ≤ j ≤ n − k} and {g ⊥ i , 1 ≤ i ≤ k} respectively denote the GHWs and gaps of the dual code C ⊥ .\nThe following lemma [5] relates the GHWs of C to those of C ⊥ .\nIn terms of the gaps of the dual code C ⊥ , (5) can be rewritten as\nIn particular, the minimum distance d of C and the largest gap g ⊥ k of C ⊥ are related by\nThis relation will be used to derive an upper bound on the minimum distance of (r, δ) i codes.\nIn this section, Theorem 2 will establish the upper bound appearing in (2), on the minimum distance of (r, δ) i codes. It will then be shown that pyramid codes, under an appropriate choice of parameters, are optimal with respect to this bound. Necessary conditions for optimality of an (r, δ) i code for the case when r|k, are identiﬁed in Theorem 6.\nTheorem 2: The minimum distance d of an (r, δ) i code C is upper bounded by\nProof: From (7), the minimum distance of C, in terms of the largest gap of C ⊥ is given by\nThe desired upper bound on d will be obtained by showing the corresponding lower bound on g ⊥ k . This lower bound on g ⊥ k will in turn, be deduced from an appropriate upper bound on the k r − 1 (δ − 1) th GHW, d ⊥ ( k\n, of C ⊥ . It will be established in the next subsection, that under the conditions of Theorem 2,\nk r\n= s. Then the number of gaps in the dual that do not exceed s is given by\nSince there are a total of k gaps in the dual code C ⊥ , there must be at least an additional k − s − k r − 1 (δ − 1)\ngaps that exceed s and hence the last gap in the dual, g ⊥ k , satisﬁes the lower bound:\nk r\nLemma 3: Let C be a systematic [n, k, d] linear code whose ﬁrst k coordinates correspond to message symbols. Let S be a subset of [n] of size s, such that [k] ⊆ S. Let P denote a sub code, supported on S, of the dual code C ⊥ , i.e., every code symbol in every codeword in P is zero outside of S. Also, let Q = [A m×k |B m×(n−k) ] be a rank p, (m × n) matrix whose row space is the code P. Then we must have rank(B) = p and hence s − k ≥ p.\nProof: Suppose rank(B) < p. Then the row space of Q would contain nonzero vectors which are supported (i.e., nonzero in) only in the ﬁrst k message symbol coor- dinates. This is not possible as this would imply a relation- ship amongst the message symbols of the code C. Hence rank(B) = p. We also know that the number of nonzero columns in B is less than or equal to s − k. It follows that s − k ≥ p.\nWe are now ready to prove that k r − 1 (δ − 1) < n − k and\nFor i ∈ [k], let the i th code (message) symbol be locally protected by a code associated to the parity check matrix H i , whose support is S i of size |S i | = s i ≤ r + δ − 1. Let V i denote the row space of H i and let ν i be its dimension. Since the nullspace of H i must deﬁne a code whose minimum distance is ≥ δ, we must have that ν i ≥ δ − 1, ∀i ∈ [k]. Let us set Ψ = ∪ k i=1 S i and s := |Ψ|.\nLet a be the largest integer such that there exists a subset {V i j } a j=1 with the property that if\nIn other words, each subspace V i j contributes at least (δ − 1) to the total dimension. Clearly, such an a exists, for a ≥ 1 is trivially true. Without loss of generality, we reorder the indices so that V i j = V j , 1 ≤ j ≤ a.\nFor the remaining subspaces V i , i = a + 1, a + 2, · · · , k, we once again deﬁne\nFor i in the range a+1 ≤ i ≤ k, we must have ∆ν i ≤ (δ −2) and also\nEquation (18) follows since any subset of (δ − 1) or less columns of each matrix H i , with indices drawn from S i , forms a linearly independent set.\n \n \nThen, rank(H) = k i=1 ∆ν i and |Supp(H)| = k i=1 ∆s i , which can be upper bounded as\nFrom the two expressions above for the size of the support of H, we obtain that\nr , \t (20) where (20) follows from (18) and the fact that for 1 ≤ i ≤ a, ∆ν i ≥ (δ − 1).\nIt follows that the rank(H) ≥ a(δ − 1) > (δ − 1)( k r − 1). Also, since rank(H) ≤ (n − k), we get that (n − k) > (δ − 1)( k r − 1) and it is hence meaningful to speak of d ⊥ ( k\n. Since the support of each submatrix H i is ≤ (r + δ − 1), we have that\nand with this, we have recovered the two inequalities appear- ing in (10).\nCorollary 4: For an (r, δ) i code C that achieves the bound in (8) with equality, we have\nWe will now show that for the case δ ≤ d, under a suitable choice of parameters, Pyramid codes [2] achieve the bound in Theorem 2 with equality.\nConsider an [k + d − 1, k, d] systematic MDS code over F q having generator matrix of the form\nWe will now proceed to modify G to obtain the generator matrix for an optimal(r, δ) i code. Let k = αr + β, 0 ≤ β ≤ (r − 1) and δ ≤ d. We now partition Q into submatrices as shown below:\n   \n   \nwhere Q i , 1 ≤ i ≤ α are matrices of size r × (δ − 1), Q α+1 is of size β × (δ − 1) and Q is a k × (d − δ) matrix. Consider a second generator matrix G obtained by splitting the ﬁrst (δ − 1) columns of Q as shown below:\n   \n   \n(24) Note that G is a k × n full rank matrix, where\nClearly, by comparing the matrices G and G , it follows that the code, C, generated by G has minimum distance no smaller than d. Furthermore, C is an (r, δ) i code. Hence, it follows from (25) that C is an optimal (r, δ) i code.\nIn this section, we will assume that r|k. We borrow notation and intermediate steps used in the proof of Theorem 2.\nTheorem 5: If an [n, k, d] linear code C having informa- tion locality (r, δ) achieves the bound in (8) with equality, then |S i | = r + δ − 1, S i ∩ S j = φ, 1 ≤ i < j ≤ a and\nC ⊥ S i is MDS, 1 ≤ i ≤ a, where a is as deﬁned together by (13) and (14).\nProof: Since, from (20), we have a ≥ k r , we get that dim(W k\n= k + k r (δ − 1). Hence, it must be true that\nr (δ − 1), \t (26) |Ψ k\nNow, since ∀i ∈ [a], |S i | ≤ r + δ − 1, from (27), it follows that |S i | = r + δ − 1 and\nCombining (26) and (28), we also get that dim((C ⊥ ) S i ) = δ − 1, ∀i ∈ [a]. This implies that the dual of (C ⊥ ) S i , which is the code, C | S i , has dimension |S i | − (δ − 1) = r. Now, noting C | S i has parameters [r + δ − 1, r, δ], it follows that C | S i and hence (C ⊥ ) S i are MDS, ∀i ∈ [a].\nTheorem 6: If an [n, k, d] linear code C having informa- tion locality (r, δ) achieves the bound in (8) with equality and d < r + 2δ − 1, then δ ≤ d and up to a reordering of columns, the parity check matrix, H of C can be assumed to be of the form:\n     \n     \n(29) where A = A 1 | A 2 | . . . | A k\ngenerates an [r + d − 1, d − 1, r + 1] MDS code. The matrices Q i and A i appearing above are of sizes (δ − 1) × r and (d − δ) × r respectively.\nProof: Only a sketch of the proof will be provided, for lack of space. The ﬁrst step is to show that a = k r . Suppose not, and if a ≥ k r + 1, then Theorem 5 can be used to show that n > k + d − δ + k r (δ − 1). But this would contradict the assumption that the code is optimal (see (8)) and hence a = k r . To show that δ ≤ d, once again note from Theorem 5 that the length of an optimal (r, δ) i code must be at least\n(r+δ−1). Now if one assumes δ > d, then from (8), we get under the assumption of optimality that n < k r (r + δ − 1), which results in a contradiction. Hence we conclude that, under optimality, δ ≤ d. Combining the facts a = k r and δ ≤ d, and also using Theorem 5, we get that the parity check matrix, H, for the code C has the form (up to permutation of columns) given in (29). For the rest of the proof, we consider those shortened codes of C that are generated by [I r | Q t i | A t i ], i = 1, . . . , k r . Arguments based on minimum distance reveal that these shortened codes are MDS and hence so are their duals.\nCorollary 7: If r|k, d < r+2δ−1 and equality is achieved in (8), then d ⊥ i = r + i, \t 1 ≤ i ≤ δ − 1.\nIn this section, we study (r, δ) a codes for the case when (r + δ − 1)|n and δ ≤ d. Firstly, for the case when n =\n(r + δ − 1), we will give an explicit construction of a code with all-symbol locality by splitting this time, rows of the parity check matrix of an appropriate MDS code. We will refer to this as the parity-splitting construction. The code so obtained is optimal with respect to (8). We will also state the existence of optimal codes with all-symbol locality without the restriction n = k r (r +δ −1). The proof of this is similar to that of Theorem 17 in [1], and will be omitted for lack of space.\nTheorem 8: Let n = k r (r + δ − 1) and δ ≤ d. Then, for q > n, there exists an explicit and optimal (r, δ) a code over F q .\nProof: Let H be the parity check matrix of an [n, k , d] Reed-Solomon code over F q , where k = k+( k r −1)(δ −1) and d = n−k +1 = n−k +1−( k r −1)(δ −1). Such codes exist if q > n. We choose H (n−k )×n to be a Vandermonde matrix. Let\nWe partition the matrix Q in terms of submatrices as shown below\nwhere Q i , 1 ≤ i ≤ k r are matrices of size δ −1×(r+δ −1). Next consider the code C whose parity check matrix, H, is obtained by splitting the ﬁrst δ − 1 rows of H as follows:\n   \n   \nDue to the Vandermonde structure of H , all rows of H are linearly independent. Thus Rank(H) = n−k +( k r −1)(δ− 1). Thus dim(C) = k − ( k r − 1)(δ − 1) = k. It is also clear from the construction that this code is an (r, δ) a code.\nLet d min be the minimum distance of C. Since any set of columns 2 of H which are linearly dependent are also linearly dependent in H , d min ≥ d = n − k + 1 − ( k r − 1)(δ − 1). But, by (8), we must have d min ≤ d. Hence d min = d.\nRemark 1: In the above construction, let k = ar + b. Let δ k = r − b. Then, it is not hard to see that d = δ + δ k . In particular if r|k, δ k = 0 and hence d = δ.\nB. Existence of Optimal (r, δ) codes with All-Symbol Local- ity\nTheorem 9: Let q > kn k and (r + δ − 1)|n. Then there exists an [n, k, d] linear code over F q with (r, δ) a all-symbol locality, where δ − 1 ≤ d, satisfying\nConsider a (serially) concatenated code (see [8], [9]) having an [n 1 , k 1 , d 1 ] code A as the inner code and an [n 2 , k 2 , d 2 ] code B as the outer code. Clearly, a concatenated code falls into the category of an (r, δ) a code with δ = d 1 , r = n 1 − d 1 + 1. Hence, the bound in (2) applies to concatenated codes as well. Using the fact that a concatenated code has length n = n 1 n 2 , dimension k = k 1 k 2 , we obtain from the results of the present paper, the following upper bound on minimum distance d:\n(35) Well known bounds on the minimum distance of a concate- nated codes are\nIn practice, concatenated codes often employ an interleaver between the inner and outer codes in order to increase the minimum distance [10]. In this case, while the upper bound in (36) no longer holds, the bound in (35) continues to hold.\nThis research is supported in part by the DRDO-IISc Program on Advanced Research in Mathematical Engineering and in part by the NetApp Faculty Fellowship program. The third author is supported by TCS Research Scholarship."},"refs":[{"authors":[{"name":"P. Gopalan"},{"name":"C. Huang"},{"name":"H. Simitci"},{"name":"S. Yekhanin"}],"title":{"text":"On the locality of codeword symbols"}},{"authors":[{"name":"C. Huang"},{"name":"M. Chen"},{"name":"J. Li"}],"title":{"text":"Pyramid codes: Flexible schemes to trade space for access efﬁciency in reliable data storage systems"}},{"authors":[{"name":"M. Blaum"},{"name":"J. Brady"},{"name":"J. Bruck"},{"name":"J. Menon"}],"title":{"text":"EVENODD: an efﬁcient scheme for tolerating double disk failures in RAID architectures"}},{"authors":[{"name":"P. Corbett"},{"name":"B. English"},{"name":"A. Goel"},{"name":"T. Grcanac"},{"name":"S. Kleiman"},{"name":"J. Leong"},{"name":"S. Sankar"}],"title":{"text":"Row-diagonal parity for double disk failure correction"}},{"authors":[{"name":"K. Wei"}],"title":{"text":"Generalized hamming weights for linear codes"}},{"authors":[{"name":"T. Helleseth"},{"name":"T. Klove"},{"name":"I. Levenshtein"},{"name":"O. Ytrehus"}],"title":{"text":"Bounds on the minimum support weights"}},{"authors":[{"name":"C. Huffma"},{"name":"V. Ples"}],"title":{"text":"W"}},{"authors":[{"name":"D. Forney Jr"}],"title":{"text":"Concatenated codes"}},{"authors":[{"name":"I. Dumer"}],"title":{"text":"Concatenated codes and their multilevel generalizations"}},{"authors":[{"name":"S. Benedetto"},{"name":"D. Divsalar"},{"name":"G. Montorsi"},{"name":"F. Pollara"}],"title":{"text":"Serial concate- nation of interleaved codes: Performance analysis, design, and iterative decoding"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565847.pdf"},"links":[{"id":"1569559617","weight":2},{"id":"1569566605","weight":2},{"id":"1569565551","weight":2},{"id":"1569564805","weight":5},{"id":"1569566409","weight":2},{"id":"1569565775","weight":2},{"id":"1569566871","weight":5},{"id":"1569564849","weight":2},{"id":"1569559541","weight":2},{"id":"1569565317","weight":2},{"id":"1569566319","weight":2},{"id":"1569566903","weight":2},{"id":"1569565809","weight":8},{"id":"1569566787","weight":5},{"id":"1569566015","weight":2},{"id":"1569566895","weight":5},{"id":"1569565321","weight":2},{"id":"1569565803","weight":5},{"id":"1569566679","weight":14},{"id":"1569566753","weight":2},{"id":"1569566217","weight":2},{"id":"1569566423","weight":2},{"id":"1569558901","weight":2},{"id":"1569565839","weight":2},{"id":"1569564857","weight":8},{"id":"1569565055","weight":2},{"id":"1569563231","weight":2},{"id":"1569565469","weight":2},{"id":"1569565393","weight":2},{"id":"1569561123","weight":8},{"id":"1569565441","weight":2},{"id":"1569565739","weight":2},{"id":"1569566275","weight":2},{"id":"1569565493","weight":2},{"id":"1569557633","weight":2},{"id":"1569557715","weight":2},{"id":"1569556361","weight":2},{"id":"1569565925","weight":2},{"id":"1569565263","weight":2},{"id":"1569565385","weight":2},{"id":"1569566887","weight":17},{"id":"1569564919","weight":8},{"id":"1569564595","weight":2},{"id":"1569566547","weight":2},{"id":"1569564861","weight":8},{"id":"1569560235","weight":2},{"id":"1569567483","weight":2},{"id":"1569561713","weight":2},{"id":"1569565561","weight":2},{"id":"1569566847","weight":2},{"id":"1569565089","weight":2},{"id":"1569566273","weight":11},{"id":"1569565373","weight":2},{"id":"1569566987","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S16.T1.4","endtime":"12:50","authors":"N Prakash, Govinda M Kamath, V Lalitha, P Vijay Kumar","date":"1341577800000","papertitle":"Optimal Linear Codes with a Local-Error-Correction Property","starttime":"12:30","session":"S16.T1: Coded Storage and Caching","room":"Kresge Rehearsal B (030)","paperid":"1569565847"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
