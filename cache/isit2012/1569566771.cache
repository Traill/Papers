{"id":"1569566771","paper":{"title":{"text":"Quadratic Gaussian Source Broadcast with Individual Bandwidth Mismatches"},"authors":[{"name":"Louis Tan"},{"name":"Ashish Khisti"},{"name":"Emina Soljanin"}],"abstr":{"text":"Abstract\u2014We study the problem of broadcasting a Gaussian source over a Gaussian broadcast channel to two users with individual source-channel bandwidth mis- matches, under a quadratic distortion measure. Speciﬁcally we study the tradeoff between the achievable distortion pairs between the two users. The case when the bandwidth- expansion factors of the two users are identical has been well studied in the literature and to our best knowledge remains an open problem. Surprisingly, when the band- width expansion factors are different, we characterize a range of values where both the users simultaneously attain their point-to-point optimal distortion. Furthermore in the high signal-to-noise ratio regime, this set includes nearly all points where the weaker user has the higher bandwidth expansion factor. In other cases, we propose an achievable tradeoff between the distortion pairs."},"body":{"text":"Consider the problem of sending a bandlimited Gaus- sian source over an additive bandlimited Gaussian noise channel. Suppose that we are unclear about the exact channel noise variance, however we still require that the encoder guarantees certain levels of reconstruction quality depending on the channel noise actually realized when the system is operational. For example, we design a single encoder and require that it achieves a low distor- tion for low noise power while relaxing our requirements and allowing for a higher distortion when experiencing higher noise power. This problem has been treated in the literature by considering a single transmitter that in fact broadcasts simultaneously to multiple receivers, each with different signal to noise ratios [1]\u2013[3]. Given that the source and channel bandwidths are W s and W c (Hz) respectively, we typically sample the source at a rate of 2W s samples per second, and subsequently encode the samples to be sent over the discrete-time Gaussian channels at a rate of 2W c channel uses per\nsecond. The associated bandwidth expansion factor is b = W c /W s channel uses per source sample. Given b and the signal-to-noise ratios, a tradeoff between the achievable distortion pairs at the two users is of interest.\nNow consider a variation on this problem. Imagine that we require a low distortion even when experiencing a weaker channel but we are willing to wait longer, i.e., observe more channel symbols before making a reconstruction. That is, we have the option of trading distortion for delay. In this setup, the transmitter contin- ues broadcasting and each receiver continues listening until the distortion is sufﬁciently small. Such a problem can be modelled as an extension of the model considered in [1]\u2013[3] where each receiver has a different bandwidth expansion factor.\nIn [4] a single server streaming model has been introduced. A server wishes to communicate a source sequence to a group of heterogeneous users over a broad- cast channel. The underlying channels are modelled as erasure channels and each user\u2019s channel has a certain loss probability. Furthermore each user is only interested in retrieving a certain fraction of source packets. The transmitter continuously broadcasts coded packets and each receiver waits until it is able to retrieve sufﬁciently many packets of the underlying source. While the focus in [4] is to optimize the degree distribution of a rateless codes for this application, it can also be formulated as a joint source-channel coding problem for sending a binary source over a binary erasure broadcast channel with an erasure distortion measure [5]. In the present paper we only focus on the Gaussian version of the problem.\nThe problem is illustrated in Fig. 1. We consider a memoryless stationary Gaussian source {S(i)} i=1,2,... producing symbols according to N (0, σ 2 ) , which we wish to communicate to two users. Denote the vector\n(S(1), S(2), . . . , S(k)) as S k . The source is communi- cated by a block encoding function that maps the length k source sequence S k , to a length n channel input sequence X n = (X(1), X(2), . . . , X(n)) where X(l) denotes the l th channel input and X n satisﬁes a power constraint. Note here that our notation deﬁnes X n as the ﬁrst n channel symbols sent.\nLet Y i (l) be the channel output observed by user i on the l th channel use for i ∈ {1, 2} and l = 1, 2, . . . , n. The channel model is given by\nY i (l) = X(l) + Z i (l), \t (1) where Z i (l) is the zero-mean additive Gaussian noise observed at user i\u2019s l th channel output. The channel is memoryless in the sense that Z i (l) is drawn i.i.d. from a N (0, N i ) distribution. Now although the length n channel input is broad- casted to both users, we will assume that due to each user\u2019s delay constraint, the i th user reconstructs the source after observing only the ﬁrst n i channel input symbols, denoted as X n i , where n i ≤ n. Speciﬁcally, we have that n = max(n 1 , n 2 ) . The reconstruction\u2019s ﬁdelity is measured with the squared error distortion\n(s(j) − ˆs(j)) 2 . \t (2) Deﬁnition 1. A (k, P, n 1 , n 2 , D 1 , D 2 ) source-channel code for source S on the Gaussian broadcast channel consists of\n1) An encoding function f k : R k → R n satisfying (1) n = max(n 1 , n 2 ) , (2)X n = f k (S k ) and (3)\n2) Two decoding functions g i : R n i → R k for i ∈ {1, 2} such that Ed(S k , g i (X n i + Z n i i )) ≤ D i holds for i ∈ {1, 2}.\nNow as mentioned in Section I, we associate with the i th user, a delay parameter b i ∈ [0, ∞), called the bandwidth expansion factor. This represents the number of channel uses per source symbol that are delivered over the i th user\u2019s channel. That is, the i th user requires that at most b i · k channel uses be employed on his channel before he reconstructs S k subject to his distortion con- straint. Our problem is now deﬁned as characterizing the achievable distortion region under a given pair of bandwidth expansion factors as per the next deﬁnition.\nDeﬁnition 2. A distortion pair (D 1 , D 2 ) is said to be (b 1 , b 2 ) achievable over the Gaussian broadcast channel under power constraint P , if for every δ > 0 there exists for sufﬁciently large k, a (k, P, b 1 ·k, b 2 ·k, d 1 , d 2 ) source- channel code such that\nD i + δ ≥ d i , i ∈ {1, 2}. \t (3) The achievable distortion region is the set of all\nachievable distortion pairs under the prescribed band- width expansion pair.\nIn this section, we propose several coding schemes that collectively provide an inner bound for the achiev- able distortion region. Assume that N 1 < N 2 . Since the performance of the Gaussian broadcast channel is iden- tical to that of a degraded Gaussian broadcast channel [6, p. 570], we will refer to user 1 as the strong user, and user 2 as the weak user. We specialize our analysis and focus on the case in which both users have bandwidth expanded and the strong user has the more stringent delay constraint, i.e., 1 < b 1 < b 2 . In this case, we will ﬁnd particular values b ∗ 1 and b 2 in Section III-A, for which both users can simultaneously achieve distortions that are point-to-point optimal. In particular, we say that user i achieves his point-to-point distortion at bandwidth expansion factor b i , if he achieves a distortion D ∗ i given by\nwhere (4) is obtained from substituting for the rate distortion and channel capacity functions of the Gaussian source/channel into the separation theorem. Since we will be interested in studying how the distortions of the\nb 1 \t b 1 \t b 2 Analog \t Digital\ntwo users depend on their bandwidth expansion factors, we use a slight abuse of notation and express D ∗ i as a function of only b i . In the following sections, we will parameterize the problem by ﬁxing any arbitrary b 2 , while considering the distortions of both users as we vary b 1 relative to b 2 .\nConsider ﬁrst, the problem of coding entirely for the weak user so that he achieves his point-to-point distor- tion at some b 2 > 1 . We will use a hybrid digital-analog coding scheme as in [1]\u2013[3]. We ﬁrst split our channel block of length n = b 2 k into a lower analog branch and an upper digital branch which are to be concatenated together, i.e., multiplexed in that order in time (see Fig. 2). The digital branch is of blocklength k(b 2 − 1) and contains a coarse description of the source sequence S k . Speciﬁcally, we perform vector quantization of the source at average distortion D Q , which is set so that the quantizer rate is equal to the weak user\u2019s channel capacity on the digital branch, i.e.,\n. (5) Denote the output of the source quantizer as S k Q .\nWe subtract S k Q from the source sequence S k , and the resultant quantization error vector E k , is scaled and sent over the analog branch, which has blocklength k.\nAt the receiver, the weak user demultiplexes the analog and digital branches and ﬁrst recovers the coarse description from the digital branch. He then obtains the linear minimum mean squared error (MMSE) estimate of the quantization error ˆ E k from the analog branch, and reconstructs the source sequence as ˆ S k = S k Q + ˆ E k . It is readily veriﬁed that this scheme is point-to-point optimal for the weak user at b 2 .\nNow consider the strong user as all this transpires. He also demultiplexes the analog and digital branches. That is, he observes the ﬁrst k channel symbols and sets this aside as the analog branch and then observes the next k(b 2 − 1) channel symbols as a digital branch. We note however, that the strong user can actually listen to only k(b ∗ 1 − 1) < k(b 2 − 1) channel symbols after the analog branch and yet still recover the coarse description.\nIn the digital branch, note that the encoder employs a Gaussian codebook composed of 2 k(b 2 −1)C 2 length k(b 2 − 1) codewords whose components are sampled\ni.i.d. from a N (0, P ) distribution, where C 2 is the channel capacity for the weak user, i.e., C 2 = 1 2 log(1 + P/N 2 ) . From the channel coding theorem, it is not hard to see that with arbitrarily small probability of error, the strong user has to listen to only k(b ∗ 1 − 1) channel uses before being able to uniquely identify which codeword was sent by joint-typicality decoding, where b ∗ 1 satisﬁes k(b ∗ 1 − 1)C 1 = k(b 2 − 1)C 2 , i.e.,\nAfter recovering the channel codeword and thus the coarse description, the strong user can perform their own MMSE estimate of the quantization error to achieve a distortion of \t D\nCombining (4), (5), (6) and (7), we have that at b ∗ 1 , the strong user can in fact achieve distortion D 1 = D ∗ 1 (b ∗ 1 ) . Theorem 1. Let b 2 > 1 . Then for some b ∗ 1 satisfying (6), the distortion pair (D 1 , D 2 ) = (D ∗ 1 (b ∗ 1 ), D ∗ 2 (b 2 )) is (b ∗ 1 , b 2 ) achievable.\nAgain, it is worth mentioning that the result of both users achieving their point-to-point distortion in The- orem 1 is not possible in the familiar problem where b 1 = b 2 . Naturally, the question now arises as to what the achievable distortions would be if we deviate from these critical bandwidth expansion factors. We explore this in the next two sections.\nIn this section, we consider the case that the delay of the strong user, b 1 , is even stricter than that given by b ∗ 1 , i.e., 1 < b 1 < b ∗ 1 < b 2 . In this case, we will use a \u201csuccessive reﬁnement\u201d strategy consisting of the coding scheme of Section III-A followed by Wyner-Ziv coding to show that both users can still simultaneously achieve point-to-point optimal distortions.\nNow given that b 1 < b ∗ 1 , we ﬁrst ﬁnd a ˜b 2 satisfying (6) when b ∗ 1 and b 2 are replaced by b 1 and ˜b 2 respectively. In other words, we ﬁnd a ˜b 2 such that k(b 1 − 1)C 1 = k(˜b 2 − 1)C 2 , i.e.,\n(8) Operationally, this is equivalent to employing the\ncoding scheme of Section III-A with a coarse de- scription that achieves distortion ˜ D Q using rate (1/2) log(σ 2 / ˜ D Q ) = (˜b 2 − 1) log(1 + P/N 2 ) . Here ˜b 2 is chosen as in (8) and from Theorem 1, we achieve\nthe point-to-point optimal distortions for both user 1 and user 2 at b 1 and ˜b 2 respectively. To show that we can also be optimal for user 2 at b 2 , we use Wyner-Ziv coding immediately after the coding scheme of Section III-A. Speciﬁcally, after k˜b 2 channel uses, we send a Wyner- Ziv bit stream for the weak user assuming that he has side information at a mean squared error of D ∗ 2 (˜b 2 ) with respect to the source. Note here that we can invoke the upper bound on the quadratic Wyner-Ziv rate-distortion function as in [2], to show that in order to achieve a new distortion of D 2 , a bit stream of rate R WZ (D 2 ) is sufﬁcient, where\n. \t (9) Setting (9) equal to the channel capacity of the weak\nuser\u2019s remaining digital branch, we get that 1\n. (10) Combining (4) and (10) and rearranging for D 2 , we\nhave that after sending the Wyner-Ziv bit stream, we can in fact achieve D 2 = D ∗ 2 (b 2 ) at b 2 .\nTheorem 2. Let b 2 > 1 and let b ∗ 1 satisfy (6) for the choice of b 2 . Then for any b 1 such that 1 < b 1 ≤ b ∗ 1 , the distortion pair (D 1 , D 2 ) = (D ∗ 1 (b 1 ), D ∗ 2 (b 2 )) is (b 1 , b 2 ) achievable.\nAs an interesting aside, from (6) we have that in the limit of high SNR (P  N 1 ), b ∗ 1 = b 2 − o P (1) where o P (1) goes to zero as P → ∞. Theorem 2 then states that we can nearly achieve point-to-point optimality for both users for any b 1 < b 2 under bandwidth expansion. C. An Achievable Tradeoff\nIn this section, we present an achievable tradeoff in distortion pairs for when 1 < b ∗ 1 < b 1 < b 2 . We will again use a hybrid-digital analog scheme, however this time, we will further divide the digital branch (in time) into two regions. Region I will include the channel uses from k to kb 1 while Region II will include the channel uses from kb 1 to kb 2 (see Fig. 3). Following this division, we now view the digital branch analogously to the product of two unmatched degraded broadcast channels [7]. Here, Region I corresponds to a degraded brodcast channel in which user 1 is the stronger user, while Region II corresponds to another broadcast channel in which user 2 is the stronger user and user 1 has inﬁnite noise power. We will use these two broadcast channels to send a common message intended for both users, and a private message intended only for user 1; cf. [2], [3].\nWe denote the common and private message rates, measured in bits per source symbol, as R 0 and R 1\nb 1 \t b ∗ 1 \t b 1 \t b 2 Analog \t I \t II\nrespectively. As the private message is intended only for user 1, we can send it only over Region I. We will dedicate a portion β ∈ [0, 1] of the total power in Region I for this purpose. Speciﬁcally, we set\n. \t (11) The common message is a coarse description of the\nsource. It is sent over both regions, however only a portion (1 − β) of the power in Region I will be used for this purpose while the full power of Region II will be used. Speciﬁcally, we perform vector quantization of the source at an average distortion ˆ D Q , set so that\n. (12) Equation (12) makes it clear that user 2 will be able\nto recover the coarse description by treating the private message as noise in Region I, and then recovering the rest of the message in Region II. In order for user 1 to also recover the message in Region I, we require that\n. \t (13) After each user recovers the coarse description, they\nagain estimate the quantization error over the analog branch, after which, user i can achieve distortion ˜ D i of\n(14) Since this is all we will be sending to the weak\nuser, ˜ D 2 is the ﬁnal distortion user 2 achieves. We will however, send extra Wyner-Ziv bits for user 1 in Region I assuming that he already has side information at distortion ˜ D 1 relative to the source. The extra bits help user 1 achieve a distortion D 1 , where we set D 1 so that the Wyner-Ziv rate equals the private message rate, i.e.,\n(15) Suppose for now that user 1 is to be optimal at b 1 . In\nthis end, deﬁne β 0 as the value of β that accomplishes this. Combining (12) and (13), we have that\nIt can be veriﬁed that 0 < β 0 < 1 whenever 1 < b ∗ 1 < b 1 < b 2 , which is the region of interest and so β 0 is indeed a valid power allocation. Deﬁning the functions D 1 (β) and D 2 (β) as in (16) and (17), after combining (11), (12), (14) and (15) for user 1 and (12) and (14) for user 2, we have that the distortion pair (D 1 (β 0 ), D 2 (β 0 )) is achievable. In particular, since the right hand sides of (12) and (13) are equal when β = β 0 , we can conﬁrm that user 1 is optimal at b 1 for this power allocation.\nLet us now consider the scenario if we did not require user 1 to be optimal at b 1 . To this end, we restrict β by setting β = αβ 0 for some α ∈ [0, 1]. In particular, if α = 1 , we recover β = β 0 as our power allocation, and user 1 is optimal. As we decrease α (and in turn β), we introduce more slackness in (13) until β = 0. This makes the coding identical to that in Section III-A, so that the weak user is optimal. In general, we may achieve a tradeoff in distortions by letting α vary in [0, 1].\nTheorem 3. Let b 2 > 1 and let b ∗ 1 satisfy (6) for the choice of b 2 . Then for any α ∈ [0, 1] and for any b 1 such that 1 < b ∗ 1 < b 1 < b 2 , the distortion pair (D 1 , D 2 ) = ( D 1 (αβ 0 ), D 2 (αβ 0 )) is (b 1 , b 2 ) achievable, where β 0 is given by (18)\nWe remark that as b 1 → b 2 , from (18) we have that β 0 → 1. In this case, Theorem 3 reduces to the achievable scheme proposed in [2]. In light of the results in [3] and [7] we also suggest that the results of this section may be improved by further allocating power amongst the analog and digital branches and sub- branches, introducing a private message to user 2 and optimizing over the boundaries of Regions I and II, however for conciseness, we do not pursue this here. Finally, we mention that the outer bound in [2] using b = max (b 1 , b 2 ) = b 2 , may also be applied here since this bound would be obeyed a fortiori when b 1 < b 2 .\nTheorem 3 completes our coding scheme for any b 1 and b 2 such that 1 < b 1 < b 2 . Fig. 4 plots our achievable\nscheme for the weak user when the strong user is always optimal at b 1 and we vary b 1 relative to a ﬁxed b 2 . As is readily seen, the weak user is also able to achieve an optimal distortion, shown as the dashed line, until a critical bandwidth expansion factor b ∗ 1 . After this critical value, the requirement that the strong user is optimal results in an increasing distortion for the weak user."},"refs":[{"authors":[{"name":"U. Mittal"},{"name":"N. Phamdo"}],"title":{"text":"Hybrid digital-analog (hda) joint source-channel codes for broadcasting and robust communica- tions"}},{"authors":[{"name":"Z. Reznic"},{"name":"M. Feder"},{"name":"R. Zamir"}],"title":{"text":"Distortion bounds for broadcasting with bandwidth expansion"}},{"authors":[{"name":"V. M. Prabhakaran"},{"name":"R. Puri"},{"name":"K. Ramchandran"}],"title":{"text":"Hybrid digital- analog codes for source-channel broadcast of gaussian sources over gaussian channels"}},{"authors":[{"name":"Y. Li"},{"name":"E. Soljanin"},{"name":"P. Spasojevi´c"}],"title":{"text":"Three schemes for wire- less coded broadcast to heterogeneous users"}},{"authors":[{"name":"L. Ta"}],"title":{"text":"MASc"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory, 2nd ed"}},{"authors":[{"name":"A. E. Gamal"}],"title":{"text":"The capacity of the product and sum of two unmatched broadcast channels"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566771.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T2.3","endtime":"12:30","authors":"Louis Tan, Ashish Khisti, Emina Soljanin","date":"1341231000000","papertitle":"Quadratic Gaussian Source Broadcast with Individual Bandwidth Mismatches","starttime":"12:10","session":"S2.T2: Variations on Broadcast Channels","room":"Kresge Auditorium (109)","paperid":"1569566771"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
