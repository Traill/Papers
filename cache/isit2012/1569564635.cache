{"id":"1569564635","paper":{"title":{"text":"Second-Order Achievable Rates in Random Number Generation for Mixed Sources"},"authors":[{"name":"Ryo NOMURA"},{"name":"Te Sun HAN"}],"abstr":{"text":"Abstract\u2014The second-order achievable rates in typical random number generation problems are considered. In these problems, several researchers have derived the ﬁrst-order and the second- order achievability rates for general sources using the informa- tion spectrum methods. Although these formulas are general, their computation are quite hard. Hence, an attempt to address explicit computation problems of achievable rates is meaningful. In this paper, we consider mixed sources of two i.i.d. sources and compute the second-order achievable rates explicitly."},"body":{"text":"The problem of random number generation is one of the main topics in information theory [1]\u2013[3]. There are several problem settings in random number generations. The resolv- ability problem and the intrinsic randomness problem are representative of them. The resolvability problem is formulated as follows [4]. We ﬁrst use the term of \u201cgeneral source\u201d to denote a sequence X = {X n } ∞ n=1 of random variables X n in- dexed by n (taking values in countably inﬁnite sets), typically, n-dimensional random variables. Given an arbitrary general source X = {X n } ∞ n=1 (called the target random number), we generate or approximate it by using a discrete uniform random number whose size is requested to be as small as possible. Han and Verd´u [1], and Steinberg and Verd´u [5] have determined the inﬁma of achievable uniform random number rates by using the information spectrum methods. On the other hand, the intrinsic randomness problem is formulated as follows [2]. Given an arbitrary general source X = {X n } ∞ n=1 (called the coin source), we try to generate or approximate, by using X = {X n } ∞ n=1 , a uniform random number with as large rates as possible. Vembu and Verd´u [2], and Han [4] have determined the suprema of achievable uniform random number generation rates, again by invoking the information spectrum methods. Since the class of general sources is quite large, their results are very basic and quite fundamental. All the formulas established here may be said to be ones of the ﬁrst-order.\nOn the other hand, the ﬁner evaluation of the achievable rates, called the second-order achievable rates, have been in- vestigated in several contexts [6]\u2013[8]. Among others, Hayashi [9] has shown the second-order achievability theorems for the intrinsic randomness problem as well as for the ﬁxed- length source coding problem with general sources, while the second-order resolvability problem for general sources has\nbeen established by Nomura and Han [10]. In particular, for i.i.d. sources [9] has calculated the corresponding second-order optimal achievable rates by using the asymptotic normality in both problems.\nIn this paper, we address the computation problem concern- ing the second-order formulas for resolvability and intrinsic randomness problems for mixed sources. In either the resolv- ability problem or the intrinsic randomness problem the degree of approximation is measured in terms of variational distance. Note that mixed sources are typical cases of nonergodic sources. Nonetheless, we show that we can use still the two-peak asymptotic normality to exploit the second-order achievable rates for mixed sources.\nRelated works include, e.g., Polyanskiy, Poor and Verd´u [11] that has developed the second-order optimal capacity rates for Gilbert-Elliott channel from the viewpoint of a mixture of two memoryless channels.\nWe ﬁrst give the necessary notations and deﬁnitions. In the sequel, let Y = {Y n } ∞ n=1 be a general source with values in countably inﬁnite sets Y n . Let Z be a countably inﬁnite set and let Z, Z be random variables with values in Z. Denote by d(Z, Z) the variational distance\nwhere P X ( ·) denotes the probability distribution of random variable X. Moreover, set U M ≡ {1, 2, · · · , M} and let U M denote the random variable uniformly distributed on U M .\nDeﬁnition 2.1: Rate R is said to be (a, δ)-achievable if there exists a mapping ψ n : U M n → Y n such that\nS r (a, δ |Y) = inf {R |R is (a, δ)-achievable} . Then, we have\nDeﬁnition 2.3: Rate R is said to be (a, δ)-achievable if there exists a mapping ϕ n : Y n → U M n such that\nIn the previous section, we have reviewed the general for- mulas for typical second-order asymptotic problems of random number generation with any general source Y = {Y n } ∞ n=1 .\nHowever, computation of these general formulas is quite hard in general. Therefore, in this section we consider to introduce a class of tractable sources Y for which the general formulas are computable but still of independent interest. One of such source classes would be the case where Y is a mixed source of two i.i.d. sources. In the sequel, we now focus on the computation problem of the second-order asymptotics for mixed sources consisting of two i.i.d. sources.\nLet us begin with the formal deﬁnition of mixed sources. Let Y = {0, 1, · · · } (countably inﬁnite) be a discrete source alphabet and y = y 1 y 2 · · · y n ∈ Y n denote a sequence emitted from the source of length n. Let Y n denote a random variable: a source sequence of length n.\nWe consider a mixed source consisting of two i.i.d. sources Y i = {Y n i } ∞ n=1 , where i = {1, 2}. Then, the mixed source Y = {Y n } ∞ n=1 is deﬁned by\nwhere w(i) are constants satisfying w(1) + w(2) = 1 and w(i) > 0 (i = 1, 2). Since two i.i.d. sources Y i (i = 1, 2) are completely speciﬁed by giving just the ﬁrst component Y i (i = 1, 2), we may write simply as Y i = {Y i } (i = 1, 2) and deﬁne the variances:\nwhere we assume that these variances are ﬁnite, and deﬁne the entropy by H(Y i ) = −\nThe following lemma plays the key role in the sequel including the proofs of Theorem 4.1 and Theorem 5.1.\nLemma 3.1 (Han [4]): Let {z n } ∞ n=1 be any real-valued se- quence. Then for the mixed source Y deﬁned in Section 2, it holds that, for i = 1, 2,\nIn this section we shall establish S r (a, δ |Y) for mixed sources. First, we introduce two fundamental lemmas due to Han [4]: Lemma 4.1 and Lemma 4.2, below.\nBefore describing lemmas, we need to deﬁne two sets. Let X = {X n } ∞ n=1 and Y = {Y n } ∞ n=1 be arbitrary general sources, then, given a sequence {z n } ∞ n=1 , deﬁne S n (z n ) and T n (z n ):\nLemma 4.1: Let X = {X n } ∞ n=1 and Y = {Y n } ∞ n=1 be arbitrary general sources, where X n and Y n are random variables taking values in X n and Y n , respectively. Then, for an arbitrary sequence {z n } ∞ n=1 and γ > 0, there exists a mapping φ n : X n → Y n such that\nLemma 4.2: Let X = {X n } ∞ n=1 and Y = {Y n } ∞ n=1 be arbitrary general sources, where X n and Y n are random variables taking values in X n and Y n , respectively. Then, for an arbitrary sequence {z n } ∞ n=1 , γ > 0 and any mapping φ n : X n → Y n it holds that\nThe above lemmas are useful for the random number generation problem to approximate a probability distribution Y = {Y n } ∞ n=1 by using an another probability distribution X = {X n } ∞ n=1 [4]. Clearly, this problem includes the resolv- ability problem as a special case: the resolvability problem is the case of X n = U M n . So, in this case the condition in the above lemmas leads to\nIn the sequel, we consider the case that 0 ≤ δ < 2 and w(1) = δ 2 hold (cf. Remark 4.1 for the case of w(1) = δ 2 ). Then, given 0 ≤ δ < 2 we divide the problem into three cases. Here, without loss of generality, we assume that H(Y 1 ) ≥ H(Y 2 ) holds:\nII \t H(Y 1 ) > H(Y 2 ) and w(1) > δ 2 hold. III \t H(Y 1 ) > H(Y 2 ) and w(1) < δ 2 hold.\nIn Case I, we shall establish S r (H(Y 1 ), δ |Y) (Obviously, this is equal to S r (H(Y 2 ), δ |Y)). In Case II and Case III we shall show S r (H(Y 1 ), δ |Y) and S r (H(Y 2 ), δ |Y), respectively. Now we have one of the main results:\nTheorem 4.1: Given 0 ≤ δ < 2, the following holds. Case I:\nδ 2\nδ 2\nRemark 4.1: It is easy to check that T 2 = −∞, T 3 = + ∞ for w(1) = δ 2 . Also, it will turn out from the way of proving the above theorem that the second-order asymptotics gets trivial if a = H(Y 1 ) and a = H(Y 2 ), because this case necessarily implies that δ = 0 or δ = 2w(1) or δ = 2, depending on the value of a; then, accordingly, we can formally set as S r (a, δ |Y) = −∞.\nRemark 4.2: Theorem 4.1 can be restated more intuitively but equivalently as follows. Let R n ≡ 1 n log M n denote the size rate of resolvability, and consider the following asymp- totic equation for R n :\nwhere Φ( ·) is the Gaussian cumulative distribution function deﬁned by\nDenote the solution of this equation by R ∗ n = 1 n log M ∗ n and set as\n= δ 2\nThen, it is not difﬁcult to verify by letting n → ∞ that, given a and δ, the corresponding solution b = b ∗ (a, δ) of this equation coincides with T 1 , T 2 and T 3 , respectively, according to Cases I, II, III. Notice here that the equation (5) subsumes Remark 4.1 too. Thus, it is concluded that b ∗ (a, δ) is nothing but the second-order resolvability S r (a, δ |Y), and hence Theorem 4.1 is equivalent to the equation (5).\nwith a = H(Y 1 ) or a = H(Y 2 ) depending on the value of δ, that is, if H(Y 1 ) = H(Y 2 ) then\nwhich enables us to evaluate how large size of M ∗ n is needed as a function of block length n and variational distance δ. Notice here that in this case b ∗ (a, δ) can be written as the simple inverse function Φ −1 of the Gaussian distribution function, and also that b ∗ (a, δ) can be negative, for example, b ∗ (a, δ) < 0 if δ > 1 + w(1), so that in this case the ﬁrst-order δ- resolvability S r (δ |Y) is H(Y 2 ) but the optimal achievable rate R ∗ n approaches it from below. In other words, it is possible to make necessary rates to be below the δ-resolvability at ﬁnite block length n. The nonergodic channel counterpart of these equations has been provided by Polyanskiy, Poor and Verd´u [11], who have observed for the Gilbert Elliott channel the same kind of non-asymptotic phenomena as here.\nLet us now turn to the computation problem of the (a, δ)- intrinsic randomness formula for mixed sources. Without loss of generality, we consider the following three cases:\nII \t H(Y 1 ) > H(Y 2 ) and w(2) > δ 2 hold. III \t H(Y 1 ) > H(Y 2 ) and w(2) < δ 2 hold.\nIn Case I, we shall establish S ι (H(Y 2 ), δ |Y) (Obviously this is equal to S ι (H(Y 1 ), δ |Y)). In Case II and Case III we shall show S ι (H(Y 2 ), δ |Y) and S ι (H(Y 1 ), δ |Y) respectively. Then, we have:\nTheorem 5.1: Given 0 ≤ ∀δ < 2, the following holds. Case I:\nProof: It sufﬁces to proceed in parallel with the arguments as made in the proof of Theorem 4.1, while taking account of the duality between resolvability and intrinsic randomness.\nIn this section, we shall extend our results to more general mixed sources. A mixed source Y = {Y n } ∞ n=1 with general mixture is deﬁned by\nwhere w(dθ) is an arbitrary probability measure on the param- eter space Λ, and Y θ = {Y n θ } ∞ n=1 (θ ∈ Λ) are i.i.d. sources with ﬁnite alphabet.\nWith this deﬁnition, we have the following formal extension of Theorem 4.1:\nTheorem 6.1: For a source Y with general mixture w(dθ) of i.i.d. sources Y θ with ﬁnite alphabet, the optimal size rate R ∗ n = 1 n log M ∗ n is given as the solution for R n of the asymptotic equation:\nand, furthermore, the second-order resolvability S r (a, δ |Y) is given as the solution b = b ∗ (a, δ) of the asymptotic equation\nw(dθ) = δ 2\nProof: The second inequality of Lemma 3.1 is not nec- essarily valid in the case with general mixture. Nevertheless, we can slightly modify it so as to be applicable to this general case. As for the details, see the proof of Han [4, Lemma 1.4.4].\nRemark 6.1: Let us deﬁne the subsets Λ 0 (a) and Λ 1 (a) of Λ as follows:\nIt is easy to see that letting n → ∞ in (6) yields the following non-asymptotic equation to determine the second- order resolvability b = b ∗ (a, δ):\nw(dθ) = δ 2\nwhich implies that a given δ is speciﬁed by the following conditions: If\nw(dθ) = δ 2 (b = −∞); If ∫ Λ 0 (a) w(dθ) > 0 then\nWe have considered the second-order achievability to evalu- ate the ﬁner structure of random number generation for mixed sources. The class of mixed sources is very important, because all of stationary sources can be regarded as forming mixed sources obtained by mixing stationary ergodic sources with respect to a probability measure. However, in general, mixed sources do not have an asymptotic normality. So, our result is also meaningful because we have demonstrated that the analysis based on the two-peak asymptotic normality is still effective also for sources whose self-information spectrum does not have a single asymptotic normality such as sources with general mixture.\nFinally, although throughout this paper, we only consider the mixture of i.i.d. sources, we can extend our results to the general mixture of Markovian sources with ﬁnite alphabet. As for the details, see Nomura and Han [10].\nA simplest way to prove Theorem 4.1 is to ﬁrst apply Theorem 2.1 to the present case of mixed sources and to proceed to the computation of necessary quantities. Here, however, more basically we start along with Lemma 4.1 and Lemma 4.2 in order to reveal the fundamental logic underlying the whole process of random number generation.\nProof of Case I: The proof consists of two parts. 1) Direct Part:\n, where γ > 0 is an arbitrarily small number. Then, trivially it holds that\nThus, it is enough to show that there exists a mapping φ n such that lim sup n →∞ d(φ n (U M n ), Y n ) ≤ δ.\nholds. Thus, from Lemma 4.1 and (3) there exists a mapping φ n such that\nn ) ≤Pr\nMoreover, from Lemma 3.1 and the deﬁnition of the mixed source, there exists a mapping φ n such that\nbecause γ n > 0 is speciﬁed in Lemma 3.1, and so γ n < γ holds for sufﬁciently large n. Then, noting that H(Y 1 ) = H(Y 2 ) holds, we have from the asymptotic normality\nTherefore, Direct Part has been proved. 2) Converse Part:\nWe consider a constant T 1 < T 1 . Assuming that T 1 is (H(Y 1 ), δ)-achievable, we shall show a contradiction. Since we assume that T 1 is (H(Y 1 ), δ)-achievable, there exists a mapping φ n such that lim sup n →∞ d(φ n (U M n ), Y n ) ≤δ, and\nwhich means that there exists a constant γ > 0 satisfying log M n − nH(Y 1 ) √\nholds. Thus, from Lemma 4.2 and (3), for any mapping φ n it holds that\nn ) ≥Pr\nThus, from Lemma 3.1 and the deﬁnition of the mixed source, for any mapping φ n we have\n· w(i) ≥ 2 ∑\n(8) because γ > γ n holds for sufﬁciently large n. Then, by virtue of the asymptotic normality, for i = 1, 2 it holds that\nbecause we can let T 1 + 3γ < T 1 hold by letting γ → 0, and by substituting the above inequality into (8) for any mapping φ n , we have\nThis is a contradiction and the proof has been completed. Proofs of Case II and Case III:\nThe proofs of Case II and Case III are similar to the proof of Case I. Hence, we omit the proofs."},"refs":[{"authors":[{"name":"T. S. Han"},{"name":"S. Verd´u"}],"title":{"text":"Approximation theory of output statistics"}},{"authors":[{"name":"S. Vembu"},{"name":"S. Verd´u"}],"title":{"text":"Generating random bits from an arbitrary source: Fundamental limits"}},{"authors":[{"name":"T. S. Han"}],"title":{"text":"Folklore in source coding: Information-spectrum approach"}},{"authors":[],"title":{"text":"Information-Spectrum Methods in Information Theory"}},{"authors":[{"name":"Y. Steinberg"},{"name":"S. Verd´u"}],"title":{"text":"Simulation of random processes and rate- distortion theory"}},{"authors":[{"name":"I. Kontoyiannis"}],"title":{"text":"Second-order noiseless source coding theorems"}},{"authors":[{"name":"M. Hayashi"}],"title":{"text":"Information spectrum approach to second-order coding rate in channel coding"}},{"authors":[{"name":"Y. Polyanskiy"},{"name":"H. Poor"},{"name":"S. Verd´u"}],"title":{"text":"Channel coding rate in the ﬁnite blocklength regime"}},{"authors":[{"name":"M. Hayashi"}],"title":{"text":"Second-order asymptotics in ﬁxed-length source coding and intrinsic randomness"}},{"authors":[{"name":"R. Nomura"},{"name":"T. S. Han"}],"title":{"text":"Second-order resolvability, intrinsic random- ness, and ﬁxed-length source coding for mixed sources: Information spectrum approach"}},{"authors":[{"name":"Y. Polyanskiy"},{"name":"H. V. Poor"},{"name":"S. Verd´u"}],"title":{"text":"Dispersion of the Gilbert- Elliott Channel"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564635.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S5.T4.1","endtime":"10:10","authors":"Ryo Nomura, Te Sun Han","date":"1341309000000","papertitle":"Second-Order Achievable Rates in Random Number Generation for Mixed Sources","starttime":"09:50","session":"S5.T4: Finite Blocklength Analysis","room":"Stratton 20 Chimneys (306)","paperid":"1569564635"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
