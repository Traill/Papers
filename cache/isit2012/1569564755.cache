{"id":"1569564755","paper":{"title":{"text":"A Berger-Levy Energy Efﬁcient Neuron Model with Unequal Synaptic Weights"},"authors":[{"name":"Jie Xing"},{"name":"Toby Berger"},{"name":"Terrence J. Sejnowski"}],"abstr":{"text":"Abstract\u2014How neurons in the cerebral cortex process and transmit information is a long-standing question in systems neuroscience. To analyze neuronal activity from an information-energy efﬁciency standpoint, Berger and Levy calculated the maximum Shannon mutual information trans- fer per unit of energy expenditure of an idealized integrate- and-ﬁre (IIF) neuron whose excitatory synapses all have the same weight. Here, we extend their IIF model to a biophysically more realistic one in which synaptic weights are unequal. Using information theory, random Poisson measures, and the maximum entropy principle, we show that the probability density function (pdf) of interspike interval (ISI) duration induced by the bits per joule (bpj) maximizing pdf f Λ (λ) of the excitatory postsynaptic potential (EPSP) intensity remains equal to the delayed gamma distribution of the IIF model. We then show that, in the case of unequal weights, f Λ (·) satisﬁes an inhomogeneous Cauchy-Euler equation with variable coefﬁcients for which we provide the general solution form."},"body":{"text":"The human brain, only two percent of the body\u2019s weight, accounts for twenty percent of the body\u2019s energy consumption[2][3]. Brains have evolved that prodigiously compute and communicate information with remarkable efﬁciency. Energy minimization subject to functional con- straints is a unifying principle[4]. Information theory often has been employed in neuroscientiﬁc data interpretation and system analysis during the last ﬁfty years [5][6] [7][8]. However, energy-efﬁcient neural codes have been studied for less than two decades [9][10][11]. Evidence for energy efﬁciency has been reported for ion channels [4], photore- ceptors [12], retina [13] [14], and cortex [15] [16]. Laughlin and Sejnowski discussed the cortex as a communicating network from an energy efﬁciency perspective [17]; Mitchi- son et al. and Chklovskii et al. applied energy efﬁciency to analyze cortical wiring and brain mapping [18][19]; Berger and Levy proposed an energy efﬁcient mathematical model for information transmission by a single neuron [1].\nThe goal of this paper is to ﬁnd the capacity-achieving input distribution of incoming EPSP intensity for an ex- tended Berger-Levy model in which their synapses have unequal weights, and the distribution of the output ISI durations that results from said capacity-achieving input distribution. Our main and perhaps striking result is that the same gamma distribution of ISI durations that Berger and\nLevy found resulted from the energy constrained capacity- achieving input distribution when the synaptic weights all were assumed to be equal continues to apply when these weights are allowed to be unequal. Also, we show that the optimal EPSP intensity for the case of unequal synaptic weights, which differs from its ﬁxed-weight counterpart, is the solution of an inhomogeneous Cauchy-Euler equation with variable coefﬁcients.\nWe ﬁrst introduce a mathematical framework for how a single neuron stochastically processes and communicates information. Let us call the cortical neuron being modeled \u201cneuron j\u201d, or simply \u201cj\u201d. Let W k = (W 1 , ..., W M k ), where W l is the weight of lth synapse of j to receive a spike during the kth ISI and produce an EPSP in response thereto. We time-order the EPSP\u2019s according to the times at which they arrive at the somatic membrane and hence contribute to j\u2019s PSP accumulation. M k is the integer- valued random cardinality of W k .\nWe inherit from the B-L neuron model [1] the as- sumption that the only synaptic responses that j sums when generating its spikes are those of its excitatory synapses, the net strength of j\u2019s inhibitory inputs serving only to scale this summation. However, we no longer assume that all of j\u2019s excitatory synapses have the same weight. Rather, we assume that the components of W k are chosen independent and identically distributed (i.i.d.) according to a certain cumulative distribution function (cdf) F W (w) = P [W ≤ w], 0 ≤ w < ∞. We model the lth contribution to j\u2019s EPSP accumulation to be W l · u(t − t l ); here, W l is a random variable (r.v.) with the aforementioned\ncdf F W (w) and u(t − t l ) equals 1 for t ≥ t l and equals 0 for t < t l . We continue to assume as in [1] that each of j\u2019s refractory periods has the same duration, ∆. Since this theoretical extension connects the plasticity of a neuron\u2019s synaptic weights, widely considered essential to learning and memory, with the communication of information by the neuron, it may possess considerable practical signiﬁcance [20].\nSlightly differently from [1], we model the EPSP\u2019s produced in response to spikes from j\u2019s afferent cohort as an inhomogeneous Poisson measure with instantaneous rate function, A(t), deﬁned by\ndt \t . (1) Then as in [1] we take a time average operation over the rate function A(t) and obtain\nwhere ∆ is the duration of j\u2019s refractory period, T k is the kth ISI duration of j and S k = T 1 + · · · + T k .\nHenceforth, we suppress the ISI index k and just write W , M , T and Λ. Thus, when Λ = λ, EPSP\u2019s are being assumed to arrive according to a homogeneous Poisson process with intensity λ.\nHere we are interested in the Shannon mutual informa- tion, I(Λ; T ). Although this has been deﬁned for a single pair of r.v.\u2019s Λ and T , it has been shown that it is a good ﬁrst-order approximation to the long term information in bits per spike, namely\nlacking only an information decrement that addresses cor- relation among successive Λ i \u2019s; see [1].\nSince T − ∆ is a one-to-one function of T , we have I(Λ; T ) = I(Λ; T − ∆), which in turn is deﬁned [21] [22] as\nwhere the expectation is taken with respect to the joint distribution of Λ and T .\nToward determining I(Λ; T ), we proceed to analyze f T −∆|Λ (t|λ) and f T −∆ (t) in cases with unequal synaptic weights.\nEven if the excitatory synaptic weights of neuron j were known, W = (W 1 , ..., W M ) would still be random because the time-ordered vector R of synapses excited during an ISI is random. However, for purposes of mathematical analysis of neuron behavior it is not fruitful to restrict attention to a particular neuron with a known particular set of synaptic weights. Rather, it is more useful to think in terms of the histogram of the synaptic weight distributions of neurons in whatever neural region is being investigated. When many such histograms have been ascertained, if their shapes almost all resemble one another closely, then they can be\narithmetically averaged to obtain a population histogram with ﬁne resolution in the weights of its synaptic bins. This, in turn, would permit one to approximate this ﬁne histogram by a continuous amplitude probability distri- bution of synaptic weights. (Then the analysis becomes more widely applicable than if one were to have used the exact weights of a particular neuron, especially considering that even that neuron will have a different set of weights in the future because of ongoing synaptic modiﬁcation.) Moreover, the strong similarity of the synaptic weight distributions has been observed through experiments.[20] Therefore, in the analysis that follows we take the view that the components of W are selected randomly from this continuous amplitude probability distribution. Said random distribution of synaptic weights also incorporates the random number of neurotransmitter-containing vesicles that are released when a spike is afferent to the synapse, the random number of neurotransmitter molecules in these vesicles, how many of those cross the synaptic cleft, bind to receptors and thereby generate EPSP\u2019s.\nThis model of random selection of weights comprising W is applicable both to ISI\u2019s in which the afferent ﬁring rate Λ is large and to those in which it is small. When the value λ assumed by Λ is large, W \u2019s components just get selected more rapidly than when λ is small, but they continue to come from the same distribution. This implies that the expected number of them in a single ISI remains the same. Hence, from now on, we assume that the weight vector components W 1 , ..., W M are jointly independent of Λ.\nWe denote the spiking threshold by θ. The contribution to j\u2019s PSP accumulation attributable to the lth afferent spike during an ISI will be assumed to be a randomly weighted step function W l · u(t − t l ), where t l is the time at which it arrives at the postsynaptic membrane. 1\nIt follows that the probability P m = P (M = m) that exactly m PSP\u2019s are afferent to j during an ISI is\nwhere (6) holds because of the assumption that W = (W 1 , ..., W M ) is independent of Λ, which implies its random cardinality, M , is independent of Λ.\nIt follows as in [1] that, given M = m and Λ = λ, T −∆ is the sum of m i.i.d. exponential r.v.\u2019s with parameter λ, i.e., a gamma pdf with parameters m and λ. Summing over all the possibilities of M and letting dt become inﬁnitesimally small, we obtain\nIt is impossible to determine P m in the general case. However, we have been able to compute it exactly in the special case of an exponential weight distribution.\nSuppose the components of the weight vector are i.i.d. and have the exponential pdf αe −αw i , w i ≥ 0 with α > 0.\nThen we know that Y m := W 1 + · · · + W m has the gamma pdf\nαθλt) where I 0 is the modiﬁed Bessel function of the ﬁrst kind with order 0 [23].\nFor the conditional pdf f T −∆|Λ (t|λ) as in (7), letting X = λ(T − ∆), we have the following equality\nNote that λ not only doesn\u2019t explicitly appear on the right-hand side of Eq. (10) but also does not appear there implicitly within any of the P m \u2019s; this is because, as noted earlier, M is independent of Λ, so P m = P (M = m) cannot be λ-dependent. Accordingly,\nHence, although X equals Λ(T − ∆), X nonetheless is independent of Λ. 2 We can rewrite the relationship as\nwhere X is marginally distributed according to Eq. (11). Then by taking logarithms in Eq. (12), we have\nWe see that (13) describes a channel with additive noise that is independent of the channel input. Speciﬁcally, the output is log(T − ∆), the input is − log Λ, and the additive noise is N := log X, which is independent of Λ (and therefore independent of − log Λ) because X and Λ are independent of one another.\nSince f Z (z) = f T −∆ (t)|dt/dz| = f T −∆ (t) · t, it ﬁnally follows that\nThus, after substituting Eq. (15) into Eq. (14) and adding the information decrement term as in [1], the long term average mutual information rate, I, we seek to maximize over the choice of f Λ (·) is\nSince N is independent of Λ, the choice of f Λ (·) affects I in Eq. (17) only through f T − (·) via the following equation\nTherefore, our bpj maximizing task has been reduced to maximizing the entropy rate h(T ) subject to Lagrange multiplier constraints on information decrement, E log T , and energy constraint ET which can be written as C 0 (1 + bT ) [1]. Taking C 0 as the energy unit, we have b as the coefﬁcient of ET . It is known that the entropy h(T ) is maximized subject to constraints on E log T and ET when\nT is a delayed gamma distribution with two parameters we denote by κ and b, i.e.,\nwhich is the bpj-maximizing distribution of neuron j\u2019s ISI duration, T , sans its refractory period which always has duration ∆.\nThe integral equation below relates the following three quantities:\n1) The to-be-optimized pdf f Λ (λ) of the arithmetic mean of the net afferent excitation of neuron j during an ISI.\n2) The conditional pdf f T − |Λ (t|λ) of j\u2019s encoding of Λ into the duration T of said ISI.\nLet\u2019s ﬁrst consider a case in which P m is nonzero only for two consecutive values of m, say n and n + 1 with respective probabilities P n = p and P n+1 = 1 − p := q. In such a case\nSubstituting Eq. (22) into Eq. (23) and applying integration by parts and inverse Laplace transform on Eq. (23), it follows that\nEq. (24) constitutes a conversion of the integral equa- tion (23) for the maximum-bpj excitation intensity f Λ (λ), into a ﬁrst-order linear differential equation. The differen- tial equation has a λ-varying coefﬁcient on its f term. Nonetheless, it has an explicit analytical solution because there exists a general solution to any inhomogeneous ﬁrst- order linear differential equation with variable coefﬁcients.\nIn general, Eq. (24) turns out to be an inhomogeneous Cauchy-Euler equation with variable coefﬁcients as Eq. (25).\nEq. (25) also has an analytical closed-form solution, which serves as the bpj-maximizing pdf of neuron j\u2019s averaged afferent excitation intensity Λ.\nWe have shown that, when neuron j is designed to maximize bits conveyed per joule expended, even though j\u2019s synapses no longer are being required to all have the same weight, the pdf of the ISI durations continues to be exactly the same gamma pdf as it was in [1] wherein all the weights were assumed to be equal. This happens despite the fact that the conditional distribution for T given Λ is now a mixture of gamma distributions instead of the pure gamma distribution that characterizes the special case of equal weights.\nAdditionally, we have implicitly determined the optimal distribution f Λ (λ) that characterizes the afferent excitation intensity by (1) maximizing the Shannon mutual informa- tion rate given a constraint on the total energy cost that a cortical neuron expends for metabolism, postsynaptic potential accumulation, and action potential generation and propagation during one ISI; (2) converting the integral equation to a differential equation with a closed-form solution.\nThe energy efﬁciency of the human brain in terms of information processing is astonishingly superior to that of man-made machines. By extending the Berger-Levy information-energy efﬁcient neuron model to an unequal synaptic weights case, the theory comes into closer cor- respondence with the actual neurophysiology of cortical networks, which might pave the way to wider applications in neuroscience and engineering."},"refs":[{"authors":[{"name":"T. Berge"},{"name":"W. B. Lev"}],"title":{"text":"A mathematical theory of energy efﬁcient neural computation and communication , IEEE Trans"}},{"authors":[{"name":"J. M. Kinne"},{"name":"H. N. Tucke"}],"title":{"text":"Clintec International Inc, Energy Metabolism: Tissue Determinants and Cellular Corollaries (Raven, New York) , p xvi, 1992"}},{"authors":[{"name":"L. C. Aiell"},{"name":"P. Wheele"}],"title":{"text":"The expensive-tissue hypothesis\u2013the brain and the digestive-system in human and primate evolution , Curr Anthropol 36:199-221,1995"}},{"authors":[{"name":"A. Hasenstau"},{"name":"S. Ott"},{"name":"E. Callawa"},{"name":"T. J. Sejnowsk"}],"title":{"text":"Metabolic cost as a unifying principle governing neuronal biophysics , Proc Natl Acad Sci USA 107: 12329-12334, 2010"}},{"authors":[{"name":"D. M. MacKa"},{"name":"W. S. McCulloc"}],"title":{"text":"The limiting information capacity of a neuronal link , Bulletin of Mathematical Biophysics, vol"}},{"authors":[{"name":"W. S. McCulloc"}],"title":{"text":"An upper bound on the informational capacity of a synapse , In Proceedings of the 1952 ACM national meeting, Pittsburgh, Pennsylvania"}},{"authors":[{"name":"R. R. de Ruyter van Steveninc"},{"name":"W. Biale"}],"title":{"text":"Real-time performance of a movement-sensitive neuron in the blowﬂy visual system: Coding and information transfer in short spike sequences , Proceedings of the Royal Society Series B, Biological Sciences, 234, 379-414, 1988"}},{"authors":[{"name":"W. Biale"},{"name":"F. R. Riek"},{"name":"R. R. de Ruyter van Steveninc"},{"name":"D. Warlan"}],"title":{"text":"Reading a neural code, Science, 252,1854-7, 1991"}},{"authors":[{"name":"W. B. Lev"},{"name":"R. A. Baxte"}],"title":{"text":"Energy efﬁcient neural codes, Neural Comput 8:531-543, 1996"}},{"authors":[{"name":"W. B. Lev"},{"name":"R. A. Baxte"}],"title":{"text":"Energy-efﬁcient neuronal computation via quantal synaptic failures , J Neurosci 22:4746-4755, 2001"}},{"authors":[{"name":"V. Balasubramania"},{"name":"D. Kimbe"},{"name":"M. J. Berr"}],"title":{"text":"Metabolically efﬁcient information processing , Neural Comput 13:799-815, 2001"}},{"authors":[{"name":"J. E. Nive"},{"name":"I. C. Anderso"},{"name":"S. B. Laughli"}],"title":{"text":"Fly photoreceptors demonstrate energyinformation trade-offs in neural coding , PLoS Biol 5:e116, 2007"}},{"authors":[{"name":"V. Balasubramania"},{"name":"M. J. Berr"}],"title":{"text":"A test of metabolically efﬁcient coding in the retina , Network 13:531-552, 2002"}},{"authors":[{"name":"S. B. Laughli"},{"name":"R. R. de Ruyter van Steveninc"},{"name":"C. Anderso"}],"title":{"text":"J"}},{"authors":[{"name":"D. Attwel"},{"name":"S. B. Laughli"}],"title":{"text":"An energy budget for signaling in the grey matter of the brain , J Cereb Blood Flow Metab 21:1133-1145, 2001"}},{"authors":[{"name":"B. D. Willmor"},{"name":"J. A. Maze"},{"name":"J. L. Gallan"}],"title":{"text":"Sparse coding in striate and extrastriate visual cortex , J Neurophysiol, 105(6):2907- 19, 2011"}},{"authors":[{"name":"S. B. Laughli"},{"name":"T. J. Sejnowsk"}],"title":{"text":"Communication in neuronal net- works , Science 301:1870, 2003"}},{"authors":[{"name":"G. Mitchiso"}],"title":{"text":"Neuronal branching patterns and the economy of cortical wiring , Proc Biol Sci 245:151-158, 1991"}},{"authors":[{"name":"D. B. Chklovski"},{"name":"A. A. Koulako"}],"title":{"text":"Maps in the brain: What can we learn from them , Annu Rev Neurosci 27:369-392, 2004"}},{"authors":[{"name":"B. Barbou"},{"name":"N. Brune"},{"name":"V. Haki"},{"name":"J. Nada"}],"title":{"text":"What can we learn from synaptic weight distributions?"}},{"authors":[{"name":"T. Cove"},{"name":"J. Thoma"}],"title":{"text":"Elements of Information Theory, 2nd ed"}},{"authors":[{"name":"R. G. Gallage"}],"title":{"text":"Information Theory and Reliable Communication, New York: Wiley, 1968"}},{"authors":[{"name":"I. S. Gradshtey"},{"name":"I. M. Ryzhi"},{"name":"A. Jeffre"},{"name":"D. Zwillinger"}],"title":{"text":"Table of Integrals, Series, and Products , Edited by   Academic Press, New York, 7th edition, 8"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564755.pdf"},"links":[{"id":"1569559617","weight":4},{"id":"1569564481","weight":2},{"id":"1569566081","weight":4},{"id":"1569565355","weight":2},{"id":"1569564245","weight":2},{"id":"1569566119","weight":4},{"id":"1569566459","weight":4},{"id":"1569563411","weight":2},{"id":"1569562685","weight":4},{"id":"1569556091","weight":2},{"id":"1569565347","weight":4},{"id":"1569565953","weight":2},{"id":"1569566889","weight":2},{"id":"1569564613","weight":2},{"id":"1569566095","weight":2},{"id":"1569555999","weight":2},{"id":"1569566643","weight":4},{"id":"1569567665","weight":2},{"id":"1569561795","weight":2},{"id":"1569566851","weight":2},{"id":"1569565915","weight":6},{"id":"1569553519","weight":2},{"id":"1569566425","weight":2},{"id":"1569566909","weight":2},{"id":"1569565633","weight":4},{"id":"1569564851","weight":4},{"id":"1569565469","weight":2},{"id":"1569565357","weight":2},{"id":"1569562207","weight":2},{"id":"1569567033","weight":2},{"id":"1569565463","weight":2},{"id":"1569564339","weight":2},{"id":"1569565439","weight":6},{"id":"1569566901","weight":2},{"id":"1569566805","weight":2},{"id":"1569566873","weight":2},{"id":"1569566129","weight":4},{"id":"1569565865","weight":2},{"id":"1569564305","weight":2},{"id":"1569566595","weight":4},{"id":"1569558779","weight":2},{"id":"1569567483","weight":2},{"id":"1569565367","weight":4},{"id":"1569564281","weight":2},{"id":"1569565805","weight":4},{"id":"1569566147","weight":2},{"id":"1569565035","weight":2},{"id":"1569565337","weight":6},{"id":"1569565889","weight":2},{"id":"1569566413","weight":2},{"id":"1569566375","weight":2},{"id":"1569566449","weight":4},{"id":"1569551541","weight":2},{"id":"1569566839","weight":4},{"id":"1569565895","weight":2},{"id":"1569564419","weight":4},{"id":"1569566417","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S16.T9.2","endtime":"12:10","authors":"Jie Xing, Toby Berger, Terrence J. Sejnowski","date":"1341575400000","papertitle":"A Berger-Levy Energy Efficient Neuron Model with Unequal Synaptic Weights","starttime":"11:50","session":"S16.T9: Information Theory in Biology","room":"Stratton West Lounge (201)","paperid":"1569564755"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
