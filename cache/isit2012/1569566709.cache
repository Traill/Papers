{"id":"1569566709","paper":{"title":{"text":"Action Dependent Strictly Causal State Communication"},"authors":[{"name":"Chiranjib Choudhuri"},{"name":"Urbashi Mitra"}],"abstr":{"text":"Abstract\u2014Channels with action-dependent states are consid- ered: given the message to be communicated, the transmitter chooses an action sequence that affects the formation of the channel states, and then creates the channel input sequence based on the observed state sequence. The capacity\u2013distortion tradeoff of such a channel is characterized for the case when the state information is available strictly causally at the channel encoder. The problem setting extends the action dependent framework of [1] and as a special case recovers the results of few previously considered joint communication and estimation scenarios in [2], [3], [4]. The scenario when the action is also allowed to depend on the past observed states is also considered and it has been shown that such adaptive action helps in achiveing a better capacity\u2013 distortion function."},"body":{"text":"In this work, we consider a communication system where encoding is in two parts: given the message, an action se- quence is created. The actions affect the formation of the chan- nel states, which are accessible to the transmitter in strictly causal manner when producing the channel input sequence. A channel with action-dependent states then is characterized by the distribution of state given an action p(s|a) and the distribution of the channel output given the input and state p(y|x, s). We are interested in the scenario when in addition to communicating pure information across the channel, the transmitter also wishes to help reveal the channel state to the receiver. We characterize the tradeoff between the independent information rate and the accuracy of estimation of the chan- nel state via the capacity-distortion function (ﬁrst introduced in [2]). Our problem formulation is motivated is motivated by a wide array of applications: active classiﬁcation [5], underwater path planning [6], [7], data storage over memory with defects [8], [9], dynamic spectrum access systems [10], just to name a few. Each of these problems can be expressed as a problem of conveying action dependent state to the destination. For example, an autonomous vehicle performing a active classiﬁcation task has control over how it views the environment or state S. The vehicle could take actions such as change its position, modify parameters on its sensor, or even manipulate the environment to improve its view. Also the autonomous vehicle is able to take actions adaptively by\nmodifying its plan as new information from viewing the object becomes available.\nChannel with action-dependent states was introduced in [1] and the capacity of such a channel both for the case where the channel inputs are allowed to depend non-causally on the state sequence, and that where they are restricted to causal dependence are also characterized in [1]. We underscore that our goals herein not only subsumes those of [1], where the determination of channel capacity was the focus, but since there is a natural tension between sending pure information (message) and revealing the channel state, a different approach is required to characterize the tradeoff as the coding strategy optimal for achiveing capacity may not be a good code for state estimation.\nOur problem framework can also be thought of as an extension of [11], [2], [3], [4], as conditioned on the action sequence the channel is equivalent to the one they study. So the role of the action sequence in our framework is not only to communicate the message, but also to setup a good commu- nication channel for both pure information transmission and state estimation. In fact we show that a two stage encoding scheme is optimal, where in the ﬁrst stage the message is communicated through the action sequence and then condi- tioned on the action sequence, a block Markov strategy similar to the one in [3] is capacity\u2013distortion optimal. We showed that although strictly causal CSI is not useful to increase the capacity, but it helps the receiver to get a better estimate of the channel state. We also quantitatively characterize the beneﬁts of feedback of the past states at the action stage. Beyond merely generalizing previously considered problems involving coding with states known at the transmitter, we show that this adaptive action framework captures scenarios considered in [12], [13] pertaining to multiple access channels (MAC) with states.\nThe rest of this paper is organized as follows. Section II describes the basic channel model with discrete alphabets, characterizes the capacity\u2013distortion function, establishes its achievability and proves the converse part of the theorem. Section III extends the results to the adaptive action setting, wherein we allow the feedback from the past states to the action encoder. Section IV illustrates our results with few examples. Finally, Section V concludes the paper.\nThroughout the paper, we closely follow the notation in [14]. In particular, For X ∼ p(x) and ∈ (0, 1), we deﬁne the set of -typical n-sequences x n (or the typical set in short) [15]\nFinally, C(x) = (1/2) log(1 + x) denotes the Gaussian capacity function.\nWe assume a discrete memoryless channel (DMC) with discrete memoryless state (DMS) model (X × S × A, p(y|x, s)p(s|a), Y) that consists of a ﬁnite input alphabet X , a ﬁnite output alphabet Y, a ﬁnite state alphabet S, a ﬁnite action alphabet A and a collection of conditional pmfs p(y|x, s) on Y. The channel is memoryless in the sense that, without feedback, p(y n |x n , s n ) = n i=1 p Y |X,S (y i |x i , s i ), and given the action sequence, the state is memoryless in the sense that (S 1 , S 2 , . . .) is independent and identically distributed (i.i.d.) with S i ∼ p S (s i |a i ).\nA (2 nR , n) code for strictly causal action dependent state communication consists of\n\u2022 an action encoder that assigns an action sequence a n (m) ∈ A n to each message m ∈ [1 : 2 nR ]\n\u2022 a channel encoder that assigns a symbol x i (m, s i−1 ) ∈ X to each message m ∈ [1 : 2 nR ] and past state sequence s i−1 ∈ S i−1 for i ∈ [1 : n], and\n\u2022 a decoder that assigns a message estimate ˆ m ∈ [1 : 2 nR ] (or an error message e) and a state sequence estimate ˆ s n ∈ ˆ S n to each received sequence y n ∈ Y n .\nWe assume that M is uniformly distributed over the message set. The average probability of error is deﬁned as P (n) e = P{ ˆ M = M }. The ﬁdelity of the state estimate is measured by the expected distortion\nwhere d : S × ˆ S → [0, ∞) is a distortion measure between a state symbol s ∈ S and a reconstruction symbol ˆ s ∈ ˆ S. Without loss of generality, we assume that for every symbol s ∈ S there exists a reconstruction symbol ˆ s ∈ ˆ S such that d(s, ˆ s) = 0. A rate\u2013distortion pair is said to be achiev- able if there exists a sequence of (2 nR , n) codes such that lim n→∞ P (n) e = 0 and lim sup n→∞ E d(S n , ˆ S n ) ≤ D. The capacity\u2013distortion function C A SC (D) is the supremum of the rates R such that (R, D) is achievable.\nWe characterize this optimal tradeoff between information transmission rate (capacity C) and state estimation (distortion D) as follows.\nTheorem 1: The capacity\u2013distortion function for strictly causal action dependent state communication is\nwhere the maximum is over all conditional pmfs p(a)p(x|a)p(u|x, s, a) and function ˆ s(u, x, a, y) such that E(d(S, ˆ S)) ≤ D and I(U, X; Y |A) − I(U, X; S|A) ≥ 0.\nRemark 1: It might sometimes be natural to consider chan- nels of the form p(y|s, x, a). The capacity\u2013distortion expres- sion remains unchanged for this more general channel model. This follows directly by deﬁning a new state S = (S, A) and applying the above characterization.\nRemark 2: When both the sender and the receiver is obliv- ious of the channel state, the capacity\u2013distortion function for action dependent state communication can be obtained by choosing U = ∅ and is given by,\nwhere the maximum is over all conditional pmfs p(a)p(x) and function ˆ s(x, a, y) such that E(d(S, ˆ S)) ≤ D.\nBefore proving the Theorem 1, we recall a lemma and summarize a few useful properties of C A SC (D) (similar to the [3, Corollary 1]).\nLemma 1: Suppose Z → V → W form a Markov chain and d(z, ˆ z) is a distortion measure. Then for every reconstruc- tion function ˆ z(v, w), there exists a reconstruction function ˆ z ∗ (v) such that\nThis lemma traces back to Blackwell\u2019s notion of channel ordering [16], [17] and can be interpreted as a data processing inequality for estimation .\nCorollary 1: The capacity-distortion function C A SC (D) in Theorem 1 has the following properties:\n(1) C A SC (D) is a non-decreasing concave function of D for all D ≥ D ∗ ,\nwhere D ∗ is the minimum distortion with strictly causal channel state at the sender akin to the zero rate case in [3].\nWe use b transmission blocks, each consisting of n symbols. The channel encoder uses rate-splitting technique, whereby in block j, it appropriately allocates it\u2019s rate between cooperative transmission of common message m j and a description of the state sequence S n (j − 1) in block j − 1.\nCodebook \t generation. Fix a conditional pmf p(a)p(x|a)p(u|x, s, a) and function ˆ s(u, x, y, a) that attain C A SC (D/(1 + )), where D is the desired distortion, and let p(u|x, a) = s p(s|a)p(u|x, s, a). For each j ∈ [1 : b],\nrandomly and independently generate 2 nR sequences a n (m j ), m j ∈ [1 : 2 nR ], each according to n i=1 p A (a i ) and for each a n (m j ), generate 2 nR S sequences x n (m j , l j−1 ), m j ∈ [1 : 2 nR ], l j−1 ∈ [1 : 2 nR S ], each according to\np X|A (x i |a i ). For each m j ∈ [1 : 2 nR ], l j−1 ∈ [1 : 2 nR S ], randomly and conditionally independently generate 2 n ˜ R S sequences u n (k j |m j , l j−1 ), k j ∈ [1 : 2 n ˜ R S ], each according to \t n i=1 p U |X,A (u i |x i (m j , l j−1 ), a i (m j )). Partition the set of indices k j ∈ [1 : 2 n ˜ R S ] into equal-size bins B(l j ) = [(l j −1)2 n( ˜ R S −R S ) +1 : l j 2 n( ˜ R S −R S ) ], l j ∈ [1 : 2 nR S ]. The codebook is revealed to the both encoder and the decoder. Encoding. By convention, let l 0 = 1. At the end of block j, the sender ﬁnds an index k j such that\nIf there is more than one such index, it selects one of them uniformly at random. If there is no such index, it selects an index from [1 : 2 n ˜ R S ] uniformly at random. In block j + 1, the action encoder chooses the action sequence a n (m j+1 ), where m j+1 is the new message index to be sent in block j + 1. Let s n (j + 1) be the channel state sequence generated in response to the action sequence. The channel encoder then transmits x n (m j+1 , l j ) over the state dependent channel in block j + 1, where l j is the bin index of k j .\nDecoding. Let \t > . At the end of block j + 1, the receiver ﬁnds the unique index ˆ m j+1 , ˆ l j such that (x n ( ˆ m j+1 , ˆ l j ), y n (j + 1), a n ( ˆ m j+1 )) ∈ T (n) . It then looks for the unique compression index ˆ k j ∈ B(ˆ l j ) such that (u n (ˆ k j | ˆ m j , ˆ l j−1 ), x n ( ˆ m j , ˆ l j−1 ), a n ( ˆ m j ), y n (j)) ∈ T (n) and ˆ k j ∈ B(ˆ l j ). Finally it computes the reconstruction sequence as ˆ s i (j) = ˆ s(u i (ˆ k j | ˆ m j , ˆ l j−1 ), x i ( ˆ m j , ˆ l j−1 ), a i ( ˆ m j ), y i (j)) for i ∈ [1 : n].\nFollowing the analysis of capacity\u2013distortion function in [3], it can be easily shown that the scheme can achieve any rate up to the capacity-distortion function given in Theorem 1.\nWe need to show that given any sequence of (2 nR , n)-codes with lim n→∞ P (n) e = 0 and E(d(S n , ˆ S n )) ≤ D, we must have R ≤ C A SC (D). We identify the auxiliary random variables U i := (M, S i−1 , Y n i+1 , A n\\i ), i ∈ [1 : n] with (S 0 , Y n+1 ) = (∅, ∅). Note that, as desired, (U i , A i ) → (X i , S i ) → Y i form a Markov chain. Consider\nwhere (a) can be shown by Fano\u2019s inequality [18, Theorem 7.7.1], (b) follows from the Csis´ zar sum identity [14, Sec. 2.3] and since A n is a function of M , (c) follows from the fact that given A i , (M, S i−1 , A n\\i ) is independent of S i , and (d) is true as X i is a function of (M, S i−1 ). Similarly, for this choice of U i ,\nwhere (a) follows from the deﬁnition of capacity-distortion function, (b) follows by the concavity of C A SC (D) (see Property 1 of Corollary 1), and (c) can be shown using Lemma 1 and Corollary 1. This completes the proof of Theorem 1.\nIt is natural to wonder whether \u201cfeedback\u201d from the past states at the action stage (a i (m, s i−1 )) increases the capacity- distortion function or not. For an extreme example, consider a channel for which p(y|s, x, a) = p(y|s, a). Clearly, the capacity\u2013distortion function for any such channel with only\nmessage dependent non-adaptive action (a n (m)) is same as that of no CSI, since the action encoder is oblivious of the channel state. But with adaptive action, the action encoder can perform block Markov strategy to yield a potentially larger capacity\u2013distortion function, which is summarized below with- out proof.\nTheorem 2: The capacity\u2013distortion function for strictly causal adaptive action dependent state communication is\nwhere the maximum is over all conditional pmfs p(a)p(x|a)p(u|x, s, a) and function ˆ s(u, x, a, y) such that E(d(S, ˆ S)) ≤ D.\nNote that the unconstrained capacity remains unchanged even if we allow the actions to depend on the past states. But in general C AA SC (D) ≥ C A SC (D) as the adaptive action helps the receiver to get a better estimate of the state. Finally, by setting A = ∅ in Theorem 2, we recover the result by [3] on the capacity\u2013distortion function when the i.i.d. state information is available strictly causally at the encoder.\nRemark 3: When the past states are available at both the encoders, the encoders cooperate to send information consist- ing of the common message and a description of the state in previous block (similar to sending a common message over multiple access channel (MAC)), whereas in the non- adaptive action scenario, while the common message is sent cooperatively, description of the state is a private message of the channel encoder.\nRemark 4: In the converse proof of Theorem 1, we have used the following Markov chain condition (M, S i−1 , A n\\i ) → A i → S i , which need not hold when allowing adaptive actions and hence the converse proof for adaptive action necessitates different deﬁnition of the key auxiliary random variable given by U i := (M, S i−1 , Y n i+1 , A i−1 ).\nIn the following subsections, we illustrate Theorem 1 and Theorem 2 through simple examples.\nConsider the case where the decoder also has access to the actions taken. Noting that this is a special case of our setting by taking the pair (Y, A) as the new channel output, that U → (X, S, A) → Y if and only if U → (X, S, A) → (Y, A), we obtain that the capacity\u2013distortion function for the case of message depepdent action is given by\nwhere the maximization is over the same set of distribution and same feasible set as in Theorem 1. Similarly we can eval- uate the capacity\u2013distortion function for the case of adaptive actions. This expression is quite intuitive: The amount of infor- mation per symbol that can be conveyed through the actions in the ﬁrst stage is represented by the term H(A). In the second stage, both encoder and decoder know the action sequence, so\ncan condition on it and can perform the usual block Markov strategy on each subsequence associated with each action symbol, achieving a rate of I(U, X; Y |A)−I(U, X; S|A). The maximization is a search for the optimal tradeoff between the amount of information that can be conveyed by the actions, and the quality of the second stage channel that they induce.\nConsider the Gaussian channel with additive action depen- dent state [1]\nwhere ˜ S ∼ N(0, Q) and the noise Z ∼ N(0, N ) are indepen- dent. Assume an expected average power constraint on both the channel and action encoder\nWe consider the squared error (quadratic) distortion measure d(s, ˆ s) = (s − ˆ s) 2 . When the action sequnce is only a function of the message, using Theorem 1 we have the following.\nProposition 1: The capacity\u2013distortion function of the Gaussian channel with message dependent action is\n   \n  \n, D max = QN Q+N and P A = P X + Q + N + P A + 2 P A (P X − ( QN D − (Q + N ))).\nWhen we allow the action encoder to observe the past states, the capacity\u2013distortion follows from Theorem 2 and it has the similar form of Proposition 1, but P A and D A min are replaced by P AA and D AA min , respectively, where P AA = P X + Q + N + P A + 2\nThe proof of the proposition is omitted here for brevity. Note that since P AA ≥ P A , the capacity\u2013distortion function is larger in the adaptive action scenario (see Fig. 2). In fact,\nthe minimum distortion achievable with adaptive action is smaller than that of non-adaptive action. But the unconstrained capacity (capacity\u2013distion function for D ≥ D max ) is same in both the cases, which implies that adaptive action in useful in estimation rather than in information transmission. Finally by substituting P A = 0, both the capacity\u2013distortion functions converges to the one in [3].\nConsider communicating a common message over a mem- oryless state-dependent MAC (see Fig. 3) characterized by p(y|s, x 1 , x 2 ), where the state sequence is known strictly- causally to both encoders. This problem can be seen as a special case of our adaptive action setting via the following associations:\nApplying Theorem 2 to this case, keeping in mind the Re- mark 1 following the statement of the Theorem 2, about channels of the form p(y|s, x, a), we get that the capacity\u2013 distortion function is given by\nwhere the maximum is over p(x 1 , x 2 )p(u|x 1 , s, x 2 ) and func- tion ˆ s(u, x 1 , x 2 , y) such that E(d(S, ˆ S)) ≤ D. This setting was considered in [12], [13] and it recovers the common message capacity results of [12], [13]. One can also consider a scenario where the state sequence is known strictly-causally to the ﬁrst encoder, but unknown at the second encoder and at the receiver. This problem, motivated by multiterminal communication scenarios involving transmitters with differ- ent degrees of channel state information, is a special case of Theorem 1, we get that the capacity\u2013distortion function (C AS SC (D)) is same as C S SC (D) with additonal constraint of I(U, X 1 ; Y |X 2 ) − I(U, X 1 ; S|X 2 ) ≥ 0 on the feasible distri- butions. Clearly C S SC (D) ≥ C AS SC (D), since with symmetric channel state information the encoders can jointly perform both message and state cooperation as oppose to only message cooperation when the state information is available at only one of the encoders.\nIn [1], they have extended the study of channels with states known at the transmitter to the case where the formation of the states is affected by actions taken at the encoder and they characterize the fundamental limits on reliable communication for such channels. In this work, we have extended their frame- work to include the scenario when the receiver is not only interested in decoding the message, but also in estimating the channel state in distortion. We have characterized the capacity\u2013 distortion function of such channels when the state is available strictly causally at (a) only the channel encoder, and (b) both the action encoder and channel encoder. By realizing that conditioned on the action sequence our framework is similar to the one in [3], we have shown that a two stage encoding strategy is optimal. We have also shown that state-dependent MAC with symmetric and asymmetric state information is a special case of our channel model and using our results we could recover common message capacity results of MAC with strictly causal CSI (see [12], [13])."},"refs":[{"authors":[{"name":"T. Weissman"}],"title":{"text":"Capacity of channels with action-dependent states"}},{"authors":[{"name":"W. Zhang"},{"name":"S. Vedantam"},{"name":"U. Mitra"}],"title":{"text":"A constrained channel coding approach to joint transmission and state estimation problem"}},{"authors":[{"name":"C. Choudhuri"},{"name":"Y.-H. Kim"},{"name":"U. Mitra"}],"title":{"text":"Capacity-distortion trade-off in channels with state"}},{"authors":[],"title":{"text":"Causal state ampliﬁcation"}},{"authors":[{"name":"M. Naghshvar"},{"name":"T. Javidi"}],"title":{"text":"Active m-ary sequential hypothesis test- ing"}},{"authors":[{"name":"I. Vasilescu"},{"name":"K. Kotay"},{"name":"D. Rus"},{"name":"M. Dunbabin"},{"name":"P. Corke"}],"title":{"text":"Data collection, storage, and retrieval with an underwater sensor network"}},{"authors":[{"name":"G. Hollinger"},{"name":"U. Mitra"},{"name":"G. Sukhatme"}],"title":{"text":"Active classiﬁcation: The- ory and application to underwater inspection"}},{"authors":[{"name":"A. V. Kusnetsov"},{"name":"B. S. Tsybakov"}],"title":{"text":"Coding in a memory with defective cells"}},{"authors":[{"name":"C. Heegard"},{"name":"A. El Gamal"}],"title":{"text":"On the capacity of computer memories with defects"}},{"authors":[{"name":"S. Haykin"}],"title":{"text":"Cognitive radio: brain-empowered wireless communica- tions"}},{"authors":[{"name":"A. Sutivong"},{"name":"M. Chiang"},{"name":"T. M. Cover"},{"name":"Y.-H. Kim"}],"title":{"text":"Channel capacity and state estimation for state-dependent Gaussian channels"}},{"authors":[{"name":"A. Lapidoth"},{"name":"Y. Steinberg"}],"title":{"text":"The multiple access channel with causal and strictly causal side information at the encoders"}},{"authors":[{"name":"M. Li"},{"name":"O. Simeone"},{"name":"A. Yener"}],"title":{"text":"Multiple access channels with states causally known at transmitters"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory"}},{"authors":[{"name":"A. Orlitsky"},{"name":"J. R. Roche"}],"title":{"text":"Coding for computing"}},{"authors":[{"name":"D. Blackwell"}],"title":{"text":"Equivalent comparisons of experiments"}},{"authors":[{"name":"M. Raginsky"}],"title":{"text":"Shannon meets Blackwell and Le Cam: channels, codes, and statistical experiments"}},{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory, 2nd ed"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566709.pdf"},"links":[{"id":"1569566381","weight":18},{"id":"1569566527","weight":2},{"id":"1569566485","weight":7},{"id":"1569565383","weight":5},{"id":"1569565223","weight":5},{"id":"1569566725","weight":2},{"id":"1569565663","weight":7},{"id":"1569565377","weight":7},{"id":"1569566385","weight":5},{"id":"1569564635","weight":2},{"id":"1569565867","weight":5},{"id":"1569565691","weight":2},{"id":"1569566875","weight":2},{"id":"1569566683","weight":2},{"id":"1569566597","weight":2},{"id":"1569552245","weight":2},{"id":"1569564481","weight":2},{"id":"1569560833","weight":2},{"id":"1569566415","weight":5},{"id":"1569565355","weight":7},{"id":"1569565931","weight":2},{"id":"1569566373","weight":2},{"id":"1569566765","weight":10},{"id":"1569565461","weight":7},{"id":"1569564731","weight":5},{"id":"1569564227","weight":7},{"id":"1569566671","weight":2},{"id":"1569566303","weight":5},{"id":"1569564233","weight":5},{"id":"1569563411","weight":10},{"id":"1569566319","weight":2},{"id":"1569566941","weight":2},{"id":"1569565291","weight":7},{"id":"1569564203","weight":10},{"id":"1569556713","weight":5},{"id":"1569566751","weight":7},{"id":"1569566467","weight":2},{"id":"1569565771","weight":2},{"id":"1569560613","weight":5},{"id":"1569566903","weight":2},{"id":"1569566999","weight":10},{"id":"1569564249","weight":2},{"id":"1569566579","weight":5},{"id":"1569558483","weight":5},{"id":"1569566089","weight":2},{"id":"1569565455","weight":13},{"id":"1569566963","weight":5},{"id":"1569564989","weight":5},{"id":"1569551763","weight":5},{"id":"1569565953","weight":7},{"id":"1569564189","weight":7},{"id":"1569565907","weight":10},{"id":"1569563981","weight":2},{"id":"1569566905","weight":5},{"id":"1569566753","weight":2},{"id":"1569566063","weight":2},{"id":"1569558681","weight":5},{"id":"1569559995","weight":2},{"id":"1569565213","weight":5},{"id":"1569566643","weight":5},{"id":"1569565841","weight":2},{"id":"1569561143","weight":5},{"id":"1569565833","weight":7},{"id":"1569566423","weight":5},{"id":"1569553909","weight":15},{"id":"1569566687","weight":5},{"id":"1569566939","weight":2},{"id":"1569553537","weight":7},{"id":"1569553519","weight":7},{"id":"1569566231","weight":2},{"id":"1569566513","weight":2},{"id":"1569554881","weight":5},{"id":"1569554971","weight":2},{"id":"1569566209","weight":2},{"id":"1569565655","weight":5},{"id":"1569558985","weight":10},{"id":"1569566473","weight":7},{"id":"1569564333","weight":2},{"id":"1569566629","weight":5},{"id":"1569566257","weight":2},{"id":"1569565033","weight":21},{"id":"1569566447","weight":2},{"id":"1569565887","weight":5},{"id":"1569566721","weight":7},{"id":"1569555879","weight":13},{"id":"1569565219","weight":7},{"id":"1569564851","weight":2},{"id":"1569556671","weight":5},{"id":"1569566223","weight":5},{"id":"1569566553","weight":5},{"id":"1569564969","weight":5},{"id":"1569566043","weight":2},{"id":"1569565029","weight":7},{"id":"1569561245","weight":2},{"id":"1569566505","weight":2},{"id":"1569566191","weight":5},{"id":"1569567033","weight":2},{"id":"1569565527","weight":5},{"id":"1569567029","weight":2},{"id":"1569565363","weight":5},{"id":"1569566051","weight":5},{"id":"1569565467","weight":5},{"id":"1569565441","weight":5},{"id":"1569565311","weight":2},{"id":"1569566667","weight":2},{"id":"1569564097","weight":5},{"id":"1569566501","weight":7},{"id":"1569566481","weight":5},{"id":"1569560503","weight":7},{"id":"1569566229","weight":2},{"id":"1569566133","weight":5},{"id":"1569562551","weight":2},{"id":"1569563395","weight":10},{"id":"1569551347","weight":5},{"id":"1569565415","weight":2},{"id":"1569555367","weight":2},{"id":"1569566383","weight":7},{"id":"1569565155","weight":2},{"id":"1569565885","weight":2},{"id":"1569566831","weight":2},{"id":"1569565549","weight":10},{"id":"1569565611","weight":5},{"id":"1569565397","weight":7},{"id":"1569565765","weight":7},{"id":"1569565435","weight":10},{"id":"1569566129","weight":5},{"id":"1569565385","weight":2},{"id":"1569565575","weight":5},{"id":"1569565919","weight":5},{"id":"1569565181","weight":2},{"id":"1569566711","weight":2},{"id":"1569565319","weight":2},{"id":"1569561221","weight":21},{"id":"1569566253","weight":5},{"id":"1569566691","weight":2},{"id":"1569566651","weight":2},{"id":"1569566823","weight":7},{"id":"1569566137","weight":2},{"id":"1569565013","weight":2},{"id":"1569566237","weight":7},{"id":"1569566283","weight":2},{"id":"1569565375","weight":5},{"id":"1569566771","weight":5},{"id":"1569566641","weight":15},{"id":"1569564247","weight":2},{"id":"1569551905","weight":7},{"id":"1569564787","weight":2},{"id":"1569566487","weight":2},{"id":"1569556759","weight":21},{"id":"1569561185","weight":5},{"id":"1569566301","weight":2},{"id":"1569558779","weight":2},{"id":"1569565669","weight":7},{"id":"1569565233","weight":5},{"id":"1569563721","weight":5},{"id":"1569566435","weight":2},{"id":"1569564923","weight":5},{"id":"1569566299","weight":15},{"id":"1569564769","weight":13},{"id":"1569566933","weight":5},{"id":"1569563919","weight":2},{"id":"1569557851","weight":7},{"id":"1569565389","weight":5},{"id":"1569565537","weight":7},{"id":"1569560785","weight":2},{"id":"1569559251","weight":2},{"id":"1569566583","weight":2},{"id":"1569560459","weight":7},{"id":"1569565853","weight":5},{"id":"1569550425","weight":10},{"id":"1569563725","weight":2},{"id":"1569564505","weight":7},{"id":"1569565165","weight":7},{"id":"1569565635","weight":2},{"id":"1569556327","weight":2},{"id":"1569565113","weight":2},{"id":"1569564257","weight":2},{"id":"1569564931","weight":5},{"id":"1569564141","weight":7},{"id":"1569564509","weight":5},{"id":"1569551751","weight":7},{"id":"1569564419","weight":7}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S17.T4.3","endtime":"16:00","authors":"Chiranjib Choudhuri, Urbashi Mitra","date":"1341589200000","papertitle":"Action Dependent Strictly Causal State Communication","starttime":"15:40","session":"S17.T4: Communication Models","room":"Stratton 20 Chimneys (306)","paperid":"1569566709"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
