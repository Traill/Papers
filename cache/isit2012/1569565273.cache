{"id":"1569565273","paper":{"title":{"text":"Large scale correlation detection"},"authors":[{"name":"Francesca Bassi,2"},{"name":"Alfred O. Hero III"}],"abstr":{"text":"Abstract\u2014This work addresses the problem of correlation detection in a group of elliptically-contoured variables, when the number p of variates greatly exceeds the number n of observed samples. We exploit the properties inherent to the Z-score representation of the data set to devise two different decision tests, whose performances are assessed by upper bounding the Type I and Type II error probabilities. The results speciﬁcally apply to the asymptotic regime where the number of variates p is large, and the number of samples n is ﬁnite and ﬁxed."},"body":{"text":"derived applying the theory of exchangeability and the method of types.\nThe paper is organized as follows. Section II reviews the U -score representation of the data set introduced in [1]. The decision problem is formally deﬁned in Section III. In Section III-A and Section III-B two different tests are proposed, whose performances are characterized by means of the respective Type I and Type II error exponents. Section IV provides experimental results.\nLet the size p random vector X be distributed according to an elliptically-contoured density f X (x) (e.g. the multivariate normal, or the multivariate t-distribution, see [10, Sec. 2.7] and references therein). The elliptically-contoured density is speciﬁed by the parameters µ, Σ, and g(·), where g(·) is a non-negative monotonic function:\nRaw data set: The matrix X [n×p] is formed by (vertically) stacking n independent drawings from f X (x).\nZ-scores: The matrix Z [n×p] is obtained centering and nor- malizing the columns of X with respect to their sample mean and standard deviation. Let m i = (n) −1 1 T x (i) denote the i-th sample mean, and s 2 i = (n − 1) −1 (x (i) − m i 1 ) T (x (i) − m i 1 ) the i-th sample variance. The columns of Z are obtained from the columns of X as\nGeometrically, the columns of Z are points living in the R n space. Each z (i) belongs to the intersection of the hyperplane M n−1 = {z ∈ R n : 1 T z = 0} with the unit hypersphere S n−1 = {z ∈ R n : z = 1}.\nU -scores [1]: The matrix U [(n−1)×p] is obtained from Z as a result of the rotation by H ∗ of its columns, and of their subsequent projection over M n−1 . Deﬁne H ∗ as an orthonormal matrix 1 whose ﬁrst row is parallel to 1 T ,\nlabeling) of the random variables is redundant, and can be discarded. This conceptual operation is formalized as the resampling (without replacement) of the data set U. The resampled data set V is deﬁned by V = UP , where the matrix P is random and uniformly distributed over the set P ⊂ B p×p of permutation matrices. Therefore, for p = 2 the density of V for the arguments (v, w) is equal to\nwhere 1/2 is the probability of choosing any of the two permutation matrices. Extending this argument to general values of p yields the following proposition.\nProposition 3. The probability density function of the resam- pled data set f V (v (1) , · · · , v (p) ) has form\nAs it is evident from (5), the distribution f V (v (1) , · · · , v (p) ) is invariant upon permutation of the arguments. The resampled data set V is hence an exchangeable sequence [11] of random points in the R n−1 space. This implies, in particular, that each column in V is distributed according to the same marginal f V (v). The covariance between any pair of columns of V is given by\nThe testing procedure will be performed on V. It is straightforward to verify that, when H 0 is in force, f V (v (1) , · · · , v (p) ) = f U (v (1) , · · · , v (p) ). The hypotesis testing problem on f V (v (1) , · · · , v (p) ) can now be solved easily, as shown below. Since exchangeability allows to consider each column of V as a drawing from f V (v), the high dimensionality p of the problem can be exploited to test, without requiring large sample size n.\nLet Q ∗ = {(i, j) : i, j ∈ {1, · · · , p}, i < j}. The vector D (V) = (D 1 , · · · , D p(p−1)/2 ) is constructed by stacking in sequence, ∀(i, j) ∈ Q ∗ , the pairwise squared Euclidean distances D k = V (i) − V (j) 2 . As consequence of the exchangeability of V, the distribution f D (d 1 , · · · , d p(p−1)/2 ) is invariant with respect to the permutation of the arguments, and D is exchangeable as well. The explicit expression of E [D], i.e. the expectation of the marginal distribution of D, is given in the following proposition.\nProposition 4. The expectation of the random variable D is given by\nBy thresholding T we obtain the hypothesis test T − 2 ≤ τ : H 0\nwhere (16) is deduced using the relation 2 = E [D] + 2γ introduced in (7). Lemma 7 in Appendix A allows to establish the relation 2γ ≥ −2/(p − 1). As a consequence of the threshold choice τ ≥ 2/(p − 1) it is concluded 2γ + τ ≥ 0. This justiﬁes (17), derived making use of the upper tail bound (30) in Lemma 9 in Appendix A.\nFor 2γ < τ , the last term in (17) is evaluated using the lower tail bound (31) derived in Lemma 9, and this yields the second part of (13). For 2γ ≥ τ , (17) can be developed as\nfrom which the ﬁrst part of (13) is ﬁnally obtained by substitution of (31).\nAs it is clear from (12) and (13), for 2γ ≥ τ the test is characterized by a fast decrease of the error probability as the dimension p increases, forcing it to zero for p → ∞. The constant γ is null when H 0 is in force, and, for high dimensional problems (i.e. when the modelization p → ∞ is allowed), is always positive (Lemma 7 in Appendix A). It increases whenever there is correlation among the elements of V, and/or the marginal f V (v (1) , · · · , v (p) ) over S n−2 de- viates from symmetry about the origin of R n−1 . Thus γ can be understood as a measure of divergence of the empirical f V (v (1) , · · · , v (p) ) from the uniform distribution on S n−2 , as a function of its ﬁrst and second order statistics. If 2γ < τ , this will almost surely induce a Type II error, for p → ∞.\nAs discussed above, testing the average of the squared dis- tance between the columns of V allows to detect the deviation, expressed by γ, of the empirical distribution from the uniform distribution on the sphere. For some a priori densities f X (x), however, the covariance term tr cov (V , W ) contributing to γ may be small. This happens, for example, when the random vector X is composed of elements that are both positively and negatively correlated 2 , or for the sparse correlation regime, when only κ ≪ p elements are correlated. Under these circum- stances the test on the empirical squared distances will have reduced power of rejecting the null hypothesis for symmetric, but not uniform, marginal distributions. This section outlines an alternative test, based on the method of types [13]. As it will be shown, the Type I error exponent increases less rapidly in p, but allows a Type II error exponent that is better behaved for symmetric marginals under the alternative hypothesis.\nDeﬁne the quantizer Q : R n−1 → {1, · · · , m}, given by a tessellation of S n−2 in m Voronoi cells of equal vo- lume. The (column by column) quantization Q (V) produces a p-dimensional vector ν of quantization indexes. Counting how many instances of each quantization index appear in ν, and normalizing for 1/p, gives the m-dimensional vector µ, describing a probability mass function on the support {1, · · · , m}. Under the high dimensionality assumption p → ∞, by effect of the law of large numbers, the empirical\nwith the ROC curves for the maximum Pearson\u2019s correlation coefﬁcient (MaxCor) and maximum Spearman\u2019s rank corre- lation coefﬁcient (MaxRCor) tests [7], and for the S biggest correlation coefﬁcients test (MaxCorS) [8], where S = 5. All the tests have comparable complexity.\nFor p = 50 and n = 12 the SqDist test outperforms the alternatives. Figure 1 presents also the SqDist ROC curves for n = 6 and n = 3: it can be observed that the SqDist test ( n = 3) achieves a performance comparable to the MaxCor and MaxCorS tests ( n = 12), but requiring only 1/4 the number of samples. For comparison, the SqDist curve for p = 100 and n = 3 is depicted as well, showing that, as expected, increasing p for ﬁxed n improves the performance.\nIn this work two tests for correlation detection in large data sets of elliptically-contoured variables are presented. Their performance is characterized for ﬁnite values of n, using Chernoff and Sanov bounds. The properties of the U -scores allow to take advantage of the high dimension of the problem without requiring n to go to inﬁnity. Using vector quantization to discretize the empirical distribution of the U -scores leads to a simple test statistic whose Type I and Type II error exponents can be computed using the method of types.\nwhere I is a random variable identifying the minimum valued component in the vector D. The distribution f D |U,I is a permutation distribution in the sense deﬁned in [12, Def. 2.10], and hence is negatively associated [12, Thm. 2.11]. This implies that the ﬁrst term in the right hand of (25) is negative. The negativity of the second term follows by the same argument in the proof to [12, Thm. 2.11].\nLemma 9. The average of the random vector D obeys Chernoff-type large deviation bounds. In particular, for ǫ > 0\nProof: The proof relies on [15, Thm. 3.2]. Recall that the elements of D are positive, bounded in the interval [0, 2]. In or- der to apply [15, Thm. 3.2] we need to prove that the elements in D are λ-correlated, as deﬁned in [15, Def. 3.1]. Deﬁne a vector X of p(p − 1)/2 independent random variables on the support [0, 2], and such that E [X i ] = E [D] , ∀i. This implies\nE D i = p(p−1)/2 i=1 \t E X i . Using linearity of the expectation it is easy to see that condition (i) in [15, Def. 3.1] is satisﬁed. Now consider a non-negative function f (·). Since the variables in D are negatively associated, invoking [12, Property 2] gives\nwhere the last equality is obtained because E [D i ] = E [X i ]. Inspection of (27) conﬁrms that condition (ii) in [15, Def. 3.1] is veriﬁed as well for λ = 1.\nNow that the elements of D have been established to be λ-correlated, [15, Thm. 3.2] can be used to evaluate the upper tail bound as follows:\nwhere (28) follows directly from [15, Thm. 3.2], obtained for E [X i ] = E [D i ] = E [D], λ = 1, D i ∈ [0, 2]. Algebraic manipulation yields (29), and the substitution ǫ = ε E [D] yields (30).\nThe lower tail bound is obtained as follows. Deﬁne the random variables C i = E [D]+1−D i and Y i = E [X]+1−X i . It is straightforward to verify that the elements of the vector C are λ-correlated for λ = 1. Hence, apply [15, Thm. 3.2] to obtain, in a similar manner to (29),\nSubstitution of the expression C i in (31) shows that the lower tail bound is equal to the upper tail bound (30). This establishes (26)."},"refs":[]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565273.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S14.T8.2","endtime":"17:20","authors":"Francesca Bassi, Alfred Hero III","date":"1341507600000","papertitle":"Large scale correlation detection","starttime":"17:00","session":"S14.T8: High-Dimensional Inference","room":"Stratton (491)","paperid":"1569565273"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
