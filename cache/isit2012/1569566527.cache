{"id":"1569566527","paper":{"title":{"text":"Efﬁcient Tracking of Large Classes of Experts"},"authors":[{"name":"Andr´as Gy¨orgy"},{"name":"Tam´as Linder"},{"name":"G´abor Lugosi"}],"abstr":{"text":"Abstract\u2014In the framework of prediction with expert advice we consider prediction algorithms that compete against a class of switching strategies that can segment a given sequence into several blocks and follow the advice of a different \u201cbase\u201d expert in each block. The performance is measured by the regret deﬁned as the excess loss relative to the best switching strategy selected in hindsight. Our goal is to construct low-complexity prediction algorithms for the case where the set of base experts is large. In particular, starting with an arbitrary prediction algorithm A designed for the base expert class, we derive a family of efﬁcient tracking algorithms that can be implemented with time and space complexity only O(n γ ln n) times larger than that of A, where n is the time horizon and γ ≥ 0 is a parameter of the algorithm. With A properly chosen, our algorithm achieves a regret bound of optimal order for γ > 0, and only O(ln n) times larger than the optimal order for γ = 0 for all typical regret bound types we examined. For example, for predicting binary sequences with switching parameters, our method achieves the optimal O(ln n) regret rate with time complexity O(n 1+γ ln n) for any γ ∈ (0, 1)."},"body":{"text":"We consider on-line (sequential) prediction problems in which an outcome space Y, a decision space D (a convex subset of a vector space), and a set of reference experts E are given. At each time instant t = 1, . . . , n, the environment chooses an action y t ∈ Y and each expert i ∈ E forms its prediction f i,t ∈ D. Then the forecaster chooses an action p t ∈ D (without knowing y t ), suffers loss (p t , y t ), and the losses (f i,t , y t ), i ∈ E are revealed to the forecaster. Here\n: D×Y → R is a loss function that is convex in its ﬁrst argu- ment. The goal of the forecaster is to minimize its cumulative loss L n = n t=1 (p t , y t ). This is equivalent to minimizing its excess loss L n − min i∈E L i,n relative to choosing the best expert in E in hindsight, where L i,n = n t=1 (f i,t , y t ) for all i ∈ E .\nSeveral methods are known that can compete suc- cessfully with different expert classes E , under vari- ous assumptions on the loss function, in the sense that the (worst-case) cumulative regret, deﬁned as R n = max y 1 ,...,y n ∈Y n L n − min i∈E L i,n only grows sub-linearly, that is, lim n→∞ R n /n = 0. We refer to [1] for a survey.\nA more ambitious goal than performing nearly as well as the best expert in a class E is to compete with the best sequence of expert predictions that may switch its experts at a certain, limited, number of times. Thus we compete with meta experts described by sequences of base experts (i 1 , . . . , i n ) ∈ E n , such that at time instants t = 1, . . . , n a meta expert follows the prediction of the \u201cbase\u201d expert i t ∈ E by predicting f i t ,t . The complexity of such a meta expert may be measured by C = |{t ∈ {1, 2, . . . , n − 1} : i t = i t+1 }|, the number of times it changes the base predictor (each such change is called a switch). These C switches partition {1, . . . , n} into C + 1 contiguous segments, on each of which the meta expert follows the prediction of the same base expert. If a maximum of m changes are allowed and the set of base experts has N elements, then the class of meta experts is of size\nN (N − 1) j . Clearly, a naive implementation of popular algorithms such as the exponentially weighted average forecaster [1] is not feasible in this case, but several more efﬁcient algorithms have been proposed.\nIn one approach to the tracking problem a transition diagram is used to deﬁne a Markovian model to specify a prior distribution on the switches of the experts, and the starting point of the current segment is estimated using this prior [2], [3]. In its straightforward version, for each time instant t, the performance of an expert algorithm is emulated for all possible segment starting points 1, . . . , t, and a weighted average of the resulting estimates is used to form the next prediction. This method converts an efﬁcient algorithm to compete with the best expert in a class E into one that competes with the best sequence of experts with a limited number of changes. However, the time complexity of the resulting algorithm increases by a factor of n compared with the original algorithm that competes with E , yielding a total complexity that is quadratic in n.\nSeveral methods have been introduced to reduce the above complexity. A linear-complexity method was developed in [4], which uses an easy-to-implement weighting of the paths in the full transition diagram, but needs to know the number of switches in advance. This assumption was eliminated by [5] and [6], [7] at the price of somewhat increasing the regret; the latter providing better bounds at the price of an increased O(n 3/2 ) complexity.\nWhile these algorithms seem to solve the complexity prob- lem arising in the transition diagram based approach, they cannot be applied in this form to the case when the base\nexpert class E is very large, since their complexity also scales linearly with the number of base experts, and they do not seem to allow to incorporate efﬁcient algorithms developed for E (that scale much better in the size of E ) without increasing the complexity to at least O(n 2 ) [8]. Such large base-expert classes play important role in, e.g., lossless [9] and lossy data compression [10]\u2013[12]. To overcome quadratic complexity, reduced transition diagrams have been used for the logarithmic loss (i.e., data compression) by [13] and by [3] (the latter work considers a probabilistic setup). Reduced transitions diagrams for the tracking problem with (more) general loss functions were considered in [14] and [15].\nIn this paper we tackle the complexity issue by presenting a general method for designing reduced transition diagrams. Our algorithm uniﬁes and generalizes the algorithms of [13]\u2013 [15]. This algorithm has an explicit complexity-regret trade- off, covering essentially all such results in the literature. In addition to the (almost) linear complexity algorithms in the aforementioned papers, the parameters of our algorithm can be set to reproduce the methods based on the full transition diagram [2], [3], [16], or the complexity-regret behavior of [6], [7]. Also, our algorithm has regret of optimal order with complexity O(n 1+γ ln n) for any γ ∈ (0, 1), while setting γ = 0 results in complexity O(n ln n) and a regret that is only a factor of ln n larger than the optimal rate (similarly to [13]\u2013 [15]).\nDue to space constraints the main results will only be presented in their simplest form and for exp-concave loss function only (i.e., for loss functions for which there exists an η > 0 such that F (p) = e −η (p,y) is concave for ﬁxed y ∈ Y); proofs and more general statements can be found in [17].\nConsider an on-line forecasting algorithm A, and suppose that for all n and possible outcome sequences of length n, A satisﬁes a regret bound\nwith respect to the base expert class E , where ρ E : [0, ∞) → [0, ∞) is a nondecreasing and concave function with ρ E (0) = 0. These assumptions on ρ E are usually satisﬁed by the known regret bounds for different algorithms [1]. Suppose 1 ≤ t 1 < t 2 ≤ n and an instance of A is used for time instants t ∈ [t 1 , t 2 ) := {t 1 , . . . , t 2 − 1}, that is, algorithm A is run on data obtained in the segment [t 1 , t 2 ). The accumulated loss of A during this period will be denoted by L A (t 1 , t 2 ). Then (1) implies\n(f i,t , y t ) denotes the loss of expert i in the interval [t 1 , t 2 ).\nFix the time horizon n ≥ 1. A meta expert that changes base experts at most C ≥ 0 times can be described by a vector of experts a = (i 0 , . . . , i C ) ∈ E C+1 and a \u201ctransition\npath\u201d T = (t 1 , . . . , t C ; n) such that t 0 := 1 < t 1 < . . . < t C < t C+1 := n + 1. For each c = 0, . . . , C, the meta expert follows the advice of expert i c in the time interval [t c , t c+1 ). Any meta expert that can be deﬁned using a given transition path T is said to follow T .\nThe total loss of the meta expert indexed by (T, a), accu- mulated during n rounds, is\nLet T t denote the set of all transition paths up to time t represented by vectors (t 1 , . . . , t C ; t) with 1 < t 1 < t 2 < . . . < t C ≤ t and 0 ≤ C ≤ t. For any T = (t 1 , . . . , t C ) ∈ T n and t ≤ n deﬁne the truncation of T at time t as T t = (t 1 , . . . , t k ; t), where k is such that t k ≤ t < t k+1 . Furthermore, let τ t (T ) = τ t (T t ) = t k denote the last change up to time t, and let C t (T ) = C(T t ) = k denote the number of switches up to time t. A transition path T with C switches splits the time interval [1, n] into C + 1 contiguous segments. We apply algorithm A on T in such a way that at the beginning of each segment (at time instants t c ) we restart A; this algorithm will be denoted in the sequel by (A, T ). Denote the output of the algorithm at time t by f A,t (T t ) = f A,t (τ t (T )). This notation emphasizes the fact that, since A is restarted at the beginning of each segment of T , its output at time t depends only on τ t (T ), the beginning of the segment which includes t. The loss of algorithm (A, T ) up to time n is\nAs most tracking algorithms, our algorithm will use weight functions w t : T t → [0, 1] satisfying T\nw t (T t t) = 1 and w t (T t ) = \t T\nw t+1 (T t+1 ). To simplify the notation, we formally deﬁne T 0 as the \u201cempty transition path\u201d T 0 := {T 0 }, L 0 (A, T 0 ) := 0, and w 0 (T 0 ) := 1.\nNow we are ready to deﬁne our master algorithm, given in Algorithm 1.\nInput: prediction algorithm A, weight functions {w t ; t = 1, . . . , n}, learning parameters η t > 0, t = 1, . . . , n. For t = 1, . . . , n predict\nWe note that the consistency of {w t } implies that Algo- rithm 1 is equivalent to the exponentially weighted average forecaster with the set of experts {(A, T ) : T ∈ T n , w n (T n ) > 0} and initial weights w n (T ) for (A, T ).\nThe next lemma gives a general regret bound for Algo- rithm 1 in terms of the weight function w n and a transition path T that approximates the true transition path in the following sense: We say that T ∈ T n covers T ∈ T n if the change points of T are also change points of T . Note that if T covers\nT , then any meta expert that follows transition path T also follows transition path T .\nLemma 1: Suppose the transition path T n is covered by T n = (ˆ t 1 , . . . , ˆ t C(T\n; n) such that w n (T n ) > 0, and A satisﬁes the regret bound (1). Assume that is exp-concave for the value of η and Algorithm 1 is used with η t ≡ η. Then\nOne may interpret the weight function {w t } as the con- ditional probability that a new segment is started, given the beginning of the current segment and the current time instant. In this case one may deﬁne {w t } in terms of a time- inhomogeneous Markov chain {U t ; t = 1, 2, . . .} whose state space at time t is {1, . . . , t}. Starting from state U 1 = 1, at any time instant t, the Markov-chain either stays where it was at time t − 1 or switches to state t. In particular, P(U 1 = 1) = 1 and for 1 ≤ t < t,\n(2) where the so-called switch probabilities p(t|t ) need only satisfy p(t|t ) ∈ [0, 1] for all 1 ≤ t < t. A realization of this Markov chain uniquely determines a transition path: T t (u 1 , . . . , u t ) = (t 1 , . . . , t C ; t) ∈ T t if and only if u k−1 = u k for k ∈ {t 1 , . . . , t C }, and u k−1 = u k for k / ∈ {t 1 , . . . , t C }, 2 ≤ k ≤ t. Inverting this correspondence, any T ∈ T t uniquely determines a realization (u 1 , . . . , u t ). Now the weight function is given for all t ≥ 1 and T ∈ T t by\nwhere (u 1 , . . . , u t ) is such that T = T (u 1 , . . . , u t ). It is easy to check that {w t } deﬁnes a sequence of compatible distri- butions as required. Clearly, the switch probabilities p(t|t ) uniquely determine {w t }.\nSome examples that have been proposed for this construc- tion (given in terms of the switch probabilities) include\n\u2022 p HW (t|t ) = α for some 0 < α < 1 [4]. \u2022 p HS (t|t ) = 1/t [5], [7], [15].\n\u2022 w L 1 used in [3] (similar weight functions were considered in [18]), is deﬁned as follows: for a given > 0, let π j = 1/j 1+ , Z t = t j=1 π(j) and Z ∞ = ∞ j=1 π(j). Then w L 1 is deﬁned by p L 1 (t|t ) = π(t−1) (Z\nWe will concentrate on the weights w L 1 . It is shown in [3, proof of Eq. (39)] that for any T ∈ T n ,\nEfﬁcient implementation of Algorithm 1 hinges on three factors: (i) Algorithm A can be efﬁciently implemented; (ii) the exponential weighting step can be efﬁciently implemented; which is facilitated by (iii) the availability of the losses L A,t . In what follows we assume that (i) and (iii) hold and develop a method for (ii) via constructing a new weight function { ˆ w t } that signiﬁcantly reduces the complexity of implementing Algorithm 1.\nFirst, we observe that the predictor ˆ p t of Algorithm 1 can be rewritten as\nIf the η t are constant during the time horizon, the above means that Algorithm 1 can be implemented efﬁciently by keeping a weight v t (t ) at each time instant t for every possible starting point of a segment t = 1, . . . , t. Indeed, if η t = η for all t, then (7), (2), and (3) imply that each v t (t ) can be computed recursively in O(t) time from the v t−1 (setting v 1 (1) = 1 at the beginning) using the switch probabilities deﬁning w t . Using this recursion, the overall complexity of computing the weights during n rounds is O(n 2 ). Furthermore, (6) means that one needs to start an instance of A for each possible starting point of a segment. If the complexity of running algorithm A for n time steps is O(n) (i.e., computing A at each time instance has complexity O(1)), then the overall complexity of our algorithm becomes O(n 2 ).\nOur goal is to reduce the linear growth of the per round complexity. To this end, we modify the weight functions in such a way that at any time instant t we allow at most O(g ln t) actual segments with positive probability (i.e., segments con- taining t that belong to sample paths with positive weights), where g > 0 is a parameter of the algorithm (note that g may depend on, e.g., the time horizon n). By doing so, the time and space complexity of the algorithm becomes O(g ln n) times more than that of algorithm A (with space complexity bounded away form zero), as we need to run O(g ln n) instances of A in parallel and the number of non-zero terms in the recursion for computing v t and in (6) is also O(g ln n). Thus, in case of a linear-time-complexity algorithm A, the overall complexity of Algorithm 1 becomes O(gn ln n).\nIn order to construct the new weight function, at each time instant t we force some segments to end. Then any path that contains such a segment will start a new segment at time t (and hence the corresponding vector of transitions contains t). Speciﬁcally, if a segment starts at time instant s, where s can be written as o2 u with o being an odd number and u an integer, o, u ≥ 0 (that is, 2 u is the largest power of 2 that divides t), then a segment starting at s can \u201clive\u201d for at most g2 u time instances, where g > 0 is a parameter of the algorithm. Thus at time s + g2 u we force a switch in the path: given p(t|t )\nˆ p(t|t ) = 1 − h t (t ) 1 − p(t|t ) \t (8) where h t (s) = I {s≤t<s+g2 u } and I E denotes the indicator of the event E. Thus h t (s) = 1 if and only if a segment started at s is still alive at time t. In this way, given the switching probabilities p(t|t ) and the associated weight function {w t }, we can deﬁne a new weight function { ˆ w t } via the new switching probabilities ˆ p(t|t ) and the procedure described in Section II-B. Note that the deﬁnition of { ˆ w t } implies that for a transition path T ∈ T t either ˆ w t (T ) = 0 or ˆ w t (T ) ≥ w t (T ).\nThe above procedure is a common generalization of pre- vious algorithms in the literature for pruning the transition paths. Speciﬁcally, g = 1 yields the procedure of [13], g = 3 yields our previous procedure [14], g = 4 yields the method of [15], while g = n yields the original weighting {w t } without pruning. We will show that the time complexity of the method with a constant g (i.e., when g is independent of the time horizon n) is, in each time instant, at most O(ln n) times the complexity of one step of A, while the time complexity of the algorithm without pruning is O(n) times the complexity of A. Complexities that interpolate between these two extremes can be achieved by setting g = O(n) appropriately.\nIn what follows we assume that the original switching prob- abilities p(t|t ) associated with the w t satisfy p(t|t ) ∈ (0, 1) for all 1 ≤ t < t. (Note that the weight function examples introduced in Section II-B all satisfy this condition.) The condition implies that w t (T t ) > 0 for all T t ∈ T t . Furthermore, if T t = (t 1 , . . . , t C ; t) ∈ T t satisﬁes t i+1 − t i < g2 u ti , i = 1, . . . , C, where u t i is the largest power of 2 divisor of t i , then from (8) we get ˆ w t (T ) > 0. We say that a segment at time instant t is alive if it contains t and is valid if there is a path T t with ˆ w t (T t ) > 0 that contains exactly that segment.\nLemma 2: At any time instant t there are at most g/2 ( log t + 1) segments that are valid and alive.\nThe lemma implies that Algorithm 1 can be implemented efﬁciently with the proposed weight function { ˆ w t }.\nTheorem 1: Assume Algorithm 1 is run with weight func- tion { ˆ w t } derived using any g > 0 from any weight function {w t } deﬁned as in Section II-B. If η t = η for some η > 0 and all t = 1, . . . , n, then the time an space complexity of Algorithm 1 is O(g ln n) times the time and space complexity of A, respectively.\nTo bound the regret, the main problem is to relate an arbitrary transition path T ∈ T and its \u201cclosest\u201d approximation T ∈ T that covers T and has positive weight. The next lemma shows that any segment [t, t ) of T can be covered by at most logarithmically many segments of T .\nLemma 3: For any T ∈ T n , there exists T ∈ T n such that for any segment [t, t ) of T with 1 ≤ t < t ≤ n+1, ˆ w t (T ) > 0, t and t are switching points of T (where t = n + 1 is considered as a switching point), and T contains at most l =\n \nWe now apply the above construction and results to the weight function {w t } = {w L 1 t } to obtain our main theorem. The proof is a combination of Lemmas 1 and 3, and (4).\nTheorem 2: Assume Algorithm 1 is run with weight func- tion { ˆ w L 1 t } (derived from {w L 1 t }) with g > 0, based on a prediction algorithm that satisﬁes (1) for some ρ E . Let S C,n be deﬁned as in Lemma 3. If is exp-concave for some η > 0 and η t = η for t = 1, . . . , n in Algorithm 1, then for any T ∈ T n the tracking regret satisﬁes\nη \t (10) where r n is deﬁned in (5).\nIn this section we apply the results of the paper for a few speciﬁc examples.\nExample 1 (Exponential weighting): Here we apply our al- gorithm to the case where A is the exponentially weighted average forecaster and the set of base experts is of size N , and discuss the obtained bounds (for simplicity we assume C(T ) ≥ 1, but C(T ) = 0 would just slightly change the presented bounds). If is exp-concave, then by [1] the regret of A is bounded by ρ E (n) = ln N η . Then, for g = O(1), the bound (10) becomes\nη \t ln(nN ) + O(1) which is a factor of O(ln n) larger than the existing bounds [2]\u2013[5], valid for algorithms having complexity O(n 2 ). For g = 2n γ − 1, we obtain a bound of optimal (C(T ) + 1) ln n order:\nThe time complexity of our algorithm is only O(n γ ln n) times larger than that of running A (which is typically linear in n). Thus, in a sense the complexity of our algorithm can get very close to linear while guaranteeing a regret of optimal order. (Note however, that a factor 1/γ appears in the regret bounds so setting γ very small comes at a price.)\nExample 2 (Krichevsky-Troﬁmov mixtures): Assume D = E = (0, 1) and Y = {0, 1}, and consider the logarithmic loss (p, y) = −I y=1 ln p − I y=0 ln(1 − p), which is exp- concave with η ≤ 1, and hence we choose η = 1. This loss plays a central role in data compression. In particular, if a prediction method achieves, on a particular binary sequence y n = (y 1 , . . . , y n ), a loss L n , then using arithmetic coding the sequence can be described with at most L n + 2 bits [2]. The expert class E = (0, 1) corresponds to the situation where the\nsequence y n is encoded using an i.i.d. coding distribution or, in a probabilistic interpretation, it is equivalent to minimizing the worst case maximum coding redundancy relative to the class of i.i.d. source distributions on {0, 1} n .\nThe Krichevsky-Troﬁmov forecaster [1] is an exponentially weighted average forecaster over all base experts θ ∈ E using initial weights 1/(π θ(1 − θ)), and can be computed efﬁ- ciently as p KT t (y t−1 ) = (n 1 (t − 1) + 1/2)/t. The performance of this forecaster can be bounded as R n ≤ 1 2 ln n + ln 2.\nIn this framework, a meta expert is allowed to change θ ∈ E a certain number of times. In the probabilistic interpretation, this corresponds to the problem of coding a piecewise i.i.d. source [2], [3], [6], [7], [13]. A slightly improved analysis of Algorithm 1 with weight function ˆ w KT (compared to Theorem 2) shows that for any transition path T ∈ T n and meta expert (T, a) with C(T ) = C\nlog(g + 1) +O((C +1) ln n). For g = 1, this bound recovers that of [13] (at least in the leading term), and improves the leading constant for g = 3 and g = 4 when compared to [14] and [15], respectively. On the other hand, for g = 2n γ − 1, γ > 0, using with ˆ w L 1 in Algorithm 1, a reﬁned version of Theorem 2 implies\nThis bound achieves the optimal O(ln n) order for any γ > 0; however, with an increased leading constant. On the negative side, for speciﬁc choices of γ our algorithm does not recover the best leading constants known in the literature (cf. [6], [7] for γ = 1/2).\nExample 3 (Tracking the best quantizers): The problem of zero-delay adaptive universal lossy source coding of individual sequences has recently been investigated in detail [8], [10]\u2013 [12]. Here an inﬁnite sequence of [0, 1]-valued source symbols x 1 , x 2 , . . . is transformed into a sequence of channel symbols y 1 , y 2 , . . . which take values from the ﬁnite channel alphabet {1, 2, . . . , M } and these channel symbols are then used to produce the ([0, 1]-valued) reproduction sequence ˆ x 1 , ˆ x 2 , . . .. The scheme operates with zero delay, that is, y n depends only on x 1 , . . . , x n , and ˆ x n on y 1 , . . . , y n , so that the encoder produces y n as soon as x n becomes available, and the decoder can produce ˆ x n when y n is received. The quality of the repro- duction is measured by the average distortion n t=1 d(x t , ˆ x t ), where d is some nonnegative bounded distortion measure. The squared error d(x, x ) = (x − x ) 2 is perhaps the most popular example.\nThe natural reference class of codes (experts) in this case is the set of M -level scalar quantizers\nThe relative loss with respect to the reference class Q is known in this context as the distortion redundancy. For the squared error distortion, the best randomized coding methods [12], with linear computational complexity with respect to the set Q, yield a distortion redundancy of order O(n −1/4\nThe problem of competing with the best time-variant quan- tizer that can change the employed quantizer several times (i.e., tracking the best quantizer), was analyzed in [8], based on a combination of [12] and the tracking algorithm of [4]. There the best linear-complexity scheme achieves O((C + 1) ln n/n 1/6 ) distortion redundancy when an upper bound C on the number of switches in the reference class is known in advance. On the other hand, applying a modiﬁed version of our scheme for randomized prediction [17] with g = O(1) in the method of [8], one can show that a linear-complexity version of this algorithm can achieve distortion redundancy O((C + 1) 1/2 ln 3/4 (n)/n 1/4 ) + O((C + 1) ln(n)/n 1/2 ) dis- tortion redundancy for any (a priori unknown) C. When g = 2n γ − 1, the distortion redundancy for linear complexity becomes somewhat worse, proportional to n − 1 2(2+γ) up to logarithmic factors."},"refs":[{"authors":[{"name":"N. Cesa-Bianch"},{"name":"G. Lugos"}],"title":{"text":"Prediction, Learning, and Games"}},{"authors":[{"name":"F. M. J. Willems"}],"title":{"text":"Coding for a binary independent piecewise- identically-distributed source"}},{"authors":[{"name":"G. I. Shamir"},{"name":"N. Merhav"}],"title":{"text":"Low-complexity sequential lossless coding for piecewise-stationary memoryless sources"}},{"authors":[{"name":"M. Herbster"},{"name":"M. K. Warmuth"}],"title":{"text":"Tracking the best expert"}},{"authors":[{"name":"W. Koolen"},{"name":"S. de Rooij"}],"title":{"text":"Combining expert advice efﬁciently"}},{"authors":[{"name":"C. Monteleoni"},{"name":"T. S. Jaakkola"}],"title":{"text":"Online learning of non-stationary sequences"}},{"authors":[{"name":"S. de Rooij"},{"name":"T. van Erven"}],"title":{"text":"Learning the switching rate by discretis- ing Bernoulli sources online"}},{"authors":[{"name":"A. Gy¨orgy"},{"name":"T. Linder"},{"name":"G. Lugosi"}],"title":{"text":"Tracking the best quantizer"}},{"authors":[{"name":"F. M. J. Willems"},{"name":"Y. N. Shtarkov"},{"name":"T. J. Tjalkens"}],"title":{"text":"The context-tree weighting method: Basic properties"}},{"authors":[{"name":"T. Linder"},{"name":"G. Lugosi"}],"title":{"text":"A zero-delay sequential scheme for lossy coding of individual sequences"}},{"authors":[{"name":"T. Weissman"},{"name":"N. Merhav"}],"title":{"text":"On limited-delay lossy coding and ﬁltering of individual sequences"}},{"authors":[{"name":"A. Gy¨orgy"},{"name":"T. Linder"},{"name":"G. Lugosi"}],"title":{"text":"Efﬁcient algorithms and minimax bounds for zero-delay lossy source coding"}},{"authors":[{"name":"F. Willems"},{"name":"M. Krom"}],"title":{"text":"Live-and-die coding for binary piecewise i.i.d. sources"}},{"authors":[{"name":"A. Gy¨orgy"},{"name":"T. Linder"},{"name":"G. Lugosi"}],"title":{"text":"Efﬁcient tracking of the best of many experts"}},{"authors":[{"name":"E. Hazan"},{"name":"C. Seshadhri"}],"title":{"text":"Efﬁcient learning algorithms for changing environments"}},{"authors":[{"name":"S. Kozat"},{"name":"A. Singer"}],"title":{"text":"Universal switching linear least squares prediction"}},{"authors":[{"name":"A. Gy¨orgy"},{"name":"T. Linder"},{"name":"G. Lugosi"}],"title":{"text":"Efﬁcient tracking of large classes of experts"}},{"authors":[{"name":"V. Vovk"}],"title":{"text":"Derandomizing stochastic prediction strategies"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566527.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S5.T8.4","endtime":"10:50","authors":"András György, Tamas Linder, Gabor Lugosi","date":"1341311400000","papertitle":"Efficient Tracking of Large Classes of Experts","starttime":"10:30","session":"S5.T8: Prediction and Estimation","room":"Stratton (491)","paperid":"1569566527"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
