{"id":"1569566821","paper":{"title":{"text":"Transmission over Arbitrarily Permuted Parallel Gaussian Channels"},"authors":[{"name":"Ayal Hitron"},{"name":"Anatoly Khina"},{"name":"Uri Erez ∗"}],"abstr":{"text":"Abstract\u2014We address the problem of communication over arbitrarily permuted parallel Gaussian channels, where the permutation is known only to the receiver. We present a practical transmission scheme, that allows to transmit over this channel using off-the-shelf codes, in conjunction with linear processing and successive interference cancellation. The scheme is based on the approach of joint matrix triangularization. Explicit precoding matrices are derived for up to six parallel channels."},"body":{"text":"The problem of transmitting information over arbitrarily permuted parallel channels was studied by Willems and Gorokhov [1] and by Hof et al. [2]. In this point-to-point scenario, the transmitter is connected to the receiver via K parallel memoryless channels (see Figure 1 for the case of K = 3 ), sharing the same input alphabet, the transition matrices of which are known but not their order. Namely, at each time instance, the transmitter generates K input symbols to be sent over the K parallel channels, and these symbols are then permuted by a one-to-one-mapping (permutation) π from {1, . . . , K} onto itself.\nThe permutation π is arbitrary, yet constant, 1 and is known to the receiver but not to the transmitter. The aim of the receiver is to recover the transmitted message with arbitrarily small error probability. This channel model is of relevance in scenarios where the gains of the channels are generated according to an i.i.d. distribution; thus, the histogram (when the number of channels is large) is known, but the permutation is not. For details see [1, Section VII].\nWhen the permutation is constant during the whole trans- mission period (as considered in [1], [2]), this setting falls under the framework of compound channels, 2 the capacity of which is well known (see, e.g., [3]).\nWillems and Gorokhov [1] constructed an MDS-like scheme for treating this case, where the receiver uses joint typicality decoding. In [2] a scheme based on polar codes along with MDS codes was proposed for the case where the channels are binary-input and output-symmetric (BIOS). Another approach to tackle this problem in the Gaussian case is using approxi- mately universal codes [4], which assumes high signal-to-noise ratio (SNR) regime.\nIn this paper we construct a practical capacity-achieving scheme for the Gaussian case, described by\ny i = α i x i + z i , i = 1, 2, . . . , K , \t (1) where x i is the input to the i-th channel which is subject to a power constraint 3\nSince the capacity-achieving input distribution for all the channels is identical (circularly-symmetric complex normal with unit variance), the capacity of the compound channel is:\nAn interesting special case of the permuted parallel channels problem is that of parallel Gaussian erasure channels, where a constant number of channels is \u201cerased\u201d at each time instance. In the notation of the Gaussian permutation channel, this cor- responds to the case of the coefﬁcients α i (1) equaling either the same constant channel gain α or 0 (in case of an erasure). For this special case, capacity in the compound setting can be efﬁciently achieved using MDS codes concatenated with codes which are good for scalar AWGN channels. However, except\nfor this extreme case, practical capacity-achieving schemes are not known.\nIn this paper, we develop a space\u2013time modulation tech- nique that, in conjunction with successive interference cancel- lation (SIC), gives rise to effective (scalar) parallel AWGN channels with the same gains (and order) for all possible permutations. Thus, by using off-the-shelf (ﬁxed-rate) AWGN codes over the effective channels, capacity is achieved. We present exact solutions for K ≤ 6 parallel channels, and discuss the generalization for larger K.\nIn this section we review the scheme proposed in [5] for multicasting a common message over MIMO Gaussian channels. This scheme uses joint matrix triangularization, along with SIC, to transform the channel into parallel single- input single-output (SISO) AWGN channels, with rates that are known at the transmitter.\nThe channel model in [5] is the two-user common-message Gaussian broadcast channel:\nz k is an additive circularly-symmetric Gaussian noise vector of dimensions n (k) r × 1.\nThe aim of the transmitter is to multicast the same (com- mon) message to all the receivers. The capacity of this scenario equals the (worst-case) capacity of the compound channel (see, e.g., [3]), with the compound parameter being the channel matrix index:\nlog det I + H k C x H \u2020 k , \t (3) where maximization is carried over all admissible channel input covariance matrices C x 0 , subject to the power constraint.\nThe transmission scheme of [5] is based on applying a unitary triangularization to two augmented matrices:\nI \t , k = 1, 2 T k = U \u2020 k G k V,\nwhere V is an n t × n t precoding unitary matrix applied at the transmitter (and thus, cannot depend on k), U \u2020 k is an n t × (n (k) r ) + n t ) matrix with orthonormal rows which is known at the receiver (and may differ between the receivers), and T k is an n t × n t upper-triangular matrix.\nReceiver k applies the matrix ˜ U \u2020 k to the channel output, where ˜ U \u2020 k is an n t × n (k) r matrix consisting of the left n (k) r columns of U \u2020 k ,\n= ˜ U \u2020 k H k C k V ˜ x + ˜ U \u2020 k z ˜ T k ˜ x + ˜ z .\nFinally, SIC is performed, i.e., the codebooks are decoded from last (j = n t ) to ﬁrst (j = 1), where each codebook is recovered from y j ˜ y j − n t l=j+1 ˜ T j,l ˆ ˜ x l , where ˆ˜x l is the decoded symbol from the l-th codebook.\nwhere [A] ij denotes the (i, j)-th element of the matrix A. If all the matrices T k have the same diagonal values, then:\nFinally, it is shown in [5] that there always exists such a decomposition, which is coined joint equi-diagonal trian- gularization (JET). Moreover, an explicit construction of the matrices V, U 1 , U 2 is given. As a result, this scheme can always be used in order to achieve the capacity of the two- user common message Gaussian MIMO broadcast channel (3). However, an exact JET is known to exist only for K = 2 for general matrices, and it is not known how to generalize it to larger values of K.\nIn this section we reformulate the problem of arbitrarily permuted parallel Gaussian channels in terms of a common- message MIMO broadcast problem for K! users, where K is the number of parallel channels.\nThe K parallel channels (1) can be regarded as a single MIMO channel:\nThe channel matrix H is a K × K diagonal matrix, which is known at the receiver:\nThe transmitter knows the matrix H, up to the unknown order of the diagonal elements.\nThe latter is, in turn, equivalent to multicasting the same (common) message to K! receivers simultaneously, where the channel matrices of the various users are all of the form:\nand π k ∈ S K is a permutation which is different for each user. The transmission scheme is obtained, similarly to the two-\nuser scheme (4), by applying a joint unitary triangularization to the augmented matrices, with C x = I :\nwhere V is a precoding unitary matrix which is known at the transmitter (and thus, cannot depend on k), U k is a matrix with orthogonal columns which is applied by receiver k, and T k is an upper-triangular matrix.\nIn the case where all the matrices {T k } have the same diagonal values, the following rate is achieved:\nwhich, according to (2), is equal to the capacity of the channel. Note that U k and T k in (6) constitute the QR decomposition\nof the matrix G k V . Consequently, the matrix T k is the Cholesky factor of the matrix V \u2020 (I + H \u2020 k H k )V :\nTo summarize, the proposed scheme allows to achieve the capacity (2) using codes designed for scalar AWGN channels with known SNRs, provided that there exists a unitary matrix V such that the Cholesky decomposition (7) holds for every k , {T k } being upper-triangular with the same diagonal values.\nFor K = 2 this is achievable using the JET, as discussed in Section II. However, as mentioned above, JET is known to exist for only K = 2 (for general matrices), and it is not known how to generalize it to larger values of K. In the following section, we show that in the special case of arbitrarily permuted channels (5), the decomposition (7) exists for K = 2 and K = 3. Later, we review the concept of space\u2013time triangularization, introduced in [6], and show that it can be used to obtain a practical scheme which achieves the capacity for 4 ≤ K ≤ 6.\nWe now consider the special case of two parallel channels (K = 2). The channel can be in one of two \u201cstates\u201d:\nThe special case a = 1 (or b = 1) corresponds to a Gaussian erasure, where there occurs exactly one erasure in every two symbols, but the location of the erasure is unknown at the transmitter.\nSince there are only two options for the channel matrix H, the capacity in this case can be achieved by using the JET described in Section II.\nSpeciﬁcally, we show next that the decomposition (7) is obtained by choosing the precoding matrix to be the (scaled) Hadamard matrix (which coincides with the 2×2 DFT matrix):\nAlternatively, we can use the fact that the diagonal values of the Cholesky factor of a matrix can be expressed as the ratios between the determinants of its principal minors (see, e.g., [7]). In our case, the determinants of the principal minors of both (8) and (9) are M 1 = 1 2 (a + b) and M 2 = ab . Therefore, the diagonal values of the Cholesky factors are\n, which coincide with (10) and (11), respectively.\nSince T 1 and T 2 have the same diagonal values, the same SISO codewords can be used to simultaneously achieve the capacities of both channels H 1 and H 2 .\nNote that the precoding matrix V used by the transmitter does not depend on a or b. Nonetheless, the rates of the SISO codebooks need to be known at both transmission ends.\nWe now treat the case of three parallel channels (K = 3). In this case, we have:\na 0 0 0 b 0 0 0 c\nwhere a, b, c ≥ 1 are known, up to an unknown permutation. In this case, we propose the following precoding matrix, which is the 3 × 3 DFT matrix:\nwhere M 1 , M 2 , M 3 are the determinants of the principal minors of (12):\nM 2 = 1 3 (ab + ac + bc) M 3 = abc .\nSince M 1 , M 2 , M 3 are invariant to the order of (a, b, c), so are the diagonal values d 1 , d 2 , d 3 . Thus, the proposed scheme, using the precoding matrix V , achieves the capacity (2) simultaneously for all the possible permutations π k .\nNote that a 3 × 3 linear transformation over the complex ﬁeld can be regarded as a 6 × 6 transformation over the reals. Thus, in the case that the parallel channels (1) are real- valued (rather than complex valued), we can, nonetheless, use the proposed scheme, by treating two consecutive real-valued input symbols as a single complex-valued symbol. In fact, as explained in the next section, this is a special case of the time\u2013 space triangularization approach.\nUnfortunately, the above two special cases do not carry over to the case of K = 4: using the 4 × 4 complex-valued DFT matrix does not yield equal diagonal values after Cholesky decomposition of V \u2020 (I + H \u2020 k H k )V . For this reason, we need to extend the space\u2013time approach beyond the complex ﬁeld, using quaternions, as detailed in the next section.\nIn order to obtain a transmission scheme for more than three parallel channels, we utilize space\u2013time triangularization, which was proposed in [6] for the general case.\nFor illustration, assume we have three parallel channels with gains α 1 , α 2 , α 3 . The parallel channels can be represented by the 3 × 3 channel matrix\nα 1 0 0 0 α 2 0 0 0 α 3\nHowever, we can also regard it is a 6 × 6 MIMO channel, where in each channel-use six symbols are being transmitted, two symbols on each one of the parallel channels. Thus, the channel matrix of this 6 × 6 channel is:\nUsing extended channel matrices, the scheme described in Section II can be employed, where the channel matrices H k are replaced by their extended versions H k . As we shall see in the sequel, this allows to achieve the channel capacity of K parallel channels beyond the case of K = 3 channels.\nIn order to achieve the capacity for 4 ≤ K ≤ 6, we will use extended matrices with two duplications, where each pair of two consecutive complex-valued symbols will be regarded as a single quaternion-valued symbol.\nA quaternion w ∈ H can be regarded as a collection of four real-valued symbols [8]\nThe transformation of multiplying a quaternion on the left by the quaternion w, W (x) wx , is a linear transformation from H to H over the ﬁeld R. Using the basis {1, i, j, k}, this transformation is given by the following matrix:\nAlternatively, the same quaternion can be regarded as a collection of two complex-valued symbols:\nW = a + bi −c − di c − di a − bi . A. Four Parallel Channels (K = 4)\nWe now show how quaternion-valued matrices allow the de- sign of a precoding matrix for four permuted parallel channels (K = 4). Using extended matrices with two duplications, the channel matrix (over the complex ﬁeld) is:\nwhich is an 8 × 8 matrix. By combining every two complex- valued symbols into a single quaternion-valued symbol, we arrive at the following 4×4 matrix over the quaternion division ring:\n  \na 0 0 0 0 b 0 0 0 0 c 0 0 0 0 d\n  \n  \n1 1 1 1 1 x i iy 1 z −1 −z 1 y −i −ix\n  \n  \nd 1 ∗ ∗ ∗ 0 d 2 ∗ ∗ 0 0 d 3 ∗ 0 0 0 d 4\n  \nand ∗ represents some value (which may differ from entry to entry). Again, the diagonal values are invariant to reordering of the values (a, b, c, d), hence this scheme achieves capacity. B. Five Parallel Channels (K = 5)\nFor ﬁve parallel channels, there also exists a capacity- achieving precoding matrix over the quaternions. The capacity (2) is achieved using the following quaternion precoding matrix:\n    \n1 w q q 2 T (w) 1 x q 2 q 4 T (x) 1 y q 3 q 6 T (y) 1 z q 4 q 8 T (z)\n    \nwhere T (w +xi+yj +zk) w + xi − yj − zk and q e 2πi 5 . The values w, x, y, z were obtained numerically:\nwhich are again invariant to permutations of a, b, c, d, e. C. Six Parallel Channels (K = 6)\nFor K = 6, a 6 × 6 quaternion precoding matrix was found numerically, but we do not have explicit expressions for the entries of this matrix. The matrix, which is given in [9], yields diagonal values of a form similar to (13).\nFor a larger number of parallel channels, algebras of higher dimensions need to be considered. to achieve a Cholesky decomposition with a form similar to (13). Another approach could be to use nearly-optimal precoding matrices, as de- scribed in [10] for general channel matrices. However, this is not practical, even for relatively small number of channels. For example, for K = 7 there can be 7! = 5040 possible matrices {H k } (in case that all the channel gains α i are different), so that using this scheme for joint triangularization would suggest an enormous amount of duplications, which becomes impractical. Nearly optimal schemes for permuted parallel Gaussian channels (i.e., this special class of matrices) is an interesting avenue for future research.\nFinally, we note that the proposed scheme can also be applied to the case of arbitrarily varying permuted Gaussian channels, where the permutation π may vary between channel uses. Suppose that we obtained a joint triangularization (6), where T k is upper-triangular with diagonal elements not de- pending on k. Since the receiver multiplies the received input signal y by U \u2020 π and performs SIC of the various codewords, the scheme allows the channel H k (and therefore the unitary matrix U k ) to vary from symbol to symbol. Note, however, that this applies only for K = 2, 3, where one sample is processed at a time. In cases where several channel outputs ought to be grouped and processed together, the permutation π needs to be constant during several consecutive channel uses. This requirement is reminiscent of the requirement in Alamouti space\u2013time coding [11]. If, for example, quaternion precoding is being used, then π need to be constant during every two consecutive channel uses."},"refs":[{"authors":[{"name":"F. Willems"},{"name":"A. Gorokhov"}],"title":{"text":"Signaling over arbitrarily permuted parallel channels"}},{"authors":[{"name":"E. Hof"},{"name":"I. Sason"},{"name":"S. S. (Shitz)"}],"title":{"text":"Polar coding for reliable com- munications over parallel channels"}},{"authors":[{"name":"J. Wolfowitz"}],"title":{"text":"Simultaneous channels"}},{"authors":[{"name":"S. Tavildar"},{"name":"P. Viswanath"}],"title":{"text":"Approximately universal codes over slow- fading channels"}},{"authors":[{"name":"A. Khina"},{"name":"Y. Kochman"},{"name":"U. Erez"}],"title":{"text":"Joint unitary triangularization for MIMO networks"}},{"authors":[{"name":"A. Khina"},{"name":"A. Hitron"},{"name":"U. Erez"}],"title":{"text":"Modulation for MIMO networks with several users"}},{"authors":[{"name":"A. S. Householde"}],"title":{"text":"The Theory of Matrices in Numerical Analysis, 1964, reprinted by Dover, New York, 1975"}},{"authors":[{"name":"W. R. Hamilto"}],"title":{"text":"On Quaternions, or On a New System of Imaginaries in Algebra"}},{"authors":[],"title":{"text":"Online]"}},{"authors":[{"name":"I. Livni"},{"name":"A. Khina"},{"name":"A. Hitron"},{"name":"U. Erez"}],"title":{"text":"Space-time MIMO multi- casting"}},{"authors":[{"name":"S. M. Alamouti"}],"title":{"text":"Multidimensional constellations - Part II: Voronoi Constellations"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566821.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S15.T3.4","endtime":"11:10","authors":"Ayal Hitron, Anatoly Khina, Uri Erez","date":"1341571800000","papertitle":"Transmission over Arbitrarily Permuted Parallel Gaussian Channels","starttime":"10:50","session":"S15.T3: Topics in MIMO","room":"Stratton S. de P. Rico (202)","paperid":"1569566821"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
