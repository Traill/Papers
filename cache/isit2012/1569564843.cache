{"id":"1569564843","paper":{"title":{"text":"The Effect of Zero-Rate Encoders in the Multi-terminal Source Coding Problem"},"authors":[{"name":"Badri N. Vellambi"}],"abstr":{"text":"Abstract\u2014This work focuses on the multi-terminal source coding problem and presents conditions when a rate point achievable with asymptotically zero-rate messages over a subset of network links, is also achievable with no communication over links in that subset. We show that when there exist block codes that are robust to small changes in the source distribution, zero- rate encoders can be ignored, i.e., their outgoing links can be assumed to be absent. Additionally, we show that when the decoder is given access to the strictly causal past realizations of the sources, zero-rate encoders can always be ignored."},"body":{"text":"In source coding, a rate region is deﬁned as the set of all achievable rate points. It is possible to design block codes that convey messages at rates arbitrarily close to such rate points while meeting the reconstruction requirements. Over the last ﬁfty years, the rate regions of several canonical problems have been successfully characterized. Some such problems include the rate-distortion, the Wyner-Ziv, and the Slepian-Wolf problems [1]. The rate regions of these problems are presented as single-letter characterizations that involve not only random variables deﬁned in the problem setup, but also additional auxiliary random variables [1], [2]. Although single-letter characterizations are complete descriptions of rate regions, they do not readily reveal the properties of the underlying rate regions. For example, in many networks, it is not straightforward to verify if a rate point is contained in the rate region. In problems without single-letter characterisations, it is harder to extract meaningful properties of rate regions such as continuity, slope of the rate region boundary, etc. Recently, Gu et al. have established the continuity of rate regions w.r.t. reconstruction demands and source distributions for several classes of network problems [3], [4].\nA property of rate regions similar to continuity is the consis- tency of rate regions. In engineering, it is common that when a solution to a problem is known, a solution to a subproblem or restriction of the problem is also obtained (almost) directly. In information theory, the question consistency is formulated as follows: \u201cCan asymptotically zero-rate communication on any subset of edges be critical to the inclusion of a rate point in the rate region?\u201d An investigation in this direction would provide conditions when a rate point with zero rates on a subset S of links is also achievable with no transmission on links of\nS. So far, in a general network setting, the equivalence of asymptotically zero-rate communication and no transmission remains an open question. It is to be noted that even though consistency and continuity are related, the former is not a consequence of the latter. While continuity relates to the smooth variation of the rate region with respect to the demand and source distribution, consistency is closely related to the asymptotic convergence properties of block codes.\nThis work investigates the effect of asymptotically zero-rate communication, and is similar to [5], [6] where the authors have investigated the effect of deleting an edge with a given link capacity on the rate region. Though both works deal with general network settings, they only consider asymptotically lossless reconstructions of sources. This work investigates the effect of zero-rate links speciﬁcally in the multi-terminal source coding (MTSC) problem involving discrete memoryless sources (DMSs) and lossy reconstruction requirements. In [7], we showed that asymptotically zero-rate communication is equivalent to no communication in the MTSC problem pro- vided (a) there are only two sources, or (b) certain Markov relation holds. In this work, we present two independent results regarding zero-rate encoders. First, we introduce a new concept of code stability, using which, we provide a sufﬁcient condition for the equivalence to hold. Next, we prove that zero-rate links can always be ignored (in any MTSC problem) when the decoder can use the strictly causal past realizations of the sources to generate source reconstructions.\nThe remainder of the paper is organized as follows. Sec- tion II deﬁnes the notations employed, and Section III deﬁnes the problem setup and various associated terminologies. Fi- nally, Section IV presents the new results and their proofs.\nFor n ∈ N, [n] {1, . . . , n}. 0 n and 1 n represent the 1 × n all-zero and all-one vectors, respectively. For two real vectors A , B ∈ R n , we denote A B to mean A i ≤ B i for each i ∈ [n]. Uppercase letters (e.g., X, Y ) are reserved for random variables (RVs) and the script versions (e.g., X , Y ) correspond to their alphabets, whose sizes are assumed to be ﬁnite in this work. The realizations of RVs are usually denoted by lowercase letter (e.g., x, y). Subscripts are used for components of vectors and generally indicate time indices, i.e., x [n] denotes a vector of length n and x j represents the j th component of x [n] . Superscripts in brackets to refer to\nsource indices, e.g., X (i) j is the j th component of the i th source. The Hamming distortion measure on a set X is denoted by ∂ X H , and E denotes the expectation operator, whose subscript (if any) represents the probability measure with which the expectation is taken. For a ﬁnite alphabet X , P(X ) denotes the set of all probability distributions on X . For p ∈ P(X ), p ⊗n denotes the joint distribution of n i.i.d. RVs, each with distribution p. For p ∈ P(X ) and ˜ p ∈ P(X n ), we denote\nGiven a DMS emitting (X (1) j , . . . , X (l) j ) j∈N with each l- tuple having a joint distribution p X (1) ···X (l) , the MTSC problem aims to identify rates at which encoders have to separately encode sequences {X (i) j } j∈N , i ∈ [l], using l encoders so that l suitably distorted reconstructions can be constructed at the joint decoder (see Fig. 1). In this work, we assume that each source is required to be reconstructed within a certain ﬁdelity constraint under a given distortion measure. This setting subsumes cases where some sources need not be reconstructed, while some others need to be reconstructed losslessly (i.e., with vanishing block-error probability). Since the MTSC problem is a canonical network problem [4], the absence of a reconstruction requirement or lossless recon- struction for a particular source can be treated as requiring a Hamming distortion of either 0.5 or 0, resp.\nFor i ∈ [l], the reconstruction {X (i) j } j∈N is a sequence of elements from the reconstruction alphabet X (i) ; these reconstructions are evaluated using the distortion measures ∂ (i) : X (i) × X (i) → [0, 1] 1 , i ∈ [l]. A rate-distortion pair (R, ∆) (R 1 , . . . , R l , ∆ 1 , . . . , ∆ l ) is said to be achievable if for each ε, δ > 0, there exists an (ε, δ)-achievable block code (φ (1) [n] , . . . , φ (l) [n] , ψ (1) [n] , . . . , ψ (l) [n] ). That is, ∀ ε, δ > 0, ∃ n ∈ N, encoders φ (i) [n] : X (i)n → M (i) , i ∈ [l], and decoders ψ (i) [n] : M (1) × · · · × M (l) → X (i) n , i ∈ [l], satisfying:\nand κ R : (0, 1) 2 → (0, 1) s.t. lim (ε,δ)→(0,0) κ R (ε, δ) = 0. A2. |M (i) | ≤ 2 n(R i +µ R (ε)) , where µ R : (0, 1) → (0, 1) s.t.\nGiven ∆, a rate point R is said to be achievable if (R, ∆) is achievable in the above sense. The set of all achievable rate points is denoted by R MTSC (∆)[p X (1) ···X (l) ]. This set, known as the rate region, is convex and closed [1]. Further, for a given source and reconstruction requirement, let R be an achievable rate point with zero rates on edges outgoing from encoders in S. Then, we say that S is zero-rate removable (ZRR) at R if R are achievable even when constant messages are sent over the edges corresponding to encoders in S (i.e., when the edges of S are deleted). Similarly, we say a subset of encoders S is ZRR if any achievable rate R with zero rates on all edges emanating from encoders in S, is also achievable when constant messages are sent over those edges.\nWe begin this section with the deﬁnition of a new concept that we call stability, which will later be used as a sufﬁcient criterion for zero rate removability.\nDeﬁnition 1: An achievable rate point R is termed (F, µ R , κ R )-stable if the following hold:\nB1. F : (0, 1) → (0, ∞) is increasing and continuous with lim x↓0 F (x) = 0; µ R : R ≥0 → R ≥0 , κ R : R 2 ≥0 → R ≥0\nB2. there exist: (i) {(ε i , δ i )} i∈N with (ε i , δ i ) → 0 2 and (ii) a sequence of codes C i of length n i symbols that operates at rate R + µ R (ε i )1 l , and offers an average distortion of no more than ∆ + κ R (ε i , δ i )1 l .\n) denotes the distortion the code C i offers for the source realization x [n i ] .\nIn this deﬁnition, we call C i an (ε i , δ i , F, µ R , κ R )-stable code at R. For notational ease, we say a rate point R is F -stable or (F, µ R , κ R )-stable when the context is clear. Lastly, a rate region is F -stable if each rate point in the region is F -stable.\nF -stability, illustrated in Fig. 2, guarantees the existence of sequences of codes that approach the required rate and dis- tortion vectors, with the additional property that they operate well for any block-DMS whose distribution is \u2018close\u2019 to p; the level of this closeness is deﬁned by the d -metric. One natural question that arises is: \u201cWhat rate points are stable under some function F?\u201d The following theorem shows that stable codes exist for the bulk (mathematically, the topological interior [8]) of the rate region.\nTheorem 1: Consider the MTSC problem for a DMS p X (1) ···X (l) with full support, and reconstruction requirement ∆ ≥ 0. Let F : (0, 1) → (0, ∞) be a continuous, increasing function with lim x↓0 F (x) = 0. Then, any achievable point R in the topological interior of the rate region is F -stable.\nOutline of Proof 1: Since R is an interior point, R \u2032 R − η1 l is an interior point for some η > 0, and by [9, Thm. 5], R \u2032 ∈ A ∗ k for some k ∈ N (see [9]). Using strong-typicality- based code design techniques, we can build codes treating the emitted symbols as those from a super-source p ⊗k . Let C be one such code over n super-symbols (nk source symbols) operating at a rate no more than R \u2032 + η1 l , and satisfying Pr[∆+η1 l ∆ C (X ([l]) [nk] )] < e −nζ for some ζ = ζ(p, k, η) > 0. Let S {x ([l]) [nk] : ∆ + η1 l ∆ C (X ([l]) [nk] )}. Then,\nwhere B(S, nkδ), deﬁned in Lemma 4, is a blown-up set of S ⊆ (X (1) × · · · × X (l) ) n , and Ω, ω are the maximum and minimum positive values p X (1) ···X (l) takes. Now, let ˜ p satisfy d (˜ p, p ⊗nk ) ≤ F (ε). Then, there exist RVs ˜ X ([l]) [nk] , X ([l]) [nk] with distributions ˜ p and p ⊗nk satisfying (1). Let Z be the Hamming distance between ˜ X ([l]) [nk] and X ([l]) [nk] when viewed as vectors over X (1) ×· · ·×X (l) , and let E be the event that Z > nk F (ε). By Markov inequality [1, p. 168], Pr[E] ≤ F (ε). Then,\nBy careful selection of n, and by allowing ε to be suitably small, we can make the above probability arbitrarily small. Thus, the code C performs well for the source ˜ p. Hence, C is a stable code for R for a suitable choice of parameters.\nNote that at F -stable rate points, there exist codes robust to small variations in the source distribution. This fact can be used to show zero-rate removability at F -stable rate points. Before we present that result, we prove a technical result that shows that concatenation of stable codes yield stable codes.\nLemma 1: Let F, g : (0, 1) → (0, ∞) be s.t.: (a) F meets the conditions in B1 (Def. 1); (b) g is continuous and increas-\ning s.t. lim x→0 g(x) = 0, and lim x→0 F (x) g(x) = 0. Let G(x) = F (x) g(x) and let C be an (ε, δ, G, µ R , κ R )-stable code of length n at R. Then, there exists an (ε, δ, F, µ R , ˜ κ R )-stable code of length n⌈ 1 nεµ R (ε) ⌉ at R, where ˜κ R (ε, δ) κ R (ε, δ) + g(ε).\n⌈ 1 nεµ R (ε) ⌉ times. We claim that C \u2032 is an (ε, δ, F, µ R , ˜ κ R )- stable code of length N n at R. We only need to show that C \u2032 satisﬁes B3. To do so, let ˜ p ∈ P(X (1)N n ×· · ·×X (l)N n ) s.t. d (˜ p, p ⊗N n ) ≤ F (ε). From (1), there exist RVs ˜ X [N n] , X [N n] with joint distribution q ˜ X ([l])\nThen, by an application of Markov inequality on (7), we see that |J| ≥ N(1 − g(ε)). Since C is (ε, δ, G, µ R , κ R )-stable,\nTheorem 2: Consider the MTSC problem for DMS p X (1) ···X (l) with reconstruction requirement ∆ ≥ 0. Suppose that for some ν > 0, R (r 1 , . . . , r l−1 , 0) is achievable and ((µ R (ε)) 1 2 −ν , µ R , κ R )-stable. Then {l} is ZRR at R.\nProof: Let p be a shorthand for p X (1) ···X (l) and let 0 < ε, δ < 1. By a direct application of Lemma 1 with g 2(µ R ) ν , one can identify a (ε, δ, F, µ R , ˜ κ R )-stable code of length n ∈ N s.t. nµ R (ε) > 1 ε , F (ε) 2 µ R (ε), and ˜ κ R (ε, δ) κ R (ε, δ) + 2(µ R (ε)) ν .\nLet (f (1) C , . . . , f (l) C ) denote the encoders of C, and let g C denote the decoder. The aim is to construct a code C \u2032 s.t. (a) the message sent over the l th edge is a constant, and (b) the difference between the average distortions offered by C and C \u2032 is bounded above by some function of (ε, δ). To do so, we will construct a distribution \u2018close\u2019 to p ⊗n . Select j ∗ ∈ M (l) = [⌈2 nµ R (ε) ⌉] s.t. Pr[f (l) C (X (l) [n] ) = j ∗ ] > 2 − 2 log 2 nµ R (ε) . Let B(j ∗ , nF (ε)) denote the set of all vectors in X (l)n that differ in fewer than nF (ε) components from some vector in f (l) C −1 (j ∗ ) ⊆ X (l)n . Now, by Lemma 4 of App. A,\n    \nz [n] \t z [n] / ∈ B(j ∗ , nF (ε)) arg min\nNote that r ∈ P(X (1)n × · · · × X (l)n ), and r(x) = 0 when x ∈ X (1)n ×· · ·×X (l−1)n × B(j ∗ , nF (ε))\\f (l) C\nProof: Let X ([l]) [n] \t (X (1) [n] , . . . , X (l) [n] ) be a random vec- tor with distribution p ⊗n . Let Y ([l]) [n] \t (Y (1) [n] , . . . , Y (l) [n] )\n(X (1) [n] , . . . , X (l−1) [n] , ξ(X (1) [n] )) . Since ξ maps B(j ∗ , nF (ε)) to f (l) C −1 (j ∗ ), and is an identity map over B(j ∗ , nF (ε)) c ,\nFrom (9), we see that Y ([l]) [n] is distributed according to r. Hence, the claim holds.\nDeﬁne a new code C \u2032 operating over n symbols as follows: (i) encoders φ (i) C \u2032 f (i) C for 1 ≤ i < l; (ii) encoder φ (l) C \u2032 maps each x (l) [n] ∈ X (l)n to j ∗ ; and (iii) decoder ψ C \u2032 g C .\nEncoders φ (i) C \u2032 , i ∈ [l], map input X ([l]) [n] to an element of M (1) × · · · × M (l−1) × {j ∗ } in two stages. In the ﬁrst, the encoders convert their input to generate an intermediate output Y ([l]) [n] ∈ X (1)n × · · · × X (l)n , where (Y (1) [n] , . . . , Y (l) [n] )\n(X (1) [n] , . . . , X (l−1) [n] , ξ(X (l) [n] )); this output Y ([l]) [n] has a distribu- tion of r. The encoders f (1) C , . . . , f (l−1) C \t are then employed on Y ([l]) [n] in the second stage to generate an index from M (1) × · · · × M (l−1) × {j ∗ }. The decoder for C \u2032 , which is the same as that of C, is ﬁnally used to generate the reconstructions (X (1) [n] , . . . , X (l) [n] ) from the generated indices. Let ∆ C (x), ∆ C \u2032 (x) denote the per-symbol distortion vectors measured between the sources and their reconstructions using codes C and C \u2032 , respectively, when the source realization is X ([l]) [n] = x ∈ X (1)n × · · · × X (l)n . Since C is F -stable and d (r, p ⊗n ) ≤ F (ε),\nThe expected distortion between the i th source and its recon- struction from code C \u2032 can now be computed as follows:\nwhere (a) follows from (8), and because ∆ C \u2032 (x ([l]) [n] ) i ≤ 1; (b) from (9), and because ∆ C \u2032 (x) = ∆ C (x) for x ∈ X (1)n × · · · × X (l−1)n × f (l) C −1 (j ∗ ), ; and ﬁnally (c) from (10).\nThus, starting from a sequence {C ε i ,δ i } i∈N of F -stable codes for rate point R and demand ∆, we can construct {C \u2032 ε i ,δ i } i∈N whose: (a) rates approach R; (b) reconstructions have an expected distortion approach ∆; and (c) encoders for X (l) are constant functions. Thus, {l} is ZRR at R.\nLemma 3: Consider a DMS p X (1) ···X (l) with MTSC en- coders {φ (i) [n] : X (i) [n] → M (i) : i ∈ [l]}. Let M (i) φ (i) [n] (X (i) [n] ) for i ∈ [n]. Then, for each m ∈ M (1) × · · · × M (l) , the optimal reconstructions x (i) j (m), i ∈ [l], j ∈ [n] that minimize the distortion measures are given by:\nProof: The expected distortion between a source and its reconstruction is minimized if the conditional expected distor- tion (conditioned on the messages output by the encoders) is minimized. This minimization yields the condition in (16).\nTheorem 3: Consider a modiﬁcation of the MTSC problem for the DMS p X (1) ···X (l) with reconstruction requirement ∆ where the decoder can use in addition to the received encoded messages, the strictly causal past source realizations (i.e., X ([l]) [j−1] ) to reconstruct the j th symbol of each source. In this modiﬁed MTSC problem, any subset S of encoders is ZRR.\nProof: We assume S = {l}, since the result can be extended to non-singleton sets by induction. Consider an achievable rate point R = (R 1 , . . . , R l−1 , 0). Let ε > 0 and let C ε be a code of length n, operating at rate R + ε1 l , and offering an expected distortion of no more ∆ + ε1 l . Let for i ∈ [l], M (i) = φ (i) [n] (X (i) [n] ). Then,\nNotice that in the above expression, the average of n non- negative numbers is bounded above by ε. Therefore, deﬁne\nNote that for j ∈ J ε the arguments from (18)-(22) hold (see next page). In these arguments, (a) follows from Pinsker\u2019s in- equality [2, p. 44], and (b) follows from Jensen\u2019s inequality [1, p. 169]. Also, in both (20) and (21), the norms are computed by viewing the conditional distributions as vectors in R |X ([l]) | . Now, deﬁne G[j] as in (23) (see next page) and let E j be the event that (X ([l]) [j−1] , M [l−1] ) ∈ G[j]. Then, by using Markov inequality and (22), we can show that\nConsider two decoders for the code C ε : Decoder A that uti- lizes M (i) , i ∈ [l], and the strictly causal source side informa- tion, and Decoder B that uses messages M (i) , i ∈ [l − 1], and the available source side information. Suppose that at the j th instant, Decoder A receives messages M ([l]) = m ([l]) and side information X ([l]) [j−1] = x ([l]) [j−1] . Then, by an argument similar to that in Lemma 3, one can show that the optimal reconstruction (say X (i) j,A ) at Decoder A for the j th symbol of the i th source de- pends on p X (i)\nmal reconstruction (say X (i) j,B ) at Decoder B for the same sym- bol depends only on p X (i)\nConsider the expected distortions of the j th symbol of the i th source offered by the two decoders. When j ∈ J ε and the event E j occurs, the difference between the conditional expectations of the distortion for the j th symbol of the i th source can be bounded above as follows.\nThis is because (23) guarantees that the difference between the corresponding a posteriori probability distributions (under the L 1 -norm) is no more than 8\ntion function is bounded above by 1. Further, when event E c j : (M [l] , X ([l]) [j−1] ) / ∈ G[j] occurs, the difference between the corresponding conditional expected distortions is no more than unity. Therefore, for j ∈ J ε , the difference in the expected distortions for j th symbol of the i th source offered by the two decoders E [|∂ (i) (X (i) j , X (i) j,A ) − ∂ (i) (X (i) j , X (i) j,B )|] is no more than Pr [E j ] 8\n√ 4ε. Averaging over all indices j ∈ [n], we see that the difference in the expected distortions for the i th source offered by the two decoders is no more than\nThus, encoders of C ε along with Decoder B offer a distortion of no more than ∆ + (ε +\ncode that uses the ﬁrst l − 1 encoders of C ε , sends a constant message, say 1, from the l th encoder, and uses Decoder B to reconstruct the sources. Then, C \u2032 ε offers a distortion of no more than ∆ + (ε +\nl . Since ε is arbitrary, {l} is ZRR at R. Lastly, since R is arbitrary in R M T SC [p X (1) ···X (l) ] except for R l = 0, we see that {l} is ZRR.\n, (27) where B(A, nδ) {y [n] : ∃ x [n] ∈ A s.t. n j=1 ∂ X H (y j , x j ) ≤ nδ}, and (x) + max(x, 0)."},"refs":[]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564843.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S5.T1.1","endtime":"10:10","authors":"Badri N Vellambi","date":"1341309000000","papertitle":"The Effect of Zero-rate Encoders in the Multi-terminal Source Coding Problem","starttime":"09:50","session":"S5.T1: Multiterminal Source Coding","room":"Kresge Rehearsal B (030)","paperid":"1569564843"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
