{"id":"1569565735","paper":{"title":{"text":"Lossy Source Coding via Spatially Coupled LDGM Ensembles"},"authors":[{"name":"Vahid Aref"},{"name":"Nicolas Macris"},{"name":"R¨udiger Urbanke"},{"name":"Marc Vuffray"}],"abstr":{"text":"Abstract\u2014We study a new encoding scheme for lossy source compression based on spatially coupled low-density generator- matrix codes. We develop a belief-propagation guided-decimation algorithm, and show that this algorithm allows to approach the optimal distortion of spatially coupled ensembles. Moreover, using the survey propagation formalism, we also observe that the optimal distortions of the spatially coupled and individual code ensembles are the same. Since regular low-density generator- matrix codes are known to achieve the Shannon rate-distortion bound under optimal encoding as the degrees grow, our re- sults suggest that spatial coupling can be used to reach the rate-distortion bound, under a low complexity belief-propagation guided-decimation algorithm.\nIndex Terms\u2014Lossy source coding, spatial coupling, LDGM, belief propagation guided decimation, rate distortion bound."},"body":{"text":"The spatial coupling of copies of a graphical code was introduced in [1] in the form of convolutional low-density parity-check (LDPC) codes. The performance of such ensem- bles under the belief propagation (BP) algorithm is consistently better than the performance of the underlying ensembles [2\u20134]. The key observation is that the BP threshold of a coupled en- semble considerably improves and gets close to the maximum a posteriori (MAP) threshold of the underlying ensemble. This threshold saturation phenomenon has been studied rigorously in [5, 6]. Furthermore, it has been investigated in other models such as the Curie-Weiss chain, random satisﬁability, graph coloring [7\u20139], and compressed sensing [10, 11].\nOne of the classic problems in communications is lossy source compression. The objective is to compress a given sequence, so that it can be reconstructed up to some spec- iﬁed distortion. For binary symmetric sources, low-density generator-matrix (LDGM) codes are able to asymptotically achieve Shannon\u2019s rate-distortion bound under optimal encod- ing (minimum distance encoding) [12, 13]. However, this is not a computationally efﬁcient scheme.\nLDGM codes are well-suited to low-complexity message passing algorithms such as the BP algorithm. But using LDGM codes with a plain BP algorithm is not very effective in lossy compression. To achieve more promising results, one can equip the BP algorithm with a decimation process. The general idea of belief-propagation guided-decimation (BPGD) algorithms is to: i) compute BP marginals, ii) ﬁx bits with the largest bias, iii) decimate the graph. Decimation reduces the graph to a smaller one, on which this process is repeated. Many variants of message passing algorithms and various decimation processes have been investigated. In [14] a survey propagation (SP) inspired decimation algorithm is proposed. Simulations show\ndistortions close to the rate-distortion bound for large block- lengths. Later, similar results were reported with modiﬁed forms of BP [15, 16]. The performance of these algorithms also depends on the choice of degree distributions for LDGM codes. A heuristic choice is to use degree distributions that have been optimized for LDPC codes on binary symmetric channel [14\u201316]. No rigorous analysis exists to date which can explain why this is the case.\nIn the present contribution, we study a spatially coupled LDGM ensemble for lossy source compression. Two of us [17] studied such ensembles in the context of rateless codes (channel coding) and demonstrated that threshold saturation takes place. We provide numerical evidence showing that a similar effect occurs in lossy compression. In particular, the BPGD distortion of the coupled LDGM ensemble approaches (numerically) the optimal distortion of the underlying en- semble. We use the simplest forms of BP and decimation processes, and we take regular degrees. It is noteworthy that no optimization is needed, thus suggesting that the observed saturation is related to fundamental principles. Regular (under- lying) LDGM ensembles with large degrees have an optimal distortion that approaches the rate-distortion limit. Thus with spatially coupled LDGM codes with regular large degrees and a BPGD algorithm we can attain the Shannon limit. The complexity of the encoding scheme presented here is O(n 2 L 2 ) where L is the number of copies of the underlying ensemble and n the size of each copy.\nIn section II, we brieﬂy review lossy compression and ex- plain the structure of coupled LDGM ensembles. In section III, we formulate lossy compression as an optimization problem and compute the optimal distortion for underlying and coupled LDGM ensembles, by using the SP formalism. In section IV, we formulate and discuss the BPGD algorithm. Simulation results for this algorithm are presented in section V. A few practical issues are discussed in section VI.\n1) Lossy Compression of Symmetric Bernoulli Sources: Let X ∈ X = {0, 1} n represent a binary source of length n. We have X = {X 1 , X 2 , . . . , X n }, where {X a } n a=1 are i.i.d random variables with P{X a = 1} = 1 2 , for a ∈ {1, . . . , n}. We compress a given source word x by mapping it to one of the 2 nR index words u ∈ U = {0, 1} nR , where R ∈ [0, 1] is the rate. The stored sequence u then deﬁnes a reconstructed source sequence x(u) ∈ X , where the source decoding map u → x(u) depends on the structure of the code. For a given pair (x, x), the distortion is measured by Hamming distance\nd H (x, x) = 1 n n a=1 |x a − x a |. Thus, the average quality of the reconstruction is measured by D := 1 n E X (d H (x, x)).\nFor the symmetric Bernoulli source, it is well-known that for any scheme, the average distortion is lower-bounded by D sh , deﬁned implicitly by the rate-distortion function h(D sh ) = 1 − R, D sh ∈ [0, 1 2 ]. Here h(·) is the binary entropy function. The goal is to ﬁnd an encoding scheme such that, for a given R, it achieves the rate-distortion lower bound.\nFor this purpose, we study LDGM codes since they are able to achieve the rate-distortion bound under the optimal encoding when the average degrees increase [12].\n2) LDGM Codes: Consider an LDGM code of block length n and rate R = m n . Let u 1 , · · · , u m be m code-bits of the index word u and let x 1 , x 2 , · · · , x n be n reconstruction bits of the source word x 1 , x 2 , · · · , x n . An LDGM code is usually represented by a bipartite graph as depicted in Figure 1. Call this graph Γ(C, G; E). Each code-bit u i is represented by a node i ∈ C(Γ). For each reconstruction bit x a , there is a generator node a ∈ G(Γ). Each edge (i, a) ∈ E(Γ) shows that the code-bit u i is connected to the corresponding reconstruction bit x a . We denote by ∂a the set of all code-bit nodes connected to a ∈ G, i.e. ∂a = {i ∈ C| (i, a) ∈ E}. Similarly, for i ∈ C, ∂i = {a ∈ G| (i, a) ∈ E}. Thus, the reconstructed bit x a is obtained from the code-bits u by a mod 2 sum x a = ⊕ i∈∂a u i .\nIn this paper, we focus on the (l, r, n)-regular LDGM random ensemble, where l (resp. r) is the degree of gener- ator (resp. code-bit) nodes. We refer to [18] for the detailed construction of this ensemble.\n3) Chain of LDGM (l, r, n) Ensembles: Consider L sets of nodes each having m = l r n code-bit nodes and n generator nodes (and reconstruction nodes). Locate the sets in positions 0 to L − 1 on a circle (see Figure 2). We randomly connect each generator node in position z ∈ [0, L − 1], to l code-bit nodes from w sets in the range [z, z + w − 1]. Eventually (for large n and m) code-bit nodes have degree r. The details of this construction are explained in [5, 17]. Note that this ensemble has the same local structure as the underlying LDGM(l, r) ensemble. Because of the global circular structure, we call it a Closed Chain LDGM(l, r, L, w, n) ensemble (CCLDGM).\nWe wish to point out a difference between the present construction and the ones used so far in channel coding. The latter are based on open linear chains with suitable boundary conditions that help initiate the decoding process, which then propagates like a wave through the system. In the present periodic construction, encoding will be seeded by preferential decimation at a speciﬁc position (say z = L/2), in an initial\nLet Γ be the factor graph of a random instance of an LDGM(l, r, n) ensemble or CCLDGM(l, r, L, w, n) ensemble. We are looking for a conﬁguration u ∗ that minimizes the distortion between x and x(u), i.e.\nNote that for the individual ensemble L = 1. As we are interested in the average distortion of the ensemble over all X ∈ X , we deﬁne the optimal distortion as\nWe transform the above minimization problem into a maxi- mum likelihood problem by equipping the conﬁguration space {0, 1} nLl/r with the following probability measure,\ne −βd H (x,x) the normalizing factor. The minimizer u ∗ in (1) maximizes the measure, i.e, max u µ β (u | x) = µ β (u ∗ | x). Moreover, for a particular x, the minimal distortion can be obtained as d min = −(nL) −1 lim β→∞ β −1 ln Z (β | x) . This formulation of the problem allows to use techniques from sta- tistical physics to compute D opt . In the physics interpretation, d H and µ β are a random hamiltonian and Gibbs measure, β is an inverse temperature, Z a partition function, D opt is the average ground state energy. The latter can be computed by the SP formalism.\nThe details of the SP equations, used to compute D opt , are not shown here. A pedagogical account of the formalism can be found in [19]. The numerical solution of the SP equations shows that the optimal distortions for the underlying LDGM(l, r) and CCLDGM(l, r, L, w) are the same for each ﬁnite w and L (here n and m are inﬁnite). In fact, for an\nensemble with even l and Poisson degree for code-bit nodes, a rigorous proof is presented in [9] where the spatially coupled periodic XORSAT problem is discussed. Optimal distortions for degree distributions (k, 2k), k = 3, 4 and 5 are given in the ﬁrst line of Table I. We observe that, as k increases, the optimal distortion converges to the rate-distortion bound D sh . This observation is consistent with the result in [12, 13].\nThe naive way to compute the partition function involves the summation over 2 nLl/r terms. Unfortunately, this approach is too complex. The same problem occurs for computing the marginal distribution of a node. On a tree, however, these computations can be done exactly and yield the BP equations. We deal with graphs that are locally tree-like and this motivates the use of the BP equations as a ﬁrst approximation for the marginals. These involve a set of 2 |E (Γ)| real valued messages, each pair being associated to an edge. The messages on the edge (i, a) ∈ C (Γ) × G (Γ) are denoted by η i→a and η a→i , and satisfy\nη a→i = 1 β\n(−1) x a tanh( β 2\nAs a side remark, note that as β → ∞ the BP equations become the so-called Min-Sum equations. From the solutions of equations (4) one can compute the BP marginal distributions of code-bit i and generator node a, and a Bethe approximation µ BP β (u|x) (this is not a probability measure in general) of the original measure µ β (u|x). We refer to [19] for more information.\nUnfortunately, the number of solutions of the BP equations which lead to roughly the same distortion, grows exponentially large in terms of n, and one cannot ﬁnd the relevant ﬁxed point by a plain iterative method. To resolve this problem, the BP iterations are equipped with a heuristic decimation process. This forms the basis of the BPGD algorithm.\nIn this section we consider an instance of CCLDGM (l, r, L, w, n) ensemble. Equations (4) will be solved iteratively starting from the initial conditions η (0) i→a = η (0) a→i = 0. At iteration t the messages are η (t) i→a and η (t) a→i . We deﬁne the\nThis represents the tendency of the code-bit to be 0 or 1. Our BPGD algorithm shown in Algorithm 1, uses a decimation condition . Let > 0 a small quantity, α > 0 a large quantity and T an iteration time. Typical values used in the simulations are = 0.01, α = 4.25 and T = 10. We say that the decimation condition is fulﬁlled if one of following occurs:\ni) After some time τ ( ) < T , the messages do not change signiﬁcantly in two successive iterations, in the sense that\n|η (t) a→i − η (t−1) a→i | < for t > τ ( ). ii) For some i and t < T , |b t (i)| > α.\n1) Begin with the graph instance Γ (0) ∈ CCLDGM (l, r, L, w, n).\n2) t = 0, Update equations (4) until the ﬁrst time t 1 such that the decimation condition is fulﬁlled.\n4) If B = 0, then randomly pick a code-bit i from range [ L−w 2 , L+w 2 ] and ﬁx it randomly to 0 or 1.\nElse pick a code-bit i ∈ j ∈ C Γ (k) | |b t 1 (j) | = B randomly and ﬁx u i = 1 2 (sign(b t 1 (i)) + 1).\n5) Update x (k+1) a \t = x (k) a − u i , for a ∈ ∂i, otherwise x (k+1) a \t = x (k) a . Then, update Γ (k+1) = Γ (k) \\{i}.\n6) If there exists an unﬁxed code-bit, then go to (2), Else ﬁnish and return u.\nIt is not difﬁcult to see that the complexity of the algorithm is O(n 2 L 2 ). Note that after each decimation, rather than resetting messages to zero we continue with the previous messages.\nAn important element in the algorithm is that when there is no signiﬁcant bias (step (4)) the random decimation occurs in a speciﬁc bounded interval centered around L/2 and of size w. We observe that this creates a seed from which the encoding process starts propagating through the ring. The usual hard decimation algorithms randomly choose (when there is no bias) a code-bit from the whole graph. We observed that when this prescription is used for CCLDGM instances, the distortion does not improve with respect to that of usual LDGM instances.\nWe have seen that a conﬁguration u ∗ maximizes the prob- ability µ β (u) for all β > 0. If µ BP β was an accurate approx- imation of µ β , we would expect the maximum of µ BP β (u) to be independent of β. But µ BP β is not an exact description of µ β . It is then natural to look at the performance of the BPGD procedure for different β and ﬁnd an optimal parameter β opt .\nFigure 3 illustrates the performance of BPGD versus β for CCLDGM(3, 6, 64, 3, 2000) and LDGM(3, 6, 128000) ensem-\nbles. For this example, the ﬁrst observation is that, for all β > 0, the coupled ensemble has smaller D BPGD than the uncoupled ensemble. We also observe that each ensemble has\nan optimal parameter β opt which lies between 3 2 and 5 2 . In order to make comparison between coupled and uncoupled ensembles and as the distortion does not vary much when β ∈ 3 2 , 5 2 , we ﬁx β = 2 in the rest of the paper. Table I shows that the BPGD distortion - for the value β = 2 - is still consistently higher than D opt .\nThe measure µ β also arises in the context of channel coding over a memoryless binary symmetric channel (BSC). Suppose that we use the LDGM code with factor graph Γ over a BSC with ﬂipping probability p. Then the posterior probability that the un-coded message u ∈ F nl/r 2 is sent given the received codeword x ∈ F n 2 can be formally expressed just as in (3) with β → ln 1−p p . The difference between channel coding and lossy source coding lies in the distribution of X. In lossy source coding, {X a } are n i.i.d. Ber(1/2) variables; whereas in channel coding over a BSC, they are not in general i.i.d. and depend on the ﬂipping probability p (or β).\nWe provide simulation results which convincingly show that the BP distortion of a CCLDGM ensemble closely approaches the optimal distortion of the underlying LDGM ensemble as n, L and w grow large. To emphasize the effect of coupling, we consider the family of (k, 2k)-regular LDGM ensembles. This family is known to yield a weak performance under the BPGD algorithm [12]. Indeed, although the optimal distortion is rather close to the rate-distortion bound and improves as k grows, the BPGD distortion becomes larger as k grows (see Table I). Analogous behaviors are well known to occur in channel coding [18].\nNow consider a CCLDGM(k, 2k, L, w) ensemble. Let D z denote the average distortion of the reconstruction nodes lying at position z. Call D z the local distortion at position z. Thus, the total average distortion is D = 1 L L−1 z=0 D z . Call the vector (D 0 , D 1 , · · · , D L−1 ) the distortion proﬁle.\nWhen we apply the BPGD algorithm, we observe a generic behaviour in the distortion proﬁle. Figure 4 illustrates the distortion proﬁle of CCLDGM(5, 10, L, w, n) ensembles for different pairs of (L, w) and n = 2000 . The proﬁle is symmetric around L 2 (this expected in view of the algorithm). Consider the ﬁrst L 2 components. In the range [0, w − 1], the local distortion is strictly decreasing. It starts at a value roughly\nequal to D BPGD of the underlying ensemble and decreases to a value that we call the saturation value. Then, in the range [w, L 2 ], the local distortions nearly remain constant and equal to the saturation value. We refer to the ﬁrst interval and the second interval respectively as the unsaturated part and the saturated part . Therefore, the average distortion considerably decreases in the coupled ensembles.\nTables II, III and IV show the saturation value (in bold) and the average distortion (in parentheses) for k = 3, 4, 5 and different values of n, L and w. Each value is averaged over 100 random code instances and random source words. Inspection of the tables suggests that it approaches D opt in the regime n \t L \t w \t 1. The average distortion D BPGD converges to the saturation value by increasing L. The reason is the unsaturated part essentially does not change for ﬁxed k, w and n (see Figure 4), thus its contribution in the average distortion vanishes in the large L limit. As a result, we expect that D BPGD gets very close to D opt for a large enough n L w 1 and the optimal β. Moreover, if k grows, D opt converges to the rate-distortion bound. Thus, the D BPGD of a regular CCLDGM ensemble can get close to the rate-distortion bound.\nAs mentioned before, the coupled chains used in channel coding are terminated by suitable boundary conditions and this incurs a rate loss of order O( w L ). In CCLDGM ensembles, we do not pay this cost in the graph structure, but it manifests\nitself in the large local distortion in the 2w positions of the unsaturated part.\nWe have observed that CCLDGM(k, 2k, L, w) ensembles can asymptotically saturate the rate-distortion bound under a BPGD algorithm. Degrees (k, 2k) have been chosen because it is known they lead to weaker results in the uncoupled case, but the saturation presumably occurs for a large class of irregular LDGM ensembles. As a result, using a right-regular CCLDGM ensemble with Poisson distribution on the code-bit nodes, would allow to achieve the rate-distortion bound for all rates R ∈ (0, 1).\nThere are clearly a number of features of the algorithm that can be improved. Two important issues are its convergence rate, and its complexity. To address the ﬁrst one, we can ﬁx to zero the code-bits lying in range [ (L−w) 2 , L+w 2 ] and then, we remove the reconstruction nodes (and source nodes) lying in ranges [0, w 2 ] and [L − 1 − w 2 , L − 1]. The total rate of the code slightly increases but the convergence rate is improved. The complexity of the BPGD algorithm used here is O(n 2 L 2 ). To reduce it one could use a \u201csliding window encoding\u201d similar to the one used for coupled LDPC codes [3]. This would reduce\nthe complexity to O(n 2 L). Finally the use of soft decimation techniques might also help improve the overall performance.\nV.A. was supported by grant No. 200021-125347, and M.V. by grant No. 2000-121903 of the Swiss National Science Foundation."},"refs":[{"authors":[{"name":"A. J. Felstrom"},{"name":"K. S. Zigangirov"}],"title":{"text":"Time-varying periodic convolu- tional codes with low density parity check matrix"}},{"authors":[{"name":"M. Lentmaier"},{"name":"A. Sridharan"},{"name":"D. J. Costello"},{"name":"K. S. Zigangirov"}],"title":{"text":"Iterative decoding threshold analysis for LDPC convolutional codes"}},{"authors":[{"name":"M. Lentmaier"},{"name":"A. Sridharan"},{"name":"K. S. Zigangirov"},{"name":"D. J. Costello"}],"title":{"text":"Ter- minated LDPC convolutional codes with thresholds close to capacity"}},{"authors":[{"name":"M. Lentmaier"},{"name":"D. G. M. Mitchell"},{"name":"G. P. Fettweis"},{"name":"D. J. Costello"}],"title":{"text":"Asymptotically regular LDPC codes with linear distance growth and thresholds close to capacity"}},{"authors":[{"name":"S. Kudekar"},{"name":"T. J. Richardson"},{"name":"R. L. Urbanke"}],"title":{"text":"Threshold saturation via spatial coupling: why convolutional LDPC ensembles perform so well over the BEC"}},{"authors":[],"title":{"text":"Spatially Coupled Ensembles Universally Achieve Capacity under Belief Propagation"}},{"authors":[{"name":"S. H. Hassani"},{"name":"N. Macris"},{"name":"R. L. Urbanke"}],"title":{"text":"Coupled graphical models and their thresholds"}},{"authors":[],"title":{"text":"Chains of mean ﬁeld models"}},{"authors":[],"title":{"text":"Threshold saturation in spatially coupled constraint satisfaction problems"}},{"authors":[{"name":"S. Kudekar"},{"name":"H. Pﬁster"}],"title":{"text":"The effect of spatial coupling on compressive sensing"}},{"authors":[{"name":"F. Krzakala"},{"name":"M. M´ezard"},{"name":"F. Sausset"},{"name":"Y. Sun"},{"name":"L. Zdeborov´a"}],"title":{"text":"Statistical physics-based reconstruction in compressed sensing"}},{"authors":[{"name":"M. Wainwright"},{"name":"E. Maneva"},{"name":"E. Martinian"}],"title":{"text":"Lossy source compression using low-density generator matrix codes: Analysis and algorithms"}},{"authors":[{"name":"S. Ciliberti"},{"name":"M. Mzard"}],"title":{"text":"The theoretical capacity of the parity source coder"}},{"authors":[{"name":"M. Wainwright"},{"name":"E. Maneva"}],"title":{"text":"Lossy source encoding via message- passing and decimation over generalized codewords of LDGM codes"}},{"authors":[{"name":"T. Filler"},{"name":"J. Fridrich"}],"title":{"text":"Binary quantization using belief propagation with decimation over factor graphs of ldgm codes"}},{"authors":[{"name":"D. Castanheira"},{"name":"A. Gameiro"}],"title":{"text":"Lossy source coding using belief propagation and soft-decimation over ldgm codes"}},{"authors":[{"name":"V. Aref"},{"name":"R. L. Urbanke"}],"title":{"text":"Universal rateless codes from coupled lt codes"}},{"authors":[{"name":"T. Richardso"},{"name":"R. Urbank"}],"title":{"text":"Modern Coding Theory"}},{"authors":[{"name":"M. M´ezar"},{"name":"A. Montanar"}],"title":{"text":"Information, physics, and computation, ser"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565735.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S3.T1.5","endtime":"16:20","authors":"Vahid Aref, Nicolas Macris, Ruediger L Urbanke, Marc Vuffray","date":"1341244800000","papertitle":"Lossy Source Coding via Spatially Coupled LDGM Ensembles","starttime":"16:00","session":"S3.T1: Lossy Source Coding","room":"Kresge Rehearsal B (030)","paperid":"1569565735"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
