{"id":"1569564857","paper":{"title":{"text":"Long MDS Codes for Optimal Repair Bandwidth"},"authors":[{"name":"Zhiying Wang ∗"},{"name":"Itzhak Tamo ∗ \u2020"},{"name":"Jehoshua Bruck ∗"}],"abstr":{"text":"Abstract\u2014MDS codes are erasure-correcting codes that can correct the maximum number of erasures given the number of redundancy or parity symbols. If an MDS code has r parities and no more than r erasures occur, then by transmitting all the remaining data in the code one can recover the original information. However, it was shown that in order to recover a single symbol erasure, only a fraction of 1/r of the information needs to be transmitted. This fraction is called the repair bandwidth (fraction). Explicit code constructions were given in previous works. If we view each symbol in the code as a vector or a column, then the code forms a 2D array and such codes are especially widely used in storage systems. In this paper, we ask the following question: given the length of the column l, can we construct high-rate MDS array codes with optimal repair bandwidth of 1/r, whose code length is as long as possible? In this paper, we give code constructions such that the code length"},"body":{"text":"MDS (maximum distance separable) codes are optimal error-correcting codes in the sense that they have the largest minimum distance given the number of parity symbols. If each symbol is a vector or a column, we call such a code an MDS array code. In (distributed) storage systems, each column is usually stored in a different disk, and MDS array codes are widely used to protect data against erasures due to their error correction ability and low computational complexity. In this paper, we call each symbol a column or a node, and the column length, or the vector size of a symbol, is denoted by l.\nIf an MDS code has r parities, then it can correct up to r erasures of entire columns. In this paper, we not only would like to recover any e erasures, e ≤ r, but also care about the efﬁciency in recovery: what is the fraction of the remaining data transmitted in order to correct e erasures? We call this fraction the repair bandwidth (fraction). For example, if e = r erasures happen, it is obvious that we have to transmit all of the remaining information, therefore, the fraction is 1. For e = 1 erasure it was shown in [5] (which also formulated the repair problem) that this fraction is actually lowered bounded by 1/r. If e ≤ r symbols are erased and we repair them exactly as they were, this fraction is lower bounded by e/r [13]. If this bound is achieved for some code, we say it has optimal repair. Since the repair of information is much more crucial than redundancy, and we study mainly high-rate codes, we will focus on the optimal repair of information or systematic nodes. Moreover, since single erasure is the most common scenario in practice, we assume e = 1. For example, in Figure 1, we show an MDS code with 4 systematic nodes, r = 2\na \t b \t c \t d a+b+c+d 2a+w+2b+3c+d w x \t y \t z w+x+y+z 3w+b+3x+2y+z\nparity nodes, and column length l = 2. One can check that this code can correct any two erasures, therefore it is an MDS code. In order to repair any systematic node, only 1/r = 1/2 fraction of the remaining information is transmitted. Thus this code has optimal repair.\nIn [8]\u2013[10] codes achieving the repair bandwidth lower bound were studied where the number of systematic nodes is less than the number of parity nodes (low code rate). For arbitrary code rate, [4], [11] proved that the lower bound is asymptotically achievable when the column length l goes to inﬁnity. And [1]\u2013[3], [6], [7], [12], [13], [15] studied codes with more systematic nodes than parity nodes (high code rate) and ﬁnite l, and achieved the lower bound of the repair bandwidth. If we are interested in the code length, i.e., the number of systematic nodes given l, low-rate codes have a linear code length l + 1 [9], [10]; on the other hand, high-rate constructions are relatively short. For example, suppose that we have 2 parity nodes, then the number of systematic nodes is only log l in all of the constructions, except for [3] it is 2 log l. In [14] it is shown that an upper bound for the code length is k ≤ 1 + l ( l l/2 ) , but the tightness of this bound is not known. It is obvious that there is a big gap between this upper bound and the constructed codes.\nThe main contribution of this paper is to construct codes with 2 parity nodes and 3 log l systematic nodes. The code uses a ﬁnite ﬁeld of size 1 + 2 log l. Moreover, we will give a general construction of high-rate codes with ( r + 1 ) log r l systematic nodes for arbitrary number of parities r. It turns out that this construction is a combination of the code in [3] and also [1], [7], [12].\nThe rest of the paper is organized as follows: in Section II we will formally introduce the repair bandwidth and the code length problem. In Section III codes with 2 parity nodes are constructed, and we show that the code length is 3 log l. Generalized code constructions for arbitrary number of parities are given in Section IV and ﬁnally we conclude in Section V.\nAn ( n, k, l ) MDS array code is an ( n − k ) -erasure- correcting code such that each symbol is a column of length l. The number of systematic symbols is k and the number of parity symbols is r = n − k. We call each symbol a column or a node, and k the code length. We assume that the code is systematic, hence the ﬁrst k nodes of the code are information or systematic nodes, and the last r nodes are parity or redundancy nodes.\nSuppose the columns of the code are C 1 , C 2 , . . . , C n , each being a column vector in F l , for some ﬁnite ﬁeld F. We assume that for parity node k + i, information node j, the coding matrix is A i,j of size l × l, i ∈ [ r ] , j ∈ [ k ] . And the parity columns are computed as\nfor all i ∈ [ r ] . For example, in Figure 1, the coding matrices are A 1,j = I for all j ∈ [ k ] and A 2,j , j = 1, 2, 3, 4 are\nHere the ﬁnite ﬁeld is F 4 generated by x 2 + x + 1. In our constructions, we require that A 1,j = I for all j ∈ [ k ] . Hence the ﬁrst parity is the row sum of the information array. Even though this assumption is not necessarily true for an arbitrary linear MDS array code, it can be shown that any linear code can be equivalently transformed into one with such coding matrices [14].\nSuppose a code has optimal repair for any systematic node i, i ∈ [ k ] , meaning only a fraction of 1/r data is transmitted in order to repair it. When a systematic node i is erased, we are going to use size l/r × l matrices S i,j , j = i, j ∈ [ n ] , to repair the node: From a surviving node j, we are going to compute and transmit S i,j C j , which is only 1/r of the information in this node.\nNotations: In order to simplify the notations, we write S i,j and S i,k+t A t,j both as matrices of size l/r × l and the subspaces of their row spans.\nOptimal repair of a systematic node i is equivalent to the following subspace property: There exist matrices S i,j , j = i, j ∈ [ n ] , all with size l/r × l, such that for all j = i, j ∈\nwhere the equality is deﬁned on the row spans instead of the matrices. And \t r\nHere the sum of two subspaces A, B of F l is deﬁned as A + B = { a + b : a ∈ A, b ∈ B } . Obviously, the dimension of each subspace S i,k+t A t,i is no more than l/r, and the sum of r such subspaces has dimension no more than l. This means these subspaces intersect only on the zero vector. Therefore,\nthe sum is actually the direct sum of vector spaces. Moreover, we know that each S i,k+t has full rank l/r.\nIt can be shown that (1) (2) are necessary and sufﬁcient conditions for optimal repair [9], [14]. The proof uses inter- ference alignment techniques ﬁrst introduced in [4], [11] for the repair problem.\nIt is shown in [14] that we can further simplify our repair strategy of node i and assume S i,j = S i , for all j = i, j ∈ [ n ] by equivalent transformation of the coding matrices (probably with an exception of the strategy of one node). Then the subspace property becomes for any j = i, j ∈ [ k ] , t ∈ [ r ] ,\nAgain the equality means equality of row spans. And the sum of subspaces satisﬁes\nNotice that if (3) is satisﬁed, we can say that S i is an invariant subspace of A t,j (multiplied on the left) for all parity nodes k + t and all information nodes j = i. If A t,j is diagonalizable and has l linearly independent left eigenvectors, an invariant subspace has a set of basis which are all eigenvectors of A t,j . As a result, our goal is to ﬁnd matrices A t,j and their invariant subspaces. And by using sufﬁciently large ﬁnite ﬁeld and varying the eigenvalues of the coding matrices, we are able to ensure that the codes are MDS. Therefore, we will ﬁrst focus on ﬁnding eigenvectors of the coding matrices and then discuss about the eigenvalues.\nFor example, in Figure 1, the matrices S i , i = 1, 2, 3, 4 are ( 1, 0 ) , ( 0, 1 ) , ( 1, 1 ) , ( 1, 3 ) .\nOne can check that the subspace property (3)(4) is satisﬁed for i ∈ [ 4 ] . For instance, since S 3 = ( 1, 1 ) is an eigenvector for A t,j , t = 1, 2, j = 1, 2, 4, we have S 3 = S 3 A t,j . And it is easy to check that S 3 ⊕ S 3 A 2,3 = span ( 1, 1 ) ⊕ span ( 3, 2 ) = F 2 .\nIn this section, we are going to construct codes with column length l = 2 m , k = 3m systematic nodes, and r = 2 parity nodes. Here m is some integer. As we showed in the previous section, we can assume the coding matrices are\nwhere A 1,i = I and A 2,i = A i correspond to parity 1 and 2 respectively.\nNow we only need to ﬁnd coding matrices A i \u2019s, and subspaces S i \u2019s. For now we only care about eigenvectors of A i , because eigenvectors determine the repair bandwidth. Later we will show that using a ﬁnite ﬁeld of size linear in k, we can choose the eigenvalues such that the code is MDS. In the following construction, for any i ∈ [ k ] , A i has two different\neigenvalues λ i,0 , λ i,1 , each corresponding to l/2 = 2 m−1 eigenvectors. Denote these eigenvectors as\n   \n   \n   \n   \nfor eigenvalues λ i,0 , λ i,1 , respectively. Therefore, A i can be computed as\nBy abuse of notations, we also use V i,0 , V i,1 to rep- resent the eigenspace corresponding to λ i,0 , λ i,1 , respec- tively. Namely, V i,0 = span { v i,1 , . . . , v i,l/2 } and V i,1 = span { v i,l/2+1 , . . . , v i,l } .\nWhen a systematic node i is erased, i ∈ [ k ] , we are going to use S i to rebuild it. The subspace property becomes\nIn the following construction, e a , a ∈ [ 0, l − 1 ] , are some basis of F l , for example, one can think of them as the standard basis. The subscript a is represented by its binary expansion, a = ( a 1 , a 2 , . . . , a m ) . For example, if l = 16, m = 4, a = 5,\nIn order to construct the code, we ﬁrst deﬁne 3 sets of vectors for i ∈ [ m ] :\nsubscript i for sets P i,u , Q i and a i (the i-th digit of vector a) is written modulo m. For example, if i ∈ [ tm + 1, ( t + 1 ) m ] for some integer t, then P i,u : = P i−tm,u .\nThe above example shows that for m = 1, 2, the constructed code has optimal repair. It is true in general, as the following theorem suggests.\nProof: By symmetry of the ﬁrst two cases in the construc- tion, we are only going to show that the rebuilding of node i, i ∈ [ m ] ∪ [ 2m + 1, 3m ] is optimal. Namely, the subspace property (6)(7) is satisﬁed. Recall that S i A j = S i is equivalent to S i being an invariant subspace of A j .\nb j = 1, a i = b i = 0, a z = b z , ∀ z = i, j } . Then it is easy to see that S i = span ( P i,0 ) = span ( B ) . Moreover, each vector in set B is an eigenvector of A j , therefore S i is an invariant subspace of A j .\n\u2022 When j − m = i, S i = V j,0 = span ( P i,0 ) , so S i is an eigenspace of A j .\n\u2022 When j ∈ [ 2m + 1, 3m ] , we can see that every vector in P i,0 is a vector in V j,0 = span ( P j,0 ) or in V j,1 = span ( P j,1 ) , hence it is an eigenvector of A j .\n\u2022 When j = i, consider a vector e a ∈ P i,0 , then a i = 0. And e a = ( e a + e b ) − e b where b i = 1, b j = a j for all j = i. Here both e a + e b and e b are eigenvectors of A i .\nBecause λ i,0 = λ i,1 , we get span { e a A i , e a } = span ( e a , e b ) . Hence S i A i + S i = span { e a , e b : a i = 0, b i = 1, a j = b j , ∀ j = i } = F l .\n\u2022 When j = i − m or j = i − 2m, S i = span ( Q i ) is an eigenspace of A j .\n\u2022 When j ∈ [ tm + 1, ( t + 1 ) m ] , and j = i − tm for t ∈ { 0, 1 } , deﬁne D = { e a + e b : a j = b j = 1 − t, a i + b i =\n0, c j = d j = 1, a i + b i = 1, c i + d i = 1, a z = b z = c z = d z , ∀ z = i, j } . We can see that S i = span ( Q i ) = span ( D ) and every vector in D is an eigenvector of A j .\nApparently, every vector in Q i is a sum of two vectors in P j,0 or two vectors in P j,1 . So S i = span ( Q i ) is an invariant subspace of A j .\n\u2022 When j = i, consider any e a + e b ∈ Q i , where a i = 1, b i = 0, a z = b z , ∀ z = i. We have\nBecause λ i,0 = λ i,1 , we get span {( e a + e b ) A i , e a + e b } = span { e a , e b } . Thus S i A i + S i = span { e a , e b :\nIt should be noted that if we shorten the code and keep only the ﬁrst 2m systematic nodes in the code, then it is actually equivalent to the code in [3]. The repairing of the ﬁrst 2m nodes does not require computation within each remaining node, since only standard bases are multiplied to the surviving columns (e.g. Figure 2). We call such repair optimal access. It is shown in [14] that if a code has optimal access, then the code has no more than 2m nodes. On the other hand, the shortened code with the last m systematic nodes in the above construction is equivalent to that of [1], [7], [12]. Since the coding matrices A i , i ∈ [ 2m + 1, 3m ] are all diagonal, every information entry is included in only r + 1 entries in the code. We say such a code has optimal update. In [14] it is proven that an optimal-update code with diagonal coding matrices has no more than m nodes. Therefore, our code is a combination of the longest optimal-access code and the longest optimal- update code, which provides tradeoff among access, update, and the code length. The shortening technique was also used in [9] in order to get optimal-repair code with different code rates.\nIn addition, if we try to extend an optimal-access code C with length 2m to a code D with length k, so that C is a shortened code of D , then the following theorem shows that k = 3m is largest code length. The proof is omitted and can be found in the long version of this paper [16]. Therefore, our construction is longest in the sense of extending C .\nNext let us discuss about the ﬁnite ﬁeld size of the code. In order to make the code MDS, it is equivalent that we should be able to recover from any two column erasures. In other words, any 1 × 1 or 2 × 2 submatrices of the matrix (5) should be invertible. Therefore, all eigenvalues λ i,s should be nonzero, i ∈ [ k ] , s ∈ { 0, 1 } . Moreover, the following matrix should be invertible for all i = j:\nThe following construction with ﬁeld of size 2m + 1 actu- ally satisﬁes the above condition and guarantees that the code has optimal repair. The proof is in [16].\nc < i>+(1−s)m , i ∈ [ 2m + 1, 3m ] \t (8) If we have an extra systematic column with A 3m+1 = I (see column N4 in Figure 1), we can use a ﬁeld of size 2m + 2 and simply multiply the above eigenvalues by c. For example, when m = 1, the coefﬁcients in Figure 1 are assigned using the above method, where the ﬁeld size is 4 and c = 2. For another example, if m = 2, we can use ﬁnite ﬁeld F 5 and c = 2, then assign the eigenvalues to be\nIn this section, we will give constructions of codes with arbitrary number of parity nodes. Our code will have l = r m rows, k = ( r + 1 ) m systematic nodes, and r parity nodes, for any r ≥ 2, m ≥ 1.\nSuppose A s,i is the coding matrix for parity node k + s and information node i. From Section II, we assume A 1,i = I for all i. In our construction, we are going to add the following assumptions. Every A s,i has r distinct eigenvalues, each cor- responding to l/r = r m−1 linearly independent eigenvectors, for s ∈ [ 2, r ] . Moreover, given an information node i ∈ [ k ] , all matrices A s,i , s ∈ [ 2, r ] , share the same eigenspaces V i,0 , V i,1 , . . . , V i,r−1 . If these eigenspaces correspond to eigen- values λ i,0 , λ i,1 , . . . , λ i,r−1 for A 2,i , then we assume they correspond to eigenvalues λ s−1 i,0 , λ s−1 i,1 , . . . , λ s−1 i,r−1 for A s,i . By abuse of notations, V i,u represents both the eigenspace and the l/r × l matrix containing l/r independent eigenvectors. Under these assumptions, it is easy to see that if we write A s,i as\n \n \n  \n  \n \nwhere the identity matrices are of size l r × l r , then A s,i = A s−1 2,i , for all s ∈ [ r ] . Hence, we are going to write A i = A 2,i , thus A s,i = A s−1 i , and our construction will only focus on the matrix A i . As a result, the subspace property becomes\nNote that such choice of eigenvalues is not the unique way to construct the matrices, but it guarantees that the code has optimal repair bandwidth. Also, when the ﬁnite ﬁeld size is large enough, we can ﬁnd appropriate values of λ i,u \u2019s such that the code is MDS. At last, since each V i,u has dimension l/r and corresponds to l/r independent eigenvectors, we know that any vector in the subspace V i,u is an eigenvector of A i .\nLet { e 0 , e 1 , . . . , e r m −1 } be the standard basis of F l . And we are going to use the r-ary expansion to represent the index of a base. An index a ∈ [ 0, r m − 1 ] is written as a = ( a 1 , a 2 , . . . , a m ) , where a i is its i-th digit. For example, when r = 3, m = 4, we have e 5 = e (0,0,1,2) . Deﬁne for i ∈ [ k ] , u ∈ [ 0, r − 1 ] the following sets of vectors:\nSo P i,u is the set of bases whose index is u in the i-th digit. The sum in Q i is over all e a such that the j-th digit of a is some ﬁxed value for all j = i, and the i-th digit varies in [ 0, r − 1 ] . In other words, a vector in Q i is the summation of the corresponding bases in P i,u , ∀ u. For example, when\nIn the following, all of the subscript i for sets P i,u , Q i and for digit a i are computed modulo m. For example, if i ∈ [ tm + 1, ( t + 1 ) m ] for some integer t, then Q i : = Q i−tm .\nThe proof is in [16]. Again, this construction can be shortened to an optimal-access code of length rm [3] and an optimal-update code of length m [1], [7], [12].\nMoreover, the ﬁnite ﬁeld size of this code can be bounded by k r−1 r m−1 + 1 (see details in [16]), but we believe that there is still a large space to improve this bound.\nso far the longest high-rate MDS code with optimal repair. The codes were constructed using eigenspaces of the coding matrices, such that they satisfy the subspace property. This\nproperty gives more insights on the structure of the codes, and simpliﬁes the proof of optimal repair.\nIf we require that the code rate approaches 1, i.e., r being a constant and m goes to inﬁnity, then the column length l is exponential in the code length k. However, if we require the code rate to be roughly a constant fraction, i.e., m being a constant and r goes to inﬁnity, then l is polynomial in k. Therefore, depending on the application, we can see a tradeoff between the code rate and the code length.\nIt is still an open problem what is the longest optimal-repair code one can build given the column length l. Also, the bound of the ﬁnite ﬁeld size used for the codes may not be tight enough. Unlike the constructions in this paper, the ﬁeld size may be reduced when we assume that the coding matrices do not have eigenvalues or eigenvectors (are not diagonalizable). These are our future work directions.\nThis work was partially supported by an NSF grant ECCS- 0801795 and a BSF grant 2010075."},"refs":[{"authors":[{"name":"V. R. Cadambe"},{"name":"C. Huang"},{"name":"J. Li"}],"title":{"text":"Permutation code: optimal exact- repair of a single failed node in MDS code based distributed storage systems"}},{"authors":[{"name":"V. R. Cadambe"},{"name":"C. Huang"},{"name":"S. A. Jafar"},{"name":"J. Li"}],"title":{"text":"Optimal repair of MDS codes in distributed storage via subspace interference alignment"}},{"authors":[{"name":"V. R. Cadambe"},{"name":"C. Huang"},{"name":"J. Li"},{"name":"S. Mehrotra"}],"title":{"text":" Polynomial length MDS codes with optimal repair in distributed storage systems"}},{"authors":[{"name":"V. R. Cadambe"},{"name":"S. A. Jafar"},{"name":"H. Maleki"}],"title":{"text":"Minimum repair bandwidth for exact regeneration in distributed storage"}},{"authors":[{"name":"A. Dimakis"},{"name":"P. Godfrey"},{"name":"Y. Wu"},{"name":"M. Wainwright"},{"name":"K. Ramchandran"}],"title":{"text":"Network coding for distributed storage systems"}},{"authors":[{"name":"D. S. Papailiopoulos"},{"name":"G. Dimakis"}],"title":{"text":"Distributed storage codes through Hadamard designs, "}},{"authors":[{"name":"D. S. Papailiopoulos"},{"name":"G. Dimakis"},{"name":"V. R. Cadambe"}],"title":{"text":" Repair Opti- mal Erasure Codes through Hadamard Designs"}},{"authors":[{"name":"K. V. Rashmi"},{"name":"N. B. Shah"},{"name":"P. V. Kumar"},{"name":"K. Ramchandran"}],"title":{"text":"Explicit Construction of Optimal Exact Regenerating Codes for Distributed Storage"}},{"authors":[{"name":"N. B. Shah"},{"name":"K. V. Rashmi"},{"name":"P. V. Kumar"},{"name":"K. Ramchandran"}],"title":{"text":"Interfer- ence alignment in regenerating codes for distributed storage: necessity and code constructions"}},{"authors":[{"name":"C. Suh"},{"name":"K. Ramchandran"}],"title":{"text":"Exact-Repair MDS Code Construction Using Interference Alignment"}},{"authors":[{"name":"C. Suh"},{"name":"K. Ramchandran"}],"title":{"text":"On the existence of optimal exact-repair MDS codes for distributed storage"}},{"authors":[{"name":"I. Tam"},{"name":"Z. Wan"},{"name":"J. Bruc"}],"title":{"text":"MDS array codes with optimal rebuilding,\u201d in ISIT, 2011"}},{"authors":[{"name":"I. Tamo"},{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"Zigzag codes: MDS array codes with optimal rebuilding"}},{"authors":[{"name":"I. Tamo"},{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"Access vs. bandwidth in codes for storage"}},{"authors":[{"name":"Z. Wang"},{"name":"I. Tamo"},{"name":"J. Bruck"}],"title":{"text":" On codes for optimal rebuilding access"}},{"authors":[{"name":"Z. Wang"},{"name":"I. Tamo"},{"name":"J. Bruck"}],"title":{"text":"Long MDS codes for optimal repair bandwidth"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564857.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S7.T5.1","endtime":"15:00","authors":"Zhiying Wang, Itzhak Tamo, Jehoshua Bruck","date":"1341326400000","papertitle":"Long MDS Codes for Optimal Repair Bandwidth","starttime":"14:40","session":"S7.T5: Regenerating Codes","room":"Kresge Little Theatre (035)","paperid":"1569564857"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
