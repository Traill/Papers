{"id":"1569556759","paper":{"title":{"text":"The State-Dependent Semideterministic Broadcast Channel"},"authors":[{"name":"Amos Lapidoth"},{"name":"Ligong Wang"}],"abstr":{"text":"Abstract\u2014We derive the capacity region of the state-dependent semideterministic broadcast channel with noncausal state- information at the transmitter. In this broadcast channel one of the outputs is a deterministic function of the channel input and the channel state, and the state is assumed to be known noncausally to the transmitter but not to the receivers."},"body":{"text":"We characterize the capacity region of the discrete, mem- oryless, state-dependent, semideterministic broadcast channel. Such a channel has a single transmitting node, two receiving nodes, and an internal state, all of which are assumed to take value in ﬁnite sets. One of the receiving nodes observes a symbol Y that is a deterministic function of the transmitted symbol x and the state S\nY = f (x, S), \t (1a) and the other receiving node observes a symbol Z which is random: conditional on the input being x and the state being s, the probability that it is z is W (z|x, s):\nPr(Z = z|X = x, S = s) = W (z|x, s). \t (1b) The state sequence S is assumed to be independent and identically distributed (IID) according to some law P S (·)\nPr(S = s) = P S (s) \t (1c) and to be revealed to the encoder in a noncausal way: all future values of the state are revealed to the transmitter before transmission begins.\nWe consider a scenario where the encoder wishes to convey two private messages: M y ∈ {1, . . . , 2 nR y } to the determinis- tic receiver, and M z ∈ {1, . . . , 2 nR z } to the nondeterministic receiver, where R y and R z denote the rates (in bits per channel use) of data transmission to the deterministic and nondeterministic receivers, respectively. The messages M y and M z are assumed to be independent and uniformly distributed. As for the broadcast channel without a state [1], [2], we deﬁne the capacity region of this channel as the closure of all rate- pairs that are achievable in the sense that the probability that at least one of the receivers decodes its message incorrectly can be made arbitrarily close to zero.\nThe main result of this paper is a single-letter characteriza- tion of the capacity region:\nTheorem 1. The capacity region of the channel (1) when the states are known noncausally to the transmitter is the convex closure of the union of rate-pairs (R y , R z ) satisfying\nR y < H (Y |S) \t (2a) R z < I (U ; Z) − I(U ; S) \t (2b)\nover all joint distribution on (X, Y, Z, S, U ) whose marginal is the given state distribution P S and under which, conditional on X and S, the channel outputs Y and Z are drawn according to the channel law (1) independently of U :\n= P S (s)P XU |S (x, u|s)1 y = f (x, s) W (z|x, s). (3) Here 1{·} denotes the indicator function. Moreover, the ca- pacity region remains the same even if the state sequence is revealed to the deterministic receiver, i.e., if we replace f (·, ·) with the mapping (x, s) → f (x, s), s .\nWe further have the following cardinality bound on the auxilliary random variable U :\nProposition 1. To exhaust the capacity region of the chan- nel (1), we may restrict the auxilliary random variable U in (2) to take value in a set U satisfying\nwhere X denotes the input alphabet, and where S denotes the state alphabet.\nState-dependent broadcast channels were considered before [3]\u2013[5]. Steinberg [3] studied the degraded state-dependent broadcast channel with causal and with noncausal side- information at the transmitter. He derived the capacity region for the causal case, but for the noncausal case his outer and inner bounds do not coincide. Steinberg and Shamai [4] then derived an inner bound for general (not necessarily degraded) state-dependent broadcast channels with noncausal\nside-information. This inner bound is based on Marton\u2019s inner bound for broadcast channels without states [6] and on Gel\u2019fand-Pinsker coding [7]. In fact, the direct part of our Theorem 1 can be deduced from [4] with a proper choice of the auxiliary random variables (see Section II-A). Some special cases of Theorem 1 were solved by Khosravi-Farsani and Marvasti [5]: the fully deterministic case, the case where the states are known to the nondeterministic receiver, and the case where the channel is degraded so (X, S) − −Y − −Z forms a Markov chain. However, capacity regions of most state-dependent broadcast channels are still unknown.\nMuch work has been done on broadcast channels without states [8]. Our work can be considered as an extension of previous works on deterministic broadcast channels (solved by Gel\u2019fand, Marton and Pinsker [9]\u2013[11]) and on semidetermin- istic broadcast channels (solved by Gel\u2019fand and Pinsker [12]). These results can be found in [2].\nIn the rest of this paper we prove the direct and converse parts of Theorem 1 in Sections II and III, respectively.\nIn this section we prove the direct part of Theorem 1. One way to do this is to use [4, Theorem 1] with a judicious choice of the auxiliary random variables, as we propose in Section II-A. For completeness and simplicity, we also sketch a self-contained proof in Section II-B. The complete version of the self-contained proof can be found in [13].\nIt was shown in [4, Theorem 1] that the capacity region of any (not necessarily semideterministic) state-dependent broad- cast channel with noncausal side-information at the transmitter contains the convex closure of the union of rate-pairs (R y , R z ) satisfying\nR y ≤ I(U 0 , U y ; Y ) − I(U 0 , U y ; S) \t (5a) R z ≤ I(U 0 , U z ; Z) − I(U 0 , U z ; S) \t (5b)\nwhere the union is over all joint distributions of (X, Y, Z, S, U 0 , U y , U z ) whose marginal is P S ; that satisfy the Markov condition\nand under which the conditional law of (Y, Z) given (X, S) is that of the given channel.\nFor the semideterministic channel, we choose the auxiliary random variables in (5) as follows:\nU 0 = 0 (deterministic) \t (7a) U y = Y \t (7b) U z = U. \t (7c)\nNote that the Markov condition (6) is satisﬁed because Y is a deterministic function of (X, S) and because in Theorem 1\nwe restrict U to be such that U − −(X, S) − −(Y, Z). With this choice of U 0 , U y , and U z , (5) reduces to (2).\nWe next sketch a self-contained proof of the direct part of Theorem 1. (See [13] for the complete proof.) Like [4, Theorem 1], our proof is based on Marton\u2019s inner bound for general broadcast channels [6], [14] and on Gel\u2019fand-Pinsker coding [7].\nFirst note that the joint distribution (3) can also be written as\ny = f (x, s). \t (9) Further note that, when P Y SU is ﬁxed, all the terms on the RHS of (2) are ﬁxed, except for I(U ; Z), which is convex in P X |Y US . Since I(U ; Z) only appears with a positive sign on the RHS of (2), it follows that the union over all joint distributions of the form (2) can be replaced by a union only over those where x is a deterministic function of (y, u, s), i.e., of the form\n= P S (s)P Y U |S (y, u|s)1 x = g(y, u, s) W (z|x, s) (10) for some g : (y, u, s) → x (and subject to (9)). We shall thus only establish the achievability of rate-pairs that satisfy (2) for some distribution of the form (10).\nChoose a stochastic kernel P Y U |S and a mapping g : (y, u, s) → x which, combined with P S and the channel law, determines the joint distribution (10) for which (9) is satisﬁed. For a given block-length n, we generate a random code as follows:\nGenerate 2 nR y y -bins, each containing 2 n ˜ R y y -tuples where the l y -th y-tuple in the m y -th bin\nTo send message m y ∈ {1, . . . , 2 R y } to the deterministic receiver and message m z ∈ {1, . . . , 2 R z } to the nonde- terministic receiver, look for a y-tuple y(m y , l y ) in y- bin m y and a u-tuple u(m z , l z ) in u-bin m z such that\ny (m y , l y ), u(m z , l z ) is jointly typical with the state sequence s. If such a pair can be found, send\nwhere in the above g(y, u, s) denotes the application of the function g(y, u, s) componentwise. In this case the sequence received by the deterministic receiver will be y (m y , l y ). Otherwise send an arbitrary codeword.\nTry to ﬁnd the unique y-bin, say m y , that contains the received sequence y and output its number m y . If there is more than one such bin, declare an error.\nTry to ﬁnd the unique u-tuple u(m z , l z ) that is jointly typical with the received sequence z and output its bin number m z . If more than one or no such u can be found, declare an error.\nWe next analyze the error probability of the above coding scheme. There are three types of errors:\nThis happens only if there is more than one bin that contains the received y. This probability tends to zero as n tends to inﬁnity provided\nThis happens if either the u-tuple u(m z , l z ) is not jointly typical with the received z-tuple, or if a different u-tuple happens to be jointly typical with the received z-tuple. The probability of the former case tends to zero as n tends to inﬁnity by the Markov Lemma [2]. The probability of the latter case tends to zero as n tends to inﬁnity provided\nThis happens only if there is no (l y , l z ) ∈ {1, . . . , 2 n ˜ R y } × {1, . . . , 2 n ˜ R z } \t such \t that\ny (m y , l y ), u(m z , l z ) is jointly typical with the state sequence s. Using the Multivariate Covering Lemma [2, Lemma 8.2], we obtain that this error probability tends to zero as n tends to inﬁnity provided\n˜ R y > I (Y ; S) \t (14a) ˜ R z > I (U ; S) \t (14b)\nSummarizing (12), (13) and (14) we conclude that the above coding scheme has vanishing error probability as n tends to inﬁnity for all (R y , R z ) satisfying (2). By time-sharing we further achieve the convex hull of all rate-pairs satisfying (2) for joint distributions of the form (10). This concludes the proof of the direct part of Theorem 1.\nOur proof of the converse part of Theorem 1 employs ideas from Nair and El Gamal\u2019s outer bound [15] and of Gel\u2019fand and Pinkser\u2019s converse for the state-dependent single- user channel [7], but it also contains some new elements.\nWe shall show that, even if the state sequence S is revealed to the deterministic receiver (which observes Y), any achiev- able rate-pair must be in the convex closure of the union of rate-pairs satisfying (2). Given any code of block-length n, we ﬁrst derive a bound on R y :\nnR y = H(M y ) \t (15) ≤ I(M y ; Y n , S n ) + n n \t (16) = I(M y ; Y n |S n ) + n n \t (17)\nwhere n is a function of n which decays to zero as n goes to inﬁnity. Here, (16) follows from Fano\u2019s Inequality; (17) because M y and S n are independent; (18) from the chain rule; (19) by dropping negative terms; and (20) because conditioning cannot increase entropy.\nnR z = H(M z ) \t (21) ≤ I(M z ; Z n ) + n n \t (22)\nHere, (22) follows from Fano\u2019s Inequality; (23) and (24) from the chain rule; (25) from Csisz´ar\u2019s Identity [16]\n(26) because S i and (M z , S i −1 ) are independent; (27) from the chain rule and by dropping negative terms; and (28) by deﬁning the auxiliary random variables\nn (R y + R z ) = H(M y , M z ) \t (31) = H(M z ) + H(M y |M z ) \t (32)\nwhere the last step follows from Fano\u2019s Inequality. Of the two mutual informations on the RHS of (33) we ﬁrst bound I (M z ; Z n ):\nHere, (34), (35) and (36) follow from the chain rule; (37) by applying Csisz´ar\u2019s Identity (29) between (S n , Y n ) and Z n ; and (38) again from the chain rule.\nHere, (39) and (40) follow from the chain rule; (41) by apply- ing Csisz´ar\u2019s Identity between (S n , Y n ) and S n ; (42) from the chain rule; (43) because S i and (M y , M z , S i −1 ) are independent; (44) again from the chain rule; and (45) because, given (M y , M z , S n ), the channel inputs X n are determined by the encoder, and hence Y n are also determined, so\nH Y i M y , M z , S n , Y n i+1 = 0. \t (46) Combining (33), (38) and (45), using the deﬁnitions (30),\nT i Y n i+1 , i ∈ {1, . . . , n}, \t (47) we obtain\nSummarizing (20), (28) and (48) and letting n go to inﬁnity we obtain that any achievable rate-pair (R y , R z ) must be contained in the convex closure of the union of rate-pairs satisfying\nR y < H (Y |S) \t (49a) R z < I (V ; Z) − I(V ; S) \t (49b)\nwhere, given (X, S), the outputs (Y, Z) are drawn according to the channel law (1) independently of the auxiliary random variables (V, T ). To prove the converse part of Theorem 1, it remains to replace V and T with a single auxiliary random variable. I.e., it remains to ﬁnd an auxiliary random variable U such that\nI (V ; Z) − I(V ; S) ≤ I(U ; Z) − I(U ; S), \t (50a) H (Y |S) + I(V, T ; Z) − I(V, T ; S, Y )\nIn fact, as we shall see, either choosing U to be V will satisfy (50) or else choosing it to be (V, T ) will satisfy (50). If we choose U = V , then (50a) is satisﬁed with equality, and the requirement (50b) becomes\nOn the other hand, if we choose U = (V, T ), then (50b) is satisﬁed with equality, and the requirement (50a) becomes\nIt remains to show that at least one of the requirements (51) and (52) must be satisﬁed: if it is (51), then we shall choose U as V , and it if is (52), then we shall choose U as (V, T ). To this end we note that for all random variables T, Z, V, S, Y\nbecause the RHS minus the left-hand side equals I(T ; Y |S, V ) which is nonnegative. Therefore, at least one of (51) and (52) must be satisﬁed. We have thus shown that there must exist a U which satisﬁes both inequalities in (50), hence the bounds (49) can be relaxed to (2). This concludes the proof of the converse part of Theorem 1.\nRemark. This outer bound can be easily generalized to a broadcast channel that is not necessarily semideterministic. Such a channel is described by the transition law\nPr(Y = y, Z = z|X = x, S = s) = W (y, z|x, s). (54) The general outer bound states the following: if the state sequence S is revealed noncausally to the transmitter, and is revealed to the receiver who observes Y but not to the receiver which observes Z, then the capacity region of this channel is contained in the convex closure of rate-pairs satisfying\nR y < I (X; Y |S) \t (55a) R z < I (U ; Z) − I(U ; S) \t (55b)\nThe authors thank the anonymous reviewers for their helpful comments."},"refs":[{"authors":[{"name":"T. M. Cove"},{"name":"J. A. Thoma"}],"title":{"text":"Elements of Information Theory"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory"}},{"authors":[{"name":"Y. Steinberg"}],"title":{"text":"Coding for the degraded broadcast channel with random parameters, with causal and noncausal side information"}},{"authors":[{"name":"Y. Steinberg"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"Achievable rates for the broadcast channel with states known at the transmitter"}},{"authors":[{"name":"R. Khosravi-Farsani"},{"name":"F. Marvasti"}],"title":{"text":"Capacity bounds for multiuser channels with non-causal channel state information at the transmitters"}},{"authors":[{"name":"K. Marton"}],"title":{"text":"A coding theorem for the discrete memoryless broadcast channel"}},{"authors":[{"name":"S. I. Gel\u2019fand"},{"name":"M. S. Pinsker"}],"title":{"text":"Coding for channel with random parameters"}},{"authors":[{"name":"T. M. Cover"}],"title":{"text":"Comments on broadcast channels"}},{"authors":[{"name":"S. I. Gel\u2019fand"}],"title":{"text":"Capacity of one broadcast channel"}},{"authors":[{"name":"K. Marton"}],"title":{"text":"The capacity region of deterministic broadcast channels"}},{"authors":[{"name":"M. S. Pinsker"}],"title":{"text":"Capacity of noiseless broadcast channels"}},{"authors":[{"name":"S. I. Gel\u2019fand"},{"name":"M. S. Pinsker"}],"title":{"text":"Capacity of a broadcast channel with one deterministic component"}},{"authors":[{"name":"A. Lapidoth"},{"name":"L. Wang"}],"title":{"text":"The state-dependent semideterministic broadcast channel"}},{"authors":[{"name":"A. El Gamal"},{"name":"E. C. van der Meulen"}],"title":{"text":"A proof of Marton\u2019s coding theorem for the discrete memoryless broadcast channel"}},{"authors":[{"name":"C. Nair"},{"name":"A. El Gamal"}],"title":{"text":"An outer bound to the capacity region of the broadcast channel"}},{"authors":[{"name":"I. Csisz´a"},{"name":"J. K¨orne"}],"title":{"text":"Information Theory: Coding Theorems for Discrete Memoryless Systems"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569556759.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T2.3","endtime":"17:40","authors":"Amos  Lapidoth, Ligong Wang","date":"1341249600000","papertitle":"The State-Dependent Semideterministic Broadcast Channel","starttime":"17:20","session":"S4.T2: Capacity of Broadcast Channels","room":"Kresge Auditorium (109)","paperid":"1569556759"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
