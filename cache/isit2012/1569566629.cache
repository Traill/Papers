{"id":"1569566629","paper":{"title":{"text":"Simpler Achievable Rate Regions for Multiaccess with Finite Blocklength"},"authors":[{"name":"Ebrahim MolavianJazi"},{"name":"J. Nicholas Laneman"}],"abstr":{"text":"Abstract\u2014Although practical communication networks employ coding schemes with blocklengths as low as several hundred symbols, classical information theoretic setups consider block- lengths approaching inﬁnity. Building upon information spectrum concepts and recent work on channel dispersion, we develop a non-asymptotic inner bound on as well as a low-complexity, second-order achievable rate region for a discrete memoryless multiple access channel with a given ﬁnite blocklength and positive average error probability. Our bounds appear to capture essentially the same region as those of Tan and Kosut, but are less computationally complex because they require only the means and variances of the relevant mutual information random variables instead of their full covariance matrix."},"body":{"text":"Traditional channel coding theorems of information theory study the fundamental limits of communication in the presence of noise and interference using coding schemes of asymptoti- cally large blocklengths. In such extremes, information can be encoded at a rate approaching a ﬁrst order statistic (the channel average mutual information ). Delay and complexity limita- tions of many practical applications, however, require coding with ﬁnite blocklength, even on the order of several hundred symbols, for which classical results do not hold. Following Strassen [1], it has recently been shown [2], [3] that a second order statistic (the channel dispersion) plays an important role in the fundamental limits with ﬁnite blocklength.\nFrom a high-level perspective, both analyses stem from the common framework of information spectrum approach [4], i.e., treating mutual information as a random variable (RV); its limiting version for asymptotically large blocklength [4], and its n-letter form for ﬁnite blocklength [1], [2], [3]. In either case, the cumulative distribution function (CDF) of this RV characterizes performance in terms of the probability that channel cannot support the communication rate and causes an \u201coutage\u201d for the actual codeword to be correctly detected at the receiver. High coding rates turn out to arise when error probability is approximated by the outage probability, and the probability of \u201cconfusion\u201d, i.e., the observation is wrongly decoded to any incorrect codeword, decays to zero.\nFor the important case of stationary memoryless channels, the limiting mutual information rate RV concentrates with probability one at the average mutual information, so we are dealing with a zero or one outage probability, depending upon whether the communication rate is less than or greater than\nthe average mutual information, or ﬁrst-order characterization. Similarly, in the regime of ﬁnite blocklength, according to the Central Limit Theorem, the CDF of the n-letter mutual information rate RV approaches that of a Gaussian, so we can estimate the outage probability and approximate achiev- able rates by using ﬁrst and second moments of the mutual information rate RV, or the second-order characterization.\nIn this paper, we show how similar ideas can be extended to a multi-user setting in which multiple users are communicating several independent messages to a single receiver over a multiple access channel. In particular, we explore the increase in coding rate, especially its second-order, as a function of the ﬁnite blocklength for a ﬁxed average error probability. A key element of our work is to use an outage-splitting approach for the problem of assigning a single average error probability to several outage events arising in a DM-MAC. We demonstrate that this approach leads to simple, but rather tight achievable regions in the ﬁnite blocklength regime.\nA 2-user discrete memoryless multiple access channel (DM- MAC) without feedback consists of two ﬁnite input alphabets X 1 and X 2 , a ﬁnite output alphabet Y, and a channel transition probability matrix P Y |X 1 X 2 (y|x 1 , x 2 ) : X 1 × X 2 → Y whose n-th extension follows\n(n, M 1 , M 2 , ) code is composed of two message sets M 1 = {1, ..., M 1 } and M 2 = {1, ..., M 2 }, and a corresponding set of codeword pairs and mutually exclusive decoding regions {(x n 1 (j), x n 2 (k), D j,k )}, with j ∈ M 1 and k ∈ M 2 , such that the average error probability satisﬁes\nAccordingly, a (log M 1 (n, )/n, log M 2 (n, )/n) pair is achievable for a DM-MAC (X 1 , X 2 , P Y |X 1 X 2 (y|x 1 , x 2 ), Y) with ﬁnite blocklength n, and average error probability if such an (n, M 1 , M 2 , ) code exists.\nAs mentioned in Section I, channel coding rates depend upon the behavior of the relevant mutual information RVs. Speciﬁcally, a 2-user DM-MAC involves the following three mutual information RVs:\nwhere T is an auxiliary \u201ctime sharing\u201d RV satisfying the Markov Chain T → X 1 X 2 → Y . In the regime of asymp- totically large blocklength, achievable rates will depend on the ﬁrst order statistics of these RVs:\nI(X 1 ; Y |X 2 T ) E[i(X 1 ; Y |X 2 T )], I(X 2 ; Y |X 1 T ) E[i(X 2 ; Y |X 1 T )], I(X 1 X 2 ; Y |T ) E[i(X 1 X 2 ; Y |T )],\nwhere expectation is taken with respect to the distribution p(t)p(x 1 |t)p(x 2 |t)P Y |X 1 X 2 (y|x 1 , x 2 ). Using these quantities, Ahlswede and Liao [5] established the capacity region of a 2-user DM-MAC. Subsequently, Dueck [6] and Ahlswede [7] proved the strong converse, concluding that, even for a non- vanishing average error probability 0 < ≤ 1, the ﬁrst- order characterization of the capacity region of a DM-MAC (X 1 , X 2 , P Y |X 1 X 2 (y|x 1 , x 2 ), Y) is given by the closure as n→∞ of all (log M 1 (n, )/n, log M 2 (n, )/n) pairs satisfying\nlog M 1 (n, ) < nI(X 1 ; Y |X 2 T ) + o(n) log M 2 (n, ) < nI(X 2 ; Y |X 1 T ) + o(n)\nfor \t some \t choice \t of \t the \t joint \t distribution p(t)p(x 1 |t)p(x 2 |t)P Y |X 1 X 2 (y|x 1 , x 2 ) with the auxiliary random variable T deﬁned on a set |T | ≤ 2.\nIn the following, we sharpen these classical results for the ﬁnite blocklength regime using the second order statistics or dispersions of the relevant mutual information RVs:\nV(X 1 ; Y |X 2 T ) Var[i(X 1 ; Y |X 2 T )], V(X 2 ; Y |X 1 T ) Var[i(X 2 ; Y |X 1 T )], V(X 1 X 2 ; Y |T ) Var[i(X 1 X 2 ; Y |T )],\nwhere the variances are again calculated with respect to the distribution p(t)p(x 1 |t)p(x 2 |t)P Y |X 1 X 2 (y|x 1 , x 2 ).\nThis section summarizes our main results in this paper. We ﬁrst state the following Dependence Testing (DT) bound for a DM-MAC, which provides a non-asymptotic achievable region valid for any blocklength. It basically describes the error probability in terms of the outage and confusion probabilities, and is based on the DT bound of [2] and ideas from the information-spectrum approach for a general MAC [4].\nand for any joint distribution p(t)p(x 1 |t)p(x 2 |t), there exists a (n, M 1 , M 2 , ) code such that\nwhere \t Y n , ¯ Y n 0 , ¯ Y n 1 , ¯ Y n 2 \t are \t n-fold \t distributions according to P Y ¯ Y 0 ¯ Y 1 ¯ Y 2 |X 1 X 2 T (y, a, b, c|x 1 , x 2 , t) \t = P Y |X 1 X 2 (y|x 1 , x 2 )P Y |T (a|t)P Y |X 1 T (b|x 1 , t)P Y |X 2 T (c|x 2 , t),\nand where γ 1 , γ 2 , γ 3 : X n 1 × X n 2 → [0, ∞) are arbitrary measurable functions whose optimal choices to give highest rates are as follows:\nThe above expression for DT bound is stated to match our outage-splitting approach later in Theorem 3. It is, however, possible to strengthen this bound by focusing on the three outages jointly.\nand for any joint distribution p(t)p(x 1 |t)p(x 2 |t), there exists a (n, M 1 , M 2 , ) code such that\nX n 2 ; ¯ Y n 0 |T n )> log γ 3 (X n 1 , X n 2 ) . (2)\nwhere \t Y n , ¯ Y n 0 , ¯ Y n 1 , ¯ Y n 2 \t are \t n-fold \t distributions according to P Y ¯ Y 0 ¯ Y 1 ¯ Y 2 |X 1 X 2 T (y, a, b, c|x 1 , x 2 , t) \t = P Y |X 1 X 2 (y|x 1 , x 2 )P Y |T (a|t)P Y |X 1 T (b|x 1 , t)P Y |X 2 T (c|x 2 , t),\nNext, we give an achievable region for a DM-MAC with (sufﬁciently large) ﬁnite blocklength, which is a consequence of the DT bound for DM-MAC in Theorem 1 by appealing to the Central Limit Theorem to utilize a Gaussian approximation for the relevant mutual information RVs, thus estimating the outage and confusion probabilities. In the following, Q −1 (·) is the well-known inverse of the complementary-CDF function of a standard Gaussian distribution Q(x) \t 1 2π ∞ x e −t 2 /2 dt.\nTheorem 3. An achievable region for the DM-MAC (X 1 , X 2 , p(y|x 1 , x 2 ), Y) is given by the union of all (log M 1 (n, )/n, log M 2 (n, )/n) pairs satisfying\n− Q −1 (λ 1 ) nV(X 1 , Y |X 2 T )+O(1), log M 2 (n, ) < nI(X 2 ; Y |X 1 T )\nfor \t some \t choice \t of \t the \t joint \t distribution p(t)p(x 1 |t)p(x 2 |t)P Y |X 1 X 2 (y|x 1 , x 2 ) with the auxiliary random variable T deﬁned on a set |T | ≤ 6, and for some positive constants λ 1 , λ 2 , λ 3 satisfying λ 1 + λ 2 + λ 3 = 1.\nIn light of our discussions in Section I, this theorem suggests that high rates arise from coding schemes in which outages dominate confusions, such that the average error probability\nis split among the three outage events of a 2-user DM-MAC according to some λ 1 , λ 2 , λ 3 partitioning. In comparison with Ahlswede and Liao\u2019s result [5], Theorem 3 suggests that taking ﬁnite blocklength into account introduces rate penalties (for the interesting case of < 1 2 ) that depend on blocklength, error probability and DM-MAC dispersions.\nOur main result depends only on the mean and variance of the relevant mutual information RVs, each of which is approximated with a scalar Gaussian distribution. By contrast, in a concurrent work on this problem, Tan and Kosut [8] treat the outage events jointly, without using a union bound to split the outages. In fact, although our Theorem 3 follows from the DT bound of Theorem 1, the Tan and Kosut result [8] can be obtained as a second-order approximation of the generalized DT bound of Theorem 2. Although the approach of [8] leads to an inner bound for the DM-MAC that is larger in principle, it requires dealing with a full covariance matrix and the inverse CDF of a multi-dimensional Gaussian distribution, which we expect to be more computationally complex than our result particularly as the number of users grows. It is worth mentioning that choosing λ 1 → 1 or λ 2 → 1 in our Theorem 3 recovers the point-to-point results of [2] along the two axes, and selecting λ 3 → 1 recovers (a signiﬁcant part of) the dominant face of the achievable region of [8].\nIn this section, we illustrates our results through the example of the \u201creal adder\u201d DM-MAC Y = X 1 + X 2 + Z that takes the real addition of binary inputs X 1 , X 2 and Bernoulli( 1 2 ) noise Z, leading to a quaternary output Y .\nFigure 1 depicts, in addition to the classical capacity region, the achievable region of Theorem 3 for n = 200 and = 10 −3 . For each valid selection of the parameters λ 1 , λ 2 , λ 3 , a pentagon is obtained and taking the union over all such choices gives rise to a convex hull, that is, a curved shape.\nFigure 2 compares our achievable rate region in Theorem 3 for blocklengths n = 200, 300, 500, 1000, 5000 and = 10 −3\nwith that of Tan and Kosut [8], the genie-aided single-user outer bound implied by [2], and the classical capacity region. Both achievable regions in the ﬁnite blocklength regime op- erate quite close to the outer bound and both have smooth shapes with no sharp corners, but as blocklength grows, they approach the well-known pentagon shape of the capacity region. Furthermore, for this example, our region appears to achieve much of the region of [8], except for a very slight gap at the blunt \u201ccorners\u201d of the region which shrinks as blocklength grows. In terms of numerical evaluation, our result takes at least one order of magnitude less time than that of [8] for the same resolution.\nHere, we summarize the proof of the DT bound for DM- MAC. The proof uses the coded time sharing method of [5] with the usual random coding technique, i.e., proving that the average error probability over the ensemble of all codes generated at random satisﬁes the DT bound, thus concluding the existence of a code with the described rate and error prob- ability performance. The decoding rule, however, is likelihood ratio test (LRT) decoding [2], which can be considered as a generalization of joint typicality decoding that evaluates the partial (conditional) and full (unconditional) dependence of the output on the input codeword pair under test.\np(t l ) and revealed to both the receiver and the two transmitters. Then, M 1 codewords X n 1 (j), j ∈ M 1 , and M 2 codewords X n 2 (k), k ∈ M 2 , all of length n are generated independently according to n l=1 p(x 1l |t l ) and n l=1 p(x 2l |t l ), respectively. These two codebooks are also revealed to the receiver and both transmitters. Given the time sharing realiza- tion t n , the codebook pair {x n 1 (j)} M 1 j=1 × {x n 2 (k)} M 2 k=1 , and the channel output y n , the decoder runs for all M 1 M 2 codeword pairs the following three LRTs\nZ (1) j,k (y n ) = 1{i (x n 1 (j); y n |x n 2 (k)t n ) > log γ 1 (x n 1 (j), x n 2 (k))}, Z (2) j,k (y n ) = 1{i (x n 2 (j); y n |x n 1 (k)t n ) > log γ 2 (x n 1 (j), x n 2 (k))},\nchoosing the ﬁrst pair (j, k) for which Z (1) j,k (y n ) = Z (2) j,k (y n ) = Z (3) j,k (y n ) = 1, where \u201cﬁrst\u201d is deﬁned as a row-by-row search, so that (m, p) < (j, k) iff either m < j or m = j, p < k. The error probability for message pair (j, k) is thus given by\nwhere the notation A j,k,t n in the conditioning is a shorthand for the event {X n 1 = x n 1 (j), X n 2 = x n 2 (k), T n = t n }, and we have used the deﬁnition of the LRT\u2019s and the union bound. Not using the union bound for the ﬁrst three summands and leaving them as a joint outage event, while keeping the rest of proof unchanged, will result in the generalized bound (2).\nNow, since the time sharing sequence is generated i.i.d according to distribution p(t) and all the codewords in the ﬁrst, resp. second, codebook are generated independently according to the distribution p(x 1 |t), resp. p(x 2 |t), we can take the average of the above inequality over all possible time sharing\n+ (j − 1)Pr i X n 1 ; ¯ Y n 2 |X n 2 T n > log γ 1 (X n 1 , X n 2 ) + Pr [i (X n 2 ; Y n |X n 1 T n ) ≤ log γ 2 (X n 1 , X n 2 )]\n+ (k − 1)Pr i X n 2 ; ¯ Y n 1 |X n 1 T n > log γ 2 (X n 1 , X n 2 ) + Pr [i (X n 1 X n 2 ; Y n |T n ) ≤ log γ 3 (X n 1 , X n 2 )]\nAveraging this over all message pairs (j, k) gives the DT bound (1). To conclude the proof of Theorem 1, it is sufﬁcient to observe that each line on its RHS is a weighted sum of two types of error in a Bayesian binary hypothesis test, and therefore corresponds to average error probability of the test. Then, it is known that the optimal test is an LRT (as we have used) with the optimal threshold equal to the ratio of priors or simply the ratio of the coefﬁcients of the two error probabilities in each test.\nHere, we sketch how Theorem 1 is used for proving Theorem 3. We basically expand each of the three mutual information RVs in the DT bound (1) as sums of i.i.d. RVs and use the Central Limit Theorem, or more speciﬁcally the Berry-Esseen Theorem, to calculate the associated outage and confusion probabilities, analogous to [2].\nUpon ﬁxing the distribution p(t)p(x 1 |t)p(x 2 |t), the output Y n of the DM-MAC p(y|x 1 , x 2 ) corresponding to the inputs X n 1 and X n 2 and the time sharing variable T n described in the DT bound above satisﬁes\nand their mean and variance can be described in terms of the corresponding average mutual information and dispersion terms as\nE[i 1l ] = I(X 1 ; Y |X 2 T ), Var[i 1l ] = V(X 1 ; Y |X 2 T ), E[i 2l ] = I(X 2 ; Y |X 1 T ), Var[i 2l ] = V(X 2 ; Y |X 1 T ), E[i 3l ] = I(X 1 X 2 ; Y |T ), Var[i 3l ] = V(X 1 X 2 ; Y |T ).\n, with S[·] being the third moment operator, represents the Berry-Esseen gap to the Gaussian distribution. On the other hand, we can use a change of measure technique as in [2]\n> γ = 1 dP dQ\n> γ dQ = dP dQ\n1 dP dQ\n(5) to obtain\n(6) where (6) is according to [2, Lemma 47].\nBy substituting (4) and (6) and the analogous bounds for the other two mutual information RVs into the DT bound (1) with the optimal selection for thresholds γ 1 , γ 2 , γ 3 , we obtain\nwhere B 1 = B 11 + B 12 and analogously for B 2 and B 3 . Now, splitting among the three ﬁrst terms of each line gives\nwhere positive constants λ 1 , λ 2 , λ 3 that sum up to 1 can be arbitrarily chosen to represent the weight of each of the three types of outage for communication over a DM-MAC with average error probability . We can further simplify the bounds in (7) using Taylor\u2019s expansion Q −1 (λ − B √ n ) ≥ Q −1 (λ ) + ˜ B/\nthe set of distributions p(t)p(x 1 |t)p(x 2 |t), so V ≤ V max and ˜ B ≤ ˜ B max , to obtain the bounds of Theorem 3.\nIn the case that one or more of the dispersion terms are zero, we directly evaluate the corresponding probabilities, using\nthe fact that a mutual information RV with zero dispersion (variance) is concentrated almost surely at the average mutual information (mean). For example, if the ﬁrst dispersion is zero, V(X 1 ; Y |X 2 T ) = 0, then with the optimal choice of threshold\nthe ﬁrst two summands on the RHS of the DT bound (1) can be evaluated using a change of measure technique as in (5).\nWe have proved a simple achievable rate region for DM- MAC in the regime of ﬁnite blocklength by splitting the allowed average error probability among several \u201coutage\u201d events, in which the channel cannot support the target rates of a subset of the users. This region appears to have a curved blunt shape in general and implies rate penalties with respect to the inﬁnite blocklength regime that depend on the allowed error probability, the chosen ﬁnite blocklength, and the dispersions of the DM-MAC, i.e., the variances of the relevant mutual information RVs. We have observed that our achievable rate region covers a signiﬁcant portion of the concurrent result in [8], while its numerical computation is much easier. We aim as a future direction to prove the tightness of an outer bound we have developed and compare it with the existing inner bounds."},"refs":[{"authors":[{"name":"V. Strassen"}],"title":{"text":"Asymptotische Abschatzungen in Shannon\u2019s Information- stheorie"}},{"authors":[{"name":"Y. Polyanskiy"},{"name":"H. V. Poor"},{"name":"S. Verd´u"}],"title":{"text":"Channel Coding Rate in the Finite Blocklength Regime"}},{"authors":[{"name":"M. Hayashi"}],"title":{"text":"Information Spectrum Approach to Second-Order Coding Rate in Channel Coding"}},{"authors":[{"name":"T.-S. Ha"}],"title":{"text":"Information-Spectrum Methods in Information Theory, Springer-Verlag, Berlin, Germany, 2003"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory, Cambridge University Press, UK, 2012"}},{"authors":[{"name":"G. Dueck"}],"title":{"text":"The Strong Converse to the Coding Theorem for the Multiple\u2013 Access Channel"}},{"authors":[{"name":"R. Ahlswede"}],"title":{"text":"An Elementary Proof of the Strong Converse Theorem for the Multiple Access Channel"}},{"authors":[{"name":"V. Y. F. Tan"},{"name":"O. Kosut"}],"title":{"text":"On the Dispersion of Three Network Informa- tion Theory Problems"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566629.pdf"},"links":[{"id":"1569566381","weight":7},{"id":"1569566485","weight":14},{"id":"1569565383","weight":21},{"id":"1569565223","weight":7},{"id":"1569566725","weight":7},{"id":"1569566385","weight":7},{"id":"1569564635","weight":28},{"id":"1569565867","weight":7},{"id":"1569559617","weight":21},{"id":"1569566683","weight":7},{"id":"1569566227","weight":7},{"id":"1569566597","weight":14},{"id":"1569566571","weight":7},{"id":"1569552245","weight":42},{"id":"1569564481","weight":7},{"id":"1569566469","weight":7},{"id":"1569565355","weight":7},{"id":"1569565931","weight":7},{"id":"1569566373","weight":7},{"id":"1569565461","weight":7},{"id":"1569564245","weight":7},{"id":"1569564227","weight":7},{"id":"1569558325","weight":7},{"id":"1569565837","weight":7},{"id":"1569559541","weight":7},{"id":"1569565123","weight":7},{"id":"1569564203","weight":14},{"id":"1569566467","weight":7},{"id":"1569565771","weight":7},{"id":"1569566999","weight":14},{"id":"1569566843","weight":7},{"id":"1569565455","weight":7},{"id":"1569566963","weight":7},{"id":"1569561679","weight":7},{"id":"1569566709","weight":14},{"id":"1569564989","weight":7},{"id":"1569566015","weight":7},{"id":"1569566523","weight":7},{"id":"1569565897","weight":7},{"id":"1569551763","weight":7},{"id":"1569565953","weight":14},{"id":"1569564189","weight":14},{"id":"1569565907","weight":7},{"id":"1569566905","weight":42},{"id":"1569566753","weight":7},{"id":"1569566311","weight":7},{"id":"1569558681","weight":7},{"id":"1569565841","weight":14},{"id":"1569567665","weight":7},{"id":"1569565833","weight":7},{"id":"1569561795","weight":7},{"id":"1569566325","weight":7},{"id":"1569566437","weight":21},{"id":"1569553909","weight":7},{"id":"1569565427","weight":7},{"id":"1569552251","weight":50},{"id":"1569553519","weight":14},{"id":"1569566885","weight":7},{"id":"1569554881","weight":7},{"id":"1569554971","weight":7},{"id":"1569566445","weight":7},{"id":"1569566209","weight":7},{"id":"1569562821","weight":7},{"id":"1569566473","weight":7},{"id":"1569564333","weight":7},{"id":"1569565033","weight":7},{"id":"1569563897","weight":7},{"id":"1569555879","weight":14},{"id":"1569558509","weight":7},{"id":"1569564851","weight":7},{"id":"1569566037","weight":7},{"id":"1569564969","weight":14},{"id":"1569566505","weight":7},{"id":"1569565393","weight":7},{"id":"1569562207","weight":7},{"id":"1569567033","weight":35},{"id":"1569566695","weight":7},{"id":"1569566673","weight":7},{"id":"1569560997","weight":7},{"id":"1569566501","weight":7},{"id":"1569566481","weight":7},{"id":"1569565463","weight":14},{"id":"1569562551","weight":21},{"id":"1569563395","weight":21},{"id":"1569551347","weight":28},{"id":"1569555367","weight":7},{"id":"1569566383","weight":7},{"id":"1569565885","weight":7},{"id":"1569566983","weight":7},{"id":"1569566479","weight":7},{"id":"1569565397","weight":7},{"id":"1569566873","weight":7},{"id":"1569557275","weight":7},{"id":"1569565093","weight":7},{"id":"1569565919","weight":7},{"id":"1569565181","weight":7},{"id":"1569566267","weight":28},{"id":"1569564919","weight":7},{"id":"1569566917","weight":7},{"id":"1569566651","weight":7},{"id":"1569566823","weight":7},{"id":"1569566595","weight":7},{"id":"1569566137","weight":7},{"id":"1569565013","weight":7},{"id":"1569565293","weight":7},{"id":"1569566641","weight":14},{"id":"1569564247","weight":7},{"id":"1569563975","weight":7},{"id":"1569551905","weight":14},{"id":"1569565457","weight":14},{"id":"1569565529","weight":7},{"id":"1569556759","weight":14},{"id":"1569566619","weight":7},{"id":"1569561185","weight":7},{"id":"1569564923","weight":14},{"id":"1569566299","weight":14},{"id":"1569566933","weight":7},{"id":"1569557851","weight":7},{"id":"1569566147","weight":7},{"id":"1569565537","weight":14},{"id":"1569559597","weight":7},{"id":"1569565337","weight":7},{"id":"1569565853","weight":7},{"id":"1569566341","weight":7},{"id":"1569565889","weight":21},{"id":"1569566413","weight":7},{"id":"1569566375","weight":35},{"id":"1569566555","weight":7},{"id":"1569564141","weight":7},{"id":"1569565031","weight":7},{"id":"1569565139","weight":7},{"id":"1569564419","weight":14},{"id":"1569566067","weight":35},{"id":"1569566825","weight":7},{"id":"1569563007","weight":7},{"id":"1569566443","weight":7}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T2.4","endtime":"11:10","authors":"Ebrahim MolavianJazi, J. Nicholas Laneman","date":"1341226200000","papertitle":"Simpler Achievable Rate Regions for Multiaccess with Finite Blocklength","starttime":"10:50","session":"S1.T2: Multiple Access Codes","room":"Kresge Auditorium (109)","paperid":"1569566629"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
