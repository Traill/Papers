{"id":"1569566193","paper":{"title":{"text":"Efﬁcient Signature Scheme for Network Coding"},"authors":[{"name":"Ely Porat ∗"},{"name":"Erez Waisbard ∗"}],"abstr":{"text":"Abstract\u2014Network coding helps maximize the network throughput. However, such schemes are also vulnerable to pollution attacks in which malicious forwarders inject polluted messages into the system. Traditional cryptographic solution, such as digital signatures, are not suited for network coding, in which nodes do not forward the original packets, but rather linear combinations of the data they received. We describe secure scheme that uses batch techniques and selective veriﬁcation to efﬁciently verify the integrity of the received packets. We show that for real peer-to-peer networks, our scheme is much more efﬁcient than previously suggested schemes.\nIndex Terms\u2014Network coding; Digital signatures; Homomor- phic signatures; Group testing; Peer-to-peer; File sharing"},"body":{"text":"The volume of content that is distributed over the internet is growing every day. The simple client-server based approach ﬁnds it difﬁcult to cope with the growing number of clients and volume of data and there is a growing usage of peer-to-peer technologies.\nA peer-to-peer network uses distributed architecture instead of relying on a single server. The beneﬁt of this approach is in the splitting of the workload between many different servers instead of overloading a single server. BitTorrent [5] is an example for a popular peer-to-peer network that is used to distribute large ﬁles over the Internet. It works by splitting the large ﬁle into smaller blocks and sending these blocks to peers. Any peer that downloaded a block also becomes a server to this block and so the number of available sources increases as more peers download it. However, as efﬁcient as BitTorrent may be, it may happen that the scheduling scheme would result in having some blocks available only from a few peers with slow connection and as a result the completion of downloading of the entire ﬁle is delayed for many users. Using network coding as an efﬁcient way to cope with this problem was suggested in [2], [8].\nNetwork coding [3] was introduced as an efﬁcient alterna- tive to traditional routing that maximizes network throughput [10], [13], [14]. Network coding improves the spreading of different blocks in a peer-to-peer network by sending a random linear combination of the blocks instead of sending a single block. In such a scheme each peer continues to act as a server for blocks it has obtained and sends out random linear combinations of the blocks it has received. After receiving enough packets a peer would be able to reconstruct the ﬁle from the system of linear equations. Note that even before a peer is able to extract the different blocks, it can already participate in the distributed effort to spread the content by\ncreating a new random linear combination of the data that it already received. Using this method every peer simultaneously sends and receives partial information about many block, thus solving the problem of rare blocks.\nOne can see that network coding improves the network throughput and works well as long as everyone follows the protocol. Unfortunately, this is not always the case in real systems. Real systems need to cope with malicious users who try to pollute the network. In traditional content distribution schemes, this problem is easily solved by verifying the in- tegrity of the packets using cryptographic tools such as hash functions and digital signatures. This is also the case in peer- to-peer networks such as BitTorrent where each block of data has a hash value stored in the .torrent ﬁle. Each packet that is received by the peer is veriﬁed by computing its hash value and comparing it to the value that appears in the .torrent ﬁle. The security of a cryptographic hash function ensures that it is infeasible to ﬁnd two different blocks that hash to the same value. The integrity check takes place for each block separably. This allows early detection of corruption without having to wait for the entire ﬁle to download and prevents the further spread of corrupted packets.\nSecuring network coding schemes is more difﬁcult than securing traditional peer-to-peer schemes. We ﬁrst note that the problem of polluting the network is more acute for network coding schemes as a single corrupted block can corrupt the entire ﬁle and prevent its reconstruction. Furthermore, such a pollution quickly propagates throughout the network. Thus, it is crucial to be able to verify the integrity of incoming packets. Alas, the effective traditional cryptographic techniques that secure peer-to-peer networks such as BitTorrent no longer work. Incoming packets in a network coding scheme are random linear combinations of the source blocks and can take many different values. Since one cannot tell in advance which combination would be used by the forwarding peers, it is impossible to compute the appropriate hash values in advance.\nSome attempts have been made to solve this problem. These attempts largely focus on settings that are different than the one needed for large distribution ﬁle sharing over the internet.\nTrying to solve the problem from an information theoretic angle, [6], [17] suggested a way to protect the network against a passive adversary. Clearly this does not provide the required protection from an adversary in our setting.\nOthers considered byzantine adversaries [10], [9], [11] and provide security against a known threshold, but since adver- saries can freely join public peer-to-peer network, they can easily outnumber the byzantine bound.\nA different approach is to use homomorphic MACs [1]. Loosely speaking, Homomorphic MACs allows nodes that do not know the secret key to create a valid tag that can be authenticated by the end recipient. This allows the end recipient to discard polluted packets, but does not prevent their distribution throughout the network. This solution also assumes the existence of a shared secret between a sender and a receiver, which is not applicable to many settings. In particular, most of the popular peer-to-peer networks work in a mode in which one user shares a copy of his ﬁles with many users which he does not know in advance.\nHomomorphic signatures [18] allow intermediate nodes to create a signature on a linear combination of the incoming messages [18] or on any polynomial function of them [4]. Homomorphic signatures start by the source signing the differ- ent blocks. Each peer gets a linear combination of the blocks along with an homomorphic signature of it. The homomorphic property enables creating a new signature from the previously received signatures. These signatures are limited to signing only linear combinations of previously received packets, which is exactly what we need for network coding. This allows intermediate nodes to verify the integrity of the messages they receive and ﬁts well with the adversarial model for peer- to-peer ﬁle sharing. However the known schemes are either inefﬁcient [4] or known to be broken [18].\nAnother approach by [12] was to use the space orthogonal to the message space as a mean to verify that incoming messages are from a valid message space. This method is indeed more efﬁcient, however, as was noted by [16] the need to securely distribute the NULL message space before one can efﬁciently use this scheme puts us in a chicken and egg situation.\nZhao, et.al. [19] introduced an interesting scheme in which a source can \u2018sign\u2019 the message in a way that allows interme- diate nodes to efﬁciently verify the integrity of the messages without requiring a prior shared secret. Their scheme works by splitting the message M into vector blocks (v 1 , . . . , v n ) and looking at the vector space that they span V = Sp(v 1 , . . . , v n ). Then they ﬁnd a random vector u which is orthogonal to the message space and \u2018sign\u2019 it using a standard signature scheme. The signed vector is sent as part of the public information (the equivalent of the .torrent ﬁle in the BitTorrent). Using the linearity property u is guaranteed to be orthogonal to every linear combination of the message blocks. Upon receiving an incoming message, the receiving peer veriﬁes that the incoming message is orthogonal to u as a proof for it being a valid combination of the original blocks. Note that there are many vectors that are orthogonal to u, but are not in V . Thus, it is important to be able to verify that a vector is indeed orthogonal to u, but without explicitly publishing u. Using the hardness assumption of the discrete logarithm problem,\nthey publish a commitment to u that allows checking if a given vector is orthogonal to u without using u directly. We elaborate on the way it is done when we provide details of our construction in section III. The number of modular operations that are required in this scheme is proportional to the size of the vectors. If one considers a typical ﬁle sharing scenario over the internet, then a back of the envelope computation indicates that the veriﬁcation time of an incoming packet is longer than the communication time to receive it. Our construction aims to improve the efﬁciency of the veriﬁcation step by signiﬁcantly reducing the number of modular operations per packet.\nWe present a method for boosting the performance of homomorphic signatures. In this paper we present our con- struction by applying it to a speciﬁc scheme that was presented in [19]. Our method signiﬁcantly reduces the number of modular exponentiations required per packet by introducing two techniques: Selective veriﬁcation and Batch veriﬁcation.\nWe start with a large ﬁle F that we wish to share and divide it into n blocks, denoted ¯ v 1 , . . . , ¯ v n . Each block is viewed as an element in the m−dimentional vector space F m p , where p and q are large primes such that p is a divisor of q − 1.\nEach vector is then assigned with a preﬁx and these aug- mented vectors v 1 , . . . , v n are given by\nwhere the ﬁrst n elements are zero except that the ith one is 1, and ¯ v i ∈ F m p is the i-th vector block from the ﬁle.\nLet us denote the subspace that is spanned by these vectors as V . Namely:\nThe source starts distributing the data by computing a random linear combinations of the augmented vectors and sending them to peers. After collecting enough of these vectors the receiving peer would have n linearly independent blocks and would be able to reconstruct the original ﬁle. Peers actively participate in the distribution of the ﬁle (even before they are able to reconstruct the original ﬁle) by sending new random linear combinations of the blocks they obtain.\nIn order to protect against pollution attacks, we use an orthogonal vector to V as an indication that the incoming blocks are indeed from V . Noting that the augmented vectors span a subspace V of F n+m p , there exist many vectors which are orthogonal to V . Let us denote one of these vectors by u = (u 1 , . . . , u m+n ). As u ⊥ V , it is also orthogonal to any linear combination of the augmented vectors. Thus, checking that an incoming block is orthogonal to u would serve as an indication that it belongs to V . Naturally, the peers would need to know u before they can verify the authenticity of the incoming blocks. The vector u also needs to be authenticated\nand this can be done by having u digitally signed by s (using any standard digital signature scheme).\nHowever, if an attacker knows u then he can easily ﬁnd v / ∈ V for which < u, v >= 0. Thus we hide u by utilizing the hardness assumption of the discrete logarithm problem. Instead of using u directly, s picks a large prime q, such that p is a divisor of q − 1 and a generator g of a group of order p in F ∗ q . Then s picks a secret set of random elements in F ∗ p : {α i } i=1,...,m+n and publishes {h i = g α i } i=1,...,m+n after digitally signing it (again, using any standard digital signature scheme). Then s ﬁnds u 1 , . . . , u m+n orthogonal to all vectors in V and computes a vector x = u 1 α\n, which he also signs.\nThe ﬁrst idea that we introduce is the selective veriﬁcation. Loosely speaking, we are going to verify only part of the w i , but still get a high level of assurance while checking a signiﬁcantly smaller number of bits. In order to ensure that one cannot avoid this selective check by corrupting a small number of bits, we are using error correcting codes that expand the incoming messages in a way that any number of corrupted bits is reﬂected in many of the expanded bits.\nThe use of the error correcting code allows us to break the resulting expansion into blocks, each of length (1 + )n, and to do the veriﬁcation in one or more of these blocks. The idea is that for the right values of , checking over one or more blocks is much faster than verifying the full length of w. We use an efﬁcient construction of the code to ensure locality in the computation. Namely in order to verify a single block, we do not need to compute the full expansion of all the blocks. A key observation is that the probability of an attacker to pass this veriﬁcation using a corrupted vector is small as the number of possible \u201dlegal\u201d blocks is much smaller than .\nWe stress that although we use error correcting codes in the veriﬁcation step, there is no change in the length of the messages that traverse the network. Thus, with the exception of the initial signature (that is part of the metadata) the communication complexity remains the same as in [19].\n1) The Error correcting code: We start by deﬁning the error correcting code that we use. While a known code like the Reed-Solomon code may be used with a small tweak, we have chosen to explicitly deﬁne a new code that allows to illustrate the main ideas of our scheme in the simplest way.\nOur random code is a function h : F m+n p \t → F (1+ )n p \t , deﬁned as follows:\nWhere each of the A i s is random 2 (m + n) × (1 + )n matrix over F ∗ p .\n2) The Algorithms: We now describe the three key compo- nents of our scheme. We start with a description of setting up the public parameters and in particular the veriﬁcation vector. We then specify the sending algorithm and veriﬁcation algorithm. We note that there is no change in the sending algorithm when compared to [19]. The change is in the veriﬁcation step.\n\u2022 Computing orthogonal vector: Instead of ﬁnding a vector u that is orthogonal to every v i in the original ﬁle, we ﬁrst extend the matrix using error correcting code (ECC).\nWe look at the resulting matrix E and break it into blocks of size (1 + )n:\nWe then ﬁnd vectors u 1 , . . . , u , where u j is orthogonal to Sp(B j ). For every vector u j we also pick a secret set of random elements in F ∗ p : {α j i } i=1,...,(1+ )n , compute\nand publish {x j i } and {h j i } along with their digital signa- tures.\n\u2022 Sending a message: Sending a message is done as usual in network coding schemes by picking at random a i ∈ F ∗ p and sending v =\n\u2022 Message veriﬁcation: Upon receiving a vector w, the receiver picks a random j ∈ {1, . . . , } as the index of the block to verify and applies the ECC locally (i.e. computes only wA j ).\nThe speed up we gain by this method is proportional to the size of the block that we check compared to the size of the original vector, i.e. roughly (1+ )n m+n . In terms of security, it was proven in [19] that under the hardness assumption of solving the discrete logarithm problem, the scheme is secure if we were to check all blocks. We are going to check only portion of the blocks, but we are going to do so after applying the ECC. Intuitively, the ECC would ensure that even a few corrupted bits in the input vector would result in plenty of corrupted blocks. In section IV we show why even under a worse case scenario we can bound the error probability of our scheme with δ of our choice.\nAnother performance enhancement comes from performing batch veriﬁcation . The batch veriﬁcation technique is inde- pendent of the selective veriﬁcation technique. It can be used\nin conjunction with selective veriﬁcation or independently (e.g. it can be applied directly to the scheme of [19]). Batch veriﬁcation works by gathering a few incoming vectors before performing the veriﬁcation. Only once enough vectors are gathered, we check all of them in single veriﬁcation operation. The way we batch the vectors together is done as follows: Let w 1 , . . . , w k be the incoming vectors. We pick random r 1 , . . . , r k and compute w = r 1 w 1 + . . . + r k w k . Clearly, if w is a linear combination of vectors that are orthogonal to u, then w would also be orthogonal to u and it is enough to verify that w is orthogonal to u. If some of the vectors are not orthogonal to u, then with high probability w will not be orthogonal to u.\nSince veriﬁcation only occurs once every few packets, the incoming vectors w 1 , . . . , w k should be stored and marked as unveriﬁed until they pass veriﬁcation. This is important in cases where veriﬁcation fails and we wish to be able to identify which of the batched vectors are the corrupted ones (and perhaps also identify their sender).\nAs the modular operations are far more expensive than computing a linear combination of the incoming vectors, if we batch j vectors, our veriﬁcation time would be j times faster.\nThis certainly helps in terms of saving on veriﬁcation operations, but it also introduces a potential delay. If each node would need to wait for the arrival of t messages before it can forward them, then we are introducing a potential bottleneck.\nIn order to prevent this bottleneck we propose a randomized forwarding scheme that would forward packets even before they are checked, but with a lower probability. Before diving into the details, we use an example to illustrate our point. Assume that 10% of the incoming packets are polluted and assume that a forwarding probability of a non veriﬁed packet is 10%. This means that an unveriﬁed malicious packet would be forwarded with probability of 1%. The probability further forwarding corrupted packets quickly drops. In order to make this enhancement more robust, we suggest not to use a ﬁxed probability, but rather start with a conservative forwarding policy that gives little to no chance of forwarding a packet from an unfamiliar source. Only after a period of time, in which no corrupted packets received from this source, the probability of forwarding unveriﬁed packets should increase.\nThe two techniques introduced above can work in conjunc- tion. It can be readily seen that the overall performance boost is the product of the boost provided be each individual technique. We now make a note on how to combine the two techniques in a way that constantly increases the level of assurance. The naive way of combining both techniques is to batch k vectors each time, then perform a selective veriﬁcation on their linear combination and later to repeat the process with a different group of incoming vectors. Since selective veriﬁcation may err, a better approach is to add previously veriﬁed vectors to the batch. For example, if we batch k vectors at a time, then initially we would do a selective veriﬁcation on the linear\ncombination of the ﬁrst k vectors. After we get an additional k vectors we would batch all of the 2k vectors using fresh r 1 , . . . , r 2k before running selective veriﬁcation on their linear combination. This way we double check the ﬁrst k vectors (on different locations), reducing the chance that selective veriﬁcation fails to spot corrupted vectors.\nIn this section we prove the security of our construction. It was proven in [19] that ﬁnding a vector w / ∈ V for which\nh x i w i i \t = 1 is as hard as the discrete log problem. What remains to show is that our selective veriﬁcation does not allow the spreading of polluted ﬁle.\nWe take a group testing [15] approach to analyzing the security of our scheme. Using the ECC we deﬁned in III-B we apply h to all the possible vectors in Sp(V ). Let us denote the number of vectors in Sp(V ) by k, i.e. k = p n .\nGiven any input vector y / ∈ {x 1 , x 2 , . . . , x k }, we ask what is the probability that the j−th element in h(y) (denoted h(y)[j]) equals the j−th element in one of the previous x i s. Summing over all the x i s (using the union bound) we get that\nSince A j is random and since x i = y, the event in which (x i − y)A j = ¯ 0 occurs with probability\nThe probability that δ elements in h(y) appear in h(x i ) is bounded by δ ( 1 k ) δ\nBy taking the union bound over all possible values of y (which is bounded by p m+n ) we get that the probability for existence of a \u201dbad\u201d y is bounded by p m+n δ ( 1 k ) δ\nIn order to give a sense of security for practical parameters, lets assume that we want to bound 3 this probability by 2 −40 . In this case we get that\nSince log p δ and log p e are constants smaller than 1 (assum- ing a typical p to be about 2 1024 ), we get that\nTherefore, in order to have an error smaller than δ we would need to use > 41+m+n δ n .\nWe now consider the size of the orthogonal vector that achieves the above security. If we take for example δ = 1 10 and we wish to use blocks of size 2n then in order to get the security assurance for = 1 we would require our orthogonal vector to be of size 21(m + n). If we allow ourselves bigger blocks of size 3n, then we take = 2 , then we can see that it is sufﬁcient to stretch our orthogonal vector to the length of 16(m + n).\nThe different tradeoffs between and the stretch can be viewed in the graph below.\nIt was mentioned both in [19] and in [16] that the public key cannot be used for too many ﬁles as it would allow to collect enough equations to compute u. Thus a different public key needs to be associated with every new ﬁle. Since this information can be part of a .torrent ﬁle the only affect is that it adds a little overhead to the original data that is being transferred.\nWe now analyze the performance gains of our scheme and compare it to [19]. For this analysis we use common parameters from the Bittorrent peer-to-peer network.\nThe ﬁle size that we are going to share is 1GB. We are assuming a modulus q of 1024 bits 4 and we get that the packet size is m = 4M B (i.e. 4096*8 values from F ∗ p and there are n = 256 vectors in our matrix).\nIn the original scheme we had m + n modular exponenti- ations, which are at least logq ∗ (m + n) = 1024(m + n) = 33816576 modular multiplications.\nIn our method, let us take = 1. We only have (1 + )n modular exponentiations, i.e. 2 · 256 = 512 modular ex- ponentiations, which are at least 512 ∗ 1024 = 524288 modular multiplications. In addition we have our ECC, which takes (m + n)(1 + )n modular multiplications assuming the expansion matrix is full. However, if we take a sparse matrix with only 10 elements in each row 5 , then we get that there are only 10(m + n) = 330240 modular multiplication. So the total number of modular multiplication in our scheme is about 854528, which makes our scheme about 40 times faster than [19] with only using the selective check method. Further performance gain can be achieved by using batch veriﬁcation. If we batch in groups of ﬁve, then we would get that our scheme is about 5 ∗ 40 = 200 faster than [19]."},"refs":[{"authors":[{"name":"S. Agrawa"},{"name":"D. Boneh"}],"title":{"text":"Homomorphic MACs: MAC-Based In- tegrity for Network Coding"}},{"authors":[{"name":"S. Acedansk"},{"name":"S. De"},{"name":"M. Medar"},{"name":"R. Koette"}],"title":{"text":"How good is random linear coding based distributed network storage?"}},{"authors":[{"name":"R. Ahlswed"},{"name":"N. Ca"},{"name":"S. L"},{"name":"R. Yeung"}],"title":{"text":"In Network information ﬂow"}},{"authors":[{"name":"D. Bone"},{"name":"D. M Freeman"}],"title":{"text":"Homomorphic Signatures for Polynomial Functions"}},{"authors":[],"title":{"text":"BitTorrent ﬁle sharing protocol"}},{"authors":[{"name":"N. Ca"},{"name":"R. Yeung"}],"title":{"text":"Network coding and error correction"}},{"authors":[{"name":"R. Gennar"},{"name":"J. Kat"},{"name":"H. Krawczy"},{"name":"T. Rabin"}],"title":{"text":"Secure Network Coding over the Integers"}},{"authors":[{"name":"C. Gkantsidi"},{"name":"P. Rodrigue"}],"title":{"text":"Network coding for large scale content distribution, in Proc"}},{"authors":[{"name":"T. H"},{"name":"B. Leon"},{"name":"R. Koette"},{"name":"M. Medard"}],"title":{"text":"Byzantine Modiﬁcation Detection in Multicast Networks using Randomized Network Coding"}},{"authors":[{"name":"T. H"},{"name":"M. Medar"},{"name":"M. Effro"},{"name":"D. Karge"}],"title":{"text":"The beneﬁts of coding over routing in a randomized setting, in Proc"}},{"authors":[{"name":"S. Jagg"},{"name":"M. Langber"},{"name":"S. Katt"},{"name":"T. H"},{"name":"D. Katab"},{"name":"M. Medard Resilient network coding in the presence of Byzantine adversaries"}],"title":{"text":"In Proc"}},{"authors":[{"name":"E. Kehd"},{"name":"B. L"}],"title":{"text":"Null Keys: Limiting Malicious Attacks Via Null Space Properties of Network Coding"}},{"authors":[{"name":"Z. L"},{"name":"B. L"}],"title":{"text":"Network coding: the case of multiple unicast ses- sions,in Proc"}},{"authors":[{"name":"D. S. Lu"},{"name":"M. Medar"},{"name":"R. Koette"}],"title":{"text":"Network coding for efﬁcient wireless unicast, in Proc"}},{"authors":[{"name":"E. Pora"},{"name":"A. Rothschil"}],"title":{"text":"Explicit Non-adaptive Combinatorial Group Testing Schemes\u201d"}},{"authors":[{"name":"Y. Wan"}],"title":{"text":"Insecure \u201dProvable Secure Network Coding\u201d"}},{"authors":[{"name":"R. Yeun"},{"name":"N. Cai"}],"title":{"text":"Network Error Correction, In Basic Concepts and Upper Bounds"}},{"authors":[{"name":"Z. Y"},{"name":"T. We"},{"name":"B. Ramkuma"},{"name":"Y. Guan"}],"title":{"text":"An Efﬁcient Signa- turebased Scheme for Securing Network Coding against Pollution Attacks"}},{"authors":[{"name":"F. Zha"},{"name":"T. Kalke"},{"name":"M. Medar"},{"name":"K. Han"}],"title":{"text":"Signatures for Content Distribution with Network Coding"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566193.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T6.3","endtime":"10:50","authors":"Erez Waisbard, Ely Porat","date":"1341484200000","papertitle":"Efficient Signature Scheme for Network Coding","starttime":"10:30","session":"S11.T6: Authentication and Signatures","room":"Kresge Rehearsal A (033)","paperid":"1569566193"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
