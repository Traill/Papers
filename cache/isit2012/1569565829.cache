{"id":"1569565829","paper":{"title":{"text":"On the Equivalence of TCM Encoders"},"authors":[{"name":"Alex Alvarado §"},{"name":"Alexandre Graell i Amat \u2021"},{"name":"Fredrik Br¨annstr¨om \u2021"},{"name":"Erik Agrell \u2021"}],"abstr":{"text":"Abstract\u2014Optimal trellis-coded modulation (TCM) schemes are obtained by jointly designing the convolutional encoder and the binary labeling of the constellation. Unfortunately this approach is infeasible for large encoder memories or constellation sizes. Traditional TCM designs circumvent this problem by using a labeling that follows the set-partitioning principle and by performing an exhaustive search over the encoders. Therefore, traditional TCM schemes are not necessarily optimal. In this paper, we study binary labelings for TCM and show how they can be grouped into classes, which considerably reduces the search space in a joint design. For the particular case of 8-ary modulation the search space for the labelings is reduced from 8! to 240. Using this classiﬁcation, we formally prove that for any channel it is always possible to design a TCM system based on the binary-reﬂected Gray code with identical performance to the one proposed by Ungerboeck in 1982. Moreover, the classiﬁcation is used to tabulate asymptotically optimal TCM schemes."},"body":{"text":"Trellis-coded modulation (TCM) systems are commonly constructed by coupling a convolutional encoder and a con- stellation labeled using the set-partitioning (SP) principle. TCM was introduced in [1], quickly adopted in the modem standards in the early 90s, and it is a well studied topic, cf. [2], [3, Ch. 18]. As an alternative to TCM, bit-interleaved coded modulation (BICM) [4], [5] was introduced in 1992. BICM is usually referred to as a pragmatic approach for coded modulation and is well suited for fading channels.\nIn this paper we study binary labelings for TCM. Of particular interest are the binary reﬂected Gray code (BRGC) [6] and the natural binary code (NBC) [7]. The BRGC is often used in BICM designs because it maximizes the BICM mutual information for medium and high signal-to-noise ratios [5, Sec. III] and the NBC is often used in TCM designs because it follows the SP principle when it is used with constellations having certain symmetries, cf. [1, Fig. 4], [8, Fig. 3].\nThe performance of BICM for the additive white Gaussian noise (AWGN) channel can be improved if the interleaver is removed [9], a conﬁguration that was later called \u201cBICM with trivial interleavers\u201d (BICM-T) in [10]. BICM-T was recognized as a TCM transmitter used with a BICM receiver and it was shown to perform asymptotically as well as TCM if\nthe convolutional encoder is properly selected [10, Table III] and the BRGC is used. The transmitters in [1, Table I] and [10, Table III] for the 8-state (memory ν = 3) convolutional encoder 1 are shown in Fig. 1 (a) and Fig. 1 (c), respectively.\nThe authors in [10] failed to note that in fact the optimal BICM-T conﬁguration is equivalent to the one proposed by Ungerboeck 30 years earlier. For a 4-ary pulse amplitude mod- ulation (PAM) constellation (shown in Fig. 1), Ungerboeck\u2019s SP mapper (which is in this case equivalent to the NBC) can be generated using the BRGC mapper plus one binary addition (transform) applied to its inputs, as shown in Fig. 1(b). If the transform is included in the mapper, the conﬁguration in Fig. 1(a) is obtained, while if it is included in the code, the conﬁguration in Fig. 1(c) is obtained. This equivalence also applies to convolutional encoders with larger number of memories 2 and simply reveals that a TCM transmitter\nbased on a BRGC mapper will have identical performance to Ungerboeck\u2019s TCM if the encoder is properly modiﬁed.\nThe previous discussion raises the question about the use of non-SP labelings for TCM. This problem has indeed been studied in the literature, see for example [11, Sec. 13.2.1, Problem 13\u201311], [3, Example 18.2] or the so-called pragmatic TCM [12, Ch. 8], [13]. In [9], a binary labeling for BICM- T was heuristically proposed for M PAM constellations for M = 4, 8, 16. Traditional TCM designs either optimize the convolutional encoder for a constellation using an SP labeling, cf. [1], [8], or simply connect a convolutional encoder designed for binary transmission with an ad-hoc binary labeling (Gray in [14] and non-Gray in [13]). TCM designs based on SP are considered heuristic [15, pp. 525, 531], and thus, they do not necessarily lead to an optimal design [11, p. 680]. Indeed, Ungerboeck\u2019s TCM design is based on heuristic rules that aim to increase the Euclidean distance (ED) when compared with uncoded transmission with the same spectral efﬁciency. This discussion raises another question, namely, the optimal joint design of the convolutional encoder and the labeling.\nTo the best of our knowledge there are no works formally addressing the joint design of the convolutional encoder and the labeling of a TCM system. In this paper we study this problem and formally prove that for any channel, binary labelings can be grouped into different classes that will result in equivalent TCM transmitters. The classes are closely related to the Hadamard classes introduced in [16] in the context of vector quantization. The proposed classiﬁcation allows us to formally prove that in any TCM system the NBC labeling can be replaced by many other labelings (including the BRGC), provided that the convolutional encoder is properly modiﬁed.\nThroughout this paper, scalars are denoted by italic letters x, row vectors are denoted by boldface letters x = [x 1 , . . . , x N ], and matrices by capital boldface letters X. Sets are denoted using calligraphic letters C and the binary set is deﬁned as B {0, 1}. Binary addition is denoted by a ⊕ b. We use R m to denote the set of all reduced column echelon binary matrices of size M × m (see Section III) and T m to denote the set of all invertible m × m binary matrices.\nWe consider the TCM encoder shown in Fig. 2 where a feedforward convolutional encoder of rate R = k/m is serially connected to a mapper Φ L where the index L emphasizes the dependency of the mapper on the labeling (deﬁned later). At each discrete time instant n, the information bits i 1,n , . . . , i k,n are fed to the convolutional encoder, which is fully determined by k shift registers and the way the input sequences are connected (through the registers) to its outputs. We denote the length of the pth shift register by ν p , with p = 1, . . . , k, the overall constraint length (or memory of the convolutional encoder) by ν = k p =1 ν p , and the number of states by 2 ν .\nThe connection between the input and output bits is deﬁned by the binary representation of the convolutional encoder matrix\n    \n    \n] T ∈ B ν p +1 is a column vector representing the connection between the pth input sequence and the lth output sequence with l = 1, . . . , m. The coefﬁcients g (l) p, 1 , . . . , g (l) p,ν\n+1 are associated to the input bits i p,n , . . . , i p,n−ν p , respectively, and G ∈ B (ν+k)×m . Through- out this paper we will show the vectors g (l) p deﬁning G either in binary or octal notation. When shown in octal notation, g (l) p, 1 will always represent the most signiﬁcant bit (cf. Fig. 1).\nThe convolutional encoder matrix (1) allows us to express the output of the convolutional encoder at time n, which we denote by u n = [u 1,n , . . . , u m,n ], as a function of (ν + k) information bits, i.e.,\nu n = j n G \t (2) where j n [i (1) n , . . . , i (k) n ] with i (p) n [i p,n , . . . , i p,n−ν p ] are the information bits, and the matrix multiplication is in GF(2).\nThe coded bits u n are mapped to N -dimensional real constellation symbols using the mapper Φ L : B m → X where X ⊂ R N is the constellation used for transmission, with |X | = M = 2 m . We use x n ∈ X to denote the transmitted symbols at time n and we use the matrix S = [s T 1 , . . . , s T M ] T with s q ∈ R N and q = 1, . . . , M to denote the ordered constellation points.\nThe binary labeling of the qth symbol in S is denoted by c q = [c q, 1 , . . . , c q,m ] ∈ B m , where c q,l is the bit associated to the lth input of the mapper in Fig. 2. The labeling matrix is deﬁned as L = [c T 1 , . . . , c T M ] T , where c q in L corresponds to the binary labeling of the symbol s q in S. The resulting spectral efﬁciency of the system is k [bit/symbol].\nThe NBC of order m is deﬁned as N m [n T 1 , . . . , n T M ] T , where n q = [n q, 1 , . . . , n q,m ] ∈ B m is the base-2 representa- tion of the integer q −1, where n q,m is the least signiﬁcant bit. The BRGC of order m is deﬁned as B m [b T 1 , . . . , b T M ] T , where b q = [b q, 1 , . . . , b q,m ] ∈ B m . The bits of the BRGC can be generated from the NBC as b q, 1 = n q, 1 and b q,l = n q,l− 1 ⊕ n q,l for l = 2, . . . , m.\n0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1\n0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 0\nAlternatively, we have that n q,l = b q, 1 ⊕ . . . ⊕ b q,l− 1 ⊕ b q,l for l = 1, . . . , m, or, in matrix notation, B m = N m T and N m = B m T − 1 , where\n       \n       \n       \n       \nFor a given constellation S and a given ν, a TCM encoder is fully deﬁned by the convolutional encoder matrix G and the labeling of the constellation L. In this paper, a TCM encoder is deﬁned by the pair Θ = [G, L]. For given integers k, m, and ν, we deﬁne the convolutional encoder universe as the set G k,m,ν of all (ν + k) × m binary matrices G. 3 In [1], [8] Ungerboeck optimized TCM codes in terms of the minimum ED over all possible convolutional codes for well-structured one- and two- dimensional constellations and a labeling L that follows the SP principle, e.g., the NBC. On the other hand, in [10, Sec. IV-C] BICM-T systems over all G ∈ G 1,2,ν (R = 1/2 and 4PAM) and L = B 2 were optimized. We are also interested in the labeling universe, deﬁned for a given integer m as the set L m of all M × m binary matrices whose M rows are all distinct.\nTo the best of our knowledge, there are no works addressing the problem of designing a TCM encoder by exhaustively searching over the labeling universe and the convolutional en- coder universe. In this paper, we show how a joint optimization over all G ∈ G k,m,ν and L ∈ L m can be restricted, without loss of generality, to a joint optimization over all G ∈ G k,m,ν and over a subset of L m .\nThe output of a given TCM encoder Θ = [G, L] at time n depends on (ν +k) information bits. Using (2), the transmitted symbol at time n can then be expressed as x n = Φ L (u n ) = Φ L (j n G ).\nDeﬁnition 1: Two TCM encoders Θ = [G, L] and ˜ Θ = [ ˜ G , ˜ L ] are said to be equivalent if they give the same output symbol for the same information bit sequence, i.e., if they fulﬁll Φ L (jG) = Φ ˜ L (j ˜ G ) for any j ∈ B ν +k .\nRemark 1: For any channel, equivalent TCM encoders have the same bit error rate and frame error rate (FER).\nLemma 1: Φ L (c) = Φ ˜ L (cT ) where ˜ L = LT , for any two mappers Φ L and Φ ˜ L that use the same constellation S, any T ∈ T m , and any c ∈ B m .\nProof: Let v q \t [0, . . . , 0, 1, 0, . . . , 0] be a vector of length M , where the one is in position q. Thus c q = v q L for q = 1, . . . , M . The mapping Φ L satisﬁes by deﬁnition Φ L (c q ) = s q or, making the dependency on L explicit,\nΦ L (c) = s q , if c = v q L \t (5) for any c ∈ B m . Similarly, for any c ∈ B m ,\n= s q , if c = v q L \t (6) where the last step follows because L = ˜ LT − 1 . Since the right-hand sides of (5) and (6) are equal, Φ ˜ L (cT ) = Φ L (c) for all c ∈ B m .\nTheorem 1: For any G ∈ G k,m,ν , L ∈ L m , and T ∈ T m , the two TCM encoders Θ = [G, L] and ˜ Θ = [ ˜ G , ˜ L ] are equivalent, where ˜ L = LT and ˜ G = GT .\nProof: For any j ∈ B ν +k , Φ ˜ L (j ˜ G ) = Φ ˜ L (jGT ) = Φ L (jG), where the last equality follows by Lemma 1. The theorem now follows using Deﬁnition 1.\nTheorem 1 tells us that an exhaustive search over G k,m,ν and L m will include many pairs of equivalent TCM encoders. Therefore, an optimal TCM encoder with given parameters can be found by searching over a subset of G k,m,ν and the whole set L m or vice versa. In this paper, we choose the latter approach, searching over a subset of L m .\nA reduced column echelon matrix 4 is, in the context of binary labelings, deﬁned as a binary labeling matrix in which (i) the ﬁrst \u201c1\u201d in any column is in a row where all other elements are \u201c0\u201d and (ii) the number of leading zeros decreases in every column. The matrix N 3 in Example 1 (or more generally N m ) is an example of a reduced column echelon matrix. On the other hand, B m is not a reduced column echelon matrix. The following theorem, adapted from [17, p. 187, Corollary 1] to the concept of reduced column echelon matrices, shows an important matrix factorization which will be used in Example 2 and Theorem 3.\nTheorem 2: Any binary labeling L ∈ L m can be uniquely factorized as\nTheorem 2 shows that all binary matrices L can be uniquely generated by ﬁnding all the invertible matrices T (the set T m ) and all the different reduced column echelon matrices L R (the set R m ). In particular, we have [16, eq. (18)] M T |T m | =\n|R m |. In Table I, the values for M R and M T for 1 ≤ m ≤ 6 are shown. In view of Theorem 1 and Table I, for a joint design and 8-ary constellations (m = 3), the total number of different binary labelings that must be tested is reduced from 8! = 40320 to 240.\nA modiﬁed Hadamard class is deﬁned as the set of matrices L that can be generated via (7) using the same reduced column\nechelon matrix L R . Note that these modiﬁed Hadamard classes are narrower than the regular Hadamard classes deﬁned in [16], each including M reduced column echelon matrices. There are thus M R modiﬁed Hadamard classes, each with cardinality M T .\nThe problem of ﬁnding the set R m of reduced column ech- elon matrices for a given m can be solved by using a modiﬁed version of the full linear search algorithm introduced in [16, Sec. VIII]. Such an algorithm would generate one member of each modiﬁed Hadamard class, the one that corresponds to a reduced column echelon matrix L R .\nwhere the ﬁrst element in R 2 is the NBC (cf. Section II-C). The M T = 6 binary invertible matrices for m = 2 are\nUsing Theorem 2, all the 24 binary labelings in L 2 (cf. Table I) can be generated by multiplying the matrices in R 2 and in T 2 .\nAs a consequence of Theorems 1 and 2, the two TCM encoders [G, L] and [GT − 1 , L R ] are equivalent for any G ∈ G k,m,ν and L ∈ L m , where L R and T are given by the factorization (7). In other words, all nonequivalent TCM encoders can be generated using one member of each modiﬁed Hadamard class only, and thus, a joint optimization over all G ∈ G k,m,ν and L ∈ L m can be reduced to an optimization over all G ∈ G k,m,ν and L ∈ R m with no loss in performance. This means that the search space is reduced by a factor of M T = M !/M R .\nAnother way of interpreting the result in Theorem 1 is that for any TCM encoder ˜ Θ = [ ˜ G , ˜ L ], a new equivalent TCM encoder can be generated using a convolutional encoder G = ˜ GT − 1 and a labeling L = ˜ LT − 1 that belongs to the same modiﬁed Hadamard class as the original labeling ˜ L . One direct consequence of this result is that any TCM encoder using the NBC labeling can be constructed using the BRGC and an appropriately selected encoder.\nExample 3: For the two TCM encoders in Fig. 1, the NBC and BRGC labelings are related via B 2 = N 2 T , i.e.,\n0 0 1 1 0 1 1 0\nThus, the BRGC and the NBC of order m = 2 belong to the same modiﬁed Hadamard class, and convolutional encoders can be chosen to make the two resulting TCM encoders equiv- alent. This was illustrated in Fig. 1, where the transform block corresponds to the transform matrix T = [[1, 1] T , [0, 1] T ] T = T − 1 . Since N 2 = B 2 T − 1 , the TCM encoders [G [13,17] , B 2 ] and [G [13,4] , N 2 ] are equivalent, where\nThe above relation between the NBC and the BRGC is generalized to an arbitrary order m in the following theorem.\nTheorem 3: The BRGC and the NBC of any order m belong to the same modiﬁed Hadamard class.\nProof: The BRGC and NBC are related via B m = N m T , with T given by (4). The theorem now follows from Theorem 2 and the deﬁnition of a modiﬁed Hadamard class.\nTheorem 3 can be understood as follows. Any TCM en- coder using the NBC N m and a convolutional encoder G is equivalent to a TCM encoder using the BRGC B m and a convolutional encoder GT with T given by (4).\nIn this section we show how the classiﬁcation introduced in this paper can be used to ﬁnd asymptotically optimal TCM encoders in terms of FER. We use a union bound on the FER that is a straightforward generalization of the bound presented in [18] for convolutional codes. For the AWGN channel, and a block length of K symbols, we obtain\nIn (11), E s is the average symbol energy, N 0 /2 is the variance of the noise, A d is the distance multiplicity of the TCM sys- tem, which gives the average number of pairs of sequences at ED d [19, eq. (6.9)] and D is the set of all EDs {d 1 , d 2 , d 3 , . . .} (d i < d i +1 ) between any two sequences 5 of the TCM system, where d 1 is the minimum ED.\nWe call the inﬁnite set of pairs (d, A d ) the distance spectrum (DS) of a given TCM encoder Θ = [G, L], where d ∈ D. An optimal DS TCM (ODSTCM) encoder is deﬁned in the same way optimum distance spectrum convolutional encoders are deﬁned in [20]. This means that to minimize the FER, the DS (d, A d ) must be sequentially optimized, i.e., ﬁrst d 1 is maximized, then A d 1 is minimized, then d 2 maximized, etc.\nWe performed a search over G ∈ G k,m,ν and L ∈ L m for k = 1 and 4PAM (m = 2 and s q = (2q − 5)/ √ 5). The results are shown in Table II, where the ODSTCM encoders are shown as [·, ·] ∗ . For 4PAM, the possible squared EDs can be expressed as d 2 l = d 2 1 + 0.8(l − 1) for l = 2, 3, . . . In this table, we also list the encoders proposed by Ungerboeck\nin [8, Table I] (shown as [·, ·] U ). The search was performed numerically considering 5 terms in the spectrum 6 . Although no gains in terms of minimum ED were obtained, the DS of the ODSTCM encoders is better than those in [8, Table I]. Also, the NBC was among the optimal labelings found for all values of ν and is therefore the chosen labeling (ﬁrst one in lexicographical order) in Table II. This is however not the case for other combinations of m, k, and ν, which are not shown here due to space limitations. Fig. 3 shows that the new TCM schemes have better FER performance not only asymptotically but also for realistic signal-to-noise ratios.\nWe analyzed the problem of jointly designing the convolu- tional encoder and the labeling of a TCM scheme, by grouping the labelings into classes. Theoretically, this contributes to a better understanding of the interplay between code and labeling in TCM systems. Practically, it enables more powerful optimization methods for TCM schemes. As a proof of con- cept, TCM schemes were found that improve on Ungerboeck\u2019s celebrated designs by up to 0.3 dB.\nThe authors would like to thank Prof. Dr.-Ing. Robert Fischer for pointing out the equivalence between TCM systems with convolutional encoders optimized for the BRGC and the NBC, and showing how the convolutional encoders in [10] and [1] are related. These observations inspired this paper."},"refs":[{"authors":[{"name":"G. Ungerboeck"}],"title":{"text":"Channel coding with multilevel/phase signals"}},{"authors":[{"name":"E. Biglier"},{"name":"D. Divsala"},{"name":"P. J. McLan"},{"name":"M. K. Simo"}],"title":{"text":"Introduction to Trellis-Coded Modulation with Applications"}},{"authors":[{"name":"S. Li"},{"name":"D. J. Costell"}],"title":{"text":"Jr"}},{"authors":[{"name":"E. Zehavi"}],"title":{"text":"8-PSK trellis codes for a Rayleigh channel"}},{"authors":[{"name":"G. Caire"},{"name":"G. Taricco"},{"name":"E. Biglieri"}],"title":{"text":"Bit-interleaved coded modula- tion"}},{"authors":[{"name":"E. Agrell"},{"name":"J. Lassing"},{"name":"E. G. Str¨om"},{"name":"T. Ottosson"}],"title":{"text":"On the optimality of the binary reﬂected Gray code"}},{"authors":[{"name":"E. Agrell"},{"name":"A. Alvarado"}],"title":{"text":"Optimal alphabets and binary labelings for BICM at low SNR"}},{"authors":[{"name":"G. Ungerboeck"}],"title":{"text":"Trellis-coded modulation with redundant signal sets Part II: State of the art"}},{"authors":[{"name":"C. Stierstorfer"},{"name":"R. F. H. Fischer"},{"name":"J. B. Huber"}],"title":{"text":"Optimizing BICM with convolutional codes for transmission over the AWGN channel"}},{"authors":[{"name":"A. Alvarado"},{"name":"L. Szczecinski"},{"name":"E. Agrell"}],"title":{"text":"On BICM receivers for TCM transmission"}},{"authors":[{"name":"J. B. Barr"},{"name":"E. A. Le"},{"name":"D. G. Messerschmit"}],"title":{"text":"Digital Communication, 3rd ed"}},{"authors":[{"name":"G. C. Clar"},{"name":"J. B. Cai"}],"title":{"text":"Jr"}},{"authors":[{"name":"A. J. Viterbi"},{"name":"J. K. Wolf"},{"name":"E. Zehavi"},{"name":"R. Padovani"}],"title":{"text":"A pragmatic approach to trellis-coded modulation"}},{"authors":[{"name":"J. P. Odenwalder"},{"name":"A. J. Viterbi"},{"name":"I. M. Jacobs"},{"name":"J. A. Heller"}],"title":{"text":"Study of information transfer optimization for communication satellites"}},{"authors":[{"name":"J. G. Proaki"}],"title":{"text":"Digital Communications, 4th ed"}},{"authors":[{"name":"P. Knagenhjelm"},{"name":"E. Agrell"}],"title":{"text":"The Hadamard transform\u2014a tool for index assignment"}},{"authors":[{"name":"G. Birkhof"},{"name":"S. Mac Lan"}],"title":{"text":"A Survey of Modern Algebra, 4th ed"}},{"authors":[{"name":"G. Caire"},{"name":"E. Viterbo"}],"title":{"text":"Upper bound on the frame error probability of terminated trellis codes"}},{"authors":[{"name":"C. B. Schlege"},{"name":"L. C. Pere"}],"title":{"text":"Trellis and Turbo Coding, 1st ed"}},{"authors":[{"name":"P. Frenger"},{"name":"P. Orten"},{"name":"T. Ottosson"}],"title":{"text":"Convolutional codes with op- timum distance spectrum"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565829.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S13.T8.1","endtime":"15:00","authors":"Alex Alvarado, Alexandre Graell i Amat, Fredrik Brännström, Erik Agrell","date":"1341499200000","papertitle":"On the Equivalence of TCM Encoders","starttime":"14:40","session":"S13.T8: Coded Modulation","room":"Stratton (491)","paperid":"1569565829"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
