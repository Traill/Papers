{"id":"1569566425","paper":{"title":{"text":"On the Capacity of Binary Input Symmetric q -ary Output Channels with Synchronization Errors"},"authors":[{"name":"Mojtaba Rahmati"},{"name":"Tolga M. Duman"}],"abstr":{"text":"Abstract\u2014 In this paper, we develop several lower bounds on the capacity of binary input symmetric q-ary output channels with synchronization errors, e.g., substitution/erasure channels with synchronization errors. More precisely, we show that if a channel with synchronization errors can be decomposed into a cascade of two independent channels where only the ﬁrst one suffers from synchronization errors, a lower bound on its capacity related to the capacity of the one with only synchronization errors can be given. We present several examples with the new approach and demonstrate that for certain channels, e.g., deletion/substitution channel, it is possible to derive tighter capacity lower bounds than the existing ones."},"body":{"text":"Synchronization errors represent some of the most impor- tant impairments encountered in various digital communica- tion systems, for instance, in bit patterned media recording systems [1] or in other communication systems where the transmitter and receiver clocks are not perfectly synchronized. Different models that can capture the effects of the syn- chronization errors exist, such as a deletion channel where transmitted bits get deleted randomly with no knowledge of the deleted bit positions at the transmitter or at the receiver. Other models include insertion channels, insertion/deletion channels, etc. It is also of interest to incorporate the effects of the additive noise present at the receiver leading to more compli- cated models, such as insertion/deletion/substitution channels, or synchronization error channels taking into account additive white Gaussian noise (AWGN) [2].\nIn this paper, we consider memoryless binary input sym- metric q-ary output channels with synchronization errors. Dobrushin in [3] proved that Shannon\u2019s theorem applies for general memoryless channels with synchronization errors in which every transmitted symbol is independently replaced with a random number of symbols (including the empty string in the case of a deletion event), and the transmitter and receiver have no information about the positions of the synchronization errors. Speciﬁcally, we consider the concatenation of two independent channels where the ﬁrst one is a binary channel with only synchronization errors and the second one is a mem- oryless binary input symmetric q-ary output channel (BSQC). As a particular example, the ﬁrst channel can be a binary insertion/deletion (ins/del) channel and the second one can be a binary symmetric channel (BSC) or a substitution/erasure (sub/ers) channel (a ternary output channel q = 3 described precisely in Section II). We compute an achievable information\nrate for the concatenated channel in terms of the capacity of the ﬁrst channel (the synchronization error only channel) and the parameters of the second channel (the memoryless channel). We then apply the resulting bound to several models of interest. For instance, we consider Gallager\u2019s deletion channel concatenated with a binary symmetric channel, and utilize the tightest available bounds on the deletion-only channel capac- ity to derive an achievable rate for the deletion-substitution channel. For certain sets of parameters, the new bounds turn out to be tighter than the existing ones. The result is general, and other models for synchronization error channels can also be employed, e.g., Gallager insertion/deletion model [4] or models adopted in [2, 5, 6].\nThere are several papers deriving upper and/or lower bounds on the capacity of the ins/del channels, e.g., [4, 7\u201312]; how- ever, there are only a few results on upper and/or lower bounds on the capacity of the ins/del channels with substitution errors, e.g., [4, 13, 14]. Hence, our results here will provide a tool to derive additional results that will help in understanding of the ins/del channels where the effects of noise are also taken into account.\nThe paper is organized as follows. In Section II, we give the general model for a binary input symmetric q-ary output chan- nel with synchronization errors and present several lemmas that will be used in the proofs of the main results. Achievable rates over several speciﬁc channel models are presented in Section III, where we ﬁrst focus on sub/ers channels with synchronization errors (sub/ers/synch channels) and binary input symmetric quaternary output channels, then give our results for arbitrary values of q. We present several numerical examples and compare our results with the existing ones in Section IV. Finally, we conclude the paper in Section V.\nBy channels with synchronization errors we refer to the general model employed by Dobrushin in [3] where memo- ryless channels with synchronization errors are described by a channel matrix allowing for the channel outputs to be of different lengths for different uses of the channel. Neither the transmitter nor the receiver have any information about the position or pattern of the synchronization errors. By a binary input symmetric q-ary output channel with synchronization errors, we refer to a channel which can be considered as a concatenation of two independent channels where the ﬁrst one is a channel with only synchronization errors with the\ninput sequence X and the output sequence Y , and the second one is a BSQC with the input sequence Y and the output sequence Y (q) . By a symmetric channel, we refer to the deﬁnition given in [15, p. 94], i.e., a channel is symmetric if by dividing the columns of the transition matrix into sub- matrices, in each sub-matrix, each row can be written as a permutation of any other row and each column can be written as a permutation of any other column. For example, a channel with independent substitution, erasure and syn- chronization errors (sub/ers/synch channel) can be considered as a concatenation of a channel with only synchronization errors and a symmetric substitution/erasure channel (a binary input ternary output channel) with the output sequence Y (3) depicted in Fig. 1. a. Similarly a binary input symmetric quaternary output channel with synchronization errors can be decomposed into two independent channels such that the ﬁrst one is a memoryless synchronization error channel and the second one is a memoryless binary input symmetric quaternary output channel shown in Fig. 1. b.\nIn this section, we give two lemmas and one proposition which will be useful in the proof of our result on BSQC channels with synchronization errors. Note that the following two lemmas hold for any binary input q-ary output channel with synchronization errors, i.e., channel symmetry is not required.\nLemma 1. In any binary input q-ary output channel with synchronization errors and for all non-negative integer values of q, we have\nis the random variable denoting the length of the received sequence Y (q) , and EM {.} denotes the expected value with respect to the random variable M.\nSince by knowing Y (q) , random variable M is also known, i.e., H(M |Y (q) ) = 0, we obtain H(Y (q) ) = H(Y (q) |M) + H(M ). By using the same approach for H(Y ), we obtain\nUsing the fact that − log(x) is a convex function of x, we apply Jensen\u2019s inequality to arrive at H(Y (q) |m) − H(Y |m)\n⎛ ⎝\n(q) |y, m)p(y|m) p(y (q) |m) p(y|m)\n⎞ ⎠\nLemma 2. In any binary input q-ary output channel with synchronization errors and for any input distribution, we have\nwhere Y j denotes the j-th output bit of the synchronization error channel (input to the binary input q-ary output channel) and Y (q) j denotes the corresponding output symbol.\nwhere the last equality follows since X → Y → Y (q) form a Markov chain. Therefore, we can write\nOn the other hand, using the fact that by knowing Y , M is also known, we obtain H(Y (q) |Y ) = H(Y (q) |Y , M). Furthermore, since the second channel is memoryless, we can write\nProposition 1. Let X, Y and Y (q) form a Markov chain, i.e., X → Y → Y (q) , if I(X; Y (q) ) ≥ I(X; Y ) + A for\nany possible joint distribution of X, Y and Y (q) , where A is a constant then the capacity of the channels X → Y (q) (CX → Y (q) ) and X → Y (CX → Y ) satisfy\ncapacity of the channel X → Y , P (X), we can write lim\n1 n I(X; Y (X)) + A = CX\nA. Achievable Rates over Substitution/Erasure Channels with Synchronization Errors\nThe following theorem gives a lower bound on the capacity of the substitution/erasure channels (illustrated in Fig. 1. a) with synchronization errors (sub/ers/synch channel) in terms of the capacity of the synchronization error-only channel.\nTheorem 1. The capacity of the sub/ers/synch channel C ses can be lower bounded by\nwhere C s denotes the capacity of the synchronization error- only channel, r = lim n→∞ E {M} n , n and m denote the length of the transmitted and received sequences, respectively.\nBefore giving the proof of Theorem 1, we consider several special cases of the result. Since we have considered a general synchronization error channel model (as deﬁned by Dobrushin [3]), the derived lower bound, holds for different models on channels with synchronization errors. A popular model for channels with synchronization errors is the Gallager ins/del model 1 in which every bit is independently deleted with probability p d or replaced with two random bits with probability p i or received correctly with probability 1 −p d −p i . If we employ the Gallager model in deriving the lower bounds, we obtain r = 1 − p d + p i , and by employing it in (11), we obtain the following two corollaries.\nCorollary 1. The capacity of the sub/ers channel with ins/del errors (Gallager\u2019s ins/del errors model) C seid is lower bounded by\nwhere C id denotes the capacity of the Gallager ins/del channel with parameters p d and p i .\nCorollary 2. The capacity of the ins/del channel with substi- tution errors (ins/del/sub channel) C ids can be lower bounded by\nWe note that another lower bound for C ids is given in [4] as C ids ≥ 1 + p d log p d + p i log p i + p c log p c + p f log(p f ), where p f = p s (1 − p d − p i ) and p c = (1 − p s )(1 − p d − p i ), obtained for i.i.d. inputs. However, our result allows us to use any lower bound on C id from the literature which potentially improves on the bound in [4] (studied via speciﬁc examples in Section IV).\nLemma 3. For a sub/ers/synch channel, for any input distri- bution, we have\nProof: Using the result of Lemma 1, we only need to obtain an upper bound on\nwhere j 1 denotes the number of transitions 0 → − or 1 → − and j 2 denotes the number of transitions 0 → 1 or 1 → 0. E.g., p(011 − |0000) = p(0|0)p(1|0)p(1|0)p(−|0) = p e p 2 s (1 − p e − p s ). Furthermore, for a ﬁxed output sequence y (3) of length m with j 1 erased symbols − , there are 2 j 1 m−j 1 j 2\npossibilities among all m-tuples such that d(y (3) ) e = j 1 , i.e., the number of erased symbols in y (3) , and d(y, y (3) ) s = j 2 , i.e., the number of the positions in y and y (3) in which Y j \u2019s are the ﬂipped versions of Y j , therefore we can write\nNote that in deriving the inequality in (4), the summation is taken over the values of y with p(y) = 0. However, in (14) the summation is taken over all possible values of y of length m (over all m-tuples), i.e., p(y) = 0 or p(y) = 0, which results in the upper bound in (14). Furthermore, by using the fact that the probability of having j 1 erasures in a sequence of length m is equal to m j 1 p j 1 e (1 − p e ) m−j 1 , we obtain\nj 1 p j 1 e (1 − p e ) m−j 1 (2p e ) j 1 (1 − p e ) m−j 1 = (1 − p e ) 2 + 2p 2 e m . \t (15)\nBy substituting this result into (1), we obtain H(Y (3) ) − H(Y ) ≥ −E{M} log (1 − p e ) 2 + 2p 2 e , which\nLemma 4. For a sub/ers/synch channel, for any input distri- bution, we have\nBy substituting (16) into the result of Lemma 2, the proof is completed.\nProof of Theorem 1 : By substituting the results of Lemmas 3 and 4 into the deﬁnition of mutual information, for the same input distribution used for both synchronization error-only and sub/ers/synch channels, we obtain\nB. Achievable Rates over Binary Input Symmetric Quaternary Output Channels with Synchronization Errors\nTheorem 2. The capacity of the binary input symmetric quaternary output channel with synchronization errors C sq can be lower bounded by\nwhere C s denotes the capacity of the synchronization error only channel.\nThe speciﬁc result by considering Gallager\u2019s ins/del model as the synchronization error channel model is given in the following corollary.\nCorollary 3. The capacity of a binary input symmetric quater- nary output channel with ins/del errors C qid is lower bounded by\nLemma 5. For a binary input quaternary output channel with synchronization errors, for any input distribution, we have\nH(Y (4) ) ≥ H(Y ) − E {M} log (p 1 + p 3 ) 2 + (p 2 + p 4 ) 2 . Proof: By considering the result of Lemma 1 and follow-\ning the same procedure as in the proof of Lemma 3, the result follows (for details see [16]).\nLemma 6. For a binary input quaternary output channel with synchronization errors, for any input distribution, we have\nProof: Substituting the straightforward result H(Y (4) j |Y j ) = H(p 1 , p 2 , p 3 , p 4 ) into the result of Lemma 2 concludes the proof.\nProof of Theorem 2 : By considering the result of Lem- mas 5 and 6, and Proposition 1, the proof follows.\nC. Achievable Rates over Binary Input Symmetric q-ary Out- put Channels with Synchronization Errors (Odd q Case)\nWe now consider a binary input symmetric q-ary out- put channel with synchronization errors for an arbitrary odd value of q, where we represent the transition prob- ability values P Y (q) j = k| ¯ Y j = b for different values of b ∈ {−1, 1} and k = {− q−1 2 , · · · , −1, 0, 1, · · · , q−1 2 } by P Y (q) j = k| ¯ Y j = b = p kb . For instance, Table III-C shows transition probabilities for a binary input 5-ary output channel.\nThe main result on the BSQC channel with synchronization errors with odd q is a generalized version of the result in Theorem 1.\nTheorem 3. The capacity of the BSQC channel with synchro- nization errors C Qs for an odd q can be lower bounded by\nwhere C s denotes the capacity of the binary input synchro- nization error channel.\nD. Achievable Rates over Binary Input Symmetric q-ary Out- put Channels with Synchronization Errors (Even q Case)\nIn this part, we consider the generalization of the result of Theorem 2 for any even q. For the transition proba- bilities of the binary input q-ary output channel, we de- ﬁne P Y (q) j = k| ¯ Y j = b = p kb , where b ∈ {−1, 1} and k = {− q 2 , · · · , −1, 1, · · · , q 2 }. For instance, Table III-D shows transition probabilities for a binary input 6-ary output channel.\nThe main result on the BSQC channel with synchronization errors for any even q is given in the following theorem.\nTheorem 4. The capacity of the BSQC channel with synchro- nization errors C Qs , for any even q can be lower bounded\nIn this section, we give several numerical examples of the lower bounds on the capacity of the ins/del/sub channel and compare them with the existing ones in the literature.\nIn Table III, we compare the lower bound (12) on the capacity of the ins/del/sub channel with the existing lower bounds in [4, 13]. We employ the lower bound derived in [9] as the lower bound on the capacity of the deletion-only channel and the lower bound in [13] as the lower bound on the capacity of the ins/del channel in (12). Note that the Gallager\u2019s model in [4] by parameters p d , p i and p f can be considered as concatenation of an ins/del channel with parameters p d and p i , and a BSC channel with cross over probability of p s where p s is the solution of p c = (1 − p s )(1 − p d − p i ). The advantage of the new lower bound (12) is in using the tightest lower bound on the capacity of the synchronization error channel in lower bounding the capacity of the overall channel, i.e., the information rate of the overall channel is lower bounded for the input distribution which results in the tightest lower bound on the capacity of the synchronization error channel. We observe that for p i = 0, a ﬁxed p d and small values of p s , the lower bound (12) improves the one given in [13]. We also observe that the new lower bound (12) outperforms the lower bound given in [4], but for the case p i = 0 does not improve the lower bound given in [13], since as the lower bound on the capacity of ins/del channel we employ the result in [13] in the ﬁrst place.\nWe presented several lower bounds on the capacity of memoryless binary input symmetric q-ary output channels with synchronization errors. We showed that the capacity of any channel with synchronization errors which can be considered as a cascade of two channels (where only the ﬁrst one suffers from synchronization errors and the second one is a memoryless channel) can be lower bounded in terms of the capacity of the ﬁrst channel and the parameters of the second channel. In particular, we considered binary input symmetric ternary output (sub/ers) and quaternary output channels with synchronization errors and generalized the results to the case of a binary input symmetric q-ary output channels."},"refs":[{"authors":[{"name":"G. Hughes"}],"title":{"text":"Patterned Media"}},{"authors":[{"name":"W. Zeng"},{"name":"J. Tokas"},{"name":"R. Motwani"},{"name":"A. Kavcic"}],"title":{"text":"Bounds on mutual information rates of noisy channels with timing errors"}},{"authors":[{"name":"R. L. Dobrushin"}],"title":{"text":"Shannon\u2019s theorems for channels with synchronization errors"}},{"authors":[{"name":"R. Gallager"}],"title":{"text":"Sequential decoding for binary channels with noise and synchronization errors"}},{"authors":[{"name":"M. Mitzenmacher"}],"title":{"text":"Capacity bounds for sticky channels"}},{"authors":[{"name":"Z. Liu"},{"name":"M. Mitzenmacher"}],"title":{"text":"Codes for deletion and insertion channels with segmented errors"}},{"authors":[{"name":"M. Rahmati"},{"name":"T. M. Duman"}],"title":{"text":"Analytical lower bounds on the capacity of insertion and deletion channels"}},{"authors":[{"name":"E. Drinea"},{"name":"M. Mitzenmacher"}],"title":{"text":"Improved lower bounds for the capacity of i.i.d. deletion and duplication channels"}},{"authors":[{"name":"A. Kirsch"},{"name":"E. Drinea"}],"title":{"text":"Directly lower bounding the information capacity for channels with i.i.d. deletions and duplications"}},{"authors":[{"name":"D. Fertonani"},{"name":"T. M. Duman"}],"title":{"text":"Novel bounds on the capacity of the binary deletion channel"}},{"authors":[{"name":"Y. Kanoria"},{"name":"A. Montanari"}],"title":{"text":"On the deletion channel with small deletion probability"}},{"authors":[{"name":"A. Kalai"},{"name":"M. Mitzenmacher"},{"name":"M. Sudan"}],"title":{"text":"Tight asymptotic bounds for the deletion channel with small deletion probabilities"}},{"authors":[{"name":"D. Fertonani"},{"name":"T. M. Duman"},{"name":"M. F. Erden"}],"title":{"text":"Bounds on the capacity of channels with insertions, deletions and substitutions"}},{"authors":[{"name":"J. Hu"},{"name":"T. M. Duman"},{"name":"M. F. Erden"},{"name":"A. Kavcic"}],"title":{"text":"Achievable in- formation rates for channels with insertions, deletions and intersymbol interference with i.i.d. inputs"}},{"authors":[{"name":"R. G. Gallage"}],"title":{"text":"Information Theory and Reliable Communication"}},{"authors":[{"name":"M. Rahmati"},{"name":"T. M. Duman"}],"title":{"text":"Achievable rates for noisy channels with synchronization errors"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566425.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T7.3","endtime":"17:40","authors":"Mojtaba Rahmati, Tolga M. Duman","date":"1341249600000","papertitle":"On the Capacity of Binary Input Symmetric q-ary Output Channels with Synchronization Errors","starttime":"17:20","session":"S4.T7: Capacity of Finite-Alphabet Channels","room":"Stratton (407)","paperid":"1569566425"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
