{"id":"1569565661","paper":{"title":{"text":"Graph-based Code Design for Quadratic-Gaussian Wyner-Ziv Problem with Arbitrary Side Information"},"authors":[{"name":"Yi-Peng Wei*"},{"name":"Shih-Chun Lin\u2020"},{"name":"Yu-Hsiu Lin*"},{"name":"Hsuan-Jung Su*"}],"abstr":{"text":"Abstract\u2014 Wyner-Ziv coding (WZC) is a compression tech- nique using decoder side information, which is unknown at the encoder, to help the reconstruction. In this paper, we propose and implement a new WZC structure, called residual WZC, for the quadratic-Gaussian Wyner-Ziv problem where side information can be arbitrarily distributed. In our two-stage residual WZC, the source is quantized twice and the input of the second stage is the quantization error (residue) of the ﬁrst stage. The codebook of the ﬁrst stage quantizer must be simultaneously good for source and channel coding, since it also acts as a channel code at the decoder. Stemming from the non-ideal quantization at the encoder, a prob- lem of channel decoding beyond capacity is identiﬁed and solved when we design the practical decoder. Moreover, by using the modiﬁed reinforced belief-propagation quantization algorithm, the low-density parity check code (LDPC), whose edge degree is optimized for channel coding, also performs well as a source code. We then implement the residual WZC by an LDPC and a low- density generator matrix code (LDGM). The simulation results show that our practical construction approaches the Wyner- Ziv bound. Compared with previous works, our construction can offer more design ﬂexibility in terms of distribution of side information and practical code rate selection."},"body":{"text":"theoretical results in [6] [7] can be applied to such cases is unknown. Moreover, the results in [4] [6] [7] require two nested codebooks good for the source and/or channel coding. Practically constructing such good codebooks with nested structure in [4] [6] [7] is still a challenging task.\nInstead of building WZC from nested codebooks as in [4] [6] [7], we proposed a new coding structure in our previous work [8], where two codebooks without nested structure were used in a two-stage serial quantization process. The encoder ﬁrst quantizes the source once, and then uses another codebook to quantize the quantization error of the ﬁrst stage. The quantization index of the second stage is then sent to the decoder. We name the coding in [8] residual WZC, which reﬂects some resemblances of our coding structure to the residual vector quantizer [9, Sec 12.11] for source coding without side information. In a theoretical random coding setting, the residual WZC was proved to be Wyner-Ziv-bound achieving.\nIn this paper, we show that using graph-based codes, the theoretically-optimal residual WZC in [8] can be prac- tically implemented. Different from the celebrated quadratic- Gaussian WZC in [10] [11], our scheme can approach the Wyner-Ziv bound for all rate regimes when the side infor- mation is arbitrarily distributed. By using the loss to the Wyner-Ziv bound as the performance metric, simulation shows that the performance of our code is comparable to that in [10]. However, in contrast to [10], our simulation result is independent of the distribution of the side information, as long as the variance of the side information is the same. Besides, our WZC has a complexity similar to that of [10] and linear in the codeword length, and much lower than that of the lattice decoder (NP problem) in [4].\nPractically implementing the residual WZC is not trivial. Firstly, the codebook of the ﬁrst stage quantizer acts as a channel code in our decoder, and must be simultaneously good for source and channel coding (SSC). Moreover, the non-ideal practical quantizers at the encoder make the channel decoder operate in a rate regime above capacity. We propose a method which can increase the equivalent signal-to-noise ratio (SNR) at the channel decoder to solve this problem. Secondly, although the low-density parity check code (LDPC) has been proved to be SSC theoretically [12], the edge degree design and practical quantization algorithm for SSC LDPC are still\nDeﬁnition 2 (mod-A distance): The mod-A distance be- tween two vectors a = (a 1 , . . . , a n ) T and b = (b 1 , . . . , b n ) T is\nEncoder part: The input of the ﬁrst-stage quantizer C 1 in Fig. 1 is\ne 1 = ( αx + d + c 1 ) mod A. \t (4) The input of the second-stage quantizer C 2 in Fig. 1 is the\nquantization error e 1 of the ﬁrst stage in (4). The distortion constraint for the second stage is 1 n E[e 2 T e 2 ] ≤ αD, and the quantization output and the quantization error of the second stage are c 2 and\ne 2 = (e 1 − c 2 ) mod A, \t (5) respectively. Finally, the encoder sends the index representing c 2 to the decoder.\nDecoder part: The decoder receives the index representing c 2 and the side information y a . As in Fig. 1, the decoder ﬁrst computes w = (c 2 − αy a − d) mod A. From [8], equivalently we have\nw = (c 1 + αv − e 2 ) mod A. \t (6) Then we can channel decode c 1 from w, by treating\nas the equivalent channel noise, where e 2 is given in (5). By denoting the channel decoder output as ˆc 1 , we can compute ˆv , the reconstruction of v, as ˆv = (w − ˆc 1 ) mod A. Finally, the reconstruction ˆx is\nLet the code rates of C 1 and C 2 be R 1 and R 2 , respectively. According to [8], by letting α be\nthere exists codebooks C 1 and C 2 such that the MSE distortion constraint (2) is met if\nlog( P V D\nquantizers C 1 and C 2 can exactly achieve the rate-distortion bound, we will get the practical quantization error variance D 2, ε of e 2 in (5) larger than the theoretical one predicted in [8]. From (6), the variance of the equivalent noise (7) will also be larger than the theoretical value in [8], which makes the selected R 1 operating in the regime above the channel capacity in (10) with A = A ε .\nTo solve the channel decoding beyond capacity problem described above, we propose a method which increases A ε to A p while R 1 is ﬁxed as that in Step 2 of Table I. The key idea is that the equivalent SNR at the channel decoder in Fig. 2 will also increase. To be more speciﬁc, from the random codebook construction in [8], we know that the optimal constellation of C 1 is uniformly distributed in [ − A ε 2 , A ε 2 ]. Thus we use the uniform pulse amplitude modulation (PAM) as the constellation of C 1 , and the equivalent SNR of the channel (6) with A = A ε is\nwhere k is a constant related to the order of the PAM constellation. If we increase the modulo size from A ε to A p with rates R 1 and R 2 unchanged, the quantization error variance of e 2 in (5) will become\nbecause the variance of C 1 \u2019s input, which is uniformly- distributed, will increase from A 2 ε /12 to A 2 p /12. Then the equivalent SNR becomes\nNow we consider the loss of the practical channel decoder with practical C 1 in Fig. 2 compared to the optimal channel coding in [8]. For the practical channel coding, let σ 2 n, ε be the variance of the maximum tolerable equivalent noise for the successful decoding, where the PAM constellation of C 1 is chosen according to A ε . Then under the non-ideal channel decoding, we have\nwhere the RHS is the variance of the equivalent noise (7). When the PAM constellation of C 1 is chosen according to A p instead of A ε , the signal power of codeword c 1 is scaled by (A p /A ε ) 2 . Then the maximum tolerable equivalent noise variance σ 2 n,p for the practical channel coding can be estimated by\nNow we wish σ 2 n,p ≥ D 2,p + α 2 P V to ensure the practical channel decoding in (6) being successful. Using this criterion with (14) and (16), the practical modulo size A p in Fig. 2 must meet,\nfrom the source. Taking quantizer C 1 as an example. We let u i be the ith element of C 1 \u2019s input (uniform), and c 1,i be the ith coded symbol of codeword c 1 . To reﬂect the modulo A ε operation before C 1 in Fig. 1, we use the following conditional probability density function (PDF) to calculate the a priori information\n(g) is the PDF of N(0, σ 2 n, ε ), and Z is the integer set. The rest of the algorithm is the same as that in [13] and is omitted here. After obtaining D 2, ε in Step 4, we can follow Step 5, which is described in Sec. III-A, to get the practical modulo size A p in Fig. 2 and complete our design.\nFinally, note that the complexity of the BP channel decoding algorithm for our WZC decoder is linear [16] in codelength (i.e. O(n)), also is the RBP algorithm used in our WZC encoder. Adopting the RBP algorithm instead of the O(n 2 ) hard-decimation-based one in [14] [18] signiﬁcantly reduces our computation complexity.\nIn our design example, different from the Gaussian side information in [10] [19], we let each element of the side information y in (1) be uniformly distributed in [ −A/2,A/2]. Due to the dither, the distribution of y will not affect our performance. The details of our design example is given in Sec. IV-A, with the distortion performance given in the end of this subsection. Finally, Sec. IV-B provides more discussions on our work.\nFollowing our design ﬂow in Table I, we ﬁrst set P V in (3) as 0.28 and the WZC rate R 2 = 0.953, and then the ideal distortion D is 0.0747. For Step 2, given ε=0.005, we ﬁnd that choosing A ε as 3 is sufﬁcient. R 1 is 0.68 bpcu. For Step 3, we use 2-PAM LDPC to implement C 1 with constellation points ± A ε 4 . To achieve the WZC bound, we choose codeword length n = 10 5 symbols per source block. The degree proﬁle is : check nodes (CND): 100% of degree 12; VND: 35.36% of degree 2, 44.74% of degree 3, and 19.89% of degree 9. By applying the BP channel decoding algorithm, we obtain σ 2 n, ε as 0.185.\nthat LDPC itself sufﬁces to be a good SSC code, thus the compound LDGM/LDPC construction proposed in [6] may not be necessary for our ﬁrst-stage quantizer C 1 .\nIn this paper, we considered the quadratic-Gaussian Wyner- Ziv problem where side information can be arbitrarily dis- tributed. We implemented the theoretically-claimed residual WZC by LDPC and LDGM. We identiﬁed and solved a problem called the channel decoding beyond capacity problem when designing our practical decoder. Moreover, we modiﬁed the RBP algorithm to make the LDPC with the edge degree optimized for the channel coding perform well as a source code. The simulation results showed that our practical con- struction approaches the Wyner-Ziv bound, and has a similar performance compared with previous works. Moreover, our construction can offer more design ﬂexibility in terms of the distribution of the side information and the practical code rate selection."},"refs":[{"authors":[{"name":"A. D. Wyner"}],"title":{"text":"The rate-distortion function for source coding with side information at the decoder-II: General sources"}},{"authors":[{"name":"D. Slepian"},{"name":"J. K. Wolf"}],"title":{"text":"Noiseless coding of correlated information sources"}},{"authors":[{"name":"Z. Xiong"},{"name":"A. D. Liveris"},{"name":"S. Cheng"}],"title":{"text":"Distributed source coding for sensor networks"}},{"authors":[{"name":"R. Zamir"},{"name":"S. Shamai(Shitz)"},{"name":"U. Erez"}],"title":{"text":"Nested linear/lattice codes for structured multiterminal binning"}},{"authors":[{"name":"G. Kramer"},{"name":"M. Gastpar"},{"name":"P. Gupta"}],"title":{"text":"Cooperative strategies and capacity theorems for relay networks"}},{"authors":[{"name":"M. J. Wainwright"},{"name":"E. Martinian"}],"title":{"text":"Low-density graph codes that are optimal for binning and coding with side information"}},{"authors":[{"name":"S. B. Korada"},{"name":"R. L. Urbanke"}],"title":{"text":"Polar codes are optimal for lossy source coding"}},{"authors":[{"name":"S.-J. Lin"},{"name":"S.-C. Lin"},{"name":"K.-S. Chen"},{"name":"H.-J. Su"}],"title":{"text":"Coding for noisy quadratic-Gaussian Wyner-Ziv problem: A successive quantization ap- proach"}},{"authors":[{"name":"A. Gersh"},{"name":"R. M. Gra"}],"title":{"text":"Vector quantization and signal compression"}},{"authors":[{"name":"Y. Yang"},{"name":"S. Cheng"},{"name":"Z. Xiong"},{"name":"W. Zhao"}],"title":{"text":"Wyner-Ziv coding based on TCQ and LDPC codes"}},{"authors":[{"name":"Z. Liu"},{"name":"S. Cheng"},{"name":"A. D. Liveris"},{"name":"Z. Xiong"}],"title":{"text":"Slepian-Wolf coded nested lattice quantization for Wyner-Ziv coding: High-rate performance analysis and code design"}},{"authors":[{"name":"V. Chandar"}],"title":{"text":"Sparse graph codes for compression, sensing, and secrecy"}},{"authors":[{"name":"A. Braunstein"},{"name":"F. Kayhan"},{"name":"R. Zecchina"}],"title":{"text":"Efﬁcient LDPC codes over GF(q) for lossy data compression"}},{"authors":[{"name":"T. Filler"},{"name":"J. Fridrich"}],"title":{"text":"Binary quantization using belief propagation with decimation over factor graphs of LDGM codes"}},{"authors":[{"name":"K.-S. Chen"}],"title":{"text":"Low density constructions for simultaneously good for channel and source coding problem with applications"}},{"authors":[{"name":"D. J. C. MacKay"}],"title":{"text":"Good error-correcting codes based on very sparse matrices"}},{"authors":[{"name":"S. ten Brink"},{"name":"G. Kramer"},{"name":"A. Ashikhmin"}],"title":{"text":"Design of low-density parity-check codes for modulation and detection"}},{"authors":[{"name":"Q. Wang"},{"name":"C. He"}],"title":{"text":"Approaching 1.53-dB shaping gain with LDGM quantization codes"}},{"authors":[{"name":"S. S. Pradhan"},{"name":"K. Ramchandran"}],"title":{"text":"Distributed source coding using syndromes (DISCUS): Design and construction"}},{"authors":[{"name":"Y.-P. Wei"},{"name":"S.-C. Lin"},{"name":"S.-J. Lin"},{"name":"H.-J. Su"}],"title":{"text":"Residual-quantization based code design for source coding with arbitrary decoder side infor- mation"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565661.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T1.2","endtime":"10:30","authors":"Yi-Peng Wei, Shih-Chun Lin, Yu-Hsiu Lin, Hsuan-Jung Su","date":"1341223800000","papertitle":"Graph-based Code Design for Quadratic-Gaussian Wyner-Ziv Problem with Arbitrary Side Information","starttime":"10:10","session":"S1.T1: Source Coding with Side Information","room":"Kresge Rehearsal B (030)","paperid":"1569565661"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
