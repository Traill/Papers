{"id":"1569566991","paper":{"title":{"text":"THE 1 ANALYSIS APPROACH BY SPARSE DUAL FRAMES FOR SPARSE SIGNAL RECOVERY REPRESENTED BY FRAMES"},"authors":[{"name":"Tiebin Mi \u2020"},{"name":"Shidong Li ,\u2020"},{"name":"Yulong Liu \u2020"}],"abstr":{"text":"A sparse-dual-frame based 1 -analysis approach for compressed sensing (CS) is proposed. The sparse dual frame is a notion of opti- mal dual frames of a non-exact frame. It is motivated in the study of compressed sensing problems where signals are sparse with respect to redundant dictionaries (frames). An alternating iterative algorithm is proposed. An error bound ensuring the correct signal recovery is obtained. Empirical studies over generally difﬁcult CS problems demonstrate that the new sparse-dual-based approach provides satis- factory solutions, whereas other existing means may not."},"body":{"text":"Standard compressed sensing studies often assume signals possess sparse (or nearly sparse) representations with respect to orthonormal bases.\nAs compressed sensing takes more stage in practical applica- tions, a growing number of problems point to scenarios where signals are sparse with respect to redundant frames rather than orthonormal bases. Obviously, the ﬂexibility of frames is the key characteristic that empowers frames to become a natural and concise signal repre- sentation tool. As a result, studies on compressed sensing problems where signals are sparse with respect to frames are becoming more and more appealing and critical.\nLet D be a dictionary/frame whose columns are the frame vec- tors. By f being sparse with respect to D, we mean f = Dx, and x is the sparse coefﬁcient vector. In general compressed sensing for- mulation, f is often measured by a under-determined sensing matrix A, namely,\ny = Af + z = ADx + z, \t (1.1) where A ∈ R m×n is typically known as \u201cfat\u201d sensing matrix with m \t n, and z ∈ R m is a noise term. The goal of the compressed sensing problem is to derive means to faithfully recover f , from the compressed measurement y.\nSince x is sparse, a straightforward approach is to view (1.1) as y = (AD)x + z, and to recover the sparse coefﬁcient x by solving the 1 -minimization problem\nwhere is an upper bound of the noise. f is then derived via synthesis operation, i.e., f = Dx . This is known as 1 -synthesis [1].\nThe 1 -synthesis approach is still by far the most popular method for signal recovery in related compressed sensing applications. Em- pirical studies also show that 1 -synthesis sometimes do achieve good recovery results for mild problems [2, 3]. However, since D is a highly coherent frame, all previously known sparse recovery condi- tions and error estimates no longer apply satisfactorily to the compos- ite matrix AD [1], [3]. Recovery guarantee is hampered.\n1 -analysis approach is an alternative that tries to ﬁnd the signal f directly by solving the problem\nHere D is assumed a Parseval frame (i.e., DD ∗ = I), and the analysis operator D ∗ is the canonical dual frame.\nThe 1 -analysis approach has a remarkable development [2] re- cently that (1.3) recovers an approximation f of the original f with an error bound\ns \t (1.4) provided that A obeys a \u201cD-RIP\u201d condition [2] with a \u201cD-RIP\u201d con- stant δ 2s < 0.08.\nRIP (Restricted Isometry Property) and D-RIP (RIP applied to the union of column subspaces of the dictionary/frame D) are both popular notions in compressed sensing studies. We refer to , e.g., [2], [4], [5], for details and further discussions.\nIndeed, 1 -analysis demonstrates a promising performance in ap- plications where both the columns of the Gram matrix D ∗ D and the coefﬁcient vector x are reasonably sparse. In other words, as long as the frame coefﬁcient vector D ∗ f is sensibly sparse, 1 -analysis is a good approach with a nice error bound guarantee (1.4).\nHowever, there is a unforgiven reality to the use of D ∗ as the analysis operator. In general, f is sparse in terms of D does not im- ply D ∗ f is necessarily sparse. Indeed, when D is a Parseval frames, D ∗ f = D ∗ Dx is the canonical expansion coefﬁcients of f . Canon- ical expansion has the minimum 2 -norm and is usually fully popu- lated and is not sparse. This is also pointed out speciﬁcally in com- pressed sensing studies with frames, e.g., [3].\nWe propose a sparse-dual-frame based analysis approach that takes advantage of both the sparsity of the analysis coefﬁcients, and a similar error bound estimate as that of (1.4). Sparse dual frames is a notion of optimal dual frames of a given (non-exact) frame that produces sparse coefﬁcients for a given f [6]. It is speciﬁcally in- troduced to cope with the lack of sparsity in D ∗ f in typical analysis schemes. To provide a solution to this sparse-dual-based formulation, an alternating iterative algorithm is developed. Some examples are also reported.\nLet us begin with a brief discussion of the relevance between sparse representations and a notion of sparse dual frames.\nLet D be a dictionary with which a signal f has a sparse repre- sentation. D could be a basis or a redundant frame. In sparse rep- resentations, the main purpose is to ﬁnd the sparse coefﬁcient for a given signal f , which is commonly formulated as\nwhere · 0 stands for the number of nonzero entries. Lead by Donoho, Cand´es, Tao and their associates, the renowned advances in the area of sparse representations lie fundamentally in the replace- ment of (P 0 ) with its convex relaxation\nThey show that with appropriate conditions over the matrix D, the so- lution to (P 1 ) is the same as the solution to (P 0 ). There have been an abundant articles exploring the equivalence between (P 0 ) and (P 1 ), e.g., [4, 5, 7, 8, 9, 10, 11, 12].\nIn this report, D shall always stand for a (frame) matrix consist- ing in its columns of all vectors of a frame. D is used for a dual frame matrix such that DD ∗ = DD ∗ = I, [13]. How is sparse represen- tation related to sparse dual frames? Let us proceed with the sparse dual discussion.\nFrom a frame theoretical point of view, when a signal f is sparse with respect to a frame D, there is a sparse coefﬁcient vector x such that f = Dx. It is not hard to imagine that there ought be an optimal dual frame, say D S that produces the very sparse coefﬁcient x, i.e., x = D ∗ S f . After all, all coefﬁcients of a frame expansion of f ought to correspond to some dual frame, which really is the spirit of frame expansions.\nWe see that knowing the solution to (P 0 ) or (P 1 ) is equivalent to knowing an optimal dual frame D S which is capable of producing the very sparse coefﬁcient x by x = D ∗ S f .\nDeﬁnition 2.1. Let D be a frame with columns of frame elements {x k } N k=1 of H n . Let 0 = f ∈ H n be sparse with respect to D such that f = Dx, where x is a sparse vector. We say D S is a sparse dual frame of D, if DD ∗ S = I and x = D ∗ S f .\nIt turns out that sparse duals D S do always exist. We have the following theorem conﬁrming the existence of sparse duals [6].\nTheorem 2.2. Let D be a frame of H n . Given 0 = f ∈ H n , and let x be any coefﬁcient vector such that f = Dx. Then there must be a dual frame D f,x such that x = D ∗ f,x f and DD ∗ f,x = I.\nSince f = Dx = DD ∗ (DD ∗ ) −1 f , x = D ∗ (DD ∗ ) −1 f + ν f,x for some ν f,x ∈ ker D. Now that P ≡ I − D ∗ (DD ∗ ) −1 D is the orthogonal projection onto ker D, there must be a vector µ f,x ∈ H n such that ν f,x = Pµ f,x . Since f = 0, there is at least one k 0 such\nthat f (k 0 ) = 0. Then, among many other possibilities, W f,x can be chosen/determined as follows. For i = 1, . . . , N and j = 1, . . . , n,\nConsequently, there is indeed a W f,x such that x = D ∗ (DD ∗ ) −1 f + (I − D ∗ (DD ∗ ) −1 D)W f,x f . The claim is then followed.\nRemark. a. Not only sparse dual frames always exist, sparse dual frames are not unique even for one given f . Because of the redun- dancy and massive freedom in the choice of W , there are common sparse dual frames to a class of signals f .\nb. Let us emphasize that the canonical dual frame is not a sparse dual frame in general. This is because that the canonical dual frame produces generally coefﬁcients of the least 2 -norm among all pos- sible coefﬁcients representing a signal. And we know that 2 -norm tends to spread the coefﬁcients into a large number of small coefﬁ- cients.\nc. We also comment that the notion of sparse dual frames for approximately sparse or compressible signals is an active on-going work that we are pursuing.\nThere is no restriction on x in Theorem 2.2. Therefore, if x is the sparse coefﬁcient of f , we reach the following corollary directly.\nCorollary 2.3. Let D be a frame of H n . Suppose 0 = f ∈ H n has a sparse frame representation f = Dx, where x is the sparse coefﬁcient. There must be a sparse dual frame D S such that x = D ∗ S f .\nThe following result indicates that though sparse duals are signal dependent, they are nevertheless locally stable. Numerically, and in practical applications, such a local continuity and stability of sparse dual frames play an important role.\nTheorem 2.4. Let D be a frame of H n . Given f ∈ H n . Suppose D ∗ S f − (D ∗ S f ) s 1 ≤ and f − g 2 ≤ δ, then\nHere ˜ B is the upper frame bound of the sparse dual frame D S , and (D ∗ S g) s is the thresholded vector of D ∗ S g whose entries are set to zeros except for its largest s entries in magnitude.\nD ∗ g − (D ∗ g) s 1 =\nExample 2.5. Let {x k } 3 k=1 be an equiangular tight frames in R 2 , which is demonstrated in Figure 1(a). The associated matrix D is given by\nTherefore, the canonical dual frame is { 2 3 x k } 3 k=1 , which is demon- strated in Figure 1(b) with dashed arrows.\nSuppose f = αx 1 . Then the sparse coefﬁcient with respect to the frame D is x 0 = [α 0 0] T . Note that the coefﬁcients of f corre- sponding to the canonical dual frame is given by\nOn the other hand, one sparse dual frame D S is demonstrated in Figure 1(b) with solid/red arrows,\nMore importantly, D ∗ S f = [α 0 0] T is exactly the sparse coefﬁcient. Moreover, the lower frame bound of D S is 2 3 , and the upper frame bound of D S is 1, indicating that the sparse dual frame is very well behaved.\n2.2. A sparse dual frame approach to compressed sensing with frames\nIn view of the second term of the right hand side of the error bound (1.4), an ultimate 1 -analysis problem should be formulated by the sparse dual frame as follows.\nwhere D ∗ S is the analysis operator associated with sparse dual frames. Since D ∗ S f , by deﬁnition, is much sparser than D ∗ f , such an exten- sion is clearly very natural. (2.2) is termed the sparse-dual-based\nThere are two immediate objectives facing us. One is to establish a similar error bound as in (1.4) for the new sparse-dual-based 1 - analysis problem (2.2).\nThe other is to derive an algorithm for the solution of the new sparse-dual-based approach.\nBefore diving into solutions to these two objectives, an important remark is in the order.\nRemark. In a related article also presented at ISIT 2012 [14], a no- tion of optimal-dual-based analysis approach is also outlined,\nOn the surface, it seems that (2.2) and (2.3) are equivalent. It is impor- tant that we outline a fundamental difference between the sparse-dual approach (2.2) and the optimal-dual approach (2.3).\nWe have shown in Theorem 2 of [14], that the optimal-dual-based analysis problem (2.3) is equivalent to the 1 synthesis approach (1.2). Because it minimizes the 1 norm of D ∗ f simultaneously over the dual frame D and the signal f . It is important to emphasize that the optimization in the optimal-dual approach (2.3) is entirely to mini- mize the 1 norm.\nThe sparse-dual-frame based approach is not a simultaneous 1 minimization over dual frames D and the signal f . Instead, the sparse dual D S is theoretically optimal from the 0 point of view. Namely, theoretically, D S is given a priori for a given (class of) f , and D S is capable to minimize D ∗ f 0 among all dual frames D. As a re- sult, D S is different from the optimal dual D o as in (2.3), where 1 minimization is the sole concern in deriving D o .\nIt is true, of course, capable of minimizing the 0 measurement is one matter, having a mean to minimize D ∗ S f 0 is another, which is clearly combinatorial. Just as in all other sparse recovery problems, in the end, after a sparse dual D S is given, the 1 -min is the corre- sponding convex relaxation, which gives rise to the sparse-dual-based\nIt is also important to mention that having a sparse dual is not all free or easy. Nevertheless, a sparse dual to a class of signals exists. It is entirely possible to derive a sparse dual for a class of signals, and using such a sparse dual in related signal recovery. This is an active subsequent work we are pursuing.\nMeantime, we also outlined Algorithm 1, an alternating iterative algorithm as given in Section 2.4. At the k th iteration, an approxima- tion f k of f is found ﬁrst, which in turn allows for an approximation of a sparse dual D k . This is followed by ﬁnding the next approxima- tion f k+1 of f by the sparse-dual-based analysis problem (2.2) using D k . The process then iterates. As an initial effort of implementing the sparse dual analysis approach, it is seen as effective. We refer readers to Algorithm 1 and examples in Section 3.\nIndeed, a similar error bound does hold for sparse dual frame analysis operator D S . In fact, we have shown in [15] that sufﬁcient conditions exist by taking any dual frame of D as the analysis operator. Error bound is similarly derived.\nConsequently, the ﬁrst objective has been achieved. One of the main results is the following theorem. For more discussions, please refer to [15].\nTheorem 2.6. Let D = {x k } N k=1 be a frame for H n with frame bounds 0 < A ≤ B < ∞. Let D S be a sparse dual frame for the given f with frame bounds 0 < ˜ A ≤ ˜ B < ∞. Suppose\nholds for some positive integers a and b satisfying 0 < b − a ≤ 3a, and ρ = s/b. Then the solution f to (2.2) satisﬁes\nRemark. Note that condition (2.4) is about the D-RIP constant. For appropriately chosen a and b, (2.4) will give rise to a condition on, say δ 2s . We have shown in [15] that (2.4) provides an improvement over the D-RIP constant in [2] for the error bound (1.4) to hold.\nMore importantly, the key point in Theorem 2.6 is that a similar error bounds holds with any dual frame D (including the sparse dual D S , of course) as the analysis operator.\nThe remaining issue is certainly about the determination of the sparse dual frame D S . There are two observations to make. First of all, suppose f = Dx is known, and x is sparse. Then x can be determined by various algorithms. Sparse dual can then be explicitly determined as well by the dual frame theory [13]. For details, and for a new null space tuning algorithm we developed for the same purpose, we refer to [16].\nSecondly, in order to solve (2.2), an explicit form of the sparse dual is not necessary as we explain next. By the dual frame theory, see, e.g., [13],\nwhere W is the free parameter matrix. Deﬁne ν f := P(W ∗ f ), where P = I − D ∗ (DD ∗ ) −1 D is the orthogonal projection onto ker D. Then, the sparse-dual-based 1 -analysis problem (2.2) can be rewrit- ten as\nIf we simply set ν f = 0, (2.6) would fundamentally reduce to the original 1 -analysis problem (1.3) where the analysis operator is the canonical dual frame.\nThe point here, of course, is that ν f = 0 in order to have the sparse coefﬁcient D ∗ S f . The determination/adjustment of ν f is the most critical part.\nWe comment that by adjusting on the value of ν f , the determina- tion of the sparse dual frame need not be explicit while trying to solve the new 1 -analysis problem.\nWe now come to the point of introducing an alternating iterative algorithm for the solution of the sparse-dual-based 1 -analysis for- mulation for compressed sensing.\n2.4. Alternating iterative algorithm for sparse-dual-based 1 - analysis solutions\nIf f is known, there are a number of algorithms to determine the sparse coefﬁcients x, and thereby determine the optimal adjustment ν f (as well as sparse dual frames). We mentioned earlier that we also developed a fast Null Space Tuning algorithm as well for this purpose [16].\nIn practice, f is to be recovered. Introduced below is a practical alternating iterative algorithm that solves compressed sensing prob- lems (2.6) where signals are sparse with respect to redundant frames, which also has an analytical error bound (2.5).\nApplications in Pulse Doppler Radar and Sonar. By the under- lying mechanism of the Pulse Doppler Radar and Sonar applications, the receiving echo signal f is often sparse with respect the Gabor frames within allowable discrete approximations\nThe example we show has the parameter setting m = 32, n = 128 and N = 256. The number of targets is s = 12 and {α k } is i.i.d. Gaussian random variable with mean zero.\nAlgorithm 1: Alternating iteration: sparse-dual-based ap- proach\nInput: A, D, y, s, 1 , 2 ; Output: f , x ; f o := 0 ;\nx u := arg min x x 1 s.t. ADx − y 2 ≤ 1 ; f u := Dx u ;\nwhile f u − f o 2 > 2 do f o := f u ;\nx s := arg min x x 1 s.t. Dx = f o ; ν f := x s − D ∗ (DD ∗ ) −1 f o ; f u :=\narg min f D ∗ (DD ∗ ) −1 f + ν f 1 s.t. Af − y 2 ≤ 1 ; f := f u ;\nThe result of our new alternating iterative algorithm is demon- strated in Figure 2. The relative error of the recovered signal is\nFigure 2(b) (and part (b) of all ﬁgures that follows) is a scatter plot of the recovered coefﬁcients (vertical axis) vs. the exact coefﬁ- cients (horizontal axis). Consequently, if the recovered coefﬁcients are exact, the scatter circles should all be on the line of y = x.\nFigures 4 and 6 show the results by the standard 1 -analysis and the 1 -synthesis approaches, respectively. The relative errors of the\n1 -analysis and the 1 -synthesis methods are quite unfavorably large at 0.6760 and 0.3792, respectively.\n= 0.0083.\n[1] M. Elad, P. Milanfar, and R. Rubinstein, \u201cAnalysis versus syn- thesis in signal priors,\u201d Inv. Prob., vol. 23, pp. 947 \u2013 968, 2007.\n[2] E. J. Cand`es, Y. C. Eldar, D. Needell, and P. Randall, \u201cCom- pressed sensing with coherent and redundant dictionaries,\u201d Appl. Comput. Harmon. Anal. , vol. 31, pp. 59\u201373, 2011.\n[3] H. Rauhut, K. Schnass, and P. Vandergheynst, \u201cCompressed sensing and redundant dictionaries,\u201d IEEE Trans. Inf. Theory, vol. 54, pp. 2210\u20132219, 2008.\n[4] E. J. Cand`es, \u201cCompressive sampling,\u201d in International Congress of Mathematicians , Z¨urich, 2006, European Mathe- matical Society, vol. 3, pp. 1433\u20131452.\nFig. 3. The coefﬁcient recovery results by the sparse-dual-based ap- proach. Horizontal axis is the original coefﬁcients, and the vertical axis is the recovered coefﬁcients.\nFig. 5. The coefﬁcient recovery results by the standard 1 -analysis. Horizontal axis is the original coefﬁcients, and the vertical axis is the recovered coefﬁcients.\n[5] E. J. Cand`es, J. Romberg, and T. Tao, \u201cRobust uncertainty prin- ciples: exact signal reconstruction from highly incomplete fre- quency information,\u201d IEEE Trans. Inf. Theory, vol. 52, no. 2, pp. 489\u2013509, 2006.\n[6] S. Li, Y. Liu, and T. Mi, \u201cA sparse dual frame approach to com- pressed sensing with respect to general frames,\u201d in preparation, 2012.\n[7] S. S. Chen, D. L. Donoho, and M. A. Saunders, \u201cAtomic de- composition by basis pursuit,\u201d SIAM Rev., vol. 43, no. 1, pp. 129\u2013159, 2001.\nFig. 7. The coefﬁcient recovery results by the 1 -synthesis. Hor- izontal axis is the original coefﬁcients, and the vertical axis is the recovered coefﬁcients.\nin general (nonorthogonal) dictionaries via 1 minimization,\u201d Proc. Natl. Acad. Sci. USA , vol. 100, no. 5, pp. 2197\u20132202, 2003.\n[9] D. L. Donoho and X. Huo, \u201cUncertainty principles and ideal atomic decomposition,\u201d IEEE Trans. Inf. Theory, vol. 47, no. 7, pp. 2845\u20132862, 2001.\n[10] M. Elad and A. M. Bruckstein, \u201cA generalized uncertainty prin- ciple and sparse representation in pairs of bases,\u201d IEEE Trans. Inf. Theory , vol. 48, no. 9, pp. 2558\u20132567, 2002.\n[11] J-J. Fuchs, \u201cOn sparse representations in arbitrary redundant bases,\u201d IEEE Trans. Inf. Theory, vol. 50, no. 6, pp. 1341\u20131344, 2004.\n[12] R. Gribonval and M. Nielsen, \u201cSparse representations in unions of bases,\u201d IEEE Trans. Inf. Theory, vol. 49, no. 12, pp. 3320\u2013 3325, 2003.\n[13] S. Li, \u201cOn general frame decompositions,\u201d Numer. Funct. Anal. Optimizat. , vol. 16(9 & 10), pp. 1181\u20131191, 1995.\n[14] Y. Liu, S. Li, and T. Mi, \u201cPerformance analysis of 1 -synthesis with coherent frames,\u201d to appear in Proceedings, Intern. Symp. Info. Theory, MIT, July 1-6, 2012.\n[15] Y. Liu, T. Mi, and S. Li, \u201cCompressed sensing with general frames via optimal-dual-based 1 -analysis,\u201d to appear in IEEE Trans. Inf. Theory, http://arxiv.org/abs/1111.4345, 2012.\n[16] T. Mi, S. Li, and Y. Liu, \u201cFast thresholding algorithms with feedbacks for sparse signal recovery,\u201d Preprint submitted for publication, http://arxiv.org/abs/1204.3700, 2011."},"refs":[]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566991.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T9.2","endtime":"10:30","authors":"Tiebin Mi, Shidong Li, Yulong Liu","date":"1341483000000","papertitle":"The l1 Analysis Approach by Sparse Dual Frames for Sparse Signal Recovery Represented by Frames","starttime":"10:10","session":"S11.T9: L1-Regularized Least Squares and Frames","room":"Stratton West Lounge (201)","paperid":"1569566991"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
