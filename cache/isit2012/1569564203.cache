{"id":"1569564203","paper":{"title":{"text":"Layered Quantize-Forward For The Two-Way Relay Channel"},"authors":[{"name":"Hieu T. Do"},{"name":"Tobias J. Oechtering"},{"name":"Mikael Skoglund"}],"abstr":{"text":"Abstract\u2014This paper proposes two new coding schemes for the discrete memoryless two-way relay channel. The main target is to show the beneﬁts of compress-forward without Wyner-Ziv binning and of layered relaying in networks wherein a relay is to help multiple destinations, that may have unequal channel quality and/or have access to different side information. Numerical results for a Gaussian channel show that the new coding schemes outperform variants of compress-forward relaying and offer a good trade-off between achievable rates and complexity and decoding delay. The idea can also be applied to other relay networks."},"body":{"text":"Ever since the seminal paper on the classical 3-node re- lay channel by Cover and El Gamal [1], research on relay networks has presented numerous coding strategies. A consid- erable part of those strategies employ compress-forward (CF) techniques. The classical CF [1] approach uses Wyner-Ziv (W- Z) source coding to convey the compression index from the relay to the destination, thereby helping the recovery of the desired message. In [2] Avestimehr et al. proposed a quantize- map-forward (QMF) relaying scheme, which does not employ W-Z binning, and showed that QMF can achieve the capacity region of the Gaussian relay network within a constant gap. In parallel work, Lim et al. proposed the notion of noisy network coding (NNC) [3], which generalizes and uniﬁes network coding and CF without W-Z binning. NNC has been shown to outperform classical CF [1] and some of CF\u2019s extensions for certain channels [3]. NNC, however, incurs long decoding delay due to the necessity of joint decoding over multiple blocks. A different relaying scheme, which is based on CF without W-Z binning and with sliding window decoding, was recently proposed by Kramer and Hou [4] and Zhong and Vu [5]. It is worth to emphasize that all different types of CF-based relaying above give the same performance for the 3-node relay channel [3], [4]. The difference in performance appears only in more general relay networks [3]. In such multi- node relay networks, it is common that a relay is to help multiple receiving nodes which may have unequal channel quality. For such a scenario G¨und¨uz et al. [6] proposed a layered CF scheme for the two-way relay channel, in the absence of direct links, and Lim et al. extend their approach to a layered NNC protocol [7] (LNNC). In this paper we propose two layered schemes for the two-way relay channel. In contrast to [6], we use only quantize-and-forward (QF), i.e., no W-Z binning, and we also take into account the presence\nof direct links between the two users. Compared with [7], our contribution is to present QF-based protocols that do not suffer from the delay and complexity inherent in NNC decoding. We compare the performance of our new schemes with existing CF-based coding techniques. The two approaches are distinguished by their decoding protocols: one protocol uses (forward) sliding window decoding while the other uses block-by-block backward decoding. The latter scheme incurs longer decoding delay but potentially achieves higher rates.\nThe goals of this paper are twofold: First, as mentioned, we aim to develop relaying schemes which do not require joint decoding over multiple blocks, thereby reducing complexity and delay, while still achieving comparable performance as in the case of layered NNC and outperforming other CF-based schemes. Second, we emphasize the beneﬁts of not using W-Z binning, and of layering in relay networks wherein a relay has to serve different nodes. We illustrate our coding strategy for the two-way relay channel but the idea is applicable for other relay networks such as interference-relay networks [8].\nConsider the two-way relay channel (TWRC), which is modeled as a network of 3 nodes. Node 1 and node 2 wish to exchange their messages m 1 and m 2 with the help of node 3 (the relay). The channel is memoryless and time invariant in the sense that\nfor all i. Therefore we can focus on the conditional probability mass function (p.m.f.) p(y 1 , y 2 , y 3 |x 1 , x 2 , x 3 ). x k is drawn from a ﬁnite alphabet X k , k ∈ [1 : 3]. In order to improve the performance when channel quality at node 1 and 2 are asymmetric, the relay in this paper quantizes its observation into two layers and forwards the quantization indices by two layers of codewords, without binning. Unlike in NNC where the decoders decode over multiple blocks, the decoders in our scheme decode block by block, either forward or backward, thereby reducing decoding complexity and/or decoding delay. The main results of this paper are Theorems 1 and 2, corre- sponding to (forward) sliding window decoding and backward decoding, respectively.\nDeﬁne R F W 1 as the set of non-negative rate pairs (R 1 , R 2 ) satisfying\n− I( ˆ Y 3 ; Y 3 |X 1 , X 2 , V, X 3 , ˜ Y 3 , Y 2 , Q) \t (1) R 1 < I(X 1 , X 3 ; Y 2 |X 2 , Q)\n− I( ˜ Y 3 , ˆ Y 3 ; Y 3 |X 1 , X 2 , V, X 3 , Y 2 , Q) \t (2) R 1 < I(X 1 ; ˜ Y 3 , ˆ Y 3 , Y 2 |X 2 , V, X 3 , Q) \t (3) R 2 < I(X 2 , V ; Y 1 |X 1 , Q) − I( ˜ Y 3 ; X 3 , Y 3 |X 1 , X 2 , V, Y 1 , Q)\n(4) R 2 < I(X 2 ; ˜ Y 3 , Y 1 |V, X 1 , Q) \t (5)\nI( ˆ Y 3 , ˜ Y 3 ; Y 3 |V, X 3 , X 1 , X 2 , Y 2 , Q) < I(X 3 ; Y 2 |X 2 , Q) (6) I( ˆ Y 3 ; Y 3 |X 1 , X 2 , Y 2 , X 3 , V, ˜ Y 3 , Q) < I(X 3 ; Y 2 |X 2 , V, Q)\n(7) I( ˜ Y 3 ; Y 3 |X 1 , X 2 , V, Y 1 , Q) < I(V ; Y 1 |X 1 , Q). \t (8)\nand q is drawn from some ﬁnite alphabet Q. In the same way we deﬁne region R F W 2 by exchanging indices 1 ↔ 2 everywhere in the description of R F W 1 .\nTheorem 1: The convex hull of R F W 1 ∪ R F W 2 is an achiev- able rate region for the discrete memoryless TWRC.\nRemark 1: By setting ˆ Y 3 = ˜ Y 3 , X 3 = V , i.e., by utilizing only one layer, we recover the rates achieved by compress- forward without Wyner-Ziv binning and with joint decoding as shown in [5] for the same channel.\nOne can show that the overall achievable region does not depend on (7). For the sake of comparison we retain (7) in the presentation of R F W 1 .\nDeﬁne R BW 1 as the set of non-negative rate pairs (R 1 , R 2 ) satisfying\n− I( ˆ Y 3 ; Y 3 |X 1 , X 2 , V, X 3 , ˜ Y 3 , Y 2 , Q) \t (9) R 1 < I(X 1 , X 3 ; Y 2 |X 2 , Q)\n− I( ˜ Y 3 , ˆ Y 3 ; Y 3 |X 1 , X 2 , V, X 3 , Y 2 , Q) \t (10) R 1 < I(X 1 ; ˜ Y 3 , ˆ Y 3 , Y 2 |X 2 , V, X 3 , Q) \t (11) R 2 < I(X 2 , V ; Y 1 |X 1 , Q) − I( ˜ Y 3 ; X 3 , Y 3 |X 1 , X 2 , V, Y 1 , Q)\n(12) R 2 < I(X 2 ; ˜ Y 3 , Y 1 |V, X 1 , Q) \t (13)\n(14) I( ˆ Y 3 ; Y 3 |X 1 , X 2 , Y 2 , X 3 , V, ˜ Y 3 , Q) < I(X 3 ; Y 2 |X 2 , V, Q)\n(15) I( ˜ Y 3 ; Y 3 |X 1 , X 2 , V, Y 1 , Q) < I(V ; Y 1 |X 1 , X 2 , Q). \t (16)\nIn the same way we deﬁne region R BW 2 by exchanging indices 1 ↔ 2 everywhere in the description of R BW 1 .\nTheorem 2: The convex hull of R BW 1 ∪ R BW 2 is an achiev- able rate region for the TWRC.\nRemark 2: If we ignore (14)\u2013(16) then the description of the achievable region R BW 1 is identical to the rate region achieved by layered NNC [7]. This means that if the rate- maximizing joint distribution for the layered NNC satis- ﬁes (14)\u2013(16) then the layered quantize-forward with back- ward decoding achieves the same rate region as layered NNC. We refer to Section IV for numerical examples.\nFor a particular joint distribution we see that the right hand sides of (9), (14) and (16) are larger than or equal to those of (1), (6), and (8). Thus we can conclude that R F W 1 ⊆ R BW 1 , i.e., backward decoding potentially achieves higher rates than sliding window decoding. The trade-off is longer decoding delay, see also numerical results in Section IV.\nCodebook generation: Consider Q = const, for general Q we can use the coded time-sharing technique [9]. Fix the distribution p(x 1 )p(x 2 )p(v, x 3 )p(ˆ y 3 , ˜ y 3 |x 3 , y 3 , v), for each block j ∈ [1 : b + 1] an independent codebook is generated as follows. For t ∈ {1, 2}, randomly and independently generate 2 nR t sequences x tj (m t ), m t ∈ [1 : 2 nR t ], each according to n i =1 p X t (x tj,i (m t )). Randomly and independently gen- erate 2 n ˜ R sequences v j (k j −1 ), k j −1 ∈ [1 : 2 n ˜ R ], each according to n i =1 p V (v j,i ). For each k j −1 ∈ [1 : 2 n ˜ R ], randomly and conditionally independently generate 2 n ˆ R se- quences x 3j (l j −1 |k j −1 ), l j −1 ∈ [1 : 2 n ˆ R ], each according to n i =1 p X 3 |V (x 3j,i |v j,i (k j −1 )). For each k j −1 ∈ [1 : 2 n ˜ R ], randomly and conditionally independently generate 2 n ˜ R se- quences ˜ y 3j (k j |k j −1 ), k j ∈ [1 : 2 n ˜ R 3 ], each according to\np ˜ Y 3 |V (˜ y 3j,i |v j,i (k j −1 )). For each k j , l j −1 , k j −1 ∈ [1 : 2 n ˜ R ] × [1 : 2 n ˆ R ] × [1 : 2 n ˜ R ] randomly and conditionally independently generate 2 n ˆ R sequences ˆ y 3j (l j |k j , l j −1 , k j −1 ), l j ∈ [1 : 2 n ˆ R ], each according to n i =1 p ˆ Y 3 | ˜ Y 3 ,X 3 ,V Ξ where Ξ denotes (ˆ y 3j,i |˜ y 3j,i (k j |k j −1 ), x 3j,i (l j −1 |k j −1 ), v j,i (k j −1 )). The above generation deﬁnes the codebook for block j:\nEncoding: The encoding is performed in b + 1 blocks to send b messages. The rate loss is negligible for sufﬁciently large b. The message m 1 of 2 nbR 1 bits is split into b blocks m 1,1 , m 1,2 , . . . , m 1,b of 2 nR 1 bits each. In block j ∈ [1 : b+1] node 1 transmits x 1j (m 1,j ), where m 1,b+1 = 1. Similarly for the message m 2 at node 2. Upon receiving y 3j at the end of\nwhere (l 0 , t 0 ) = (1, 1) by convention. If there are more than one such index pair, select one of them uniformly at random. If there is no such index pair, select an arbitrary pair at random. The relay node transmits x 3,j+1 (l j |k j ) in block j + 1.\nDecoding: Let ǫ > ǫ \u2032 . The decoders at node 1 and 2 use sliding window decoding as follows. As usual for block Markov coding [1], assuming that node 1 has decoded k j −1 correctly in block j. At the end of block j + 1, node 1 looks for a unique index pair ( ˆ m 2,j , ˆ k j ) such that\nAssume that node 2 has decoded l j −1 , k j −1 correctly in block j. At the end of block j + 1, node 2 looks for a unique index triple ( ˆ m 1,j , ˆl j , ˆ k j ) such that\nx 1j ( ˆ m 1,j ), x 2j (m 2,j ), v j (k j −1 ), x 3j (l j −1 |k j −1 ), ˜ y 3j (ˆ k j |k j −1 ), ˆ y 3j (ˆl j |ˆ k j , l j −1 , k j −1 ), y 2j ∈ T (n) ǫ .\nThe encoding and decoding processes are depicted in Table I. Error analysis : Here we do error analysis for decoder 2.\nLet (M 1,j , M 2,j , M 1,j+1 , M 2,j+1 ) denote the message indices chosen by the transmitters and (K j −1 , L j −1 ) denote the in- dices chosen by the relay at the corresponding blocks. Due to the symmetry of codebook generation, sub-codebooks with respect to (l j −1 , k j −1 ) have the same distribution. Therefore, we can equivalently assume L j −1 = K j −1 = 1 and M 1,j = M 2,j = M 1,j+1 = M 2,j+1 = 1 for the analysis, cf. [9, Appendix 11A]. First note that the joint typicality check at the relay fails if the following event occurs:\nE 1j = ˆ Y 3j (l j |k j , 1, 1), ˜ Y 3j (k j |1), X 3j (1|1), V j (1), Y 3j / ∈ T (n) ǫ \u2032 for all (l j , k j ) ∈ [1 : 2 n ˆ R ] × [1 : 2 n ˜ R ] .\nUsing the same bounding techniques as done [9, Appendix 8A] and [7] we can show that P (E 1j ) → 0 as n → ∞ if\n˜ R > I( ˜ Y 3 ; X 3 , Y 3 |V ) \t (17) ˜ R + ˆ R > I( ˜ Y 3 ; X 3 , Y 3 |V ) + I( ˆ Y 3 ; Y 3 |X 3 , V, ˜ Y 3 ). (18)\nAgain, due to the symmetry of codebook generation we can assume that L j = K j = 1 are found by the relay. Let us deﬁne the following events:\nThe decoding at decoder 2 will be in error if at least one of the following events occur:\nOverall, the error probability at receiver 2 is bounded by: P (E(2)) ≤ P (E 1j ) + P (E 2j |E c 1j ) + P (E 3j |E c 1j ).\nBy the conditional typicality lemma [9], P (E 2j |E c 1j ) → 0 as n → ∞. In the remaining part we will bound P (E 3j |E c 1j ). Let A j := E 1,j+1 (l j , k j ) ∩ E 2,j (m 1,j , l j , k j ). By the union of events bound we have P (E 3j |E c 1j ) ≤ 5 i =1 P (e 3i ), where\nwhere (a) comes from the union of events bound, (b) due to the fact that the codebooks in different blocks are generated independently and channel is memoryless. For (m 1,j = 1, l j , k j = 1) we have X 3(j+1) (l j |k j ), V j +1 (k j ) ∼\np V,X 3 x 3(j+1),i (l j |k j ), v j +1,i (k j ) is independent of (X 2(j+1) (1), Y 2(j+1) ). Thus, by the joint typicality lemma [9]\nP (E 2,j (m 1,j , l j , k j )) ≤ 2 −n(I 2j −δ(ǫ)) , \t (26) where I 2j = I(X 1 ; V, X 3 , X 2 , Y 2 ) + I( ˜ Y 3 ; X 1 , X 2 , X 3 , Y 2 |V )\nPutting (25) and (26) into (24) and simplifying the mutual information terms we have P (e 31 ) → 0 as n → ∞ if\nR 1 + ˆ R + ˜ R < I(X 1 , X 3 ; Y 2 |X 2 ) + I( ˜ Y 3 ; X 1 , X 2 , X 3 , Y 2 |V ) + I( ˆ Y 3 ; X 1 , X 2 , Y 2 |V, X 3 , ˜ Y 3 ). \t (27)\nIn the same way one can show that P (e 3i ), i ∈ [2 : 5], and therefore P (E 3j |E c 1j ), vanish as n → ∞ if:\n+ I( ˆ Y 3 ; X 1 , X 2 , Y 2 |V, X 3 , ˜ Y 3 ) \t (28) R 1 < I(X 1 ; ˜ Y 3 , ˆ Y 3 , Y 2 |X 2 , V, X 3 ) \t (29)\n+ I( ˆ Y 3 ; X 1 , X 2 , Y 2 |V, X 3 , ˜ Y 3 ) \t (30) ˆ R < I(X 3 ; Y 2 |V, X 2 ) + I( ˆ Y 3 ; X 1 , X 2 , Y 2 |V, X 3 , ˜ Y 3 ).\n(31) The union of events bound guarantees that the error probability at decoder 2 vanishes as n → ∞ if (27)\u2013(31) are satisﬁed.\nSimilarly we can show that the error probability at decoder 1 vanishes as n → ∞ if\nR 2 + ˜ R < I(X 2 , V ; Y 1 |X 1 ) + I( ˜ Y 3 ; X 1 , X 2 , Y 1 |V ) (32) R 2 < I(X 2 ; ˜ Y 3 , Y 1 |V, X 1 ) \t (33)\nCollecting all constraints in (17), (18) and (27)\u2013(34), and eliminating ˜ R and ˆ R by the Fourier-Motzkin procedure we obtain the region as speciﬁed by (1)\u2013(8).\nCodebook generation: codebooks are generated by a similar procedure as in Section III-A except for an extra step to prepare for the backward decoding, as done in [10], as follows: For each codeword x 3 (l|k), (l, k) ∈ [1 : 2 n ˆ R ] × [1 : 2 n ˜ R ], gen- erate a sequence y 3 according to the conditional distribution\nand swap the labeling (l ∗ , k ∗ ) ↔ (1, 1) for ˆ y 3 (l ∗ |k ∗ , l, k) and ˜ y 3 (k ∗ |k) if such a (l ∗ , k ∗ ) can be found. Do nothing if no (l ∗ , k ∗ ) is found. As before, such (l ∗ , k ∗ ) exists with high probability for sufﬁciently large n if (17) and (18) are satisﬁed.\nEncoding: Similarly to Section III-A, the encoding at the relay succeeds for sufﬁciently large n if (17), (18) are satisﬁed.\nDecoding: Let ǫ > ǫ \u2032 . The destinations use backward decoding as follows. Assume that node 1 has decoded k j correctly in block j + 1. For block j, node 1 looks for a unique index pair ( ˆ m 2,j , ˆ k j −1 ) such that\nAssume that node 2 has decoded l j , k j correctly in block j + 1. For block j, node 2 looks for a unique index triple ( ˆ m 1,j , ˆl j −1 , ˆ k j −1 ) such that\nThe encoding and decoding processes are depicted in Table II. The key difference between backward decoding and sliding window decoding is that for backward decoding the joint typicality check at each decoder only involves codewords belonging to the same block. This leads to less restrictive conditions for the probability of error to vanish as compared with sliding window decoding, thereby leading to potentially higher rates. The error analysis follows similar procedures as in Section III-A. Details are omitted due to space constraint.\nThis section compares the sum rates achieved by our schemes with other CF schemes for the Gaussian TWRC:\nY 1 = g 21 X 2 + g 31 X 3 + Z 1 Y 2 = g 12 X 1 + g 32 X 3 + Z 2\nwhere Z i \u2019s are i.i.d. ∼ N (0, 1). X i has average power constraint P i , i ∈ {1, 2, 3}. To evaluate the sum rates achieved by layered quantize-forward in Theorem 1 and Theorem 2 we let Q = ∅, X i be i.i.d. ∼ N (0, P i ) for i = 1, 2, V ∼ N (0, αP 3 ) for α ∈ [0, 1] and X 3 = V + W where W ∼ N (0, (1 − α)P 3 ), independent of everything else. Let ˆ Y 3 = Y 3 + ˆ Z 3 and ˜ Y 3 = ˆ Y 3 + ˜ Z 3 where ˆ Z 3 ∼ N (0, ˆ σ 2 ) and ˜ Z 3 ∼ N (0, ˜ σ 2 ), independent of everything else. Furthermore, for the sake of comparison we choose to use the geometric model as used in [7], i.e., P 1 = P 2 = P 3 = 10 and channel gains are given by g 13 = g 31 = d −γ , g 23 = g 33 = (1 − d) −γ , where d ∈ [0, 1] is the location of the relay between nodes 1 and 2 and γ = 3 is the path loss exponent. In the plots we use CF, CFNB, NNC, LNNC to denote sum rates achieved\nby compress-forward [11], [12], compress-forward without Wyner-Ziv binning [5], noisy network coding [3], and layered noisy network coding [7], respectively. LQF-BW and LQF- BW denotes our schemes in Theorem 1 and 2, and LCF denotes the layered CF [6] for channel without direct links.\nFig. 1 shows achievable sum rates for the Gaussian TWRC with direct links. We see that LQF with sliding window decoding outperforms CF, CF without binning (which equals NNC), and meets layered NNC in certain regimes (with lower delay and decoding complexity). With the same decoding delay but less complexity, LQF with backward decoding meets the layered NNC in a large part of channel gains. We also notice the considerable gain due to layering in this case: the gap between our schemes and other non-layering schemes are most prominent when the channels from the relay to the receivers are asymmetric (when d is close to 0). It shows that layering can be very helpful, especially when the channel gains are considerably distinct. In that case a simple layering scheme outperforms even the noisy network coding without layering.\nFig. 2 shows numerical simulations for the Gaussian TWRC without direct links. For this channel we observe that both LQF with sliding window decoding and with backward decoding achieve the same sum rate as LNNC and outperform all other variants of compress/quantize-forward. Also note that the layered CF scheme proposed in [6] only performs equally to the classical CF scheme in this case.\nWe proposed two novel relay schemes, which are partic- ularly useful when a relay node serves multiple receiving nodes. The proposed schemes show promising gains compared to non-layering schemes while not suffering from the high complexity and decoding delay of the schemes based on noisy\nnetwork coding. The results in this paper also conﬁrm the advantage of not using Wyner-Ziv binning in networks that are more complex than the classical relay channel [1]. To further improve the performance one can combine our protocols with partial decode-forward or hybrid relaying [13], [14].\nThis work is funded in part by the Swedish Research Council and the Swedish Foundation for Strategic Research."},"refs":[{"authors":[{"name":"T. Cover"},{"name":"A. Gamal"}],"title":{"text":"Capacity theorems for the relay channel"}},{"authors":[{"name":"A. Avestimehr"},{"name":"S. Diggavi"},{"name":"D. Tse"}],"title":{"text":"Wireless network information ﬂow: A deterministic approach"}},{"authors":[{"name":"S. H. Lim"},{"name":"Y.-H. Kim"},{"name":"A. El Gamal"},{"name":"S.-Y. Chung"}],"title":{"text":"Noisy network coding"}},{"authors":[{"name":"G. Kramer"},{"name":"J. Hou"}],"title":{"text":"Short-message quantize-forward network cod- ing"}},{"authors":[{"name":"P. Zhong"},{"name":"M. Vu"}],"title":{"text":"Compress-forward without Wyner-Ziv binning for the one-way and two-way relay channels"}},{"authors":[{"name":"D. G ¨und¨uz"},{"name":"E. Tuncel"},{"name":"J. Nayak"}],"title":{"text":"Rate regions for the separated two-way relay channel"}},{"authors":[{"name":"S. H. Lim"},{"name":"Y.-H. Kim"},{"name":"A. El Gamal"},{"name":"S.-Y. Chung"}],"title":{"text":"Layered noisy network coding"}},{"authors":[{"name":"O. Sahin"},{"name":"E. Erkip"}],"title":{"text":"Achievable rates for the Gaussian interference relay channel"}},{"authors":[{"name":"A. El Gama"},{"name":"Y.-H. Ki"}],"title":{"text":"Network Information Theory"}},{"authors":[{"name":"H.-F. Chong"},{"name":"M. Motani"},{"name":"H. K. Garg"}],"title":{"text":"Generalized backward decoding strategies for the relay channel"}},{"authors":[{"name":"B. Rankov"},{"name":"A. Wittneben"}],"title":{"text":"Achievable rate regions for the two-way relay channel"}},{"authors":[{"name":"C. Schnurr"},{"name":"T. Oechtering"},{"name":"S. Stanczak"}],"title":{"text":"Achievable rates for the restricted half-duplex two-way relay channel"}},{"authors":[{"name":"M. Khormuji"},{"name":"M. Skoglund"}],"title":{"text":"Noisy analog network coding for the two-way relay channel"}},{"authors":[{"name":"Y.-H. Kim"},{"name":"S. H. Lim"},{"name":"P. Minero"}],"title":{"text":"Relaying via hybrid coding"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564203.pdf"},"links":[{"id":"1569566381","weight":23},{"id":"1569566485","weight":23},{"id":"1569565383","weight":2},{"id":"1569564889","weight":2},{"id":"1569565223","weight":2},{"id":"1569566725","weight":2},{"id":"1569565377","weight":2},{"id":"1569566385","weight":11},{"id":"1569565867","weight":2},{"id":"1569565067","weight":2},{"id":"1569565691","weight":5},{"id":"1569566875","weight":2},{"id":"1569566605","weight":2},{"id":"1569566597","weight":2},{"id":"1569566571","weight":2},{"id":"1569564481","weight":2},{"id":"1569566415","weight":2},{"id":"1569566081","weight":5},{"id":"1569565931","weight":2},{"id":"1569564245","weight":2},{"id":"1569564227","weight":2},{"id":"1569565837","weight":2},{"id":"1569566119","weight":2},{"id":"1569563411","weight":2},{"id":"1569566319","weight":5},{"id":"1569566941","weight":17},{"id":"1569558459","weight":2},{"id":"1569565291","weight":8},{"id":"1569556713","weight":2},{"id":"1569566843","weight":5},{"id":"1569558483","weight":2},{"id":"1569566173","weight":5},{"id":"1569565347","weight":2},{"id":"1569565455","weight":20},{"id":"1569566709","weight":11},{"id":"1569565897","weight":2},{"id":"1569551763","weight":14},{"id":"1569565953","weight":20},{"id":"1569564189","weight":8},{"id":"1569566865","weight":5},{"id":"1569565907","weight":2},{"id":"1569564311","weight":2},{"id":"1569566617","weight":2},{"id":"1569566733","weight":2},{"id":"1569566063","weight":5},{"id":"1569558681","weight":2},{"id":"1569555999","weight":2},{"id":"1569559995","weight":2},{"id":"1569566643","weight":5},{"id":"1569566511","weight":11},{"id":"1569565841","weight":5},{"id":"1569566531","weight":5},{"id":"1569565833","weight":20},{"id":"1569564611","weight":5},{"id":"1569566325","weight":2},{"id":"1569566423","weight":2},{"id":"1569566811","weight":8},{"id":"1569553909","weight":2},{"id":"1569559111","weight":2},{"id":"1569553537","weight":2},{"id":"1569566403","weight":2},{"id":"1569553519","weight":5},{"id":"1569566231","weight":11},{"id":"1569554971","weight":2},{"id":"1569566649","weight":5},{"id":"1569565655","weight":5},{"id":"1569566473","weight":5},{"id":"1569564333","weight":8},{"id":"1569566629","weight":5},{"id":"1569565033","weight":17},{"id":"1569566447","weight":2},{"id":"1569565929","weight":2},{"id":"1569565633","weight":2},{"id":"1569555879","weight":23},{"id":"1569565219","weight":2},{"id":"1569558509","weight":2},{"id":"1569566223","weight":2},{"id":"1569566553","weight":14},{"id":"1569565469","weight":5},{"id":"1569564969","weight":20},{"id":"1569566043","weight":11},{"id":"1569565029","weight":5},{"id":"1569566505","weight":2},{"id":"1569562207","weight":8},{"id":"1569566191","weight":2},{"id":"1569565527","weight":2},{"id":"1569567029","weight":2},{"id":"1569565363","weight":2},{"id":"1569566695","weight":5},{"id":"1569566051","weight":2},{"id":"1569555787","weight":2},{"id":"1569566673","weight":2},{"id":"1569565441","weight":5},{"id":"1569566233","weight":2},{"id":"1569566667","weight":8},{"id":"1569566407","weight":5},{"id":"1569560349","weight":5},{"id":"1569566501","weight":23},{"id":"1569565741","weight":2},{"id":"1569566481","weight":5},{"id":"1569566387","weight":5},{"id":"1569560503","weight":2},{"id":"1569565439","weight":2},{"id":"1569563395","weight":8},{"id":"1569555367","weight":2},{"id":"1569566929","weight":5},{"id":"1569565611","weight":2},{"id":"1569566983","weight":2},{"id":"1569566097","weight":2},{"id":"1569566479","weight":2},{"id":"1569565397","weight":2},{"id":"1569566129","weight":11},{"id":"1569565181","weight":5},{"id":"1569566711","weight":2},{"id":"1569565661","weight":2},{"id":"1569564131","weight":5},{"id":"1569561221","weight":2},{"id":"1569566035","weight":5},{"id":"1569566691","weight":8},{"id":"1569566547","weight":5},{"id":"1569566823","weight":17},{"id":"1569566137","weight":17},{"id":"1569565375","weight":11},{"id":"1569566713","weight":2},{"id":"1569565293","weight":2},{"id":"1569566641","weight":14},{"id":"1569564437","weight":2},{"id":"1569566487","weight":2},{"id":"1569556759","weight":8},{"id":"1569566619","weight":5},{"id":"1569561185","weight":2},{"id":"1569566301","weight":2},{"id":"1569565669","weight":5},{"id":"1569565233","weight":5},{"id":"1569560235","weight":2},{"id":"1569566817","weight":5},{"id":"1569564157","weight":2},{"id":"1569566389","weight":2},{"id":"1569567483","weight":2},{"id":"1569566911","weight":14},{"id":"1569566299","weight":20},{"id":"1569564769","weight":5},{"id":"1569565769","weight":2},{"id":"1569566933","weight":2},{"id":"1569563919","weight":2},{"id":"1569557851","weight":11},{"id":"1569565537","weight":11},{"id":"1569565561","weight":2},{"id":"1569560459","weight":2},{"id":"1569550425","weight":5},{"id":"1569561397","weight":2},{"id":"1569564257","weight":5},{"id":"1569564931","weight":2},{"id":"1569566973","weight":2},{"id":"1569566987","weight":2},{"id":"1569565031","weight":2},{"id":"1569551751","weight":8},{"id":"1569564419","weight":14},{"id":"1569566609","weight":2},{"id":"1569565315","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S3.T3.5","endtime":"16:20","authors":"Hieu T. Do, Tobias J. Oechtering, Mikael Skoglund","date":"1341244800000","papertitle":"Layered Quantize-Forward For The Two-Way Relay Channel","starttime":"16:00","session":"S3.T3: *-and-Forward Relaying","room":"Stratton S. de P. Rico (202)","paperid":"1569564203"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
