{"id":"1569561185","paper":{"title":{"text":"On the Vector Gaussian L -Terminal CEO Problem"},"authors":[{"name":"Jia Wang"},{"name":"Jun Chen"}],"abstr":{"text":"Abstract\u2014We derive an outer bound of the rate region of the vector Gaussian L-terminal CEO problem by establishing a lower bound on each supporting hyperplane of the rate region. To this end we prove a new extremal inequality by exploiting the connection between differential entropy and Fisher information as well as some fundamental estimation-theoretic inequalities. It is shown that the outer bound matches the Berger-Tung inner bound in the high-resolution regime."},"body":{"text":"The CEO problem, also known as the indirect multiterminal source coding problem, was introduced by Berger, Zhang, and Viswanathan in [1]. A series of papers were devoted to the scalar Gaussian version of the problem [2]\u2013[4], culminating in a complete characterization of the rate region by Oohama [5] and Prabhakaran et al. [6] (see also [7] for the solution to a generalized version of this problem). However, the proof technique in [5], [6] is not completely suitable for the vector Gaussian case due to its heavy reliance on the entropy power inequality. The reason is that the proportionality condition (on the relevant covariance matrices) for the tightness of the entropy power inequality is not necessarily satisﬁed in the vector source setting, though this technical issue can some- times be resolved by invoking the entropy power inequality in conjunction with an enhancement argument [8] (see, e.g., [9] for bounding the sum rate of the vector Gaussian CEO problem via this approach).\nA new approach to the Gaussian CEO problem was pro- posed in [10], which is directly applicable to the vector case due to its estimation-theoretic nature. However, this approach is only effective for bounding the sum rate part of the rate region. In order to treat a general supporting hyperplane of the rate region, one has to resolve the tension among various information-theoretic quantities, which calls for a certain extremal inequality. It turns out that in the two-terminal case [11], [12] the desired extremal inequality is essentially a strengthened version of the Liu-Viswanath inequality [13]. Unfortunately, to handle the general L-terminal case, one has to deal with a certain long Markov chain structure and the extremal inequality needed for that purpose is signiﬁcantly different from the Liu-Viswanath inequality and its variants (see, e.g., [14], [15]). Among other contributions of this paper, we prove such an extremal inequality for the general vector Gaussian L-terminal CEO problem, which yields an outer bound of the rate region.\nThe remainder of this paper is organized as follows. A formal deﬁnition of the rate region of the vector Gaussian L-terminal CEO problem is given in Section II. In Section III we derive an outer bound of the rate region of the vector Gaussian CEO problem by establishing a lower bound on each supporting hyperplane of the rate region; furthermore, it is shown that the outer bound coincides with the Berger-Tung inner bound in the high-resolution regime. A new extremal inequality, which is the main technical ingredient in the deriva- tion of the outer bound for the vector Gaussian CEO problem, is given in Section V; the proof of this extremal inequality relies on the connection between differential entropy and Fisher information as well as some fundamental estimation- theoretic inequalities. Section VI concludes the paper.\nThroughout this paper, for any random object W and m ×n random matrix X we deﬁne Σ X = 1 n E [XX T ] and Σ X|W = Σ X−E[X|W ] ; we assume the logarithm function is to base e and deﬁne log + x = max(log x, 0).\nLet X 0 , N 1 , · · · , N L be mutually independent m ×1 Gaus- sian random vectors with mean zero and positive deﬁnite covariance matrices Σ X 0 , Σ N 1 , · · · , Σ N L , respectively. Let X i = X 0 + N i , i = 1, · · · , L. We refer to X 0 as the remote source and X i as the noisy observation at Encoder i, i = 1, · · · , L.\nLet {(X 0 (t), N 1 (t), · · · , N L (t), X 1 (t), · · · , X L (t))} ∞ t =1 be i.i.d. copies of (X 0 , N 1 , · · · , N L , X 1 , · · · , X L ). The rate region of the vector Gaussian L-terminal CEO problem is deﬁned as follows.\nDeﬁnition 1: A rate vector (R 1 , · · · , R L ) is said to be achievable subject to distortion constraint D if for all sufﬁ- ciently large n, there exist encoding functions f (n) i : R m ×n → {1, · · · , K i }, i = 1, · · · , L, and decoding function g (n) :\n{1, · · · , K i } → R m ×n such that 1\nwhere W i = f (n) i (X n i ), i = 1, · · · , L, and ˆ X n 0 = g (n) (W 1 , · · · , W L ). The rate region R(D) is the closure of the set of all achievable rate vectors subject to distortion constraint D.\nRemark: Clearly, there is no loss of optimality in assuming g (n) (W 1 , · · · , W L ) = E[X n 0 |W 1 , · · · , W L ]. Therefore, R(D) is not affected if we replace (1) with Σ X n 0 |W 1 , ··· ,W L D.\nSince R(D) is a (closed) convex set, it sufﬁces to charac- terize its supporting hyperplanes, i.e., to solve the following optimization problem\nwhere α = (α 1 , · · · , α L ) with α i ≥ 0, i = 1, · · · , L. Note that one can obtain an outer bound (inner bound) on R(D) by lower-bounding (upper-bounding) R (D, α).\nClearly, there is no loss of generality in assuming D Σ N . Furthermore, in view of the fact that Σ N ≺ Σ X n 0 |W 1 , ··· ,W L\nwhere S(D) = {D : Σ N ≺ D Σ X 0 , D D } and cl(·) is the closure operator. As a consequence, we have\nTherefore, it sufﬁces to focus on R(D) and R(D, α) with Σ N ≺ D Σ X\n; moreover, it is clear that there is no loss of generality in considering α with α 1 ≥ · · · ≥ α L ≥ 0.\nThe following theorem, which is a generalization of [12, Theorem 2] from the two-terminal case to the L-terminal case, provides a lower bound on R (D, α). The proof of this result relies on the extremal inequality (i.e., Theorem 5) in Section V.\n, i = 1, · · · , L, where\nOne can readily obtain the following upper bound on R (D, α) by evaluating the standard Berger-Tung inner bound [16], [17]. This result is a straightforward generalization of [12, Theorem 3] from the two-terminal case to the L-terminal case. The proof is omitted.\nIt is easy to show that R (D, α) = R(D, α) in the scalar case (i.e., m = 1), which recovers the well-known result in [5], [6]. The following result provides a simple and explicit matching condition for the vector case.\nProof: It is clear that R (D, α) = R(D, α) if there exists an optimal solution ( ˆ D 1 , · · · , ˆ D L ) to the minimization problem associated with R (D, α) such that\nLet (D ∗ 1 , · · · , D ∗ L ) be an optimal solution to the minimization problem associated with R (D, α). Deﬁne\nand ˆ D i = D ∗ i , i = 2, · · · , L. Note that (2) is satisﬁed by this constructed ( ˆ D 1 , · · · , ˆ D L ). Moreover, we have D ∗ 1 ˆ D 1 and\n, \t (3) where (3) is due to D (Σ −1 N − Σ −1 N 1 ) −1 . One can readily see that ( ˆ D 1 , · · · , ˆ D L ) must also be an optimal solution to the minimization problem associated with R (D, α). This completes the proof.\nRemark: Theorem 3 implies that R(D) can be completely characterized if D satisﬁes the following high-resolution con- dition\nA stronger matching condition can be found for the special case α = 1 (1, · · · , 1), which corresponds to the sum rate.\nProof: It is clear that R (D, 1) is associated with the following convex semideﬁnite programming problem\n0 D i Σ N i , i = 1, · · · , L. The Lagrangian of (P) is given by\nwhere Λ, Π 1 , · · · , Π L are positive semideﬁnite matrices. Note that ( ˆ D 1 , · · · , ˆ D L ) is an optimal solution to (P) if the following KKT conditions are satisﬁed\n, i = 1, · · · , L. Now we choose\nΠ i = 0, i = 1, · · · , L, ˆ D i = 1\nIt can be veriﬁed that with such a choice the KKT conditions are indeed satisﬁed. In particular, we have\nwhere (4) is due to Σ −1 N − LΣ −1 N i \t D −1 , i = 1, · · · , L. Note that (5) implies R (D, 1) = R(D, 1), which completes the proof.\nLet X 0 , X 2 , · · · , X L , N 2 , · · · , N L be deﬁned as in Section II. For the purpose of subsequent analysis, we deﬁne\nY = E[X 0 |X 2 , · · · , X L ], ˜ N = X 0 − Y,\nNote that ˜ N is independent of (X 2 , · · · , X L ), and ˜ N i is independent of X i , i = 2, · · · , L. Moreover, it can be veriﬁed that\nLet U 2 , · · · , U L , V be random objects jointly distributed with (X 0 , X 2 , · · · , X L ) such that the joint distribution factors as\nLet µ i = (α i −α i +1 )θ i +1 , i = 1, · · · , L−1, and µ L = µ L −1 + α L , where α 1 ≥ · · · α L > 0 and θ i ∈ [0, 1], i = 2, · · · , L.\nThe main result of this section is the following extremal inequality.\nTheorem 5: If Σ X i |X 0 ,U i ,V D i for some positive deﬁnite matrix D i , i = 2, · · · , L, and there exist matrices ˆ D i and O i with 0 ≺ ˆ D i D i and O i 0, i = 2, · · · , L, such that\n2 log |2πe ˆ D i | + µ L −1 2 log |2πe ˆ D X L |U L | − µ L 2 log |2πe ˆ D L |,\ni = 2, · · · , L − 1, ˆ D X\nThe proof is based on a monotone path argument [13], [18]. Deﬁne\nNow we shall introduce some auxiliary random ob- jects. Let X 2 , · · · , X L , ˜ X L , N 2 , · · · , N L −2 , ˜ Y 2 , · · · , ˜ Y L −1\nbe zero-mean Gaussian random vectors, independent of (X 0 , X 2 , · · · , X L , U 2 , · · · , U L , V ), with\nWe assume X 2 , · · · , X L , N 2 , · · · , N L −2 are mutually inde- pendent. Deﬁne\n, i = 2, · · · , L − 1. Note that\n+ √ 1 − λX i , i = 2, · · · , L, ˜ X L,λ = √ λX L + √ 1 − λ ˜ X L ,\n, i = 2, · · · , L − 1, ˜ Y i,λ = √ λY + √ 1 − λ ˜ Y i , i = 2, · · · , L − 1.\n2 log |2πe ˆ D i | + µ L −1 2 log |2πe ˆ D X L |U L | − µ L 2 log |2πe ˆ D L |,\ndλ ≥ 0 \t (9) for λ ∈ (0, 1). It can be shown by leveraging the de Bruijn\u2019s Identity [19] that\n+ µ L −1 2λ m − tr ˆ D X L |U L J ( ˜ X L,λ |U L , V ) − µ L 2λ m − tr ˆ D L J (X L,λ |X 0 , U L , V )\nfor λ ∈ (0, 1). As a consequence, for the purpose of proving (9), it sufﬁces to establish the following two lemmas.\nThe proofs of these two lemmas are omitted due to space constraints.\nA new extremal inequality is established and is leveraged to derive an outer bound of the rate region of the vector Gaussian CEO problem. Furthermore, it is shown that this outer bound coincides with the Berger-Tung inner bound in the high-resolution regime.\nIt is now well understood that indirect Gaussian multiter- minal source coding is intimately connected with its direct coding counterpart [10], [20]\u2013[22]. In fact, the direct vector Gaussian multiterminal source coding problem can be viewed as a limiting version of the vector Gaussian CEO problem. By exploiting this connection, one can readily translate the results in the present work to the direct Gaussian multiterminal source coding setting [23].\nThe work of Jia Wang was supported in part by the NSFC under Grant 60802020 and in part by the 973 Program (2010CB731401, 2010CB731406). The work of Jun Chen was supported in part by an Early Research Award from the Province of Ontario and in part by the Natural Science and Engineering Research Council (NSERC) of Canada under a Discovery Grant."},"refs":[{"authors":[{"name":"T. Berger"},{"name":"Z. Zhang"},{"name":"H. Viswanathan"}],"title":{"text":"The CEO problem"}},{"authors":[{"name":"H. Viswanathan"},{"name":"T. Berger"}],"title":{"text":"The quadratic Gaussian CEO problem"}},{"authors":[{"name":"Y. Oohama"}],"title":{"text":"The rate-distortion function for the quadratic Gaussian CEO problem"}},{"authors":[{"name":"J. Chen"},{"name":"X. Zhang"},{"name":"T. Berger"},{"name":"S. B. Wicker"}],"title":{"text":"An upper bound on the sum-rate distortion function and its corresponding rate allocation schemes for the CEO problem"}},{"authors":[{"name":"Y. Oohama"}],"title":{"text":"Rate-distortion theory for Gaussian multiterminal source coding systems with several side informations at the decoder"}},{"authors":[{"name":"V. Prabhakaran"},{"name":"D. Tse"},{"name":"K. Ramchandran"}],"title":{"text":"Rate region of the quadratic Gaussian CEO problem"}},{"authors":[{"name":"S. Tavilda"},{"name":"P. Viswanat"},{"name":"A. B. Wagne"}],"title":{"text":"The Gaussian many-help- one distributed source coding problem,\u201d IEEE Trans"}},{"authors":[{"name":"H. Weingarten"},{"name":"Y. Steinberg"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"The capacity region of the Gaussian multiple-input multiple-output broadcast channel"}},{"authors":[{"name":"S. Tavildar"},{"name":"P. Viswanath"}],"title":{"text":"On the sum-rate of the vector Gaussian CEO problem"}},{"authors":[{"name":"J. Wang"},{"name":"J. Chen"},{"name":"X. Wu"}],"title":{"text":"On the sum rate of Gaussian multiter- minal source coding: New proofs and results"}},{"authors":[{"name":"J. Chen"},{"name":"J. Wang"}],"title":{"text":"On the vector Gaussian CEO problem"}},{"authors":[{"name":"J. Wang"},{"name":"J. Chen"}],"title":{"text":"Vector Gaussian two-terminal source coding"}},{"authors":[{"name":"T. Liu"},{"name":"P. Viswanath"}],"title":{"text":"An extremal inequality motivated by multi- terminal information-theoretic problems"}},{"authors":[{"name":"H. Weingarten"},{"name":"T. Liu"},{"name":"S. Shamai (Shitz)"},{"name":"Y. Steinberg"},{"name":"P. Viswanath"}],"title":{"text":"The capacity region of the degraded multiple-input multiple-output compound broadcast channel"}},{"authors":[{"name":"R. Liu"},{"name":"T. Liu"},{"name":"H. V. Poor"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"A vector generaliza- tion of Costa\u2019s entropy-power inequality with applications"}},{"authors":[{"name":"T. Berger"}],"title":{"text":"Multiterminal source coding"}},{"authors":[{"name":"S.-Y. Tung"}],"title":{"text":"Multiterminal Source Coding"}},{"authors":[{"name":"A. Dembo"},{"name":"T. M. Cover"},{"name":"J. A. Thomas"}],"title":{"text":"Information theoretic inequalities"}},{"authors":[{"name":"D. Guo"},{"name":"S. Shamai (Shitz)"},{"name":"S. Verdu"}],"title":{"text":"Mutual information and minimum mean-square error in Gaussian channels"}},{"authors":[{"name":"A. B. Wagner"},{"name":"S. Tavildar"},{"name":"P. Viswanath"}],"title":{"text":"Rate region of the quadratic Gaussian two-encoder source-coding problem"}},{"authors":[{"name":"Y. Oohama"}],"title":{"text":"Distributed source coding of correlated Gaussian sources."}},{"authors":[{"name":"Y. Yang"},{"name":"Y. Zhang"},{"name":"Z. Xiong"}],"title":{"text":"A new sufﬁcient condition for sum-rate tightness in quadratic Gaussian multiterminal source coding."}},{"authors":[{"name":"J. Wang"},{"name":"J. Chen"}],"title":{"text":"Vector Gaussian multiterminal source coding"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569561185.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S4.T1.3","endtime":"17:40","authors":"Jia Wang, Jun Chen","date":"1341249600000","papertitle":"On the Vector Gaussian L-Terminal CEO Problem","starttime":"17:20","session":"S4.T1: The Slepian-Wolf and CEO Problems","room":"Kresge Rehearsal B (030)","paperid":"1569561185"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
