{"id":"1569565501","paper":{"title":{"text":"An Upper Bound on Relaying over Capacity"},"authors":[{"name":"Feng Xue"}],"abstr":{"text":"Abstract\u2014The upper bound on the capacity of a 3-node discrete memoryless relay channel is considered, where a source X wants to send information to destination Y with the help of a relay Z. Y and Z are independent given X, and the channel is statistically degraded in the sense that XY Z or XZY can be re-described statistically as a Markov chain. The link from Z to Y is lossless with rate R 0 . A new method is introduced to bound the capacity when the encoding rate is beyond both individual links XY and XZ. It generalizes the well-known blowing-up lemma and links it with conditional entropy. The new bound is explicitly computable and strictly better than the well-known cut-set bound when the latter is C XY + R 0 . The binary erasure channel is analyzed in detail as an example, and generalization to more cases is also discussed."},"body":{"text":"The relay channel model was ﬁrst formulated by Van-der Meulen [1] in 1971, consisting a source X, a relay Z, and a destination Y . The relay transmits a signal X 1 based on its observation to help Y . As a basic building block of the general wireless networks, it has since then attracted much research interests; see e.g. [2] and references therein.\nA set of achievability results were introduced in Cover and El Gamal [3]. Decode-forward and compress-forward are two basic achievability methods. Several capacity results were also established for cases such as degraded, reverse degraded [3], and semi-deterministic channels [5]. They are all based on the well-known cut-set bound; see e.g. Chapter 14 of [4].\nIn general, however, it is hard to establish capacity. The cut-set bound is the typical tool, but it seems not tight in many cases. Some progress of improving the cut-set bound was made by Zhang in 1988 [12] for the channel depicted in Figure 1. When the link from the relay to the destination is lossless with ﬁxed rate R 0 , it is shown that the cut-set bound cannot be tight when Y and Z are conditionally independent given X and X-Z-Y can be re-described as a Markov chain. However, the paper does not provide a new bound. In [7], a class of modulo additive noise relay channels is considered, in which the relay observes a corrupted version of the noise. The capacity is established and is strictly lower than the cut- set bound. On the other hand, the cut-set bound is shown to be tight when the relay output Z is a deterministic function of X and Y [6].\nIn this paper, we consider a discrete memoryless channel depicted in Figure 1 as introduced in [12], characterized by the conditional distribution p(y, z|x). Y and Z are assumed to be independent given X, and the channel is statistically degraded in the sense that XY Z or XZY can be re-described statistically as a Markov chain. The link from the relay Z\nto the destination Y is lossless with rate R 0 . That is, in a transmission over n slots, an index from {1, 2, · · · , 2 nR 0 }, called \u201ccolor\u201d in the paper, can be sent to Y without error. Note the cut-set bound is max p(x) min{I(X; Y )+R 0 , I(X; Y, Z)}.\nWe introduce a new method to improve the cut-set bound for when the encoding rate is beyond the capacities of both the XZ and XY links. Note that in this regime, decode-forward obviously does not work.\nWe explain the main idea as follows by focusing on the case when Y and Z are i.i.d. given X. Suppose otherwise that the rate I(X; Y ) + R 0 is achievable, then the relay Z must fully utilize the wired link to Y . It turns out that the sender X is almost sure about the color the relay will send to Y , even though it is at the \u201cother side\u201d of a channel. Mathematically it is that, given X n , the conditional entropy of the message from Z to Y is diminishing. Since Y n has the same distribution as Z n given X n , Y can guess the color correctly with high conﬁdence. This means there is no need of the relay, leading to a contradiction. In general, the sender X must have certain control on the color of Z\u2019s observation, being represented by the conditional entropy of the color given the transmitted code word. Denote S(Z n ) as the set of z n \u2019s with the same color of the received signal Z n at the relay. By generalizing the well-known blowing-up lemma [8], one can show that Y n will be within a certain Hamming distance d ∗ of S(Z n ) with non-diminishing probability. Thus the node Y can randomly pick a point and ﬁnd its color in the ball of radius d ∗ around Y n . Then for this color and Y n , it applies the well-known decoding function to decode the code word, as if it was the message from the relay. Overall, this procedure leads to certain computable decoding probability. On the other hand, note that the procedure is based on Y n only. There has been well-known upper bound on the decoding probability for rate exceeding the channel capacity [9]. Thus the decoding probability obtained by our procedure must be smaller, leading to the desired bound.\nThe above idea can be readily generalized to the cases when XY Z or XZY is statistically degraded.\nBased on this new method, we show an explicitly com- putable bound which is strictly lower than max p(x) I(X; Y ) + R 0 . This directly improves the result in [12]. As an illustration, we take the binary erasure channel for detailed derivation. We also discuss how the method could be applied to cases when the relay-destination link is no longer lossless.\nThe rest of the paper is organized as follows. Section II introduces the basic deﬁnitions, notations and a well-known bound on decoding probability. Section III generalizes the blowing up lemma and links to conditional entropy. Section IV applies it to show an explicit bound for the case when Y\nand Z are i.i.d. given X. Section V subsequently generalizes to the case when the channel is statistically degraded. The binary erasure channel is analyzed in detail. Finally, Section VI suggests a way generalizing to cases when the relay- destination link is lossy.\nThe memoryless relay channel we consider consists of three nodes, sender X, relay Z and destination Y , deﬁned by the conditional distribution p(y, z|x). Given X, Y and Z are independent, i.e., p(y, z|x) = p(y|x)p(z|x). The values of X, Y and Z are from ﬁnite spaces Ω X , Ω Y and Ω Z respectively. Correspondingly, for a transmission of length n, the code word x n is chosen from Ω n X , deﬁned as the product space of Ω X , and the received observations are y n ∈ Ω n Y and z n ∈ Ω n Z respectively. The link from Z to Y is a lossless link with rate R 0 . Namely, for a transmission of length n, a number from {1, 2, · · · , 2 nR 0 } can be send to Y without error.\nA coding strategy of rate R for n channel uses is deﬁned by a 3-tuple (C n , g n (z n ), f n ( ˆ z n , y n )). Set C n := {x n (m), m = 1, · · · , 2 nR } is the code book at the source X. It chooses one codeword uniformly from the set and transmits to the channel. Function g n (z n ) is the encoding function at the relay Z, which is a function mapping an observation z n to a \u201ccolor\u201d j in {1, 2, · · · , 2 nR 0 }. In this paper, we also use ˆ z n to denote this function, and call the set {1, 2, · · · , 2 nR 0 } the color set. Function f n ( ˆ z n , y n ) is the decoding function at the destination Y , mapping the color from the relay and the observation y n to a code word in C n . All C n , g n (·) and f n (·) are well-known at all nodes.\nDeﬁnition 1. Rate R is achievable if there exists a sequence of coding strategies of rate R, {(C n , g n (z n ), f n ( ˆ z n , y n )), n = 1, 2, · · · }, such that the successful decoding probabil- ity approaches one as n goes to inﬁnity. That is, lim n P r(f n ( ˆ Z n , Y n ) = X n ) = 1.\n\u2022 C XY and C XZ are the channel capacities from the channels X-Y and X-Z, respectively.\n\u2022 d H (x n 1 , x n 2 ) denotes the Hamming distance of two points. log is with base 2. Also, we reserve the use of the hat\nsymbol ˆ ω on top of a random variable solely for the coloring.\nWe now quote the following known result on decoding probability [9].\nTheorem 1. Suppose that a discrete memoryless channel with an input alphabet of K letters {a 1 , · · · , a K } and an output alphabet of J letters {b 1 , · · · , b J } is described by transition probabilities P jk = p(b j |a k ). Then, for any block length n, any number of codewords M = 2 nR , and any selection of codes, the probability of decoding satisﬁes\nP r(Decoding) ≤ 2 −n(−ρR+min p Φ 0 (ρ,p)) , ∀ρ ∈ [−1, 0), (1) where p represents a distribution and\nIn the paper, we deﬁne the \u201cbest\u201d exponent as E(R) := max\nRemark 1. ([9]) E(R) > 0 for any R > C XY . So the decoding probability diminishes exponentially when the coding rate is beyond capacity.\nThe well-known blowing-up lemma [8], [10] states that if an event A in a product probability space Q n has probability diminishing slower than exponential, then the event consisting all points that are within a small Hamming distance of A will have a probability going to one.\nIn this section, we generalize to the case when the event probability may vary arbitrarily. Following almost exactly Marton\u2019s proof [10] and the summary in El Gamal\u2019s slides [13], we have\nLemma 1. (Generalized blowing-up Lemma) Suppose Q n ∼ P Q n = Π n i=1 P Q i and P Q n (A) ≥ 2 −nc n for c n ≥ 0. Then for any λ > 1, P Q n (Γ nλ √ c n (A)) ≥ 1 − 1/λ > 0, where Γ l (A) := {x n : min y n ∈A d H (x n , y n ) ≤ l}.\nRemark 2. The proof is in the appendix. This lemma is very similar to the original blowing up lemma. If an event A has certain probability, then A and its \u201cneighborhood\u201d within certain distance will have a non-diminishing probability.\nA connection to the conditional entropy is shown in the following (See appendix for proof).\nTheorem 2. Assume that H( ˆ Z n |X n ) = na n . Then for all λ > 1, there exists a set of codewords C 1 satisfying: i) P r(X n ∈ C 1 ) ≥ 1 − 1/λ; ii) For each code word x n in C 1 , there is a set of colors S(x n ) ⊆ {1, · · · , 2 nR 0 } such that P r( ˆ Z n ∈ S(x n )|X n = x n ) ≥ 1 − 1/λ. Furthermore, for each j of S(x n ), we have\nIn this section, we consider the case when Y and Z are conditionally i.i.d. given X. Denote Ω Y = Ω Z := Ω.\nDeﬁnition 2. A ball of radius r centered at a point in a space Ω n is denoted as Ball(r), and is deﬁned as the set of points which are within Hamming distance r of the point.\nIt is easy to show the following on the volume based on Stiring\u2019s approximation. The proof is omitted.\n|Ω| ρn , and 1 n log |Ball(nρ)| ≤ ρ log |Ω| + H 2 (ρ) + o(1), where the o(1) is only a function of n, and H 2 (ρ) is the binary entropy function −ρ log ρ − (1 − ρ) log(1 − ρ).\nTheorem 3. Assume that Y and Z are i.i.d. given X, and H( ˆ Z n |X n ) = na n . Also assume that rate R > C XY is achievable. Then for all λ > 1, there exists δ n going to zero, determined by n and λ only, and integer N 1 , such that for n ≥ N 1 , 1 n log |Ball(nλ 3/2\nn )| + δ n ≥ E(R), where E(R) is for the XY channel as deﬁned in (2).\nProof: By Theorem 2, for any λ > 1, there exist a set of code words C 1 and constant p 0 := 1 − 1/λ > 0 such that: i) P r(X n ∈ C 1 ) ≥ p 0 ; and ii) for each x n ∈ C 1 , there exists a set of colors S(x n ) such that P r( ˆ Z n ∈ S(x n )|x n ) ≥ p 0 , and for each color j ∈ S(x n ),\nwhere A j := {z n ∈ Ω n : ˆ z n = j}. Note we use Y n in (3) instead of Z n because Y n and Z n are i.i.d. given X n . In other words, in the ball of radius nλ 3/2\nn around an independently drawn Y n , with probability at least p 0 a point will have color j, assuming the code word sent is from C 1 .\nBased on this, the following procedure can be applied to decode X n based on Y n only . Randomly and uniformly pick a point ω n in the ball. Assume its color is ˆ ω n . Apply the decoding function f ( ˆ ω n , Y n ) to map to a code word. Announce it to be the codeword sent.\nNow we can calculate the decoding probability. By assumption, since the code book is feasible, we have P r(f ( ˆ Z n , Y n ) = X n ) → 0. So there exists an integer N 1 > 0 such that at least half of the code words in C 1 satisﬁes\n= P r(f ( ˆ Z n , Y n ) = X n , Y n ∈ Γ nλ 3/2 √ a n (A j )|x n , ˆ Z n = j) ·P r( ˆ ω n = ˆ Z n |f ( ˆ Z n , Y n ) = X n ,\nY n ∈ Γ nλ 3/2 √ a n (A j ), X n = x n , ˆ Z n = j) ≥ P r(f ( ˆ Z n , Y n ) = X n , Y n ∈ Γ nλ 3/2 √ a n (A j )|x n , ˆ Z n = j)\nwhere the last inequality is because one picks a point uni- formly within the ball. For the ﬁrst term, we know\nP r(f ( ˆ Z n , Y n ) = X n , Y n ∈ Γ nλ 3/2 √ a n (A j )|x n , ˆ Z n = j) = P r(Y n ∈ Γ nλ 3/2 √ a n (A j )|x n , j)\nnoting that Y n is independent of Z n given X n . Because of (3), we thus know\nP r(f ( ˆ ω n , Y n ) = X n |x n , ˆ Z n = j) \t (5) ≥ p 0 − P r(f ( ˆ Z n , Y n ) = X n |x n , j) · \t 1 |Ball(nλ 3/2 √ a\nP r(f ( ˆ ω n , Y n ) = X n ) =\n·P r(f ( ˆ ω n , Y n ) = X n |X n = x n , ˆ Z n = j) ≥\n·P r(f ( ˆ ω n , Y n ) = X n |X n = x n , ˆ Z n = j) ≥ \t 1 |Ball(nλ 3/2 √ a\nn )| + δ n ≥ E(R), where δ n is a function of n and λ.\nBased on this theorem and applying Remark 3 with ρ := λ 3/2 √ a n , we have\nCorollary 1. Assume that Y and Z are i.i.d. given X, and H( ˆ Z n |X n ) = na n . Then for all λ > 1, there exists δ (2) n = δ (2) (n, λ) → 0 such that E (R) ≤ H 2 (λ 3/2\nn , where deﬁne H 2 (ρ) = 0 for ρ > 1. We now prove the following lemma.\nLemma 2. Assume that H( ˆ Z n |X n ) = na n . For any achiev- able rate R, it satisﬁes that R ≤ C XY + R 0 − a n + o(1).\nProof: Since the code book is achievable, we have H(X n ) = nR and, by Fano\u2019s lemma, H(X n |Y n , ˆ Z n ) = n · o(1). So n(R + o(1)) = I(X n ; Y n , ˆ Z n )\nTheorem 4. Assume that Y and Z are i.i.d. given X. Then there exists a ∈ [0, R 0 ] such that any achievable rate R larger than C XY satisﬁes:\nProof: Assume that H( ˆ Z n |X n )/n = a n . From Corollary 1 and Lemma 2, we know R − C XY ≤ R 0 − a n + o(1) and E (n) ≤ H 2 (λ 3/2 √ a n ) + λ 3/2 √ a n log |Ω| + o(1). Suppose lim sup a n = a, which exists because a n ∈ [0, R 0 ]. Then R − C XY ≤ R 0 − a and E(R) ≤ H 2 (λ 3/2\na log |Ω|. Because this is valid for any λ > 1, we know the theorem is true.\na log |Ω| is con- tinuous in a and is zero at a = 0, the following is obvious.\nCorollary 2. The maximum achievable rate is strictly less than C XY + R 0 .\nIn this section, we consider the case when the channel is statistically degraded. We say XY Z is degraded if there exists a transition probability distribution q 1 (z|y) such that p(z|x) = \t y q 1 (z|y)p(y|x). Similarly, XZY is degraded if there exists a probability distribution q 2 (y|z) such that p(y|x) = z q 2 (y|z)p(z|x). Note that [12] considers the case when Z is better than Y .\nThe following procedure can be employed by Y to de- code X n based on observation Y n only. For any received observation Y , it generates a random variable ˜ Z based on the transition probability q 1 (z|y); thus for the observed Y n , an\n˜ Z n is generated. Now consider the relay channel formed by X, ˜ Z, and Z. It is obvious that Z and ˜ Z are i.i.d. given X. The same procedure in Section IV, namely the method for ˜ Z to guess X n and the derivation on the decoding probability, can be applied. This leads to the following.\nTheorem 5. Suppose that XY Z is statistically degraded. Denote H( ˆ Z n |X n ) = na n . Then for all λ > 1, there exists δ n → 0, determined by n and λ only, such that\nlog |Ball Ω Z (nλ 3/2 √ a n )| + δ n ≥ E Y (R), for R > C XY . Here E Y (R) is for the XY channel as deﬁned in (2).\nTheorem 6. Under the same condition in Theorem 5, there exists a ∈ [0, R 0 ] such that any achievable rate R larger than C XY satisﬁes: R − C XY ≤ R 0 − a and E Y (R) ≤ H 2 (\n√ a) + √\nThe upper bound for this case can be derived by considering the decoding probability when Z tries to decode X n based on Z n as follows.\nWe build a new channel based on the relay channel XY Z as depicted in Figure 2. First, add a new random variable ˜ Z which is independent of others given X and has the same distribution as Z given X. Then add another random variable ˜ Y based on Z as follows. Whenever Z is received, node Z generates ˜ Y according to q 2 (y|z). Thus we have a new channel XZ ˜ Y ˜ Z. Finally add a lossless link of rate R 0 from ˜ Z to ˜ Y . Since the channels X ˜ Y ˜ Z and XY Z are equivalent statistically, any rate achievable by the XY Z channel must be achievable by the channel XZ ˜ Y ˜ Z. More speciﬁcally, given observation ˜ Z n , node ˜ Z maps to a color ˆ ˜ Z n based on the same mapping from Z n to ˆ Z n . For any feasible code rate R, node Z invokes the associated decoding function f ( ˆ ˜ Z n , ˜ Y n ) to decode X n .\nConsider the channel XZ ˜ Y ˜ Z. Now node Z can guess X n based on Z n only by the following procedure. Assume H( ˆ ˜ Z n |X n ) = na n , and ﬁx a constant λ > 1. Node Z draws a ball of radius nλ 3/2\nn . Because Z and ˜ Z are i.i.d. given X, as shown in the proof for Theorem 4, the color ˆ ˜ Z n is contained in the ball with non-diminishing probability. Randomly pick a point ω n in the ball, node Z announces f ( ˆ ω n , ˜ Y n ) as the code word. By similar argument, the following is true.\nTheorem 7. Assume XZY is statistically degraded. Denote H( ˆ Z n |X n ) = na n . Then for all λ > 1, there exists δ n going to zero, determined by n and λ only, such that\nTheorem 8. Assume the same condition in Theorem 7. Then there exists a ∈ [0, R 0 ] such that any achievable rate R larger\nthan C XZ satisﬁes: R − C XY ≤ R 0 − a and E Z (R) ≤ H 2 (\nand XZ are conditionally i.i.d. binary erasure channels with erasure probability . We determine E (R). For input distribu- tion such that P r(X = 0) = p, by deﬁnition\nR log \t R (1− )(1−R) − log[ R 1−R + ], R ∈ (1 − , 1 − 2− ); R − log(2 − ), R ≥ 1 − 2− .\nThus one can calculate the bound numerically based on Theorem 4. It is nevertheless very close to the cut-set bound.\nThe same idea for upper-bounding the capacity could be generalized to more general cases, where the relay-destination link may not be lossless. For example, suppose the relay channel is now represented by four random variables X, Y , X 1 and Z with joint distribution p(x, x 1 , y, z), such that:\n\u2022 The relay\u2019s observation Z is independent of Y and X 1 given X, i.e. p(z|x, y, x 1 ) = p(z|x);\n\u2022 Y is independent of Z given X and X 1 , i.e., p(y|x, x 1 , z) = p(y|x, x 1 ).\nTo upper-bound the capacity using the tools developed, one can replace the X 1 Y channel by a link with deterministic rate R 0 = min{log |Ω X 1 |, log |Ω Y |}. This new relay channel has greater capacity because any encoding/decoding process for the original one can be considered as a special case. If the cardinality of the space Ω X 1 or Ω Y is small, one can achieve a upper bound better than the cut-set bound. One extreme case is when: 1) Y = (Y 1 , Y 2 ), and 2) X 1 Y 1 represents the relay- destination link independent of all other random variables.\nThe proof applies the following lemma from [10]. Recall that the KL-divergence between two distributions P 1 and P 2 is deﬁned as D(P 1 ||P 2 ) := i P 1 (i) log(P 1 (i)/P 2 (i)).\nLemma 1 of [10]: Let Q n ∼ n i=1 P Q i , i.e. Q i \u2019s are independent, and ¯ Q n ∼ P ¯ Q n . Then, there exists a joint probability measure P Q n , ¯ Q n with these given marginals such that 1 n E(d H (Q n , ¯ Q n )) ≤ 1 n D P ¯ Q n || n i=1 P Q i 1/2 .\nNow deﬁne P ¯ Q n (x n ) as P ¯ Q n (x n ) = P Q n |A (x n ) = P Q n (x n )/P Q n (A), ∀x n ∈ A, and P ¯ Q n (x n ) = 0, otherwise.\nBy the lemma, we know there exists a joint distribution such that Ed H (Q n , ¯ Q n ) ≤ n\nwhere (7) and (8) follow from the fact that P Q n , ¯ Q n (x n , ¯ x n ) = 0 when ¯ x n ∈ A.\nWe present two lemmas ﬁrst. Due to page limit, we omit the proofs. Recall that ˆ Z n is the \u201ccoloring\u201d function on Z n .\nLemma 3. Suppose H( ˆ Z n |X n ) = na n . Then for all µ > 1, P r(X n ∈ {x n : H( ˆ Z n |X n = x n ) ≤ nµa n }) ≥ 1 − 1/µ > 0.\nLemma 4. If 2 nR0 j=1 −p j log p j ≤ nb n , then for any α > 1, those colors S := {j : p j ≥ 2 −nb n α } have a total probability no less than 1 − 1/α.\nNow, by Lemma 3, we know that for any µ > 1, P r({x n : H( ˆ Z n |x n ) ≤ nµa n }) ≥ 1 − 1/µ.\nDeﬁne C 1 := {x n : H( ˆ Z n |x n ) ≤ nµa n }. For each x n in C 1 , by deﬁnition, we have 2 nR0 k=1 −p k log p k ≤ nµa n , where p k := P r( ˆ Z n = k|x n ). Then by Lemma 4, we know for any α > 1 there exists a set of colors S such that: 1) P r( ˆ Z n ∈ S|x n ) ≥ 1 − 1/α, and 2) for each color j ∈ S, p j ≥ 2 −nµa n α .\nFor such an x n and color j, by Lemma 1, we know for any λ > 1, P r( ˆ Z n ∈ Γ nλ √ µa n α (A j )|X n = x n ) ≥ 1 − 1/λ."},"refs":[]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565501.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S5.T2.1","endtime":"10:10","authors":"Feng Xue","date":"1341309000000","papertitle":"An upper bound on relaying over capacity","starttime":"09:50","session":"S5.T2: Relay Channels","room":"Kresge Auditorium (109)","paperid":"1569565501"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
