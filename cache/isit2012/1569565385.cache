{"id":"1569565385","paper":{"title":{"text":"Systematic Error-Correcting Codes for Rank Modulation"},"authors":[{"name":"Hongchao Zhou"},{"name":"Anxiao (Andrew) Jiang"},{"name":"Jehoshua Bruck"}],"abstr":{"text":"Abstract\u2014The rank modulation scheme has been proposed recently for efﬁciently writing and storing data in nonvolatile memories. Error-correcting codes are very important for rank modulation, and they have attracted interest among researchers.\nIn this work, we explore a new approach, systematic error- correcting codes for rank modulation. In an (n, k) systematic code, we use the permutation induced by the levels of n cells to store data, and the permutation induced by the ﬁrst k cells (k < n) has a one-to-one mapping to information bits. Systematic codes have the beneﬁts of enabling efﬁcient information retrieval and potentially supporting more efﬁcient encoding and decoding procedures. We study systematic codes for rank modulation equipped with the Kendall\u2019s τ -distance. We present (k + 2, k) systematic codes for correcting one error, which have optimal sizes unless perfect codes exist. We also study the design of multi- error-correcting codes, and prove that for any 2 ≤ k < n, there always exists an (n, k) systematic code of minimum distance n −k. Furthermore, we prove that for rank modulation, systematic codes achieve the same capacity as general error-correcting codes."},"body":{"text":"The rank modulation scheme has been proposed recently for efﬁciently and robustly writing and storing data in nonvolatile memories (NVMs) [7], [8]. Its applications include ﬂash memories [3], which are currently the most widely used family of NVMs, and several emerging NVM technologies, such as phase-change memories [2]. The rank modulation scheme uses the relative order of cell levels to represent data, where a cell level denotes a ﬂoating-gate cell\u2019s threshold voltage for ﬂash memories and denotes a cell\u2019s electrical resistance for resistive memories (such as phase-change memories). Consider n memory cells, where for i = 1, 2, · · · , n, let c i ∈ R denote the level of the ith cell. It is assumed that no two cells have the same level, which is easy to realize in practice. Let S n denote the set of all n! permutations of {1, 2, · · · , n}. The n cell levels induce a permutation [x 1 , x 2 , · · · , x n ] ∈ S n , where c x 1 > c x 2 > · · · > c x n . The rank modulation scheme uses such permutations to represent data. It enables memory cells to be programmed efﬁciently and robustly from lower levels to higher levels, without the risk of over-programming. It also makes it easier to adjust cell levels when noise appears without erasing/resetting cells, and makes the stored data be more robust to asymmetric errors that change cell levels in the same direction [7], [8].\nError-correcting codes for rank modulation are very impor- tant for data reliability [3], [9]. Errors are caused by noise in cell levels, and the smallest error that can happen is for two adjacent cell levels to switch their order in the permuta- tion, which is called an adjacent transposition [5]. An adja- cent transposition changes a permutation [x 1 , x 2 , · · · , x n ] ∈ S n to [x 1 , · · · , x i −1 , x i+1 , x i , x i+2 , · · · , x n ] for some i ∈ {1, 2, · · · , n−1}. In this paper, as in [1], [8], [9], we measure the distance between two permutations x = [x 1 , x 2 , · · · , x n ] ∈ S n and y = [y 1 , y 2 , · · · , y n ] ∈ S n by the minimum number of adjacent transpositions needed to change x into y (and vice versa), and denote it by d τ (x, y). This distance metric is called the Kendall\u2019s τ -distance [5]. For example, if x = [2, 1, 3, 4] and y = [3, 1, 4, 2], then d τ (x, y) = 4, because to change the permutation from x to y (or vice versa), we need at least 4 adjacent transpositions: [2, 1, 3, 4] → [1, 2, 3, 4] → [1, 3, 2, 4] → [1, 3, 4, 2] → [3, 1, 4, 2]. Based on this distance metric, an error-correcting code that can correct t errors is a subset of S n whose minimum distance is at least 2t + 1.\nThere have been some results on error-correcting codes for rank modulation equipped with the Kendall\u2019s τ -distance. In [9], a one-error-correcting code is constructed based on metric embedding, whose size is provably within half of the optimal size. In [1], the capacity of rank modulation codes is derived for the full range of minimum distance between codewords, and the existence of codes whose sizes are within a constant factor of the sphere-packing bound for any ﬁxed number of errors is shown. Some explicit constructions of error-correcting codes have been proposed and analyzed in [11] and [12]. There has also been some work on error- correcting codes for rank modulation equipped with the L ∞ distance [13], [14]. The distance metric is more appropriate for cells where the noise in cell levels has limited magnitudes.\nIn this paper, we study systematic error-correcting codes for rank modulation as a new approach for code design. Let k and n be two integers such that 2 ≤ k < n. In an (n, k) systematic code, we use the permutation induced by the levels of n cells to store data. The ﬁrst k cells are called information cells, whose induced permutation has a one-to-one mapping to information bits. The last n − k cells are called redundant cells, which are used to add redundancy to the codewords. Compared to the existing constructions of error-correcting\ncodes for rank modulation, systematic codes have the beneﬁt that they support efﬁcient data retrieval, because when there is no error (or when error correction is not considered), data can be retrieved by only reading the information cells. And since every permutation induced by the information cells represents a unique value of the data, the permutations can be mapped to data (and vice versa) very efﬁciently via enumerative source coding (e.g., by ordering permutations alphabetically and map them to data) [4], [10]. In addition, the encoding algorithm of the error-correcting code can potentially be made very efﬁcient by deﬁning the positions of the redundant cells in the permutation as a function of the corresponding positions of the information cells.\nWe study the design of systematic codes, and analyze their performance. We present a family of (k + 2, k) systematic codes for correcting one error, where either k or k + 1 is a prime number. We show that they have optimal sizes among systematic codes, unless perfect systematic one-error- correcting codes, which meet the sphere-packing bound, exist. We also study the design of systematic codes that correct multiple errors, and prove that for any 2 ≤ k < n, there exists a systematic code of minimum distance n − k. Furthermore, we prove that for rank modulation, systematic codes have the same capacity as general error-correcting codes. This result establishes that asymptotically, systematic codes are as strong in their error correction capability as general codes.\nThe rest of the paper is organized as follows. In Section II, we deﬁne some terms and show properties of systematic codes. In Section III, we study systematic codes that correct one error. In Section IV, we study codes that correct multiple errors. In Section V, we present the capacity of systematic codes, which matches the capacity of general codes. Due to space limitation, we skip some details. Interested readers can refer to [15] for the full paper.\nIn this section, we deﬁne some terms for systematic codes, and show its basic properties. Let C ⊆ S n denote a general (n, k) systematic error-correcting code for rank modulation. Given a codeword x = [x 1 , x 2 , · · · , x n ] ∈ C, we call the permutation induced by the ﬁrst k cells (i.e., the information cells) a = [a 1 , a 2 , · · · , a k ] ∈ S k the information sector of the codeword x. More speciﬁcally, if c 1 , c 2 , · · · , c n are the n cells\u2019 levels that induce the permutation [x 1 , x 2 , · · · , x n ] ∈ C, then we have c a 1 > c a 2 > · · · > c a k . Clearly, the information sector [a 1 , a 2 , · · · , a k ] is a subsequence of its codeword [x 1 , x 2 , · · · , x n ]; namely, [a 1 , a 2 , · · · , a k ] = [x i 1 , x i 2 , · · · , x i k ] for some 1 ≤ i 1 < i 2 < · · · < i k ≤ n.\nExample 1. Let k = 4 and n = 6 . Let c 1 = 1.0 , c 2 = 2.1 , c 3 = 0.8 , c 4 = 0.2 , c 5 = 1.5 , c 6 = 0.6 . Then the permutation\nGiven a permutation x = [x 1 , x 2 , · · · , x n ] ∈ S n , we can see it as constructed by sequentially inserting 1, 2, · · · , n\ninto an initially- empty permutation. Hence, we deﬁne the insertion vector of x as the positions of inserting 1, 2, · · · , n. Speciﬁcally, for 1 ≤ i ≤ n, let g i (x) denote the position of the insertion of the integer i. That is, if p ∈ {1, 2, · · · , n} denotes the integer such that x p = i, then\nwhere Z i = {0, 1, 2, ..., i − 1}. Note that given g(x), we can reconstruct x uniquely. It has been shown that for any x, y ∈ S n [1],\nFor an (n, k) systematic code, it is required that for every permutation a = [a 1 , a 2 , · · · , a k ] ∈ S k , there is exactly one codeword with a as its information sector, which we will denote by x a . The code has k! codewords, and we deﬁne its rate as ln k! ln n! . Given an information sector a ∈ S k , we can get the insertion vector of its codeword x a , namely,\nIt means that x a can be constructed from a in the fol- lowing way: First, we insert k + 1 (namely, the (k + 1)th cell) into the permutation [a 1 , a 2 , · · · , a k ] at the position g k+1 (x a ) ∈ Z k+1 ; next, we insert the integer k + 2 (namely, the (k + 2)th cell) at the position g k+2 (x a ) ∈ Z k+2 ; and so on. (The last integer to insert is n.) To design good systematic codes, given the information permutation a, we need to ﬁnd [g k+1 (x a ), g k+2 (x a ), ..., g n (x a )] appropriately to maximize the code\u2019s minimum distance.\nExample 2. Let k = 4 and n = 6 . If a = [1, 3, 2, 4] , g 5 (x a ) = 3 and g 6 (x a ) = 0 , then x a = [6, 1, 3, 2, 5, 4] . \t 2\nThe following theorem shows how the insertion of redun- dant cells into the information sector affects the Kendall\u2019s τ - distance between codewords.\nIn this section, we analyze and design systematic codes for correcting one error. Such codes have minimum distance 3. In particular, we present a family of (k + 2, k) systematic codes, where either k or k+1 is a prime number. It will be shown that the codes have optimal sizes among systematic codes, unless perfect systematic one-error-correcting codes, which meet the sphere-packing bound, exist.\nGiven a permutation x ∈ S n , the ball of radius r cen- tered at x, denoted by B r (x), is the set of permutations in S n that are within distance r from x. Namely, B r (x) = {y ∈ S n |d τ (x, y) ≤ r}, for 0 ≤ r ≤ n(n −1) 2 . (The maximum Kendall\u2019s τ -distance for any two permutations in S n is n(n −1) 2 . [8]) A simple relabeling argument sufﬁces to show that the size of a ball does not depend on the choice of its center. So we use |B r (n) | to denote |B r (x) | for any x ∈ S n . It can be proved that [15] for any 0 ≤ r ≤ n(n −1) 2 ,\nAn r-error-correcting code C ⊆ S n for rank modulation needs to satisfy the sphere-packing bound: |C| ≤ n! |B\n| . If the inequality in the above bound becomes equality, we call the code perfect. For one-error-correcting codes, since |B 1 (n) | = n, the following result holds.\nIt is known that perfect codes are often rare. Well-known examples include binary codes, where the only perfects codes are Hamming codes and Golay codes, and Lee metric codes in three-dimensional and higher-dimensional spaces [6]. For rank modulation, there is a simple (3, 2) one-error-correcting code that is perfect: {[1, 2, 3], [3, 2, 1]}. However, beside this trivial code, no other perfect code has been found yet. If we add the requirement that the code needs to be systematic, it will be even harder for such codes to exist. For instance, it can be proved that there does not exist any perfect systematic one-error-correcting code when k = 3.\nFor any given k ≥ 3, if the perfect (k + 1, k) code does not exist, then the (k + 2, k) code becomes the optimal systematic code.\nWe now present the construction that builds a family of (k + 2, k) systematic one-error-correcting codes.\n(2i − 1)a i mod m g k+2 (x a ) =\nThe following theorem shows that the above code can correct one error.\nProof: In the (k + 2, k) code of Construction 6, either k or k + 1 is a prime number. Let us ﬁrst consider the case that k is a prime number. Assume that a = [a 1 , a 2 , · · · , a k ] ∈ S k and b = [b 1 , b 2 , · · · , b k ] ∈ S k are two distinct information sectors, whose corresponding codewords are x a , x b ∈ S n , respectively. Our goal is to prove that d τ (x a , x b ) ≥ 3. We consider three cases:\n1) Case 1: d τ (a, b) ≥ 3. In this case, we have d τ (x a , x b ) ≥ d τ (a, b) ≥ 3.\n2) Case 2: d τ (a, b) = 1. In this case, we can write b as b = [b 1 , b 2 , · · · , b k ] = [a 1 , a 2 , · · · , a i+1 , a i , · · · , a k ] for some i ∈ {1, 2, · · · , k −1}. If we deﬁne ∆ = a i+1 −a i , then we get\nSince 1 ≤ |∆| ≤ k − 1 and k ≥ 3 is a prime number, we know that 2∆ is not a multiple of k. As a result, we get |g k+1 (x a ) − g k+1 (x a ) | ≥ 1.\nwhere 8i∆ is not a multiple of k, either, because 1 ≤ i, |∆| ≤ k−1 and k ≥ 3 is a prime number. This implies that |g k+2 (x a ) − g k+2 (x b ) | ≥ 1.\nSo by Theorem 3, we get d τ (x a , x b ) ≥ d τ (a, b) + |g k+1 (x a ) − g k+1 (x b ) |+|g k+2 (x a ) − g k+2 (x b ) | ≥ 1+ 1 + 1 = 3.\n3) Case 3: d τ (a, b) = 2. In this case, it takes at least two adjacent transpositions to change the permutation a into b. These two transpositions can be either separated or adjacent to each other. By considering the two cases sep- arately (detailed proof omitted due to space limitation), we can get that d τ (x a , x b ) ≥ 3.\nTherefore, we can conclude that when k is a prime number, for any two distinct codewords x a , x b , their distance is at least 3. When k + 1 is a prime number, we can apply the same procedure for the proof, \u2013 by only replacing \u201cmod k\u201d with \u201cmod k + 1\u201d, \u2013 and get the result that d τ (x a , x b ) ≥ 3. And that concludes the proof.\nWe now present the encoding and decoding algorithms of the (k + 2, k) systematic code. Let L = {0, 1, · · · , k! − 1} denote the set of information symbols to encode. (If the input are information bits, they can be easily mapped to the information symbols in L via enumerative source coding. L can be rounded down to a power of 2.) For encoding, given an information symbol ℓ ∈ L, it can be mapped to its corre- sponding permutation (i.e., information sector) a ∈ S k in time linear in k [10]. Based on Construction 6, the insertion vector (g k+1 (x a ), g k+2 (x a )) can be directly computed, which gives\nus the codeword x a . That completes the encoding algorithm. The decoding algorithm of the construction is also efﬁcient: Given the received codeword y, let b denote its information sector. If there is an error in b, i.e., b ̸= a, then we can write a = [b 1 , ..., b i+1 , b i , ..., b k ] for some i with 1 ≤ i ≤ k − 1. Based on the construction, this i can be determined by solving a simple equation, hence, making the decoding process very efﬁcient.\nIn this section, we study the design of systematic codes that correct multiple errors, and prove that for any 2 ≤ k < n, there exists an (n, k) systematic code of minimum distance n − k.\nFirst, we present a generic scheme for constructing an (n, k) systematic code of minimum distance d. The scheme is based on greedy searching, hence, not explicit. But the analysis of this scheme is very useful for proving the existence of codes with certain parameters, and for deriving the capacity of systematic codes.\nNote that given any a ∈ S k , there are (k+1) ×(k+2)×· · ·× n = n! k! permutations in S n that have a as their information sector. For the above code construction to succeed, n −k needs to be sufﬁciently large. In the following theorem, we derive a bound for the parameters.\n< n! k!\nProof: In Construction 8, for any information sector s i ∈ S k (where 1 ≤ i ≤ k!), there are n! k! possible choices for the vector [g k+1 (x s i ), g k+2 (x s i ), ..., g n (x s i )]. Our goal is to make sure that at least one of them \u2013 which will become the corresponding codeword x s i \u2013 can guarantee to satisfy the requirement in (2).\nLet us consider the maximum number of choices for the vector [g k+1 (x s i ), g k+2 (x s i ), ..., g n (x s i )] whose correspond- ing permutations in S n are at distance less than d from at least\none permutation in {x s 1 , x s 2 , ..., x s i −1 }. Such vectors cannot be chosen for the codeword x s i . Our proof is based on two main observations: First, given s i ∈ S k , let N l be the number of permutations in S k whose distance to s i is l, then\nSecond, given s j with j < i, if d τ (s i , s j ) = l, there are at most\nassignments for [g k+1 (x s i ), g k+2 (x s i ), ..., g n (x s i )] such that d τ (x s j , x s i ) ≤ d − 1.\nFrom (4) and (5), we can get that the total number of u- navailable assignments for [g k+1 (x s i ), g k+2 (x s i ), ..., g n (x s i )] is at most\nNow, we present an explicit construction of systematic multi-error-correcting codes, by slightly modifying the multi- error-correcting codes derived in [11]. The idea is that given any two integers g i (x a ), g i (x b ) < 2 m , there exists a function ϕ m : Z 2 m → {0, 1} m (called Gray map) such that\nwhere d H indicates the Hamming distance between two binary vectors. As a result, we can convert the problem of construct- ing rank modulation codes to the problem of constructing binary error-correcting codes in Hamming space. To make the code being systematic, we use ϕ ⌈log\n≤ i ≤ k for the mapping of information part, instead of using ϕ ⌊log 2 i ⌋ in the original construction.\nIn this section, we prove that for rank modulation, sys- tematic error-correcting codes achieve the same capacity as general error-correcting codes. In [1], Barg and Mazumdar have derived the capacity of general error-correcting codes for rank modulation. Let A(n, d) denote the maximum size of a code of length n and minimum distance d. (So the code is a subset of S n .) Deﬁne the capacity of error-correcting codes of minimum distance d as C(d) = lim n →∞ ln A(n,d) ln n! . It is shown in [1] that\n1 − ϵ, if d = Θ(n 1+ϵ ) with 0 < ϵ < 1 0, \t if d = Θ(n 2 ).\nFor systematic codes, let k(n, d) denote the maximum num- ber of information cells that can exist in systematic codes of length n and minimum distance d. (Such codes are (n, k(n, d)) systematic codes, and have k(n, d)! codewords.) The capacity of systematic codes of minimum distance d is\nThe following theorem shows that systematic codes have the same capacity as general codes.\n1 − ϵ, if d = Θ(n 1+ϵ ) with 0 < ϵ < 1 0, \t if d = Θ(n 2 ).\nProof: Since systematic codes are a special case of general error-correcting codes, by Equation (6), it is sufﬁcient to prove\n1 − ϵ, if d = Θ(n 1+ϵ ) with 0 < ϵ < 1 0, \t if d = Θ(n 2 ).\nAccording to Theorem 9, there exists an (n, k) systematic code of minimum distance d if k is the maximum integer that satisﬁes \t (\n< n! k!\nFor such k, we have k(n, d) ≥ k. For convenience, let α = lim n →∞ k n be a constant. In this case, if α > 0,\nTo prove the ﬁnal conclusion, we will show that if d = O(n), then α = 1; if d = Θ(n 1+ϵ ), then α ≥ 1 − ϵ. (If d = Θ(n 2 ), the result α ≥ 0 is trivial).\n1) If d = O(n), we have d ≤ βn for some β > 0. By Stirling\u2019s approximation, the formula above yields\nwhich shows that n ln n − αn ln(αn) = O(n). Hence α approaches 1 as n → ∞.\n2) If d = Θ(n 1+ϵ ) for 0 < ϵ < 1, by applying Stirling\u2019s approximation to Equation (7), we get\nn ln n − k ln k + O(n) \t = 1. Since k = αn and d = Θ(n 1+ϵ ), we get\n(1 − α)n ln n \t = 1. That leads to α ≥ 1 − ϵ.\nBased on the above analysis and the fact that S sys (d) ≥ α, we get the ﬁnal conclusion.\nThis work was supported in part by an NSF grant ECCS- 0801795 and by a BSF grant 2010075."},"refs":[{"authors":[{"name":"A. Barg"},{"name":"A. Mazumdar"}],"title":{"text":"Codes in permutations and error correction for rank modulation"}},{"authors":[{"name":"G. W. Burr et al."}],"title":{"text":"Phase change memory technology"}},{"authors":[{"name":"P. Cappellett"},{"name":"C. Goll"},{"name":"P. Oliv"},{"name":"E. Zanoni (Ed"}],"title":{"text":"Flash memories, Kluwer Academic Publishers, 1st Edition, 1999"}},{"authors":[{"name":"T. M. Cover"}],"title":{"text":"Enumerative source coding"}},{"authors":[{"name":"M. Deza"},{"name":"H. Huang"}],"title":{"text":"Metrics on permutations, a survey"}},{"authors":[{"name":"S. W. Golomb"},{"name":"L. R. Welch"}],"title":{"text":"Perfect codes in the Lee metric and the packing of polyominoes"}},{"authors":[{"name":"A. Jiang"},{"name":"R. Mateescu"},{"name":"M. Schwartz"},{"name":"J. Bruck"}],"title":{"text":"Rank modulation for ﬂash memories"}},{"authors":[{"name":"A. Jiang"},{"name":"M. Schwartz"},{"name":"J. Bruck"}],"title":{"text":"Error-correcting codes for rank modulation"}},{"authors":[{"name":"A. Jiang"},{"name":"M. Schwartz"},{"name":"J. Bruck"}],"title":{"text":"Correcting charge-constrained errors in the rank-modulation scheme"}},{"authors":[{"name":"M. Mares"},{"name":"M. Straka"}],"title":{"text":"Linear-time ranking of permutations"}},{"authors":[{"name":"A. Mazumdar"},{"name":"A. Barg"},{"name":"G. Z´emor"}],"title":{"text":"Construction of rank modulation codes"}},{"authors":[{"name":"A. Mazumdar"},{"name":"A. Barg"},{"name":"G. Z´emor"}],"title":{"text":"Parameters of rank modulation codes: examples"}},{"authors":[{"name":"M. Schwartz"},{"name":"I. Tamo"}],"title":{"text":"Optimal permutation anticodes with the inﬁn- ity norm via permanents of (0, 1)-matrices"}},{"authors":[{"name":"I. Tamo"},{"name":"M. Schwartz"}],"title":{"text":"Correcting limited-magnitude errors in the rank-modulation scheme"}},{"authors":[{"name":"H. Zhou"},{"name":"A. Jiang"},{"name":"J. Bruck"}],"title":{"text":"Systematic Error-Correcting Codes for Rank Modulation"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565385.pdf"},"links":[{"id":"1569566381","weight":4},{"id":"1569566725","weight":4},{"id":"1569559889","weight":4},{"id":"1569564805","weight":4},{"id":"1569566765","weight":4},{"id":"1569565775","weight":12},{"id":"1569563411","weight":4},{"id":"1569565317","weight":12},{"id":"1569566739","weight":4},{"id":"1569565609","weight":4},{"id":"1569564249","weight":16},{"id":"1569565809","weight":8},{"id":"1569566579","weight":4},{"id":"1569565455","weight":4},{"id":"1569566709","weight":4},{"id":"1569566787","weight":25},{"id":"1569566015","weight":4},{"id":"1569566895","weight":8},{"id":"1569558785","weight":4},{"id":"1569563981","weight":4},{"id":"1569566733","weight":4},{"id":"1569563307","weight":4},{"id":"1569566423","weight":25},{"id":"1569558901","weight":41},{"id":"1569566939","weight":4},{"id":"1569565839","weight":4},{"id":"1569566513","weight":4},{"id":"1569554971","weight":4},{"id":"1569566909","weight":4},{"id":"1569558985","weight":4},{"id":"1569564857","weight":8},{"id":"1569566257","weight":4},{"id":"1569565033","weight":4},{"id":"1569566447","weight":4},{"id":"1569565847","weight":4},{"id":"1569565887","weight":4},{"id":"1569566721","weight":4},{"id":"1569556671","weight":4},{"id":"1569564973","weight":4},{"id":"1569565029","weight":4},{"id":"1569565393","weight":16},{"id":"1569565933","weight":4},{"id":"1569561123","weight":4},{"id":"1569565311","weight":4},{"id":"1569564097","weight":4},{"id":"1569563395","weight":4},{"id":"1569566383","weight":4},{"id":"1569565155","weight":4},{"id":"1569557633","weight":4},{"id":"1569557715","weight":4},{"id":"1569565397","weight":4},{"id":"1569566129","weight":4},{"id":"1569566887","weight":4},{"id":"1569564919","weight":4},{"id":"1569561221","weight":4},{"id":"1569564595","weight":29},{"id":"1569566237","weight":4},{"id":"1569566283","weight":4},{"id":"1569564861","weight":8},{"id":"1569556759","weight":4},{"id":"1569561185","weight":4},{"id":"1569567483","weight":4},{"id":"1569566299","weight":4},{"id":"1569564769","weight":4},{"id":"1569561713","weight":20},{"id":"1569557851","weight":4},{"id":"1569565861","weight":4},{"id":"1569566147","weight":4},{"id":"1569560785","weight":4},{"id":"1569565631","weight":4},{"id":"1569559251","weight":4},{"id":"1569564253","weight":4},{"id":"1569565165","weight":4},{"id":"1569565565","weight":4},{"id":"1569565635","weight":4},{"id":"1569564931","weight":4},{"id":"1569565373","weight":37},{"id":"1569551751","weight":4},{"id":"1569564419","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S17.T1.1","endtime":"15:20","authors":"Hongchao Zhou, Anxiao Andrew Jiang, Jehoshua Bruck","date":"1341586800000","papertitle":"Systematic Error-Correcting Codes for Rank Modulation","starttime":"15:00","session":"S17.T1: Rank-Modulation Coding","room":"Kresge Rehearsal B (030)","paperid":"1569565385"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
