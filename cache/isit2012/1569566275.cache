{"id":"1569566275","paper":{"title":{"text":"A Lifting Decoding Scheme and its Application to Interleaved Linear Codes"},"authors":[{"name":"Guillaume Quintin"}],"abstr":{"text":"Abstract\u2014In this paper we design a decoding algorithm based on a lifting decoding scheme. This leads to a unique decoding algorithm with complexity quasi linear in all the parameters for Reed-Solomon codes over Galois rings and a list decoding algorithm. We show that, using erasures in our algorithms, allows one to decode more errors than half the minimum distance with a high probability. Finally we apply these techniques to interleaved linear codes over a ﬁnite ﬁeld and obtain a decoding algorithm that can recover more errors than half the minimum distance.\nIndex Terms\u2014Algorithm design and analysis, Decoding, Error correction, Reed-Solomon codes, Interleaved codes."},"body":{"text":"Reed-Solomon (RS) codes form an important and well- studied family of codes. They can be efﬁciently decoded. See for example [10], [15]. They are widely used in practice [19]. Sudan\u2019s 1997 breakthrough on list decoding of RS codes [18], further improved by Guruswami and Sudan in [14], showed that RS codes are list decodable up to the Johnson bound in polynomial time.\nLet B be a quotient ring of a discrete valuation ring A with uniformizing parameter π. We design a decoding scheme that can be adapted to a wide range of linear codes over B. Let C be a code over B, then given a black box decoding algo- rithm BlackBoxDec for C/πC, we can construct a decoding algorithm for C generalizing [12, algorithm of Section 3]. The constructed decoding algorithm has the property to correct all error patterns that can be corrected by BlackBoxDec. We study in detail the complexities in the case of Reed-Solomon codes over Galois rings and truncated power series rings over a ﬁnite ﬁeld.\nWe improve the construction given in [12, algorithm of Section 3] and in [5], [7] by integrating an idea used by Marc Armand in [2], [4]. We use erasures at suitable places within our decoding algorithm to improve its decoding radius. This improvement allows one to decode more error patterns than BlackBoxDec with a high probability. We study and give complexities when RS codes are involved. In fact, we decode exactly the same error patterns as in Armand\u2019s papers [2], [4] but with a lower complexity thanks to the decoding scheme of [12].\nFinally we show that, given any linear code C over F q , we can view interleaved codes with respect to C as codes over F q [[t]]/(t r ). This allows one to apply the previous techniques to interleaved codes to obtain a decoding algorithm that can\ndecode more errors than half the minimum distance of C with a high probability over small alphabets (small ﬁnite ﬁelds). Our approach is different from [6], which treats a priori only the case of interleaved RS codes while our algorithm is able to decode (further than half the minimum distance) any interleaved linear code as soon as a decoding algorithm for the underlying code is available. Therefore we can consider codes over small alphabet like F 2 . A lot of families of codes are subﬁeld-subcodes of alternant codes. Thus a lot of interleaved codes can be decoded with the approach of [6] but at a higher cost than our approach which does not need to consider alternant codes.\nOur approach for a lifting decoding scheme has ﬁrst been studied in [12], then in [5], [7] RS codes over a commutative ﬁnite ring have been studied by M. Armand in [1]\u2013[4]. The decoding of interleaved codes has been studied in [6], [8], [11].\nThe \u201csoft-Oh\u201d notation f (n) ∈ O(g(n)) means that f (n) ∈ g(n) log O(1) (3 + g(n)). It is well known [9] that the time needed to multiply two integers of bit-size at most n in binary representation is O(n). The cost of multiplying two polynomials of degree at most n over a ring A is O(n) in terms of the number of arithmetic operations in A. Thus the bit-cost of multiplying two elements of the ﬁnite ﬁeld F p n is O(n log p).\nIn this section we let A be any commutative ring with identity and n be a positive integer. Let C be a subset of A n . We call C an error correcting code over A or simply a code over A. If C is a submodule of A n we say that C is a linear code over A. The integer n is called the blocklength of C. If C is a linear code and C is free of rank k, then we say that C has parameters [n, k] A .\nthe Hamming weight (or simply weight) of u. Let v be another vector of A n . The integer w(u − v) is called the Hamming\ndistance (or simply distance) between u and v and is denoted by d(u, v).\nThe integer d = min u,v∈C and u=v d(u, v) is called the minimum distance of C. Note that when C is a linear code we have d = min u∈C\\{0} w(u), we then say that C has parameters [n, k, d] A if C is free of rank k.\nDeﬁnition 2. Suppose that C is free of rank k. A matrix whose rows form a basis of C is called a generator matrix of C.\nThe generator matrix is used to encode a message m ∈ A k . A generator matrix induces a one-to-one correspondence between messages and codewords, the map m → mG is a A- linear embedding A k → A n . Under this map, we will identify messages and codewords.\nLet m be a maximal ideal of A. The vector space C/mC, if not zero, is a linear code with parameters [n, ≤ k, ≤ d] A/m with generator matrix G . The matrices G and G have the same number of columns but can have a different number of rows. However G can be deduced from G, ﬁrst compute G = G mod m, then remove from G appropriate rows to obtain a basis of C/mC.\nDeﬁnition 3. Borrowing the terminology of [12, Section 3], if G and G have the same number of rows and columns and that G mod m = G then C is called a splitting code.\nWe will consider codes over a special kind of rings which we deﬁne now.\nDeﬁnition 4. Let A be a ring. If A is a local principal ideal domain, we call A a discrete valuation ring (DVR). Any element π ∈ A such that (π) is the maximal ideal of A is called a uniformizing parameter of A.\nReed-Solomon codes over rings are deﬁned in a slightly different way to their ﬁeld counterparts. We let A[X] <k denote the submodule of A[X] consisting of all the polynomials of degree at most k − 1 of A[X].\nDeﬁnition 5. Let x 1 , . . . , x n be elements of A such that x i − x j ∈ A × ﬁr i = j (where A × is the group of units of A). The submodule of A n generated by the vectors (f (x 1 ), . . . , f (x n )) ∈ A n where f ∈ A[X] <k is called a Reed-Solomon code over A. The n-tuple (x 1 , . . . , x n ) is called the support of the RS code.\nProposition 6. Let C be a RS code over A. Then C has parameters [n, k, d = n − k + 1] A .\nProposition 7. Let C be a RS code with parameters [n, k, d = n − k + 1] A over a discrete valuation ring A with uniformizing parameter π. Then C/π r C is a RS code with parameters [n, k, d] A/(π r ) over A/(π r ). Moreover of (x 1 , . . . , x n ) is the support of C then (x 1 mod π r , . . . , x n mod π r ) is the sup- port of C/π r C.\nIn this section we let A be a discrete valuation ring with uniformizing parameter π and by κ = A/(π) the residue ﬁeld of A. We also let C be a free splitting linear code over A of parameters [n, k, d] A and with generator matrix G. We let C\ndenote the linear code C/πC and G a generator matrix of C such that G = G mod π.\nInput: A positive integer τ ≤ n and a received vector y of κ n (with zero or more erasures).\nNote that BlackBoxDec can return one or more code- words in particular it can be a list decoding algorithm; but we do not require that it return all codewords within distance τ of y.\nInput: A positive integer τ ≤ n, two nonnegative integers i ≤ r, a received vector y of A n (with zero or more erasures) and a black box decoding algorithm BlackBoxDec for C(π).\n(2) or ∅ (meaning FAILURE).\n4: Call to BlackBoxDec with input τ and (y mod π) to obtain the set S.\n11: \t Put erasures in y 1 at the locations indicated by Supp(e 0 ).\n12: \t Call recursively Algorithm 2 with input τ , i + 1, r, y 1 and BlackBoxDec to obtain the set T .\nInput: A positive integer τ ≤ n, a positive integer r, a received vector y of A n (with zero or more erasures) and a black box decoding algorithm BlackBoxDec for C(π).\n(3) or ∅ (meaning FAILURE).\n1: return the set returned by the call to Algorithm 2 with input τ , 0, r, y and BlackBoxDec.\nProposition 8. Suppose that BlackBoxDec returns all the codewords from C within distance τ of y ∈ κ n . Then Algorithm 2 can decode up to τ errors up to precision r.\nProof: The proof is done by descending induction on i. For i = r and i = r − 1 the proposition holds.\nNow let i < r − 1 and (m, e) ∈ κ k × κ n . Let c = mG be such that w(e mod π r−i ) ≤ τ and y = c + e. There exists (m 0 , e 0 ) ∈ S such that c 0 = m 0 G = c mod π, e = e 0 mod π and Supp(e 0 ) ⊆ Supp(e). If we count erasures as errors, we have w(e) ≤ τ and therefore w(π −1 (e 0 − e)) ≤ τ . On the other hand we have mG = m 0 G mod π and mG = m 0 G in C whence m = m 0 mod π. Therefore π −1 (mG − m 0 G) = (π −1 (m − m 0 ))G ∈ C.\nBy the inductive hypothesis, we can ﬁnd (m 1 , e 1 ) ∈ T such that π −1 (c−c 0 ) = m 1 G mod π r−(i+1) and π −1 (e−e 0 ) = e 1\nWe now have the straightforward proposition which gives the complexity of Algorithm 3 in terms of bit operations.\nProposition 9. Suppose that the number of codewords re- turned by BlackBoxDec is at most L > 1. Denote by Lift(C) the complexity of lifting a codeword of C into a codeword of C up to precision r in terms of the number of bit operations. Denote by Dec(C) the complexity of algorithm BlackBoxDec in terms of the number of bit operations. Then Algorithm 3 performs at most\nL r − 1 L − 1\nbit operations. If L ≤ 1 then Algorithm 3 performs at most r (Lift(C) + Dec(C)) bit operations.\nThe interesting part of Algorithm 2 (and hence of all other algorithms) resides in the BlackBoxDec argument. We have shown that if BlackBoxDec is a classical decoding algorithm then Algorithm 3 becomes a decoding algorithm with the same decoding radius as BlackBoxDec.\nFrom now we suppose that κ = A/(π) is a ﬁnite ﬁeld. Every element of B = A/(π r ) can be uniquely written as uπ s , where u ∈ B × and 0 ≤ s ≤ r − 1.\nInput: A positive integer τ ≤ n, a received vector y of (A/(p r )) n (with zero or more erasures) and a black box decoding algorithm BlackBoxDec for C(π).\n2: S ← the set returned by the call to Algorithm 2 with input τ , 0, r, y and BlackBoxDec.\nRS codes are free splitting codes over B by Proposition 7 so we can apply Algorithm 4 to RS codes. Complexities of decoding with Algorithm 4 are given by the following proposition which is a direct consequence of Proposition 9.\nExample-proposition 10. Suppose that C is a RS code over B. If B = GR(p r , s) (the unique Galois extension over Z/pZ of degree s) then\n\u2022 if BlackBoxDec is the unique decoding algorithm of [15] (that can decode up to τ = d−1 2 errors) then Algorithm 4 can decode up to τ errors in O(rnks log p) bit operations,\n\u2022 if BlackBoxDec is the Guruswami-Sudan list decod- ing algorithm of [13, Corollary 3.3, page 36] (that can decode up to J = n − (k − 1)n − 1 errors) then Algorithm 4 can list decode up to J errors in O [n(|κ| − 1)] r−1 n 7 k 5 s log p bit operations.\n\u2022 if BlackBoxDec is the unique decoding algorithm of [15] (that can decode up to τ = d−1 2 errors) then Algorithm 4 can decode up to τ errors in O(rnk) arithmetic operations over κ.\n\u2022 if BlackBoxDec is the Guruswami-Sudan list decod- ing algorithm of [13, Corollary 3.3, page 36] (that can decode up to J = n − (k − 1)n − 1 errors) then Algorithm 4 can list decode up to J errors in O [n(|κ| − 1)] r−1 n 7 k 5 arithmetic operations over κ.\nWe show that if we choose a decoding algorithm able to handle errors and erasures for BlackBoxDec then we can decode, with a non negligible probability, further than half the minimum distance and further than the Johnson bound.\nDeﬁnition 11. Following the terminology of [16, Subsec- tion 2.1, page 404] we say that an element of B has ﬁltration s if it is written uπ s where u ∈ B × .\nWe let q be the cardinality of κ. Then the cardinality of B is q r while the cardinality of A/(π s ) A/(π s+1 ) is q.\nProposition 12. Let C be a splitting code over B with parameters [n, k] B . Suppose that erasures occurred and that BlackBoxErasuresDec is provided as the\nInput: A received vector y of κ n with erasures and at most τ ( ) errors.\nOutput: All the codewords within distance τ ( ) + of y or ∅ (FAILURE).\nBlackBoxDec argument to Algorithm 4. The number of error vectors of weight w that can be corrected by Algorithm 4 is at least\nV w = {(v 0 , . . . , v r−1 ) ∈ N r : v 0 + · · · + v r−1 = w and 0 ≤ v 0 ≤ τ ( ) and 0 ≤ v i−1 ≤ τ ( + v 0 + · · · + v i−2 )\nProof: Let e ∈ B n be an error vector. We let v i (e) for i = 1, . . . , r − 1 denote the number of coordinates of e of ﬁltration i. The number of error vectors e ∈ B n such that (v 0 (e), . . . , v r−1 (e)) ∈ V w is given by formula (5). Let c be a codeword of C and y = c + e with v i = v i (e) for i = 0, . . . , r − 1 and (v 0 , . . . , v r−1 ) ∈ V w . The rest of the proof is similar to the proof of Proposition 8.\nProposition 13. Let C be a splitting code over B with parameters [n, k, d] B . Then there exists a decoding algorithm such that τ ( ) = d− −1 2 .\nProof: This is a consequence of [17, Theorem 1.7, page 16].\nProposition 14. Let C be a Reed-Solomon code over B with parameters [n, k, d = n − k + 1] B then there exists\n\u2022 a unique decoding algorithm which can correct errors and erasures with τ ( ) = n− −k 2 ,\n\u2022 a list decoding algorithm which can correct errors and erasures with τ ( ) = (n − ) − (k − 1)(n − ) − 1 and\n\u2022 a unique decoding algorithm which can correct up to w errors and erasures with w ≤ n − − k and which does succeed for a fraction of at least P ( , B, w) error patterns.\nIn addition the costs of Algorithm 4 are the same as the ones given in Proposition 10.\nProof: For the ﬁrst item, see for example [10, Section 4, page 7 and 8] while for the second item see [14, Theorem 16, page 1762]. The third item is a consequence of the ﬁrst item and Proposition 12.\nIn this section we let A be the power series ring over the ﬁnite ﬁeld F q namely we let A = F q [[t]], π = t and B = F q [[t]]/(t r ). We recall the construction of interleaved codes and show that all interleaved codes over F q are exactly codes over B. We let C be a linear code over F q with parameters [n, k, d] F q and with generator matrix G .\nLet r messages m 0 , . . . , m r−1 ∈ F k q and their encodings c 0 = m 0 G , . . . , c r−1 = m r−1 G . For i = 0, . . . , r − 1 and j = 1, . . . , n deﬁne c ij to be the j-th coordinate of c i and s j = (c 0,j , . . . , c r−1,j ).\nc 0,1 \t c 0,2 . . . \t c 0,n → c 0 c 1,1 \t c 1,2 . . . \t c 1,n → c 1\n↓ \t ↓ \t ↓ s 1 \t s 2 \t s n\nThe vectors transmitted over the channel are not c 1 , . . . , c r−1 ∈ F n q but s 1 , . . . , s n ∈ F r q . We will make an abuse of notation and call such an encoding scheme a interleaved code with respect to C and of degree r. Usually the vector s j (for j = 1, . . . , n) is seen as an element of F q r , but we can associate the element r−1 i=0 c i,j t i ∈ B to s j . In this context, if y = (y 1 , . . . , y n ) ∈ (F r q ) n , the weight of y is the nonnegative integer |{i ∈ {1, . . . , n} : y i = 0}| and if y corresponds to the received word then the weight of the error is |{i ∈ {1, . . . , n} : y i = s i }|.\nProposition 15. The words transmitted over the channel using interleaved linear codes are precisely the transmitted words using linear codes over truncated power series.\nProof: Let G = G be the generator of the linear code C over B with parameters [n, k, ≤ d] B , then C/tC = C . We have c i = m i G for i = 0, . . . , r − 1. As a consequence we have\nThis shows that the transmitted words using inter- leaved linear codes correspond exactly to codewords of C. Moreover the weight of (s 1 , . . . , s n ) as de- ﬁned above is the same as the Hamming weight of\n9 \t 0.81 \t 0.94 0.96 0.97 0.98 10 \t 0.49 \t 0.80 0.88 0.91 0.91 11 0.0073 0.53 0.70 0.75 0.78 12 0.00012 0.14 0.38 0.48 0.53\n22 1.00000 1.00000 1.00000 1.00000 23 0.999997 0.999999 0.999999 0.999999 25 0.999844 0.999963 0.999981 0.999987 27 0.998099 0.999469 0.999715 0.999789 28 0.995114 0.998531 0.999185 0.999391 29 0.989079 0.996477 0.997984 0.998470 30 0.978112 0.992458 0.995554 0.996581\nTheorem 16. Given a linear code C over F q with parameters [n, k, d] F q and a unique decoding algorithm BlackBoxErasuresDec from errors and erasures that can correct erasures and τ ( ) errors in Dec(C ) arithmetic operations over F q , there exists a unique decoding algorithm for interleaved codes with respect to C and of degree r from errors and erasures that can correct erasures and τ ( ) errors with at most rDec(C ) arithmetic operations over F q . Moreover it can correct at least a fraction of P ( , B, w) error patterns of Hamming weight at most w > τ ( ) over B where P is deﬁned by (6), also with at most rDec(C ) arithmetic operations over F q .\nProof: As G = G there is no need to lift a codeword from C into C and the given complexities are a consequence of Proposition 9. The existence of both algorithm is ensured by Proposition 15 and Proposition 12.\nIn Tables 1 and 2, the ﬁrst row gives the degrees of interleaving and the ﬁrst column shows the number of errors up to which we want to decode. The second row corresponds to half the minimum distance and, as expected, all of the probabilities are 1.0. We can see that the fraction of corrigible error patterns increases with the degree of interleaving and that codes with a high minimal distance are good candidates for interleaving.\nIn this paper we designed a decoding algorithm based on a lifting decoding scheme. It allowed us to obtain a unique decoding algorithm for RS codes over Galois rings with a low complexity. We also applied this scheme to get a list decoding algorithm for RS codes over Galois rings. We then show that using erasures at appropriate positions in the proposed algorithms allows us to decode more errors than half the\nminimum distance. Finally we applied these techniques to decode interleaved linear codes over a ﬁnite ﬁeld and get a decoding algorithm that can decode more errors than half the minimum distance.\nThe author would like to thank Daniel Augot for his pre- cious advice and readings of this article and Gr´egoire Lecerf for his careful readings of this article. The author would also like to thank the reviewers who helped improve this article."},"refs":[{"authors":[{"name":"M. A. Armand"}],"title":{"text":"Improved list decoding of generalized Reed-Solomon and alternant codes over rings"}},{"authors":[],"title":{"text":"Improved list decoding of generalized Reed-Solomon and alter- nant codes over Galois rings"}},{"authors":[],"title":{"text":"List decoding of generalized Reed-Solomon codes over commu- tative rings"}},{"authors":[{"name":"M. A. Armand"},{"name":"O. de Taisne"}],"title":{"text":"Multistage list decoding of general- ized Reed-Solomon codes over Galois rings"}},{"authors":[{"name":"N. Babu"},{"name":"K.-H. Zimmermann"}],"title":{"text":"Decoding of linear codes over Galois rings"}},{"authors":[{"name":"D. Bleichenbacher"},{"name":"A. Kiayias"},{"name":"M. Yung"}],"title":{"text":"Decoding of Interleaved Reed Solomon Codes over Noisy Data"}},{"authors":[{"name":"E. Byrne"}],"title":{"text":"Lifting Decoding Schemes over a Galois Ring"}},{"authors":[{"name":"D. Coppersmith"},{"name":"M. Sudan"}],"title":{"text":"Reconstructing curves in three (and higher) dimensional space from noisy data"}},{"authors":[{"name":"M. F¨urer"}],"title":{"text":"Faster Integer Multiplication"}},{"authors":[{"name":"S. Gao"}],"title":{"text":"A New Algorithm for Decoding Reed-Solomon Codes"}},{"authors":[{"name":"P. Gopalan"},{"name":"V. Guruswami"},{"name":"P. Raghavendra"}],"title":{"text":"List Decoding Tensor Products and Interleaved Codes"}},{"authors":[{"name":"M. Greferath"},{"name":"U. Vellbinger"}],"title":{"text":"Efﬁcient decoding of Z p k -linear codes"}},{"authors":[{"name":"V. Guruswam"}],"title":{"text":"List decoding of error-correcting codes: winning thesis of the 2002 ACM doctoral dissertation competition , ser"}},{"authors":[{"name":"V. Guruswami"},{"name":"M. Sudan"}],"title":{"text":"Improved Decoding of Reed-Solomon and Algebraic-Geometric Codes"}},{"authors":[{"name":"J. Justesen"}],"title":{"text":"On the complexity of decoding Reed-Solomon codes (Corresp.)"}},{"authors":[{"name":"M. Lazard"}],"title":{"text":"Graduations, ﬁltrations, valuations"}},{"authors":[{"name":"R. Rot"}],"title":{"text":"Introduction to coding theory"}},{"authors":[{"name":"M. Sudan"}],"title":{"text":"Decoding Reed-Solomon codes beyond the error-correction diameter"}},{"authors":[{"name":"S. Wicke"},{"name":"V. Bhargav"}],"title":{"text":"Reed-Solomon Codes and Their Applica- tions "}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566275.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T5.4","endtime":"11:10","authors":"Guillaume Quintin","date":"1341226200000","papertitle":"A Lifting Decoding Scheme and its Application to Interleaved Linear Codes","starttime":"10:50","session":"S1.T5: List Decoding and Reed-Solomon Codes","room":"Kresge Little Theatre (035)","paperid":"1569566275"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
