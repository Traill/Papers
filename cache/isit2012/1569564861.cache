{"id":"1569564861","paper":{"title":{"text":"Access vs. Bandwidth in Codes for Storage"},"authors":[{"name":"Itzhak Tamo ∗ \u2020"},{"name":"Zhiying Wang ∗"},{"name":"Jehoshua Bruck ∗"}],"abstr":{"text":"Abstract\u2014Maximum distance separable (MDS) codes are widely used in storage systems to protect against disks (nodes) failures. An ( n, k, l ) MDS code uses n nodes of capacity l to store k information nodes. The MDS property guarantees the resiliency to any n − k node failures. An optimal bandwidth (resp. optimal access) MDS code communicates (resp. accesses) the minimum amount of data during the recovery process of a single failed node. It was shown that this amount equals a fraction of 1/ ( n − k ) of data stored in each node. In previous optimal bandwidth constructions, l scaled polynomially with k in codes with asymptotic rate < 1. Moreover, in constructions with constant number of parities, i.e. rate approaches 1, l scaled exponentially w.r.t. k. In this paper we focus on the practical case of n − k = 2, and ask the following question: Given the capacity of a node l what is the largest (w.r.t. k) optimal bandwidth (resp. access) ( k + 2, k, l ) MDS code. We give an upper bound for the general case, and two tight bounds in the special cases of two important families of codes."},"body":{"text":"Erasure-correcting codes are the basis for widely used storage systems, where disks (nodes) correspond to symbols in the code. An important family of codes is the Maximum distance separable (MDS) codes, which provide an optimal resiliency to erasures for a given amount of redundancy. Namely, an MDS code with r redundancy (parity) symbols can recover the information from any r symbol erasures. Because of this storage efﬁciency, MDS codes are highly favorable, and a lot research has been done to construct them. Examples of MDS codes are the well known Reed Solomon codes and EVENODD. It is evident that in the case of r erasures, one needs to communicate the entire surviving information during the recovery process. However, although the MDS codes used in practice, are resilient to more than a single erasure, i.e. number of parity nodes r > 1, the practical and more interesting question is; what is the minimum repair bandwidth in a single node erasure. The repair bandwidth is deﬁned as the amount of information communicated during the recovery process. This question has received much interest recently due to both its practical and theoretical importance. From a practical point of view, decreasing the repair bandwidth makes both the recovery process, and the inaccessibility time of the erased information, shorter. Moreover, from the theoretical perspective this question has deep connections to the widely used interference alignment technique and network coding.\nThe problem of efﬁcient recovery was deﬁned by Dimakis et. al. in [4]. It considers a ﬁle of size M divided into k equally sized chunks stored using an ( n, k, l ) MDS code,\nwhere n is the number of nodes, each of capacity l = M k . The ﬁrst k nodes referred as the systematic nodes, store the raw information. The later r = n − k nodes are the parity nodes who store a function of the raw information. Since the code is MDS it can tolerate any loss of up to r nodes. However, the more common scenario is the failure (erasure) of only one node. [4] proved that\nis a lower bound on the repair bandwidth for an ( n, k, l ) MDS code. In particular, for a code with r = 2 parities, the repair bandwidth for each surviving node is l 2 , i.e. at least one half of its information needs to be communicated. Note that recovery is possible since the code is resilient to more than one erasure, and a repair strategy of communicating the entire remaining information sufﬁces. An MDS code is termed optimal bandwidth if it achieves the lower bound in (1) during the recovery process of all of its systematic nodes 1 . Figure 1 shows an optimal bandwidth ( 6, 4, 2 ) MDS code. For recovering an erased node, one bit of information is transmitted to the repair center from each surviving node. In some applications such as data centers, reading (accessing) the information is more costly than transmitting it. Therefore during a recovery process, the need to transmit data that is a function of a large portion of the information stored within a node, can cause a bottleneck. E.g., node N1 needs to access its entire stored information, for it to calculate a + w, during the recovery process of node N3. Therefore, in a large scale storage systems, one might need to minimize not only the amount of information transmitted, but also the number of accessed information elements. An optimal access MDS code\nis an optimal bandwidth code that transmits only the elements it accesses. By deﬁnition, any optimal access code is also an optimal bandwidth code. The shortened code restricted to nodes { N 1 , N 2 , Parity 1, Parity 2 } in Figure 1 is an example of an optimal access ( 4, 2, 2 ) MDS code.\nIn a value\u2019s update of a stored element, one needs to update each parity node at least once. To avoid an overload on the system during a frequent operation such as updating, one needs to design an optimal update code, that updates exactly once in each parity node, when an element changes its value. E.g. in Figure 1 the shortened code restricted to nodes { N 3 , N 4 , Parity 1, Parity 2 } is an optimal update and optimal bandwidth ( 4, 2, 2 ) MDS code, because, updating any of the elements c, d, y, z will require updating exactly one element in each of the parity nodes.\nVarious codes [4], [7]\u2013[9], [11], [15]\u2013[17] were constructed with the goal to have optimal bandwidth, however these constructions all have low rate, i.e., k/n ≤ 1/2. In [9], [11], [17] the key idea was using vector coding. Namely, each symbol in a codeword is a vector and not scalar as in \u201cstandard\u201d codes. Speciﬁcally [9], [11] constructed optimal bandwidth ( 2k, k, k ) MDS codes. Using interference alignment it was shown in [3] that the bound in (1) is asymptotically achievable also for high rate codes ( k/n ≥ 1/2) . The question of existence of optimal bandwidth codes with high rate, was resolved in several constructions [1], [2], [5], [6], [12], [13], [18]. The constructions have an arbitrary number of parity nodes r, however when r is constant, i.e. rate approaching 1 in all of the constructions k = O ( log r l ) , i.e., the capacity l scales exponentially with the number of systematic nodes k.\nOur main goal in this paper is to understand the relation between l the capacity of each node, and the number of systematic nodes k. More precisely, given the capacity of the node l, what is the largest integer k, such that there exists an optimal bandwidth or optimal access ( k + 2, k, l ) MDS code. We will derive three upper bounds on k as a function of only l, for different families of codes. To derive the bounds we use 3 different combinatorial techniques. The ﬁrst bound considers the general problem, where no requirements on the MDS code are imposed except the optimal bandwidth property. The bound is derived by deﬁning an appropriate set of multivariate polynomials. We proceed by deriving a tight bound for optimal bandwidth MDS codes with diagonal encoding matrices. These\ncodes are a part of an important family of codes with an optimal update property. The last result provides a tight bound on optimal access MDS codes. Table I summarizes the known results together with our new results. Due to space limitation we only consider the more practical case of r = 2 parities, although the results can be extended to an arbitrary r. Some of the proofs are also omitted and can be found in [14].\nConsider a ﬁle of size M = kl, divided into k nodes of capacity l. Each systematic node 1 ≤ i ≤ k is represented by an l × 1 vector a i ∈ F l p over the ﬁeld F p . We construct an ( k + 2, k, l ) MDS code by adding parity nodes k + 1 and k + 2, which will give the resiliency to node erasures. Parity node k + i for i ∈ { 1, 2 } stores the information vector a k+i of length l over F p , and is deﬁned as\nWhere A i , B i are square matrices of order l, which are called the encoding matrices. Note that the code has a systematic structure, i.e., the ﬁrst k nodes store the information itself, and not a function of it. Therefore, the code is deﬁned uniquely by the matrix\nThe code is called an MDS if it can recover from any 2 node erasures, which is equivalent to any 1 × 1 and 2 × 2 block sub matrix in (2) is invertible. In a scenario of an erasure of a systematic node i, 1 ≤ i ≤ k, a linear combination of the information stored in the parity nodes is transmitted in order to recover the lost data. Namely, the parity nodes k + 1, and k + 2, project their data on the recovering subspaces S i , T i of dimension l/2, respectively. In other words, the transmitted information from parity nodes k + 1, k + 2 during the recovery process of systematic node i ∈ [ k ] is the projection S i a k+1 , T i a k+2 respectively. where each subspace S i , T i is represented by an l/2 × l matrix whose rows form a basis of the subspace. In general, each subspace will be represented by a matrix whose rows form a basis of the subspace. Recovering the lost information is possible if\nMoreover, the recovery process is optimal bandwidth if for each j = i,\nSimilar conditions were derived in [9]. Therefore an optimal bandwidth algorithm for the systematic nodes is deﬁned by the pairs of recovering subspaces ( S i , T i ) that satisfy (3), (4) for 1 ≤ i ≤ k. For any integer k denote by [ k ] = { 1, ..., k } . For simplicity we will assume that the capacity of each node l, is a power of 2, and all the logarithms are of base 2.\nThe remainder of the paper is organized as follows. Section II deﬁnes the subspace property for a set of matrices, and shows the equivalency of this property to optimal bandwidth codes. Section III provides an upper bound for the most gen- eral case, i.e., an MDS code with optimal bandwidth property. We proceed in Section IV where a tight bound is derived for codes with diagonal encoding matrices. In SectionV a tight bound for codes with optimal access property is derived. We conclude with a summary in Section VI .\nIn this section we deﬁne the Subspace Property for a set of invertible matrices, and show its connection to optimal bandwidth MDS codes.\nSubspace Property: A set of invertible matrices C 1 , ..., C k of order l, is said to satisfy the subspace property, if there exists a set of subspaces S 1 , ..., S k each of dimension l 2 , such that for any 1 ≤ i, j ≤ k,\nwhere { 0 } is the zero subspace, and S i C j is image of the action of the invertible matrix C j on the l/2-dimensional subspace S i . We start with a theorem that shows we can assume w.l.o.g, that an optimal bandwidth MDS code, has a certain structure. Where a subset of the encoding matrices satisfy the subspace property.\nTheorem 1 There exists an optimal bandwidth ( k + 2, k, l ) MDS code iff there exists an optimal bandwidth MDS code with the same parameters and encoding matrices\nsuch that the matrices C 1 , ..., C k−1 , satisfy the subspace prop- erty. Moreover, from any set C 1 , ..., C k−1 of invertible matrices of order l that satisfy the subspace property, we can construct over a ﬁeld large enough, an optimal bandwidth, ( m + 2, m, l ) MDS code, where k − 1 ≤ m ≤ k.\nBy the previous Theorem, we assume that any optimal bandwidth MDS code is of the form (6), with a set of matrices { C i } that satisfy the subspace properties. Therefore, we recast the recovering problem into a problem on a set of matrices which satisfy this property.\nTheorem 1 shows that constructing an optimal bandwidth MDS code with 2 parities is equivalent to ﬁnding a set of invertible matrices that satisfy the subspace property.\nWe start with the most general problem which seems to be the hardest of them all. We impose no constraints on the encoding matrices and the recovering subspaces. We derive an upper bound on the number of information nodes k in an optimal bandwidth ( k + 2, k, l ) MDS code. The bound is a function of only the capacity of the node l, regardless the ﬁeld size being used.\nBefore we prove the upper bound, for a set of indexes of equal size I, J deﬁne det ( B ) I,J to be the determinant of the matrix of B restricted to rows I and columns J.\nTheorem 3 Let C 1 , ..., C k be a set of matrices of order l over a ﬁeld F, together with a set of subspaces S 1 , ..., S k of dimension\n2 each, such that the subspace property is satisﬁed, then k ≤ l l l/2 .\nProof: Assume that each subspace i is represented by a matrix S i of dimension l 2 × l. For any 1 ≤ i ≤ k the matrix\nis of full rank, hence there exists a set of indexes I ⊂ [ l ] of size l 2 + 1 such that the l 2 + 1 × l 2 + 1 sub matrix restricted to the set of rows and columns, [ l 2 + 1 ] and I respectively, is invertible. Namely,\nthe sub matrix restricted to the same set of rows and columns is not of full rank (note that for distinct i\u2019s the set of indexes I might be different). Hence, the polynomial f i : F l 2 ×l → F, deﬁned by,\n \n \nand T 2 = { x 1,i : 1 ≤ i ≤ l } , where ( [l] l/2 ) is the set of l/2- subsets of [ l ] . Using (7) check that the polynomials { f i } are linearly independent, and they are spanned by the set\nCorollary 4 Let k be the largest integer, such that there exists an optimal bandwidth ( k + 2, k, l ) MDS code, then\nProof: The upper bound is a consequence of Corollary 2 and Theorem 3, the lower bound is given by the code constructed in [19].\nAs one can notice, there exists a big gap between the upper and the lower bound. We conjecture that the lower bound is more accurate, and in fact k = θ ( log l ) .\nWe proceed by giving a tight bound for the number of systematic nodes k in the case where all the encoding matrices are diagonal.\nOne of the most common operations in the maintenance of storage systems is updating. Namely, a certain element changed its value, and that needs to be updated in the system. Since the code is an MDS, each parity node is a function of the entire systematic nodes. Therefore in a single update, each parity node needs to be updated at least in one of the elements it stores. An optimal update code is one that needs to update each parity node exactly once in an update of any information element. We derive a tight bound in a special case of an optimal update code, where all the encoding matrices are diagonal. We begin with a simple Lemma on an entropy. Lemma 5 Let X be a random variable such that for any pos- sible outcome x, P ( X = x ) ≤ 1 2 , then its entropy satisﬁes\nBefore we proceed to prove the upper bound, recall that the meet of two partitions X, Y of some set, is deﬁned as,\nMoreover, for a set of indices x denote by span ( e x ) = span ( e i : i ∈ x ) , where e i is the i-th vector in the standard basis.\nTheorem 6 Let { C i } k i=1 be a set of invertible and simulta- neously diagonalizable matrices of order l, that satisfy the subspace property, then k ≤ log l.\nProof: Since the subspace property is preserved under similarity transformation we can assume that all the matrices C 1 , ..., C k are diagonal and the standard basis { e 1 , ..., e l } is a set of eigenvectors for all the matrices. Each matrix C i deﬁnes a partition X i of [ l ] , by m, n ∈ [ l ] are in the same set of the partition, iff the corresponding vectors e m , and e n , have the same eigenvalue in C i . Let j ∈ [ k ] , set S = S j and denote the meet of the partitions\nIt is clear that a vector v = 0 is an eigenvector for all the matrices C i , i = j iff v ∈ span ( e x ) , for some set x in the partition X. Assume S is represented in its reduced row echelon form. Since S is an invariant subspace for C i , i = j, it is clear that each row vector in S is an eigenvector for each of the matrices C i , i = j. Hence for each row of S, the set of indices of the nonzero entries is contained in some set of the partition X. Therefore,\nwhere S x = S ∩ span ( e x ) . Let x ∈ X, and note that dim ( S x ) = | x | /2. Since, if S x > | x | /2 and the fact that span ( e x ) is also an invariant subspace of C j we get S x C j , S x ⊂ span ( e x ) . Hence S x C j ∩ S x = { 0 } , which contradicts the subspace property. Moreover, since\nwe get that dim ( S x ) = | x | /2. Denote the partition of x by X j as x = { x ∩ y : y ∈ X j } . We claim that\nAssume to the contrary, that z ∈ x, | z | > | x | /2. Note that each v ∈ span ( e z ) is an eigenvector also for C j , and\nHence, S x ∩ span ( e z ) = 0, i.e., S x contains an eigenvector of C j which contradicts the subspace property, because\nPick randomly and with equal probability a vector v from the standard basis, and deﬁne for i ∈ [ k ] the random variable Y i to be the eigenvalue corresponding to the eigenvector v in C i . From (8) and by Lemma 5 we conclude that the entropy of Y j satisﬁes\nCorollary 7 Let k be the largest integer such that there exists an optimal bandwidth ( k + 2, k, l ) MDS code with diagonal encoding matrices, then k = 1 + log l.\nProof: The lower bound is given by the code constructed in [12].\nNote that when restricting to diagonal encoding matrices, there is no difference if the code is an optimal access or optimal bandwidth (see Table I). In the next section we show that these two properties are not equivalent in the general case.\nRecall that in an optimal bandwidth MDS codes the trans- mitted information can be a function of the entire information in the node. Namely, in order to generate the transmitted data, one has to access all the information stored in the node, which of course can be an expensive task. An optimal access code is an optimal bandwidth code that transmits only the elements it accesses. The property of Optimal Access is equivalent to that each recovering subspace S i is spanned by an l/2-subset of the standard basis e 1 , ..., e l , i.e., S i = span ( e m : m ∈ I ) for some I an l/2-subset of [ l ] .\nWe start with an useful lemma that shows that the set of subspaces S 1 , ..., S k do not have large intersections.\nLemma 8 Let C 1 , ..., C k be a set of matrices of order l, that satisfy the subspace property with the subspaces S 1 , ..., S k , then for any subset of indices J ⊆ [ k ]\nMoreover, The number of subspaces { S i } k i=1 that contain an arbitrary vector v = 0 is at most log l.\nThe previous Lemma shows that an arbitrary vector v = 0 can not belong to \u201ctoo many\u201d subspaces S i . This observation gives a tight bound on the number of nodes k in an optimal access code, as the following theorem shows.\nTheorem 9 Let C 1 , ..., C k be a set of invertible matrices of order l that satisfy the subspace property with subspaces S 1 , ..., S k . If each subspace S i is spanned by an l/2-subset of the standard basis e 1 , ..., e l , then k ≤ 2 log l.\nCorollary 10 Let k be the largest integer such that there exists an optimal access ( k + 2, k, l ) MDS code, then k = 2 log l.\nProof: The lower bound is derived by the code con- structed in [1], [19].\nNote that [19] constructed also an optimal bandwidth code with k = 3 log l. Therefore, in the general case where we do not require an optimal update code, there is a difference between optimal access and optimal bandwidth code. Namely, these two properties are not equivalent (see Table I).\nIn this paper we considered optimal bandwidth (resp. ac- cess) MDS codes with two parities. Speciﬁcally we asked, given the capacity of each node l what is the largest possible integer k such that there exists an optimal bandwidth (resp. access) ( k + 2, k, l ) MDS code. We used distinct combinatorial tools to derive 3 upper bounds on k. The ﬁrst bound considers\nthe general case of optimal bandwidth code. The last two bounds are tight, and they consider optimal access and optimal update codes. Moreover, we showed that in the general case, the properties of optimal bandwidth and optimal access are not equivalent. Although in some certain codes such as codes with diagonal encoding matrices, they are indeed equivalent. It is an open problem what is the longest optimal bandwidth code with capacity l .\nThis work was partially supported by an NSF grant ECCS- 0801795 and a BSF grant 2010075."},"refs":[{"authors":[{"name":"R. Cadambe"}],"title":{"text":"Poly- nomial Length MDS Codes with Optimal Repair in Distributed Storage Systems"}},{"authors":[{"name":"V. R. Cadambe"},{"name":"C. Huang"},{"name":"J. Li"}],"title":{"text":"Permutation code: optimal exact- repair of a single failed node in MDS code based distributed storage systems"}},{"authors":[{"name":"R. Cadambe"},{"name":"A. Jafar"}],"title":{"text":"Asymptotic Interference Alignment for Optimal Repair of MDS codes in Distributed Data Storage"}},{"authors":[{"name":"A. Dimakis"},{"name":"P. Godfrey"},{"name":"Y. Wu"},{"name":"M. Wainwright"},{"name":"K. Ramchandran"}],"title":{"text":"Network coding for distributed storage systems"}},{"authors":[{"name":"S. Papailiopoulos"},{"name":"G. Dimakis"}],"title":{"text":"Distributed Storage Codes through Hadamard Designs"}},{"authors":[{"name":"S. Papailiopoulos"},{"name":"G. Dimakis"},{"name":"R. Cadambe"}],"title":{"text":"Repair Optimal Erasure Codes through Hadamard Designs"}},{"authors":[{"name":"K. V. Rashmi"},{"name":"N. B. Shah"},{"name":"P. V. Kumar"},{"name":"K. Ramchandran"}],"title":{"text":" Explicit construction of optimal exact regenerating codes for distributed storage"}},{"authors":[{"name":"K. V. Rashmi"},{"name":"N. B. Shah"},{"name":"P. V. Kumar"}],"title":{"text":"Enabling node repair in any erasure code for distributed storage"}},{"authors":[{"name":"N. B. Shah"},{"name":"K. V. Rashmi"},{"name":"P. V. Kumar"},{"name":"K. Ramchandran"}],"title":{"text":"Interfer- ence alignment in regenerating codes for distributed storage: necessity and code constructions"}},{"authors":[{"name":"N. B. Shah"},{"name":"K. V. Rashmi"},{"name":"P. V. Kumar"},{"name":"K. Ramchandran"}],"title":{"text":"Dis- tributed storage codes with repair-by-transfer and non-achievability of interior points on the storage-bandwidth tradeoff"}},{"authors":[{"name":"C. Suh"},{"name":"K. Ramchandran"}],"title":{"text":"Exact-repair MDS codes for distributed storage using interference alignment"}},{"authors":[{"name":"I. Tamo"},{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"MDS array codes with optimal rebuilding"}},{"authors":[{"name":"I. Tamo"},{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"Zigzag Codes: MDS Array Codes with Optimal Rebuilding"}},{"authors":[{"name":"I. Tamo"},{"name":"Z. Wang"},{"name":"J. Bruck"}],"title":{"text":"Access Vs. Bandwidth in Codes for Storage"}},{"authors":[{"name":"Y. Wu"},{"name":"R. Dimakis"},{"name":"K. Ramchandran"}],"title":{"text":"Deterministic regenerating codes for distributed storage"}},{"authors":[{"name":"Y. Wu"}],"title":{"text":"Existence and construction of capacity-achieving network codes for distributed storage"}},{"authors":[{"name":"Y. Wu"},{"name":"A. Dimakis"}],"title":{"text":"Reducing repair trafﬁc for erasure coding-based storage via interference alignment"}},{"authors":[{"name":"Z. Wang"},{"name":"I. Tamo"},{"name":"J. Bruck"}],"title":{"text":"On Codes for Optimal Rebuilding Access"}},{"authors":[{"name":"Z. Wang"},{"name":"I. Tamo"},{"name":"J. Bruck"}],"title":{"text":"Long MDS Codes for Opti- mal Repair Bandwidth"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569564861.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S7.T5.2","endtime":"15:20","authors":"Itzhak Tamo, Zhiying Wang, Jehoshua Bruck","date":"1341327600000","papertitle":"Access vs. Bandwidth in Codes for Storage","starttime":"15:00","session":"S7.T5: Regenerating Codes","room":"Kresge Little Theatre (035)","paperid":"1569564861"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
