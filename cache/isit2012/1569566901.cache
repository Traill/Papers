{"id":"1569566901","paper":{"title":{"text":"Expurgated Inﬁnite Constellations at Finite Dimensions"},"authors":[{"name":"Amir Ingber"},{"name":"Ram Zamir"}],"abstr":{"text":"Abstract\u2014We revisit the setting of a Gaussian channel without power constraints, proposed by Poltyrev, where the codewords are points in Euclidean space and their density is considered instead of the communication rate. We reﬁne the expurgation technique (proposed by Poltyrev for the derivation of the error exponent) to the ﬁnite dimensions case and obtain a ﬁnite- dimensional achievability bound. While the expurgation exponent improves upon the random coding exponent only for certain rates (below a rate known as δ ex ), we show that for ﬁnite dimensions the expurgation technique is useful for a broader range of rates. In addition, we present precise asymptotical analysis of the expurgation bound and ﬁnd the sub-exponential terms, which turn out to be non-negligible."},"body":{"text":"Communication schemes over the Gaussian channel are traditionally limited by the power of the transmitted signal [1], as without such limitation the channel capacity becomes inﬁnite, since one can space the codewords arbitrarily far apart from each other and achieve a vanishing error probability. However, many coded modulation schemes take an inﬁnite constellation (IC) and restrict the usage to points of the IC that lie within some n-dimensional \u2019shaping\u2019. A main example for an IC is a lattice [2], and examples for the shaping regions include a hypersphere in n dimensions, and a Voronoi region of another lattice [3].\nIn 1994, Poltyrev [4] studied the model of a channel with Gaussian noise without power constraints, where the codewords are simply points in the n-dimensional Euclidean space. The analog to the number of codewords is the density γ of the constellation points (the average number of points per unit volume) and the analog of the communication rate is the normalized log density (NLD) δ 1 n log γ (since rate cannot be deﬁned here in its usual meaning as the log of the number of codewords per dimension). The error probability in this setting can be thought of as the average error probability, where all the points of the IC have equal transmission probability. Poltyrev showed that the NLD δ is the analog of the rate in classical channel coding, and established the analog term to the capacity, the highest achievable NLD for coding on the un- constrained Gaussian channel with vanishing error probability, denoted δ ∗ . Random coding, sphere packing and expurgation error exponent bounds were also derived, which are analogous\nto Gallager\u2019s error exponents in the classical channel coding setting [5], and to the error exponents of the power-constrained AWGN channel [6], [5]. Recently, Poltyrev\u2019s setting was revisited with an emphasis on ﬁnite-dimensions [7], where explicit bounds (both upper and lower) on the error probability were derived. Those bounds can be used to derive reﬁnements for the random coding and sphere packing error exponents for the setting, as well as to derive a channel dispersion result [7][8]. The main interest and strongest results of [7] are above the critical NLD δ cr which plays the same role of the critical rate in classic channel coding [5].\nIn this paper we consider the expurgation technique as a tool to obtain achievability bounds for low NLD values, namely be- low the rate termed δ ex [4], a rate below which the expurgation technique gives a better error exponent than the random coding technique. We particularize the expurgation technique for ﬁnite dimensions and obtain an achievability bound that is explicit for any dimension n (where the expurgation exponent is only an asymptotic result). For ﬁnite dimensions, we demonstrate numerically that the expurgation technique improves upon the random coding technique also for rates that are above δ ex (and not only below δ ex , as in the error exponent case). In addition, the bound is evaluated asymptotically (for ﬁxed δ), and the exponential form of the bound is re-derived. We also ﬁnd the sub-exponential terms in the approximation, and it turns out that they are polynomial, with degree that depends on the distance from capacity.\nWe adopt most of the notations of Poltyrev\u2019s paper [4]: Let Cb(a) denote a hypercube in R n :\nLet Ball (y, r) denote a hypersphere in R n and radius r > 0, centered at y ∈ R n :\nand let Ball (r) denote Ball(0, r). V n \t π n/2 Γ(n/2+1) denotes the volume of an n dimensional hypersphere with radius 1 [2].\nLet S be an IC. We denote by M(S, a) the number of points in the intersection of Cb(a) and the IC S, i.e. M(S, a)\n|S Cb(a) |. The density of S, denoted by γ(S), or simply γ, measured in points per volume unit, is deﬁned by\na n . \t (3) The normalized log density (NLD) δ is deﬁned by 1\nDeﬁnition 1 (Expectation over a hypercube): Let f : S → R be an arbitrary function. Let E a [f (s)] denote the expectation of f (s), where s is drawn uniformly from the code points that reside in the hypercube Cb(a):\nThroughout the paper, an IC will be used for transmission of information through the unconstrained AWGN channel with noise variance σ 2 (per dimension). The additive noise shall be denoted by Z = [Z 1 , ..., Z n ] T . An instantiation of the noise vector shall be denoted by z = [z 1 , ..., z n ] T .\nFor s ∈ S, let P e (s) denote the error probability when s was transmitted. When the maximum likelihood (ML) decoder is used, the error probability is given by P e (s) = Pr{s + Z / ∈ W (s)}, where W (s) is the Voronoi region of s, i.e. the convex polytope of the points that are closest to s than to any other point s \u2032 ∈ S (in the Euclidean sense). The maximal error probability is deﬁned by\nand the average error probability is deﬁned by P e (S) lim sup\nOur achievability results are based on lattices where all Voronoi regions are congruent. Therefore for a lattice Λ,\nIt is known [4] that whenever δ < δ ∗ \t 1 2 log 1 2πeσ 2 , a vanishing error probability can be achieved. In other words, δ ∗ is the capacity for the setting (and also known as the \u201cPoltyrev Capacity\u201d).\nAs in classical channel coding, the exact value of the error exponent E (δ) is not known for all NLD values δ, but only\nbounds are available. In his paper [4], Poltyrev showed that the following exponent is achievable:\n(10) where\nPoltyrev initially used a random coding-like argument in order to derive the achievability exponent bounds. This bound yields a value of δ ∗ − δ + 1 2 log e 4 for all rates below δ cr . For rates below δ ex , an expurgation method was used in order to improve the exponent. It should be noted that only above δ cr the upper bound for the exponent (the sphere packing exponent [4]) coincides with the lower bound. In the current paper we reﬁne the expurgation technique, and obtain better error probabilities even for δ ex ≤ δ ≤ δ cr . Before we present the new bound, we review the main tool used in such bounds, namely the Minkowski-Hlawka-Siegel (MHS) theorem and the MHS ensemble.\nThe MHS theorem states that there exists a random ensem- ble of lattices with density γ, denoted L, with the following property [9, Theorem 5, p. 205] (see also [10]):\nLet f : R n → R + be a real nonnegative integrable function with bounded support. Denote f (Λ) \t λ∈Λ\\{0} f (λ). Then the following holds:\nwhere E L denotes expectation w.r.t. the random ensemble L. An immediate corollary is that there must exist at least one lattice Λ that satisﬁes\nThis is the main tool used in the achievability proof. We shall later on prove that most of the lattices in L have a good minimum distance, a fact that will facilitate the new result.\nBefore we present the expurgation bound, it is pedagogical to ﬁrst review a simpler bound which is based on a union bound. The expurgated bound is best understood as a modiﬁ- cation of this bound.\nTheorem 1 (Union Upper Bound): For any NLD δ and any ξ > 0, there exists a lattice Λ with density γ and error probability upper bounded by\nProof: The proof follows by taking the union bound of all pair-wise error events: Let Λ be an arbitrary lattice, and assume w.l.o.g. that the zero codeword was sent. Let r 0 be a given noise radius. Then the error probability is upper bounded (using the union bound) by\nwhere Q(x) = 1 √ 2π ∞ x e −t 2 /2 dt and ˜ Q (x) is deﬁned to be Q(x) when x ≥ r 0 /σ and zero elsewhere.\nSince ˜ Q(·) has a bounded support, we may use the MHS theorem and conclude that there exists a lattice Λ s.t.\nThe last step (which follows by elementary algebraic manipu- lations of the integral) leads to (14). r 0 can be arbitrarily large to ﬁt ξ that is arbitrarily small so the proof is concluded.\nTheorem 2 (Union Upper Bound Asymptotics): Fix \t the NLD δ. Then as n grows,\nProof: Immediate by the Stirling approx. for Γ[z]. Notes:\n1) This bound is different from the ML bound in [7] (an explicit ﬁnite-dimensional version of the random coding bound [7]). In fact, the UUB can be viewed as the ML bound with r = ∞.\n2) Numerically, The UUB is only slightly weaker than the ML bound δ < δ cr . As expected, for δ > δ cr the ML bound is much better since they have different exponents.\n3) The resulting exponent is of a straight line, as expected (and as seen in the DMC case [5]). The exponent keeps its straight-line form for any δ (since (16) holds for any δ).\nThe minimum distance of a lattice Λ, denoted d min (Λ), is given by the minimal distance of any two lattice points. It appears that most of the lattices in the ensemble L have good minimum distance:\nLemma 1 (Most lattices in L have good d min ): Let r eﬀ = (γV n ) −1/n ( r eﬀ is the radius of a sphere with the same volume as a Voronoi cell of the lattice). Set a value for 0 ≤ α < 1. Let Λ be drawn from the random ensemble L. Then,\nProof: For a set S, denote by N S (Λ) the number of nonzero lattice points in S ∩ Λ.\n(a) follows from the fact that for any Λ s.t. d min (Λ) < αr eﬀ , then N Ball (αr eff ) (Λ) ≥ 1. (b) follows from the MHS theorem used with the characteristic function of Ball (αr eﬀ ). (c) follows from the deﬁnition of r eﬀ .\nDeﬁnition 2 (Expurgated ensemble): The ensemble L x contains all the lattices in L whose minimum distance is at least αr eﬀ .\nFor any bounded-support nonnegative function f : R n → R + , the following holds:\nProof: Denote by A the event where a lattice drawn from L satisﬁes d min (Λ) ≥ αr eﬀ . Therefore an average of f (Λ) w.r.t. L x can be written as E L [f (x)|A].\nTheorem 3: There exists a lattice Λ whose error probability is upper bounded by\nfor any dimension n, any parameter 0 ≤ α < 1, and ξ > 0 arbitrarily small. P XB e (n, δ, α) is given by\nClearly, α can be optimized, and hence we deﬁne P XB e (n, δ) \t inf\nProof: Let Λ be a given lattice. We start with the union bound as in Theorem 1:\nfor λ ≥ αr eﬀ and zero elsewhere. Therefore for all the lattices in L x we have\nWe use Lemma 2, Lemma 1 and the MHS theorem, and conclude that there exists a lattice Λ with\nNotes: 1) For α arbitrarily close to 1 (from below), for large enough n the term 1 1−α n goes to 1 and the behavior of the term is governed by the integral. 2) For α = 0 the bound reduces to Theorem 1. 3) For ﬁxed n, α can be optimized in order to give the best bound.\nWe now wish to analyze the ﬁnite-dimensional expurgation bound further in order to get an analytical bound and a precise asymptotic form.\nTheorem 4: Let ρ ∗ r 2 eff nσ 2 . Then for any dimension n > 3, α ∈ (0, 1) s.t. α 2 ρ ∗ − 4 + 12 n > 0, the expurgation bound P XB e (n, δ, α) is upper bounded by\n(32) where ρ ∗ r 2 eff nσ 2 .\nNote that as n grows, the condition α 2 ρ ∗ −4+ 12 n > 0 translates to δ < δ ex + log α.\n(a) follows from the well known bound on the Q function: Q(x) ≤ 1 √ 2πx e −x 2 /2 for all x > 0. (b) follows from the following technical lemma:\nLemma 3: Let n ∈ N and x ∈ R s.t. n > 3 and x > 4− 12 n . Then\nn x − 4 + 12 n . \t (34) The detailed proof of the lemma is omitted. The proof follows from the fact that the logarithm of the integrand of the LHS of (34) is concave, and therefore can be upper bounded by its ﬁrst-order taylor series. The modiﬁed integral converges for x > 4 − 12 n and therefore (34) follows. The technique is similar [7, Lemma 2].\nThe above derivation is useful since it gives a bound that does not require numeric calculation of unsolvable integrals. In addition, it can lead to more precise asymptotic analysis.\nTheorem 5: For ﬁxed NLD δ, the following error probabil- ity is asymptotically achievable:\n, (35)\nProof: the upper bound ¯ P XB e (n, δ, α) is asymptotically given by\nThe proof follows from (33), and the approximations of V n and ρ ∗ (see [7, Eqs. (64)-(68)]).\nWe now select α = 1 − β n since any other selection would weaken the bound by a non-constant factor. Since\n1 − β n n/2 = e −β/2 + O(log(n)/n), we arrive at (35) with K \u2032 given in (36). Further optimizing w.r.t. β gives (37).\nNotes: 1) The precise asymptotic form in Theorem 5 reveals the sub-exponential term in the expurgation \u2018exponent\u2019. It is revealed that beyond the exponential form e −nE x (δ) , there is also a polynomial factor that renders the exponential term alone inexact. 2) Further analysis shows that the (38) is in fact a precise asymptotic form of the expurgation bound (here we only presented the upper bound since this contributes directly to the achievability bound). The proof for this fact follows the steps of the proof of [7, Lemma 5]. This fact shows that the analytical bound and its approximations are tight. 3) We do not claim that ˜ P XB e (n, δ) approximates P XB e (n, δ), since the optimization of α is done on the bound ¯ P XB e (n, δ, α). However, it approximates it very well, we show next.\nHere we present the expurgation bound P XB e , with α values optimized numerically, vs. the ML bound from [7]. The ML bound is the ﬁnite-dimensional version of the random coding bound. When error exponents are considered, the expurgation technique improves upon random coding only for δ < δ ex [4]. However, as we demonstrate in Fig. 1, for short lengths (e.g. n = 10) the bound improves even for higher values of δ, sometimes even as high as around δ cr . For larger n, e.g. n = 100 as shown in Fig. 2, the advantage of the expurgation vanishes above δ ex .\nIn Fig. 3 we demonstrate the inaccuracy of the expurgation exponent form, and show the accuracy of the precise asymp- totic form ˜ P XB e (n, δ). As shown in the ﬁgure, the exponential form alone is far off by orders of magnitude from the true bound, where ˜ P XB e (n, δ) is much more precise.\nThe above example demonstrate the usefulness of our reﬁned bound. We expect the same technique to be able to improve existing ﬁnite blocklength bounds in many additional channels, such as the binary symmetric channel, modulo- additive channels and more, and, with some modiﬁcations, for the power-constrained Gaussian channel."},"refs":[{"authors":[{"name":"G. D. Forney Jr."},{"name":"G. Ungerboeck"}],"title":{"text":"Modulation and coding for linear Gaussian channels"}},{"authors":[{"name":"J. H. Conwa"},{"name":"N. J. A. Sloan"}],"title":{"text":"Sphere packings, lattices and groups, ser"}},{"authors":[{"name":"U. Erez"},{"name":"R. Zamir"}],"title":{"text":"Achieving 1/2 log(1+SNR) over the additive white Gaussian noise channel with lattice encoding and decoding"}},{"authors":[{"name":"G. Poltyrev"}],"title":{"text":"On coding without restrictions for the AWGN channel"}},{"authors":[{"name":"R. G. Gallage"}],"title":{"text":"Information Theory and Reliable Communication"}},{"authors":[{"name":"C. E. Shannon"}],"title":{"text":"Probability of error for optimal codes in a gaussian channel"}},{"authors":[{"name":"A. Ingber"},{"name":"R. Zamir"},{"name":"M. Feder"}],"title":{"text":"Finite dimensional inﬁnite constel- lations"}},{"authors":[],"title":{"text":"The dispersion of inﬁnite constellations"}},{"authors":[{"name":"P. M. Grube"},{"name":"C. G. Lekkerkerke"}],"title":{"text":"Geometry of Numbers"}},{"authors":[{"name":"H. A. Loeliger"}],"title":{"text":"Averaging bounds for lattices and linear codes"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566901.pdf"},"links":[{"id":"1569565663","weight":6},{"id":"1569565067","weight":12},{"id":"1569559617","weight":6},{"id":"1569566981","weight":6},{"id":"1569566683","weight":12},{"id":"1569566697","weight":12},{"id":"1569565551","weight":6},{"id":"1569566943","weight":25},{"id":"1569552245","weight":12},{"id":"1569559967","weight":6},{"id":"1569564481","weight":6},{"id":"1569566469","weight":6},{"id":"1569565355","weight":25},{"id":"1569564469","weight":12},{"id":"1569551535","weight":6},{"id":"1569565775","weight":6},{"id":"1569565461","weight":12},{"id":"1569564233","weight":6},{"id":"1569565123","weight":6},{"id":"1569566941","weight":6},{"id":"1569566739","weight":12},{"id":"1569566821","weight":6},{"id":"1569556713","weight":6},{"id":"1569566467","weight":6},{"id":"1569566903","weight":12},{"id":"1569566999","weight":6},{"id":"1569566843","weight":6},{"id":"1569566925","weight":6},{"id":"1569565455","weight":6},{"id":"1569564989","weight":6},{"id":"1569564613","weight":6},{"id":"1569566865","weight":6},{"id":"1569566095","weight":18},{"id":"1569559565","weight":6},{"id":"1569566905","weight":12},{"id":"1569558681","weight":6},{"id":"1569555999","weight":6},{"id":"1569565213","weight":6},{"id":"1569566369","weight":6},{"id":"1569567665","weight":6},{"id":"1569564611","weight":12},{"id":"1569566437","weight":12},{"id":"1569565915","weight":12},{"id":"1569552251","weight":6},{"id":"1569566885","weight":6},{"id":"1569566425","weight":6},{"id":"1569554881","weight":6},{"id":"1569566909","weight":18},{"id":"1569557083","weight":12},{"id":"1569565055","weight":6},{"id":"1569555879","weight":6},{"id":"1569565219","weight":6},{"id":"1569565095","weight":12},{"id":"1569566553","weight":6},{"id":"1569565469","weight":6},{"id":"1569562207","weight":6},{"id":"1569566191","weight":12},{"id":"1569567033","weight":6},{"id":"1569566853","weight":6},{"id":"1569566603","weight":6},{"id":"1569560503","weight":6},{"id":"1569565463","weight":6},{"id":"1569565439","weight":12},{"id":"1569562551","weight":6},{"id":"1569563395","weight":6},{"id":"1569565415","weight":6},{"id":"1569565571","weight":6},{"id":"1569564411","weight":6},{"id":"1569566805","weight":12},{"id":"1569565665","weight":6},{"id":"1569557715","weight":6},{"id":"1569556361","weight":12},{"id":"1569566873","weight":6},{"id":"1569565925","weight":6},{"id":"1569565435","weight":6},{"id":"1569566129","weight":12},{"id":"1569566711","weight":12},{"id":"1569565661","weight":12},{"id":"1569565865","weight":6},{"id":"1569566253","weight":6},{"id":"1569564305","weight":6},{"id":"1569566651","weight":6},{"id":"1569566137","weight":6},{"id":"1569565829","weight":6},{"id":"1569566639","weight":6},{"id":"1569566819","weight":6},{"id":"1569566813","weight":6},{"id":"1569566771","weight":12},{"id":"1569563975","weight":6},{"id":"1569551905","weight":6},{"id":"1569566487","weight":12},{"id":"1569566619","weight":6},{"id":"1569565271","weight":31},{"id":"1569566397","weight":6},{"id":"1569566435","weight":12},{"id":"1569564923","weight":6},{"id":"1569565367","weight":6},{"id":"1569564281","weight":50},{"id":"1569563919","weight":6},{"id":"1569557851","weight":6},{"id":"1569565389","weight":6},{"id":"1569566147","weight":12},{"id":"1569565561","weight":6},{"id":"1569555891","weight":6},{"id":"1569565035","weight":6},{"id":"1569565337","weight":6},{"id":"1569565853","weight":6},{"id":"1569565889","weight":6},{"id":"1569565165","weight":6},{"id":"1569561397","weight":6},{"id":"1569565731","weight":6},{"id":"1569566413","weight":12},{"id":"1569565113","weight":12},{"id":"1569566375","weight":12},{"id":"1569564257","weight":25},{"id":"1569565031","weight":25},{"id":"1569564755","weight":6},{"id":"1569564509","weight":6},{"id":"1569551541","weight":6},{"id":"1569565895","weight":6},{"id":"1569566067","weight":6},{"id":"1569566615","weight":12},{"id":"1569566443","weight":6},{"id":"1569560581","weight":6}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T7.3","endtime":"10:50","authors":"Amir Ingber, Ram Zamir","date":"1341225000000","papertitle":"Expurgated Infinite Constellations at Finite Dimensions","starttime":"10:30","session":"S1.T7: Gaussian Channels","room":"Stratton (407)","paperid":"1569566901"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
