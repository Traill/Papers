{"id":"1569565091","paper":{"title":{"text":"Finite Length LT Codes over F q for Unequal Error Protection with Biased Sampling of Input Nodes"},"authors":[{"name":"Birgit Schotsch"},{"name":"Radu Lupoaie ⋆"}],"abstr":{"text":"Abstract\u2014Finite length LT codes over higher order Galois ﬁelds F q for unequal error protection (UEP) are analysed under maximum likelihood (ML) decoding. We consider a biased sampling method to create the LT code graph. In contrast to a previous approach by Rahnavard et al., where a predetermined number of edges is created per importance class given a check node of degree d, our procedure allows to precisely adjust the desired class weights. Moreover, we provide upper and lower bounds on the symbol erasure probability for each importance class."},"body":{"text":"Fountain codes are a class of incremental redundancy codes [1] that have been proposed in [2] as an alternative approach to retransmission schemes to recover lost packets in packet-switched communication networks. Fountain codes are rateless erasure correcting codes such as LT (Luby Transform) codes [3], Raptor codes [4] and Online codes [5] for which simple and efﬁcient encoding and decoding algorithms exist. Originally developed for the binary erasure channel (BEC), rateless codes do not require any information about the era- sure probability. Especially in point-to-multipoint transmission scenarios, where the individual and independent channel con- ditions of the users are not known to the transmitter, this characteristic is particularly useful.\nBesides the original studies on rateless codes that target at equal error protection (EEP) of data, some proposals for rate- less codes for unequal error protection (UEP) have followed. EEP is needed, e.g. for the distribution of bulk data [2], while UEP is better suited for, e.g. audio or video transmission where some parts of the data are more important than others and therefore need a stronger protection. Two examples of rateless UEP schemes for LT codes are the approach by Rahnavard et al. [6] which we will refer to as weighted UEP and the expanding window (EW) method by Sejdinovic et al. [7]. However, in this paper we will only deal with the weighted UEP method, in which we use biased sampling of the input symbols in order to allow for continuous effective weights of the differently important data parts. Furthermore, we provide upper and lower bounds on the symbol erasure probability under maximum likelihood (ML) decoding.\nIn the following, we consider LT codes over Galois ﬁelds F q of order q = 2 m , where m ≥ 1, since it has been shown\nrecently that rateless codes over higher order Galois ﬁelds exhibit a better erasure correction performance than their bi- nary counterparts [8], [9]. Additionally, we have demonstrated in [10] that this improved erasure correction performance even comes with a lower computational complexity if the equivalent binary input size is kept constant.\nUsing rateless codes, the transmitter can generate a potentially inﬁnite number n T of encoded symbols y = (y 1 , y 2 , . . . y n T ) from a ﬁnite amount of k input symbols u = (u 1 , u 2 , . . . u k ). Though in practice the input and output symbols u i and y j consist of l F q -elements each, where i ∈ {1, 2, . . . k} and j ∈ {1, 2, . . . n T }, we consider only l = 1 in the following as this number l has no inﬂuence on the erasure correction performance of the codes [3]. Note that F q -elements have an equivalent binary representation which requires m bits per element. In order to allow for a fair comparison of codes over Galois ﬁelds of different orders, we ﬁx the number k = k 2 of input bits and distribute them to k q = ⌈ k 2 ld q ⌉ = ⌈ k 2 m ⌉ input symbols. Thus, the input size of a code over F q with q = 2 m is k q .\nIn general, rateless codes are designed such that the receiver is able to decode the original k q input symbols u from any n R = k q (1 + ε R ) received code symbols with high probability if ε R ≥ 0, where ε R is the required relative reception overhead.\nThe generator matrix G ∈ F n T × k q q \t of an LT code, with q = 2 m , deﬁnes a weighted graph that connects the set of k q input nodes u ∈ F 1×k q q \t to the set of n T output nodes y ∈ F 1×n T q \t , where n T can be arbitrarily large. A more detailed description of binary LT codes can be found in [3].\nThe input symbols are assigned to input nodes and the output symbols are assigned to output nodes that are also called check nodes. In vector-matrix notation we encode by y T = Gu T . In contrast to traditional block codes, G is generated online and may differ for each data block. G is assumed to be known at the decoder. This can be achieved by synchronised pseudo-random processes that produce G.\nThe erasure correcting performance of an LT code is largely deﬁned by its check node degree distribution Ω 1 , Ω 2 , . . . Ω k q on {1, 2, . . . k q }, where a check node has degree d with probability Ω d , i.e. it is connected to d distinct input nodes. The degree distribution is often described by its generating polynomial Ω(x) = k q d =1 Ω d x d . For EEP the d connected\ninput nodes are chosen uniformly at random, i.e. with proba- bility p = 1 k q , from the set of k q input nodes, while for UEP the input nodes are ﬁrst assigned to T importance classes. The input nodes of different classes have different probabilities of being chosen to be connected to a check node. The exact UEP construction is explained in the next section.\nThe d non-zero entries in a row of the generator matrix G correspond to the weights of the d edges between a check node and d input nodes. The value of a check node is determined by adding up the product of each value of the d input nodes with the weight of the corresponding connecting edge. The non-zero entries of G are sampled uniformly at random from the set of q − 1 non-zero F q -elements.\nAt the encoder, n T output symbols are generated, which are then transmitted over a symbol erasure channel (SEC) that randomly erases some of the transmitted Galois ﬁeld symbols. Finally, the decoder tries to reproduce the original k q input symbols from the n R ≤ n T received symbols. Having collected n R output symbols, the decoder uses the n R rows of G that are associated with the collected, non-erased symbols to form a new matrix G \u2032 which is used for decoding. Since G \u2032 consists of a set of n R rows sampled at random from the original matrix G according to the erasures that occur on the SEC, G \u2032 has the same statistical properties as G.\nFirst, we brieﬂy review the original approach [6, Sec. IV] using our notation. The k q input nodes are ﬁrst assigned to T importance classes, where importance class τ has size k q,τ = α τ k q , with 1 ≤ τ ≤ T , 0 ≤ α τ ≤ 1 and T i =1 α i = 1, where α τ is the relative size of class τ . According to the importance of the classes, weighting factors ω τ are chosen such that the new initial probability of connecting an input node from class τ to the current check node is p τ = ω τ k\n= ω τ p. Thus, T i =1 p i k q,i = T i =1 ω i α i = 1. In their ﬁnite length analysis, the number d τ of input nodes from an arbitrary class τ that are connected to a check node of degree d is set to min([α τ ω τ d ] , k q,τ ), where [x] means rounding to the nearest integer. In general, it is desired to be able to set the weights to arbitrary non-negative values that comply with the side conditions imposed by the code parameters such that the class speciﬁc protection reaches the required levels. However, due to this rounding operation, only a discrete set of effective weights ω [eff] τ is obtained, although the target weights ω τ are chosen from a continuous set. The effective weights are given as a function of ω τ :\nwhere ¯ Ω = k q d =1 d Ω d is the average degree of the given degree distribution Ω(x). The numerator in (1) is the effective average degree ¯ Ω τ of class τ , while the denominator is the average degree of class τ in the EEP case. The discontinuities are highly dependent on the underlying degree distribution.\nAs an example, two binary UEP LT codes of length k 2 = 100 and k 2 = 10000 are considered that consist of two classes with relative sizes α 1 = 0.1 and α 2 = 0.9 and are based on the degree distribution\nwhich is taken from [4]. The effective weight ω [eff] 1 of the respective class 1 is plotted in Fig. 1 in blue as a function of the target weight ω 1 . The dashed black line indicates the optimum case ω [eff] 1 = ω 1 . Due to the discontinuities not all effective weights can be attained with the given parameters input size k q , class sizes k q,τ and degree distribution Ω(x).\nFor the short code an additional deviation of the effective weight from the target weight becomes apparent in Fig. 1(a), i.e. for higher target values the effective weight deviates towards lower values. This is due to the min(·) operation, which clips the number of edges connected to this class to the number of available nodes. Clipping obviously only occurs for high degrees that are in the same order of magnitude as the sizes of the involved classes. Accordingly, for the long code this effect is not visible in the depicted range of target weights (see Fig. 1(b)).\nIn order to prevent the discontinuous relation between ω τ and ω [eff] τ , we propose to use biased sampling in order to select the input nodes from the different classes to be connected to the current check node of degree d. This biased sampling of the input nodes is equivalent to drawing d balls one by one without replacement from an urn that contains k q = T i =1 k q,i balls of T different colours, where each ball of colour τ has weight ω τ . The probability of picking a ball of a particular colour at a particular draw is proportional to its relative weight with respect to the total weight of the remaining balls. Biased sam- pling has been analysed by Wallenius [11] for the univariate case (T = 2) and has been generalised to the multivariate case by Chesson [12]. The partitioning of the overall degree d into class degrees d τ , where T τ =1 d τ = d, therefore follows the so-called multivariate Wallenius\u2019 noncentral hypergeometric distribution mwnchypg d d; k q , ω [11], [12]. This distri- bution expresses the conditional probability mass function (pmf)\nwith the vectors d = (d 1 , d 2 , . . . d T ) comprising the class degrees, k q = (k q, 1 , k q, 2 , . . . k q,T ) comprising the class sizes and ω = (ω 1 , ω 2 , . . . ω T ) comprising the class speciﬁc target weights. This pmf can be evaluated by numerical integration as described in [13] using the BiasedUrn R package [14]. Without loss of generality, the degree d T is not explicitly mentioned in the left-hand side of (3), since it is included\nimplicitly according to T τ =1 d τ = d. In order to simplify the notation, we omit the parametrisation with the class sizes k q and weights ω and deﬁne the joint pmf as\nwhere P (d) = Ω d , i.e. the coefﬁcients Ω d of the check node degree distribution Ω(x).\nIn the remainder of this paper we will use the following simpliﬁed notation: Given an arbitrary function f (d), the collated sum\nwhere the sums are calculated for all combinations of the values of d = (d 1 , d 2 , . . . d T ) for which 1 ≤ d ≤ d max and\nd τ = d. Additionally, 0 ≤ d τ ≤ min(d, k q,τ ) with 1 ≤ τ ≤ T .\nwhere ¯ Ω τ is the average degree of class τ and P (d τ ) is obtained by marginalising P (d).\nApplied to our example codes of sizes k 2 = 100 and k 2 = 10000, the resulting effective weight ω [eff] 1 of the respective class 1 is plotted in Fig. 1 in red and is now a continuous function of the target weight ω 1 . For the long code the effective\nweight even equals the target weight. In case of the short code the deviation of the effective weight from the target weight is due to the fact that the given degree distribution is not well suited for the current code and class sizes. As an example we consider a given degree d = 66 and weight ω 1 = 2. The target degree of class 1 is then d 1 = α 1 dω 1 = 13.2. However, since class 1 contains only 10 symbols, the effective degree of class 1 will be considerably smaller and thus also the effective weight. In order to compensate for this saturation effect, it is possible to (iteratively) ﬁnd a weight vector that results in the original target weights. For two classes this compensation is quite simple. In order to obtain, e.g. an effective weight ω [eff] 1 = 1.35, the actually assigned weight has to be 1.44 in case of the short example code as marked by the red circle in Fig. 1(a).\nIn the following, we will derive a lower and an upper bound 1 on the symbol erasure probability P [ML,S] q,τ in importance class τ for weighted UEP LT codes over F q under ML decoding, where the codes are constructed using biased sampling.\nAnalogously to the binary EEP case [4], a lower bound on the symbol erasure rate P [ML,S] q,τ is given by the probability that\nThe following derivation of the upper bound on the symbol erasure probability P [ML,S] q,τ in class τ for UEP LT codes over F q with biased sampling is inspired by the one in [6] for binary weighted UEP LT codes based on rounded class degrees.\nLemma 1. Given the generator matrix G of a UEP LT code of length k q , with check node degree distribution Ω(x), T impor- tance classes of sizes k q = (k q, 1 , k q, 2 , . . . k q,T ) and weights\n= (ω 1 , ω 2 , . . . ω T ) that is created using biased sampling, an upper bound on the symbol erasure probability P [ML,S] q,τ \t is given in Eq. (6) on the following page, where γ R = 1 + ε R is the inverse reception rate. The non-zero elements in G are chosen with equal probability from F q \\ {0}.\nProof: The probability P [ML,S] q,τ \t is equal to the probability that the ith F q -symbol cannot be determined by ML decoding for an arbitrary i ∈ τ , where τ is the set of input node indices in importance class τ\nP [ML,S] q,τ = Pr ∃u ∈ F 1×k q q , u i = a : G \u2032 u T = 0 T , (7) with arbitrary but ﬁxed a ∈ F q \\{0}. The right-hand side of (7) is the probability of the ith column of the decoding matrix G \u2032 being linearly dependent on a non-empty set of columns. This can be upper bounded by the probability of any possible set of columns of G \u2032 being linearly dependent on column i ∈ τ\nDue to the random and independent construction of check nodes, the k q γ R rows of G \u2032 can be viewed as the outcomes of independent trials of a random variable r ∈ F 1×k q q , where r = (r 1 , r 2 , . . . r T ) with r j ∈ F 1×k q,j q \t and 1 ≤ j ≤ T . Also the vector u can be expressed as u = (u 1 , u 2 , . . . u T ) with u j ∈ F 1×k q,j q \t :\nThe weight of a vector over F q equals the number of non-zero elements and is denoted | · |. Now, the probability Pr ru T = 0 is determined, conditioned on |r j | = d j and |u j | = w j , ∀j. A row r has weights (|r 1 | , |r 2 | , . . . |r T |) = d with probability P (d) as given in (4), and there are\nchoices of u \t = \t (u 1 , u 2 , . . . u T ) of weights w = (w 1 , w 2 , . . . w T ) with u i = a and i ∈ τ , where δ τ,j is the Kronecker delta function. Let v = (v 1 , v 2 , . . . v T ) = (v 1 , v 2 , . . . v k q ) with v l = r l u l ,\nwhere v l , r l and u l are the lth elements of the vectors v, r and u, respectively, then we obtain Eq. (10) on the next page. The ﬁrst term in (11) is\n \n \nwith the probability of occurrence of exactly s j non-zero elements in the subvector v j\nReassembling all terms yields Eq. (6) on the following page which concludes the assertion.\nThe resulting bounds are exemplarily illustrated in Fig. 2 for three short LT codes with degree distribution Ω(x) as given in (2), k 2 = 100 and two importance classes. The codes are constructed either according to the method in [6] (green and blue) or by using biased sampling (red).\nIn this paper we provide an analysis of ﬁnite length LT codes over higher order Galois ﬁelds F q for unequal error protection (UEP) under ML decoding when the UEP property is established by assigning appropriate weights to the different importance classes. According to the weights, the edges of a check node have different probabilities to be connected to the input nodes of the different classes. In contrast to the literature, the number of input nodes in an importance class that is connected to a check node of degree d is not ﬁxed. Instead, the connections are determined using biased sampling, which can be described by the multivariate Wallenius\u2019 noncentral hypergeometric distribution. Our main contribution is the derivation of importance class speciﬁc upper and lower bounds on the symbol erasure probability under ML decoding for the biased sampling code construction method.\nOur biased sampling approach enables continuous effective UEP weights as a function of the target weights. For properly chosen degree distributions, the effective UEP weights are even equal to the target weights, while this is not the case in the approach from the literature, in which a rounding operation is used. Though this rounding operation signiﬁcantly simpliﬁes especially the computation of the upper bound on the symbol erasure probability, it introduces discontinuities in the effective weights as a function of the target weights, which leads to deviations of the protection levels of the respective importance classes from the targeted ones.\n \n "},"refs":[{"authors":[{"name":"B. Dorsch"}],"title":{"text":"Successive check digits rather than information repetition"}},{"authors":[{"name":"J. W. Byers"},{"name":"M. Luby"},{"name":"M. Mitzenmacher"},{"name":"A. Rege"}],"title":{"text":"A digital fountain approach to reliable distribution of bulk data"}},{"authors":[{"name":"M. Luby"}],"title":{"text":"LT Codes"}},{"authors":[{"name":"A. Shokrollahi"}],"title":{"text":"Raptor Codes"}},{"authors":[{"name":"P. Maymounkov"}],"title":{"text":"Online Codes"}},{"authors":[{"name":"N. Rahnavard"},{"name":"B. N. Vellambi"},{"name":"F. Fekri"}],"title":{"text":"Rateless Codes With Unequal Error Protection Property"}},{"authors":[{"name":"D. Sejdinovic"},{"name":"D. Vukobratovic"},{"name":"A. Doufexi"},{"name":"V. Senk"},{"name":"R. Piechocki"}],"title":{"text":"Expanding Window Fountain Codes for Unequal Error Protection"}},{"authors":[{"name":"G. Liva"},{"name":"E. Paolini"},{"name":"M. Chiani"}],"title":{"text":"Performance versus overhead for fountain codes over F q "}},{"authors":[{"name":"A. Shokrollah"},{"name":"M. Lub"}],"title":{"text":"Raptor Codes, ser"}},{"authors":[{"name":"B. Schotsch"},{"name":"R. Lupoaie"},{"name":"P. Vary"}],"title":{"text":"The Performance of Low- Density Random Linear Fountain Codes over Higher Order Galois Fields under Maximum Likelihood Decoding"}},{"authors":[{"name":"K. T. Wallenius"}],"title":{"text":"Biased sampling: The noncentral hypergeometric probability distribution"}},{"authors":[{"name":"J. Chesson"}],"title":{"text":"A non-central multivariate hypergeometric distribution arising from biased sampling with application to selective predation"}},{"authors":[{"name":"A. Fog"}],"title":{"text":"Calculation Methods for Wallenius\u2019 Noncentral Hypergeo- metric Distribution"}},{"authors":[],"title":{"text":"BiasedUrn: \t Biased Urn \t Model \t Distributions"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569565091.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S10.T5.3","endtime":"12:30","authors":"Birgit Schotsch, Radu Lupoaie","date":"1341403800000","papertitle":"Finite Length LT Codes over Fq for Unequal Error Protection with Biased Sampling of Input Nodes","starttime":"12:10","session":"S10.T5: Rateless Codes","room":"Kresge Little Theatre (035)","paperid":"1569565091"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
