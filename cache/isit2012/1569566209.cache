{"id":"1569566209","paper":{"title":{"text":"Worst-Case Expected-Rate Loss of Slow-Fading Channels"},"authors":[{"name":"Jae Won Yoo"},{"name":"Tie Liu"},{"name":"Shlomo Shamai (Shitz)"}],"abstr":{"text":"Abstract\u2014For delay-limited communication over block-fading channels, the difference between the ergodic capacity and the maximum expected rate for coding over a ﬁnite number of coherent blocks represents the penalty incurred by the delay constraint. This paper introduces a notion of worst-case expected- rate loss. Focusing on the slow-fading scenario (one block delay), the worst-case expected-rate loss is precisely characterized for the point-to-point fading channel and is characterized to within one bit for the fading-paper channel."},"body":{"text":"Consider the discrete-time baseband representation of the single-user ﬂat-fading channel:\nwhere {X[m]} is the channel input which is subject to an average power constraint SNR, {G[m]} are the power gains which are unknown at the transmitter but known to the receiver, {Z[m]} is the additive white circularly symmetric complex Gaussian noise with zero mean and unit variance, and {Y [m]} is the channel output. As often done in the literature, we shall consider the so-called block-fading model, where {G[m]} are assumed to be constant within each coherent block of length T c and change independently across different coherent blocks according to a given distribution F G ( ·). The coherent time T c is assumed to be large so that the additive noise {Z[m]} can be \u201caveraged out\u201d within each coherent block.\nWe shall focus on the delay-limited regime, where the block length of communication T = LT c for some ﬁnite positive integer L. In this case, Shannon capacity is a very pessimistic measure, as it is dictated by the worst realization of the power gains. An often-adopted measure in the literature is expected rate [1], which is deﬁned as the expected reliably decoded rate where the expectation is over the power-gain process.\nThe problem of characterizing the maximum expected rate is closely related to the problem of broadcasting over Gaussian channels. The case with L = 1 represents the most stringent delay requirement and is usually known as slow fading. For the slow-fading scenario, the problem of characterizing the maximum expected rate is closely related to the problem of scalar Gaussian broadcast channel. It is known [2] that the broadcast strategy of sending a degraded message set [3], [4] maximizes the expected rate. For L > 1, the maximum expected rate can be improved by treating each realization of\nthe power gains as a user in an L-parallel Gaussian broadcast channel and coding over different sub-channels [5]. In the limit as L → ∞, by the ergodicity of the power-gain process each \u201ctypical\u201d realization of the power gains can support a reliable rate of communication which is arbitrarily close to\nThus, C erg is both the Shannon capacity (usually known as the ergodic capacity) and the maximum expected rate in the limit as L → ∞.\nAs such, the difference between the ergodic capacity and the maximum expected rate that can be achieved by coding over L coherent blocks represents the penalty incurred by the delay constraint of LT C . In this paper, we are interested in the worst-case expected-rate loss, where the worst case is over all transmit signal-to-noise ratio SNR and all possible power-gain distribution F G ( ·) with a ﬁxed sample-space size K.\nConsider the point-to-point fading channel (1), which can be identiﬁed by the transmit signal-to-noise ratio SNR and the power-gain distribution F G ( ·). Denote by C erg (SNR, F G ) and C exp (L, SNR, F G ) the ergodic capacity and the maximum expected rate that can be achieved by coding over L coherent blocks, respectively. We deﬁne the worst-case expected-rate loss A(L, K) as\nwhere the supreme is over all SNR > 0 and all power-gain distribution F G ( ·) with a ﬁxed sample-space size K.\nThe main result of this section is a precise characterization of A(L, K) for L = 1 and arbitrary ﬁnite K, as summarized in the following theorem.\nNote that the above result is very pessimistic, as the worst- case expected-rate loss grows unboundedly (albeit slowly) as the number of different possible realizations of the power\ngain in each coherent block K tends to inﬁnity. This is due to the following two facts. First, the slow-fading scenario that we consider here is subject to the most stringent delay requirement. Hence, the pessimistic result here calls for the need of coding over multiple coherent blocks should the delay requirement allow. Second, here we consider the worst-case scenario over all possible transmit signal-to-noise ratio and all possible power-gain distribution. Note that for Raleigh fading channels, the expected-rate loss is bounded regardless of the transmit signal-to-noise ratio [4] even though the fading distribution in this case is continuous. This example illustrates the importance of considering the worst-case scenario, as the result of a speciﬁc fading distribution may lead to unwarranted optimism for other fading distributions.\nLet {g 1 , . . . , g K } be the collection of K different possible realizations of the power gain in each coherent block and let p k := Pr(G = g k ). Without loss of generality, we may assume that\nThe maximum expected rate of the block-fading channel (1) for coding over one coherent block, C exp (1, SNR, F G ), is given by [3], [4]\nNote that for the above optimization program, not only the optimal solutions cannot be written in a closed-form, the objective function is also non-convex with respect to the power allocation vector (β 1 , . . . , β K ). Following [6], we shall rewrite the optimization program (6) using the rate vector (r 1 , . . . , r K ) where\nNote that for any given nonnegative rate vector (r 1 , . . . , r K ), one can solve for a unique power allocation vector (β 1 , . . . , β K ) where\nn k := 1/g k for k = 1, . . . , K, and n 0 := 0. Thus, the optimization program (6) can be equivalently written as\nUnlike the original optimization program (6), the new optimization program (9) is convex, so the following Karush-\nµ k r ∗ k = 0 (12) r ∗ k ≥ 0 (13) µ k ≥ 0 (14)\nfor all k = 1, . . . , K. Note that if λ = 0, by the KKT condition (10) we have µ k = −F k < 0, which contradicts the KKT condition (14). Thus, λ must be strictly positive, and by the KKT condition (11) we have\nFurther let ˜ F k = F k + µ k . We can rewrite the KKT conditions (10)\u2013(15) as\n( ˜ F k − F k )r ∗ k = 0 (19) r ∗ k ≥ 0 (20)\n˜ F k − F k ≥ 0 (21) λ > 0 (22)\nfor any rate vector (r ∗ 1 , . . . , r ∗ K ) that satisﬁes the KKT condi- tions (17)\u2013(22).\nTo show that A(1, K) ≤ log K, we shall need the following proposition.\nProposition 1. For any rate vector (r ∗ 1 , . . . , r ∗ K ) that satisﬁes the KKT conditions (17)\u2013(22) and any k = 1, . . . , K,\np k . \t (27) The proof of the above proposition is fairly lengthy (and\ntechnical) and is omitted from the paper due to the space limitation. By Proposition 1, for any SNR > 0 and any power- gain distribution F G ( ·) with sample-space size K we have\nWe thus conclude that A(1, K) ≤ log K for any positive integer K.\nTo show that A(1, K) ≥ log K, let us ﬁx SNR and K and consider the power-gain distribution F G ( ·) with p k = 1/K (so F k = k/K) and g k =\nd j for some d > (K − 1)/SNR and k = 1, . . . , K. Consider the rate vector (r ∗ 1 , . . . , r ∗ K ) where\nIt is straightforward to verify that (r ∗ 1 , . . . , r ∗ K ) satisﬁes the KKT conditions (17)\u2013(22) with λ = d/(1 + d · SNR) and\n˜ F k = F k for all k = 1, . . . , K. Further note that for any k = 1, . . . , K,\nCombining the facts that A(1, K) ≤ log K and A(1, K) ≥ log K completes the proof of Theorem 1.\nwhere {X[m]} is the channel input which is subject to an average power constraint of SNR, {G[m]} are the power gains which are unknown at the transmitter but known to the receiver, {S[m]} and {Z[m]} are independent additive white circularly symmetric complex Gaussian interference and noise with zero means and variance INR and 1 respectively, and {Y [m]} is the channel output. The interference signal {S[m]}\nis assumed to be non-causally known at the transmitter but not to the receiver. Note here that the instantaneous power gain G[m] applies to both the channel input X[m] and the known interference S[m], so the model is particularly relevant to the problem of precoding for multiple-input multiple-output fading broadcast channel.\nAs for the point-to-point fading channel (1), we are inter- ested in characterizing the worst-case expected-rate loss for the slow-fading scenario. However, unlike the point-to-point fading channel (1), the ergodic capacity of the fading-paper channel (33) is unknown. Below, we ﬁrst characterize the ergodic capacity of the fading-paper model (33) to within in one bit. As we will see, this will also lead to a characterization of the worst-case expected-rate loss to within one bit for the slow-fading scenario.\nDenote by C f p erg (SNR, INR, F G ) the ergodic capacity of the fading-paper channel (33). We have the following theorem.\nTheorem 2. For any transmit signal-to-noise ratio SNR, any transmit interference-to-noise ratio INR, and any power-gain distribution F G ( ·), we have\nwhere C erg (SNR, F G ) is the ergodic capacity of the point-to- point fading channel (1).\nNext, denote by C f p exp (L, SNR, INR, F G ) the maximum expected rate of the fading-paper channel (33) for coding over L coherent blocks. We have the following theorem.\nTheorem 3. For any transmit signal-to-noise ratio SNR, any transmit interference-to-noise ratio INR, and any power-gain distribution F G , we have\nwhere C exp (1, SNR, F G ) is the maximum expected rate of the point-to-point fading channel (1) for coding over one coherent block.\nbe the worst-case expected-rate loss of the fading-paper chan- nel (33) for coding over L coherent blocks, where the supreme is over all SNR > 0, all INR > 0, and all power-gain distribution F G ( ·) with a ﬁxed sample-space size K. We have the following theorem.\n1) Proof of Theorem 2: To prove the ﬁrst inequality in (34), let us assume that the interference signal {S[m]} is also known at the receiver. When the receiver knows both the power gain G[m] and the interference signal S[m], it can subtract √\nG[m]S[m] from the received signal Y [m]. This will lead to a \u201cclean\u201d point-to-point fading channel (1), whose ergodic capacity is denoted by C erg (SNR, F G ) and is an upper bound for C f p erg (SNR, INR, F G ).\nis an achievable ergodic rate for the fading-paper channel (33), where x + := max(x, 0). Since\n≥ E G [log(1 + G · SNR)] − log 2 \t (41) = C erg (SNR, F G ) − log 2. \t (42)\nTo prove the achievability of the ergodic rate (38), we shall consider a communication scheme which is motivated by the following thought process. Note that with ideal interleaving, the block-fading channel (33) can be converted to a fast- fading channel, where the power gains {G[m]} are indepen- dent across different time index m. Now that the channel is memoryless, by the well-known result of Gel\u2019fand and Pinsker [10] the following ergodic rate is achievable:\nwhere U is an auxiliary variable which must be independent of (G, Z). An optimal choice of the input-auxiliary variable pair (X, U ) is unknown [7], [8]. Motivated by the recent work [11], let us consider the auxiliary variable\nwhere X is circularly symmetric complex Gaussian with zero mean and variance SNR and is independent of S. For this choice of the input-auxiliary variable pair (X, U ), we have\nG(X + S) + Z |G) − I(U; S) \t (45) = E G [log(1 + G(SNR + INR))] −\n(46) ≥ E G [log(G · SNR)] . \t (47)\nis an achievable ergodic rate for the fading-paper channel (33). Note that even though the achievable ergodic rate (48) is\nis not always within one bit of C erg (SNR, F G ). Next, moti- vated by the secure multicast code proposed in [12], we shall consider a variable-rate coding scheme that takes advantage of the block-fading feature to boost the the achievable ergodic rate from (48) to (38).\nFix ϵ > 0 and let U be chosen as in (44). Consider communicating a message W ∈ {1, . . . , e LT c R } over L coherent blocks.\nCodebook generation. Randomly generate L codebooks, each for one coherent block and consisting of e T c (LR+I(U ;S)+ϵ) codewords of length T c . The codewords are independently generated (across different codewords within each codebook and across different codebooks) according to the product distribution P T c U . Randomly partition each codebook into e LT c R bins, so each bin contains e T c (I(U ;S)+ϵ) codewords. See Fig. 1 for an illustration of the codebook structure.\nEncoding. Given the message W and the interference signal {S[m]}, the encoder looks into the W th bin in each codebook and tries to ﬁnd a codeword that is jointly typical with S T c l , where S T c l represents the interference signal {S[m]} within the lth coherent block. By assumption, T c is sufﬁciently large, so with high probability such a codeword can be found in each codebook. Denote by U T c l the codeword chosen from the lth codebook. The transmit signal X T c l over the lth coherent block is given by U T c l − S T c l .\nDecoding. Let G l be the realization of the power gain during the lth coherent block and let L := {l : I(U;\nl (X + S) + Z) − I(U; S) ≥ 0}. Let C(L) be a codebook formed by the union of e LT c R sub-codebooks, where sub-codebook i is formed by the product of the ith bins over the coherent blocks in L. Given the received signal {Y [m]}, the decoder looks into C(L) and tries to ﬁnd a codeword that is jointly typical with {Y [m]}. If such a codeword can be found, the estimated message ˆ W is given by the index of the sub-codebook that contains the decoded codeword. Otherwise, a decoding error is declared.\nfor sufﬁciently large T c . Hence, the transmit message W can be reliably communicated (with arbitrarily small error probability for sufﬁciently large T c ) as long as\n1 L\n(53) Further note that\n1 L\n1 L\n1 L\nin probability in the limit as L → ∞. We thus conclude that (38) is an achievable ergodic rate for the fading-paper channel (33). This completes the proof of Theorem 2.\n2) Proof of Theorem 3: Consider the K-user memoryless Gaussian broadcast channel:\nwhere X is the channel input which is subject an average power constraint, S and Z k are independent additive white circularly symmetric complex Gaussian interference and noise, and g k and Y k are the power gain and the channel output of receiver k, respectively. The interference S is assumed to be non-causally known at the transmitter but to the receivers. Through successive precoding at the transmitter, it can be shown that the degraded message set capacity region of this channel is the same as if the interference S is also known at the receivers. Based on this fact, it can be further shown that the maximum expected-rate for coding over one block is the same as if the interference S is also known at the receivers, which is given by C exp (1, SNR, F G ). The details of the proof are omitted from the paper due to the space limitation.\nA f p (1, K) = sup\n] (58) ≤ sup [C erg (SNR, F G ) − C exp (1, SNR, F G )] \t (59) = A(1, K) \t (60)\nwhere (58) follows from (35), (59) follows from the ﬁrst inequality in (34), and (61) follows from (4). On the other hand, following (58) we have\n≥ sup [C erg (SNR, F G ) − log 2 − C exp (1, SNR, F G )] (62) = A(1, K) − log 2 \t (63) = log(K/2) \t (64)\nwhere (62) follows from the second inequality in (34), and (64) follows from (4). Combining (61) and (64) completes the proof of Theorem 4.\nThis research was supported in part by the National Science Foundation under Grant CCF-08-45848 and by the Philipson Fund for Electrical Power, Technion Research Authority."},"refs":[{"authors":[{"name":"M. Effros"},{"name":"A. Goldsmith"}],"title":{"text":"Capacity denitions and coding strategies for general channels with receiver side information"}},{"authors":[{"name":"S. Verd´u"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"Variable-rate channel capacity"}},{"authors":[{"name":"S. Shamai (Shitz)"}],"title":{"text":"A broadcast strategy for the Gaussian slowly fading channel"}},{"authors":[{"name":"S. Shamai (Shitz)"},{"name":"A. Steiner"}],"title":{"text":"A broadcast approach for a single- user slowly fading MIMO channel"}},{"authors":[{"name":"P. A. Whiting"},{"name":"E. M. Yeh"}],"title":{"text":"Broadcasting over uncertain channels with decoding delay constraints"}},{"authors":[{"name":"D. N. C. Tse"}],"title":{"text":"Optimal power allocation over parallel Gaussian broadcast channels"}},{"authors":[{"name":"A. Bennatan"},{"name":"D. Burstein"}],"title":{"text":"On the fading paper achievable region of the fading MIMO broadcast channel"}},{"authors":[{"name":"W. Zhang"},{"name":"S. Kotagiri"},{"name":"J. N. Laneman"}],"title":{"text":"Writing on dirty paper with resizing and its application to quasi-static fading broadcast channels"}},{"authors":[{"name":"S. Borade"},{"name":"L. Zheng"}],"title":{"text":"Writing on fading paper and causal transmitter CSI"}},{"authors":[{"name":"S. I. Gelfand"},{"name":"M. S. Pinsker"}],"title":{"text":"Coding for channel with random parameters"}},{"authors":[{"name":"M. El-Halabi"},{"name":"T. Liu"},{"name":"C. Georghiades"},{"name":"S. Shamai (Shitz)"}],"title":{"text":"Secret writing on dirty paper: A deterministic view"}},{"authors":[{"name":"A. Khisti"},{"name":"A. Tchamkerten"},{"name":"G. W. Wornell"}],"title":{"text":"Secure broadcasting over fading channels"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566209.pdf"},"links":[],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S12.T7.5","endtime":"13:10","authors":"Jae Won Yoo, Tie Liu, Shlomo (Shitz) Shamai","date":"1341492600000","papertitle":"Worst-Case Expected-Rate Loss of Slow-Fading Channels","starttime":"12:50","session":"S12.T7: Fading Channels","room":"Stratton (407)","paperid":"1569566209"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
