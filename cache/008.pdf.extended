[[[ ID ]]]
8
[[[ INDEX ]]]
7
[[[ TITLE ]]]
On L 1 -distance error control codes
[[[ AUTHORS ]]]
Luca G. Tallini
Bella Bose
[[[ ABSTR ]]]
Abstract—This paper gives some theory and design of efﬁcient codes capable of controlling (i. e., correcting/detecting/correcting erasure) errors measured under the L 1 distance deﬁned over m-ary words, 2 ≤ m ≤ +∞. We give the combinatorial characterizations of such codes, some general code designs and the efﬁcient decoding algorithms. Then, we give a class of linear and systematic m-ary codes, m = sp with s ∈ IIN and p a prime, which are capable of controlling d ≤ p−1 errors. If n and k ∈ IIN are respectively the length and dimension of a BCH code over GF (p) with minimum Hamming distance d + 1 then the new codes have length n and k = k + r log m s information digits.
Index Terms—m-ary alphabet, error control codes, asymmet- ric/unidirectional/symmetric errors, Z-channel, ﬂash memories, insertion and deletion errors, repetition errors.
[[[ BODY ]]]
be the m-ary alphabet, m = 2, 3, . . . , +∞; where we let ZZ +∞ def = IIN = {0, 1, 2, . . .}. The L 1 -distance (or Manhattan distance) between two m-ary words of length n ∈ IIN, X = x 1 x 2 . . . x n ∈ ZZ n m and Y = y 1 y 2 . . . y n ∈ ZZ n m , is deﬁned as
where X and Y are regarded as n component vectors over the real ﬁeld IR, and |d| indicates the absolute value of d ∈ IR. For example, if m = 3, n = 4, X = 2102 and Y = 1222 then d L 1 (X, Y ) = |2−1|+|1−2|+|0−2|+|2−2| = 1+1+2+0 = 4.
This paper gives a new theory and design of error control (correct, detect, correct erasure) codes in L 1 metric. Such error control codes for the L 1 metric are fundamental whenever the transmission channel is characterized by an error probability of P r(symbol y is received | symbol x is sent) ≈ |x−y| , for all x, y ∈ {0, 1, . . . , m − 1} ⊆ IR and x = y, where
∈ [0, 1] ⊆ IR + is a small constant. A practical example of physical channels with the above error probability are the multi-level ﬂash memories where each cell can store more than two levels of electrical charge [1]. Another application of the theory is in the design of efﬁcient error control codes to combat the insertions and/or deletions of a repeated symbol in a data sequence. In fact, this repetition error correction problem can be reduced to the error correction problem for the L 1 distance over the alphabet ZZ +∞ = IIN [4]. The results given here are a particular generalization to the m- ary alphabet, m ≥ 2, of the theory given in [5], [3] for the binary case m = 2. In [5], [3], considering the words as subsets of a set, new algebraic decoding procedures for new and previously known error control codes are given. Such decoding procedures are based on ﬁnding the solution of a general key equation involving the elementary symmetric
functions (instead of the power sums) of the received word and the unknown coefﬁcients of the error locator polynomial. Here, regarding m-ary words as submultisets of a multiset, we extend the results in [5], [3] to design efﬁcient m-ary error control codes for the L 1 distance for m = 2, 3, . . . , +∞. In Section II we deﬁne the error model and give the combinatorial characterizations of codes controlling errors in the L 1 metric. In Section III, we prove the m-ary key equation which is the basis of our code designs. In Section IV we deﬁne a wide class of codes with efﬁcient decoding algorithms to control errors in the L 1 metric. In Section V, we ﬁnd some efﬁcient codes in the class of Section IV with very simple encoding algorithms. Due to space limitation some of the proofs of the theorems given here are omitted.
Let us ﬁx some useful notations. If X = x 0 x 1 . . . x n ∈ ZZ n+1 m is any word of length n+1 over the m-ary alphabet ZZ m then let supp(X) indicate a subset of the index set [0, n] def = {0, 1, . . . , n} where every element i ∈ [0, n] is counted with its multiplicity, m X (i) = x i ∈ ZZ m ⊆ IIN, given by the i- th component of X. Namely, X ≡ supp(X) is a multiset on [0, n], and we simply let the weight of X to be w(X) = |X| = |supp(X)| = i∈[0,n] x i = i∈[0,n] m X (i). For example, if m = 3, n = 3 and X = 2012 ∈ ZZ 4 3 then x 0 = m X (0) = 2, x 1 = m X (1) = 0, x 2 = m X (2) = 1, x 3 = m X (3) = 2, supp(X) = {0, 0, 2, 3, 3} and the weight of X is w(X) = |supp(X)| = i∈[0,n] m X (i) = 5. Let
be the set of indices where X is different from 0 and note that ∂X can be regarded as a subset of [0, n]. The multiset supp(X) should not be confused with the (proper) set ∂X. Note that the usual Hamming weight of X is w H (X) = |∂X|, and supp(X) = ∂X if, and only if, X ∈ ZZ n+1 2 . For example if X = 2012, ∂X = 1011 ≡ {0, 2, 3} ⊆ [0, 4] and w H (X) = |∂X| = 3 = |supp(X)| = w(X) = 5. Let the integer scalar product between c ∈ IIN and X = x 0 x 1 . . . x n ∈ ZZ n+1 m ⊆ IIN n+1 be deﬁned as c · X = cx 0 cx 1 . . . cx n ∈ ZZ n+1 c(m−1)+1 ⊆ IIN n+1 . For example, if X = 2012 ∈ ZZ 4 3 ⊆ IIN 4 then 3 · X = 6036 ∈ ZZ 4 7 ⊆ IIN 4 . Deﬁne the total order in ZZ m as 0 ≤ 1 ≤ 2 ≤ . . . ≤ (m − 1) and, for all x, y ∈ ZZ m , let the minimum (maximum) operation min(x, y) (max(x, y)) be deﬁned as the minimum (maximum) between x and y, let the natural subtraction operation in ZZ m be deﬁned as x . − y def = 0 if x ≤ y, and x . − y def = x − y if x > y; where “−” indicates the usual integer subtraction. Then given any two words/multisets X, Y ∈ ZZ n+1 m , the words/multiset operations X ∩ Y ∈ ZZ n+1 m , X ∪ Y ∈ ZZ n+1 m , X + Y ∈ IIN, and X . − Y ∈ ZZ n+1 m are deﬁned as the digit by digit min, max, integer addition and . − operation between X and Y , respectively. For example, if m = 3, n = 8, X = 012012012
and Y = 000111222 then X ∩ Y = 000011012, X ∪ Y = 012112222, X + Y = 012123234, X . − Y = 012001000 and
Y . − X = 000100210. Given any two words X, Y ∈ ZZ n+1 m , we say that X is contained in Y and write X ⊆ Y if, and only if, X = X ∩ Y . For example, 000011012 ≡ {4, 5, 7, 8, 8} ⊆ {1, 2, 2, 4, 5, 5, 7, 8, 8} ≡ 012012012. Note that the relation ⊆ deﬁnes a partial ordering in the family of multisets on [0, n] with multiplicity at most m − 1 (≡ the sets of m-ary words of length n + 1). Under this multiset interpretation, an m-ary generalization of the binary Hamming distance between two words/submultisets X and Y can be deﬁned as the “symmetric distance”
which is nothing but the L 1 distance deﬁned in (1). Hence, an m-ary generalization of the binary asymmetric distance can be deﬁned as the “L 1 asymmetric distance”
Deﬁnition 1: Given X, Y ∈ ZZ n+1 m , we say that Y is obtained from X due to t + ∈ IIN positive errors and t − ∈ IIN negative errors if, and only if,
In general, we say that Y is obtained from X due to t ∈ IIN errors if, and only if, d S (X, Y ) = t.
Given Deﬁnition 1, the following theorem holds on error correcting/detecting codes for the L 1 distance.
Theorem 1: A code C ⊆ ZZ n+1 m is capable of correcting t + or less positive errors, detecting d + or less positive errors, correcting t − or less negative errors, and simultaneously detecting d − or less negative errors (i. e., C is a (t + , t − )- EC/(d + , d − )-ED code), with t + , t − , d + , d − ∈ IIN, t + ≤ d + and t − ≤ d − , if, and only if, for all distinct X, Y ∈ C,
Or equivalently, if, and only if, for all distinct X, Y ∈ C, min{|X . − Y |, |Y . − X|} > min{t + +d − , d + +t − }, or
+ , and |X . − X | ≤ τ −
denote the set of all vectors obtained from X due to τ + or less positive errors and τ − or less negative errors. Note that C is a (t + , t − )-EC/(d + , d − )-ED code if, and only if,
Let us prove that if (3) holds then (5) holds as well. Consider any two codewords X, Y ∈ C. Without loss of generality assume that (3) holds because |X . − Y | > t + + d − . Now, for all X ∈ S d + ,d − (X), |X . − X | ≤ d − ; whereas, for all Y ∈ S t + ,t − (Y ), |Y . − Y | ≤ t + . Thus, from (2),
and so, 1 ≤ |X . − Y |. This implies that X = Y , for all X ∈ S d + ,d − (X) and for all Y ∈ S t + ,t − (Y ). Hence, (5) holds. Conversely, if (3) does not hold then there exists X, Y ∈ C such that, X = Y and
Let X ⊆ X . − Y be such that |X | = min{|X . − Y |, t + }, Y ⊆ Y . − X be such that |Y | = min{|Y . − X|, d + } and
Note that Z ⊆ X∪Y ∈ ZZ n m is well deﬁned and Z ∈ S d + ,d − (X) because, from (7) and the ﬁrst relation of (6), the number of negative errors from X to Z is equal to |X . − Z| = |X . − Y | − |X | = |X . − Y | − min{|X . − Y |, t + } = min{0, |X . − Y |−t + } ≤ d − , whereas the number of positive errors from X to Z is |Z . − X| = |Y | = min{|Y . − X|, d + } ≤ d + . Further- more, Z ∈ S t + ,t − (Y ) because, from (7) and the second relation of (6), the number of negative errors from Y to Z is |Y . − Z| = |Y . − X| − |Y | = |Y . − X| − min{|Y . − X|, d + } =
min{0, |Y . − X|−d + } ≤ t − and the number of positive errors from Y to Z is |Z . − X| = |X | = min{|X . − Y |, t + } ≤ t + . In this way, the word Z ∈ S d + ,d − (X)∩S t + ,t − (Y ) = ∅. Hence, (5) does not hold. By exchanging X and Y in (3), it is readily seen that Condition (3) is equivalent to Condition (4).
Note that, Theorem 1 for d + = t + + δ and d − = t − + δ gives Theorem 2: Given t + , t − , δ ∈ IIN, a code C ⊆ ZZ n+1 m is a
(t + , t − )-EC/(t + + δ, t − + δ)-ED code if, and only if, for all distinct X, Y ∈ C, d A (X, Y ) > t + + t − + δ.
In the full paper, we extend Theorem 1 to include erasure error correction as follows. We consider an m-ary erasure channel whose output alphabet is ZZ m ∪ {∗ 1 , ∗ 2 , . . . , ∗ m−1 }, where each erasure symbol, ∗ y , encodes the receiver detector indecision between the two adjacent symbols (y − 1), y ∈ ZZ m , for all y = 1, 2, . . . , (m−1). In this case, we prove the follow- ing theorem on error correcting/detecting/erasure correcting codes for the L 1 distance.
Theorem 3: Given t + , t − , d + , d − , e + ∈ IIN with t + ≤ d + and t − ≤ d − , a code C is capable of simultaneously correcting t + + e + or less positive errors or (y − 1) → ∗ y erasure errors, detecting e + + d + or less positive errors or (y − 1) → ∗ y erasure errors, correcting t − or less negative errors, detecting d − or less negative errors, and correcting all y → ∗ y erasure errors, for all y = 1, 2, . . . , (m − 1), if
+ + t + + d − , or |Y . − X| > e + + d + + t − .
Furthermore, if m = 2 then the equivalence holds in the above statement; however, by simply setting ∗ y to y, the receiver can reduce the correction/detection/erasure correction problem to the correction/detection problem of Theorem 1.
Note that for m = 2, e + = 1 and t + = d + = t − = d − = 0, Theorem 3 implies that an Hamming code (whose minimum asymmetric distance is 2) can correct one 0 → {1, ∗} error and all 1 → ∗ erasures, with ∗ def = ∗ 1 . Now, there may be many channels (close to the Z-channel) where it is more convenient to correct all 1 → ∗ erasures and one 0 → {1, ∗} error, rather than to perform the erasure error correction usually done (that is, to correct two {0, 1} → ∗ erasures).
Let K be any ﬁeld and S ∈ ZZ n+1 m be a multiset on K such that ∂S = {a 0 , a 1 , . . . , a n } ⊆ K is a set of n + 1 distinct elements in K. For the sake of generality, assume a 0 = 0 ∈ S ⊆ K. Obviously, in our identiﬁcation word/multiset, the proper set ∂S can be chosen as the index set by just identifying the element a i ∈ ∂S with i ∈ [0, n], for all i ∈ [0, n]. As in [5], given any m-ary word X = x 0 x 1 . . . x n ∈ ZZ n+1 m let the polynomial associated with X be formally deﬁned as
For example, if m = 3, n = 3 and X = 2102 = {0, 0, 1, 3, 3} then σ X (z) = z 2 (1 − a 1 z) 1 (1 − a 3 z) 2 = z 2 − (a 1 + 2a 3 )z 3 + (2a 1 a 3 + a 2 3 )z 4 − (a 1 a 2 3 )z 5 . In this generalization to the m-ary case, σ X (z) is a polynomial of degree ∂σ X = w(X) = |X| having w H (X) distinct roots in K, each with multiplicity x i = m X (i) > 0, for i ∈ [0, n]. In particular, σ X (z) is the polynomial over K whose set of roots counted with their multiplicity coincides with the multiset X = {1/a i ∈ K : i ∈ X} ≡ X, where here we let 1/0 def = 0 ∈ K. In the above example, σ X (z) has w H (X) = 3 distinct roots in K: 1/a 1 with multiplicity 1, and 1/a 0 = 0 and 1/a 3 with multiplicity 2 (and, 1/a 2 with multiplicity 0; i. e., 1/a 2 is not a root of σ X (z)). The following theorem holds.
Theorem 4 (Key equation): Let K be any ﬁeld and S ∈ ZZ n+1 m be a multiset over K. Let ∂S = {a 0 , a 1 , . . . , a n } ⊆ K be a set of n + 1 distinct elements of K, and σ X (z) be deﬁned as in (8). Then, the following relation holds:
for all X, Y ⊆ S, σ X (z)σ Y . −X (z) = σ Y (z)σ X . −Y (z). (9) Proof: First note that, for all X, Y ∈ ZZ n+1 m , σ X+Y (z) =
σ X (z)σ Y (z). Furthermore, for all x, y ∈ ZZ m , max(x, y) = x + (y . − x) = y + (x . − y), and so for all X, Y ∈ ZZ n+1 m , X ∪ Y = X + (Y . − X) = Y + (X . − Y ). Hence, σ X∪Y (z) = σ X (z)σ Y . −X (z) = σ Y (z)σ X . −Y (z).
As in [5], also in the general case, we let X to be the sent word and Y to be the received word, in such a way that the decoding problem reduces to ﬁnding X . − Y and Y . − X, using Key Equation (9). In particular, having some partial information on X (such as, σ X (z) mod a certain polynomial, the weight of X, . . .) and having Y (i. e., σ Y (z)), the receiver must ﬁnd the error polynomials σ X . −Y (z) and σ Y . −X (z), and hence the positive error pattern E + = (Y . − X) and the negative error pattern E − = (X . − Y ). Note that the receiver can recover the error patterns E + and E − completely by keeping track of the multiplicity of the roots of σ Y . −X (z) and σ X . −Y (z), respectively. Note that the computation of σ X (z) from X ∈ ZZ n+1 m can be efﬁciently done as explained in [5] for m = 2.
Theorem 5: Let K be any ﬁeld and S a multiset over K. Let ∂S = {a 0 , a 1 , . . . , a n } ⊆ K be a set of n + 1 distinct elements in K and σ X (z) be deﬁned as in (8). Let p(z) ∈ K[z] be any polynomial over K. Then, for any σ(z) ∈ K[z] the code deﬁned as C σ,p (n + 1) def =
d A (C σ,p (n + 1)) ≥ ∂p − ∂ gcd(σ, p) ≥ ∂p − ∂ gcd(σ S , p). Furthermore, if S = X∈C
X then equality holds in the rightmost inequality of the above relation.
The minimum asymmetric L 1 distance codes deﬁned in The- orem 5 can be used to perform error correction/detection in the case considered by Theorem 2 as follows.
Algorithm 1 ((t + , t − )-EC/(t + + δ, t − + δ)-ED decoding): Input: The received word Y ∈ ZZ n+1 m .
Output: Recover the original word X ∈ C σ,p (n + 1) or detect uncorrectable errors.
Let ˜ p(z) def = [p/ gcd(σ, p)](z) ∈ K[z] and assume that d A (C σ,p (n + 1)) ≥ ∂ ˜ p > t + + t − + δ.
S2: Based on (9) taken mod ˜ p(z), ﬁnd the minimal solution (α(z), β(z)), with α(z), β(z) ∈ K[z], of
This can be accomplished either with the Extended Euclidean Algorithm (with at most t − steps of EEA. See [5, Theorem 4]), or with any other means.
S3: If ∂α ≤ t + and ∂β ≤ t − then the decoder sets the detect signal to 0 and corrects the errors by executing the following steps: 1) set σ Y . −X (z) = α(z) and σ X . −Y (z) = β(z); 2) compute X = Y − (Y . − X) + (X . − Y ) from σ Y . −X (z) and σ X . −Y (z); 3) output X and exit.
S4: If ∂α > t + or ∂β > t − (the other case), then the decoder sets the detect signal to 1, output the detect signal and exit.
In general if t = min{t + , t − } then the essential computation in the error correcting/detecting procedure resides in ﬁnding the solution of a particular t × t linear system implied by (9). Now, for all p(z) ∈ K[z], such problem can be solved in at most t steps of the Extended Euclidean Algorithm or, when p(z) = z d , the problem can be solved in at most t steps of the Berlekamp-Massey algorithm.
The error correction/detection decoding problem in the general case of Theorem 1 can be tackled by considering the constrained weight codes deﬁned in Theorem 6 below (see (4)). For all m, n, w, D ∈ IIN deﬁne
Theorem 6: In the same hypothesis of Theorem 5, let T def = d A (C σ,p (n+1)) ∈ IIN, D ∈ IIN with D ≥ T , and w ∈ [0, D −1].
min{|X . − Y |, |Y . − X|} ≥ T , or d A (X, Y ) ≥ D.
With regard to the existence of non-trivial minimum asym- metric L 1 distance codes introduced here, some good lower bounds on the code cardinality can be proved similarly to Theorem 6 in [5].
Among all codes, linear codes are convenient because they can be easily encoded. The codes introduced here are linear. In addition the checks are embedded in some information digits and so these codes can be considered as systematic codes. First, some further notations are needed. Given X ∈ ZZ n m let X mod p ∈ ZZ n p indicate the vector obtained from X by applying the mod p operation to every component of X. Note that there is a unique way to write X = Q X · p + X mod p, where Q X ∈ ZZ n (m−1)/p +1 and X mod p ∈ ZZ n p . For example, if X = 3791 ∈ ZZ 4 10 then X mod 5 = 3241 ∈ ZZ 4 5 , Q X = 0110 ∈ ZZ n 2 and X = 3791 = 0110 · 5 + 3241.
Furthermore, given any polynomial p(z) ∈ K[z] over a ﬁeld K let p (z) ∈ K[z] indicate the formal derivative of p(z). Now, given m ∈ IIN ∪ {+∞}, let K be a ﬁeld with characteristic char(K) = p > 0 and S ∈ ZZ n m be a multiset over K. Let ∂S = {a 1 , a 2 , . . . , a n } ⊆ K − {0} and σ X (z) be deﬁned as in (8). For all d ≤ p − 1, consider the following code C p (m, n, d) def =
Note that d A (C p (m, n, d)) ≥ d + 1 because of Theorem 5, and we wish to ﬁnd a simple encoding for C p (m, n, d). The following theorem holds.
Theorem 7: The code C p (p, n, d) is a linear BCH code (eventually shortened) in the vector space (ZZ n p , + mod p, ZZ p , · mod p) with minimum Hamming distance d H (C p (p, n, d)) ≥ d+1 and minimum asymmetric L 1 distance d A (C p (p, n, d)) ≥ d + 1.
and prove that C p (p, n, d) = C 1,z d+1 (n) = C 0,z d (n). In fact, σ X (z) = 1 + σ 1 (X)z + . . . + σ d (X)z d + . . . + σ p−1 (X)z p−1 + σ p (X)z p + . . . and σ X (z) = σ 1 (X) + . . . + dσ d (X)z d−1 + . . . + (p − 1)σ p−1 (X)z p−2 + 0 · σ p (X)z p−1 + . . .. So, if X ∈ C 1,z d+1 (n) then σ X (z) = 1 mod z d+1 , and so σ 1 (X) = σ 2 (X) = . . . = σ d (X) = 0. Thus σ X (z) = 0 mod z d , and so X ∈ C 0,z d (n). Conversely, if X ∈ C 0,z d (n) then σ X (z) = 0 mod z d , and σ 1 (X) = σ 2 (X) = . . . = σ d (X) = 0 because d ≤ p − 1, and σ X (z) = 1 mod z d+1 ; thus X ∈ C 1,z d+1 (n). Now, given X = x 1 x 2 . . . x n ∈ ZZ n p , for all i ∈ IIN let S i (X) def = x 1 a i 1 + x 2 a i 2 + . . . + x n a i n be the i-th power sum of X, and S X (z) def = S 1 (X)z + S 2 (X)z 2 + S 3 (X)z 3 + . . . . Newton’s identity (see [2], page 212) implies that for all multisets X ∈ ZZ n p , S X (z)σ X (z) − zσ X (z) = 0, which implies
and note that C BCH,x d is a minimum Hamming distance d + 1 (eventually shortened) BCH code. Let us prove that C 0,z d (n) = C BCH,x d . In fact, X ∈ C 0,z d (n) ⇐⇒ σ X (z) = 0 mod z d ⇐⇒ zσ X (z) = 0 mod z d+1 . Now, since σ X (z) = 0 mod z d+1 , from (10), zσ X (z) = 0 mod z d+1 ⇐⇒ S X (z) = 0 mod z d+1 ⇐⇒ X ∈ C BCH,x d .
Hence, since C = C p (p, n, d) is a linear code over ZZ p , encoding can be done efﬁciently. Furthermore, Theorem 7 tells us that C is a BCH (eventually shortened) code with d H (C) ≥ d + 1. But, from Theorem 5, d A (C) ≥= d + 1 and so these BCH codes can be easily decoded using all the error control algorithms described here. In particular, from Theorem 2 with δ = 0, they can be used to correct t + or less positive errors and, simultaneously, correct t − or less negative errors (and this can be done efﬁciently with Algorithm 1), for a total of d = t + + t − errors measured in the L 1 metric. Note that, there are many error patterns which can be corrected in this way and not corrected with the usual BCH code decoding algorithms. Note that this holds true even if K = ZZ p and C is a Reed-Solomon code. The next theorem is the basis for some new construction of “essentially linear” codes (hence, easy to encode) which are less redundant than BCH/Reed- Solomon codes. Let E : ZZ k p → C p (p, n, d), with k ∈ IIN, be any encoding of the BCH code C p (p, n, d) where the ﬁrst r digits (the ones whose index i ∈ [1, r] ⊆ [1, n]) are the check digits and the remaining k = n − r digits (the ones whose index i ∈ [r + 1, r + k] ⊆ [1, n]) are the information digits. Furthermore, let E (D) def = C(D)D ≡ C(D) + D, where C(D) ∈ ZZ r p and D ∈ ZZ k p are considered as multisets on [1, n] such that ∂C(D) ⊆ [1, r] and ∂D ⊆ [r + 1, r + k]. Now, let m def = sp, with s ∈ IIN, and the function E : ZZ r s ×ZZ k m → ZZ r+k m be deﬁned as follows. Consider D 1 ∈ ZZ r s and D 2 ∈ ZZ k m as multisets on [1, n] such that ∂D 1 ⊆ [1, r] and ∂D 2 ⊆ [r + 1, r + k], and deﬁne
Note that the above function is deﬁned by ﬁrst 1) computing the check symbol C(D 2 mod p) associated with the second piece of information part D 2 ∈ ZZ k m (and this can be done with algebraic operations in the ﬁeld K as if D 2 were an element of ZZ k p ); 2) multiplying the ﬁrst piece of information part D 1 ∈ ZZ r s by p and adding the result to the check symbol in 1); and then 3) concatenating the result of 2) to the second piece of information part D 2 ∈ ZZ k m . We have the following.
Theorem 8: The function E is an (essentially systematic) encoding of C def = C p (m, n, d). Hence, C is a minimum asymmetric L 1 distance d A (C) ≥ d + 1 code with
Proof: Let X = E(D 1 , D 2 ) and note that D 2 is embedded in the information digit components (whose indices i ∈ [r + 1, r + k] ⊆ [1, n]). Whereas, D 1 can be recovered from the check digit components (whose indices i ∈ [1, r] ⊆ [1, n]) by computing the component-wise quotients of the digit divided by p. This means that E is an encoding. Now, write D 2 = Q D 2 · p + D 2 mod p and note that
But σ E (D 2 mod p) (z) = 1 mod z d+1 because of Theorem 7, and [σ D 1 Q D2 (z)] p = 1 mod z d+1 because char(K) = p ≥ d + 1 and so [σ D 1 Q D2 (z)] p = 1 mod z p . So, E is an encoding in C. Conversely, it is not difﬁcult to show that given X ∈ C there exists D 1 ∈ ZZ r s and D 2 ∈ ZZ k m such that X = E(D 1 , D 2 ). So, E is an encoding of C. The rest of the theorem follows from Theorem 5 and |C p (m, n, d)| = s r m k .
For example, if p = 5, K = GF (5), ∂S = {1, 2, 3, 4} ⊆ K − {0}, d = 2 and s = 5 then C def = C p (p, n, d) is the Reed- Solomon code over GF (5) with minimum Hamming distance d H (C ) ≥ 3, length n = |∂S| = 4, k = 2 and r = 2. Hence, our code C def = C p (m, n, d) is an m(= 25)-ary code with k = 2 + (1/2)2 = 3 information digits, r = 2/2 = 1 check digits, and minimum asymmetric L 1 distance d A (C) ≥ 3. Now, the H matrix of the Reed-Solomon code C in systematic form is
Hence, if E (D) def = c 1 c 2 δ 3 δ 4 , with D def = δ 3 δ 4 ∈ ZZ 2 5 then the check digits can be computed as c 1 = c 1 (δ 3 , δ 4 ) = −2δ 3 −2δ 4 and c 2 = c 2 (δ 3 , δ 4 ) = −3δ 3 − δ 4 , where the operations are done in the ﬁeld GF (5). If E : ZZ 2 5 × ZZ 2 25 → C ⊆ ZZ 4 25 is our encoding to C, D 1 def = δ 1 δ 2 and D 2 def = d 3 d 4 then E(D 1 , D 2 ) =
x 1 x 2 d 3 d 4 with x 1 = c 1 (d 3 , d 4 ) + 5 · δ 1 and x 2 = c 2 (d 3 , d 4 ) + 5 · δ 2 (note that here the addition is the integer addition). For example,
Now, since d A (C) > 2, C can be used to correct, say, d = 2 positive errors. In this case, if X ∈ C is sent and Y is received then σ X (z) = 1 mod z 3 and σ X . −Y (z) = σ ∅ (z) = 1. Hence, (9) reduces to σ Y . −X (z) = σ Y (z) mod z 3 ; that is, the syn- drome is exactly equal to the error polynomial and so decoding is straightforward. For example, if X = E(0 2, 1 6) = 1 11 1 6 ∈ C is sent and Y = 2 11 1 7 is received then σ Y (z) = (1 − z) 2 (1 − 2z) 11 (1 − 3z)(1 − 4z) 7 = [1 − z 4 ][(1 − 2z) 2 (1 − 4z)] 5 [(1 − z)(1 − 4z)], and so the receiver computes σ Y . −X (z) = σ Y (z) mod z 3 = (1 − z)(1 − 4z) = 1 − z 2 . This implies Y . − X = 1 0 0 1 and X = 2 11 1 7 − 1 0 0 1 = 1 11 1 6. Note that if we let D 1 = 0 0 and m = +∞ then this code construction example can be used to design a very simple binary code of length 10 (in average) with 4 information bits (in average) capable of correcting 2 repetition errors [4].
The parameters of some of these codes are given in Table I for p = 17 and d = 1, 2, . . . p − 1 = 16.
This work was supported by the National Science Founda- tion Grants CCF-0701452 and CCF-0728810.
[[[ REFS ]]]
Y. Cassut
M. Schwart
V. Bohossia
J. Bruc
--
Codes for multi- level ﬂash memories: Correcting asymmetric limited-magnitude errors, Proceedings of 2007 IEEE International Symposium on Information Theory , pp
----
E. R. Berlekam
--
Algebraic coding theory, Aegean Park Press, 1984
----
L. G. Tallini
B. Bose
--
On decoding some error control codes using the elementary symmetric functions
----
L. G. Tallini
N. Elarief
B. Bose
--
On Efﬁcient Repetition Error Cor- recting Codes
----
L. G. Tallini
B. Bose
--
On a new class of error control codes and symmetric functions
[[[ META ]]]
xmlpapertitle -> On L 1 -distance error control codes
pdf -> E:\testDataset\008.pdf
parsed -> yes
xmldate -> -
file -> E:\testDataset\008.pdf
xmlauthors -> Luca G. Tallini, Bella Bose
xmlroom -> -
[[[ LINKS ]]]

