[[[ ID ]]]
53
[[[ INDEX ]]]
0
[[[ TITLE ]]]
Generation of Innovative and Sparse Encoding Vectors for Broadcast Systems with Feedback
[[[ AUTHORS ]]]
Ho Yuet Kwan
Kenneth W. Shum
Chi Wan Sung
[[[ ABSTR ]]]
Abstract—In the application of linear network coding to wireless broadcasting with feedback, we prove that the problem of determining the existence of an innovative encoding vector is NP-complete when the ﬁnite ﬁeld size is two. When the ﬁnite ﬁeld size is larger than or equal to the number of users, it is shown that we can always ﬁnd an encoding vector which is both innovative and sparse. The sparsity can be utilized in speeding up the decoding process. An efﬁcient algorithm to generate innovative and sparse encoding vectors is developed. Simulations show that the delay performance of our scheme with binary ﬁnite ﬁeld outperforms a number of existing schemes in terms of average and worst-case delay.
[[[ BODY ]]]
Linear network coding provides an excellent solution to the wireless broadcasting problem in terms of reliability and channel utilization [1], [2]. The idea is to send encoded packets that are obtained by taking linear combinations over a ﬁnite ﬁeld of all the original packets. The encoding vector speciﬁes the coefﬁcients for the linear combination and is determined by the transmitter. An encoded packet together with a header which contains the corresponding encoding vector is broadcasted to all users. An encoded packet is said to be innovative to a user if the corresponding encoding vector is not in the subspace spanned by the encoding vectors already received by that user. It is called innovative if it is innovative to all users who have not yet received enough packets for decoding. Obviously, if all the encoded packets generated by the transmitter for transmission are innovative, the total number of packet transmissions for all users to obtain the complete set of packets can be minimized.
To utilize the radio channel efﬁciently, it is important to generate innovative packets. In [3], it is shown that if the size of the ﬁnite ﬁeld is equal to the number of users, an innovative packet can always be found. In [4], the authors consider a system with perfect feedback, in which the transmitter knows the status of all users and tries to ﬁnd an innovative packet by a probabilistic algorithm. This approach is shown to be rate-optimal if the underlying ﬁnite ﬁeld is sufﬁciently large. The average number of transmissions is analyzed in [5]. By exploiting the feedback information from users, some authors
develop algorithms to generate instantly decodable network- coded packets in [6], [7] so that innovative packets can be decoded once the packets are available at the receivers without waiting for the complete reception of the full set of packets. Randomized broadcast coding without utilizing any feedback is analyzed in [8]. The computation with large ﬁnite ﬁeld may be costly for mobile hand-held devices. In order to reduce encoding and decoding complexity, random linear network code over the binary ﬁeld without feeding back what the receivers have received is considered in [9], [10]. This approach lowers computational complexity at the expense of larger number of retransmissions.
When the ﬁnite ﬁeld size is small, an innovative encoding vector may not exist. In Section III, we prove that the problem of determining the existence of innovative encoding vector is NP-complete. A related result is also obtained in [11], where the broadcast channel is assumed to be noiseless, and the problem of minimizing the number of packets required to ﬁnish off the ﬁle transmission with the binary ﬁnite ﬁeld is shown to be NP-complete. In Section IV, we show that we can always ﬁnd a sparse and innovative encoding vector with at most K non-zero components using a deterministic algo- rithm called the cofactor method. In Section V, the cofactor method is compared with some other transmission schemes by simulation, for both small and large ﬁnite ﬁelds.
We consider a wireless single-hop system consisting of one transmitter and K receivers/users. We denote S as the source node and U i as the i-th receiver, where i ∈ {1, 2, . . . , K}. The source node S wants to broadcast a ﬁle to all receivers via a wireless channel, which is modeled as a broadcast erasure channel. The input to the broadcast erasure channel is a q- ary alphabet. We will also call a q-ary alphabet a packet. Each receiver successfully receives the transmitted packet with probability 1 − P e , independent of each other, where P e denotes the erasure probability. An erased packet is unrecov- erable and discarded, while a successfully received packet is assumed to be error-free. We assume that there is a feedback channel from each receiver to the source. Upon receiving a packet successfully, a receiver sends an acknowledgement to the source node. We assume that the feedback channel has no delay and no error. The source node keeps track of the status
of each receiver. The transmitted packet is a function of the source ﬁle and the acknowledgements from the K receivers.
In this paper, we focus on transmission schemes with linear network coding. The alphabet size q is a power of prime and the alphabet set is identiﬁed with the ﬁnite ﬁeld GF (q). The ﬁle is packetized into N packets. The transmitted packet is a linear combination of the N packets, with coefﬁcients drawn from GF (q). An encoding vector is an N -vector whose components are the N coefﬁcients used in the generation of a transmitted packet. Each user returns an acknowledgement to the source node if a packet is received successfully, until he has already received N packets whose encoding vectors are linearly independent over GF (q). In order to minimize the delay of each user, it is crucial to generate encoding vectors which are innovative to all users.
Our objectives are (i) to determine whether an innovative encoding vector exists, and (ii) to devise an effective algorithm for generating innovative and sparse encoding vectors.
If the ﬁeld size q is larger than or equal to K, it is known that an innovative encoding can always be found [3]. Indeed, the number of non-zero encoding vectors which are not innovative to user i is equal to q r i , where r i is the rank of the subspace spanned by the encoding vectors already received by user i and r i < N , and hence by the union bound, the number of non-zero vectors which are not innovative is at most (q r 1 − 1) + (q r 2 − 1) + . . . + (q r K − 1). When q ≥ K, the number of non-zero and non-innovative encoding vector is strictly less than q N − 1, and hence we can always ﬁnd an innovative packet.
When the underlying ﬁnite ﬁeld is small, an innovative encoding vector may not exist.
Problem q-IEV: A problem instance consists of K matrices C i over GF (q), i = 1, 2, . . . , K, and each matrix has N columns. Determine whether there is an N -dimensional vector over GF (q) which is not in the row space of C i , for all i.
Proof: The idea is to reduce the 3-SAT problem, well- known to be NP-complete [12], to the 2-IEV problem. Recall that the 3-SAT problem is a Boolean satisﬁability problem, whose instance is a Boolean expression written in conjunctive normal form with three variables per clause (3-CNF), and the question is to decide if there is some assignment of TRUE and FALSE to the variables such that the given Boolean expression has a TRUE value.
Let E be a given Boolean expression with n variables x 1 , . . . , x n , and m clauses in 3-CNF. We want to reduce the 3-SAT problem to the 2-IEV problem with N = n + 1 packets and K = m + 1 users.
To the i-th clause (i = 1, 2, . . . , m), we ﬁrst construct a 3 × N matrix B i . If the j-th literal (j = 1, 2, 3) in the i-th clause is x k , then let the k-th component in the j-th row of B i be 1, and the other elements be all zero. Otherwise, if the
j-th literal in the i-th clause is ¬x k , then let the k-th and the (n + 1)-st component in the j-th row of B i be 1, and the remaining components be all zero. Let C i be the matrix whose rows form a basis of the orthogonal complement of the row space of B i . We will use the fact that a vector v is in the row space of C i if and only if B i v T = 0.
Consider an example with n = 4 Boolean variables. From the clause ¬x 1 ∨ ¬x 2 ∨ x 3 , we get
It can be veriﬁed that each row in B i is orthogonal to the rows in C i , i.e., the row space of C i is the orthogonal complement of the row space of B i .
For the extra user, user m + 1, let B m+1 be the 1 × (n + 1) matrix [0 n 1], where 0 n stands for the 1 × n all-zero vector. The problem reduction can be done in polynomial time.
Let x = [x 1 x 2 . . . x n ] be a Boolean row vector and ˆ x = [x 1]. Obviously, any solution x to a 3-SAT problem would cause the product B j ˆ x T a non-zero vector for j = 1, 2, . . . , m and [0 n 1]ˆ x T = 0. Therefore ˆ x is not in the row space of C j for all j. Hence ˆ x is also a solution to the derived 2-IEV problem.
Conversely, any solution to the derived 2-IEV problem also yields a solution to the original 3-SAT problem as well. Let c = [c 1 c 2 . . . c n c n+1 ] ∈ GF (2) n+1 be a solution to the derived 2-IEV problem. Note that we must have c n+1 = 1 because of B m+1 . Let i be an integer between 1 and m. Since c is not in the row space of C i , the product B i c T is a non- zero vector, for otherwise c would belong to the orthogonal complement of B i . Hence, if we assign TRUE to x k if c k = 1 and FALSE to x k if c k = 0, for k = 1, 2, . . . , n, then the i-th clause will have a TRUE value. Since this is true for all i, the whole Boolean expression also has a TRUE value.
The problem 2-IEV is clearly in NP, since it is efﬁciently veriﬁable. Hence it is NP-complete.
After receiving N packets whose encoding vectors are linearly independent over GF (q), a user can recover the source data by solving a system of N linear equations. The standard Gaussian elimination requires O(N 3 ) operations over GF (q). One way to reduce the decoding complexity is to choose encoding vectors which are sparse. A vector is called w-sparse if there are no more than w non-zero components.
Theorem 2. If q ≥ K, we can ﬁnd an innovative encoding vector which is K-sparse.
Proof: Suppose that user k, for k = 1, 2, . . . , K, has received r k packets whose encoding vectors are linearly in- dependent. Let C k be the r k × N matrix obtained by putting together the r k encoding vectors. We want to ﬁnd a K-sparse innovative encoding vector x = [x 1 x 2 . . . x N ].
Since C k is full-rank, we can ﬁnd r k columns of C k which are linearly independent. Let I k be a set of indices of r k linear independent columns in C k . For each k, we arbitrarily
pick a column whose index is not in I k . We call this the extra column and let I k be the union of I k and the index of this extra column. The cardinality of I k is r k + 1. For each k = 1, 2, . . . , K, we construct an (r k + 1) × (r k + 1) matrix
ˆ H k , by ﬁrst appending the vector x = [x 1 x 2 . . . x N ] to the bottom of matrix C k , and then deleting all columns of the resulting matrix except the columns with indices in I k .
For each k, we compute the r k + 1 cofactors of the entries in the last row of ˆ H k . Let x i k be the variable with largest index in the last row of ˆ H k whose cofactor is non-zero. The column indices i 1 , . . . , i K so obtained may not be distinct. Let J {j 1 , j 2 , . . . , j s } be the set of distinct indices such that J = {i 1 , i 2 , . . . , i K } and j 1 < j 2 < . . . < j s . Also, for t = 1, 2, . . . , s, we let K t be the set of users such that k ∈ K t if and only if i k = j t . We remark that J contains at most K distinct indices, i.e., s ≤ K.
We obtain a K-sparse innovative encoding vector as follows. First, we set all variables x i , for i / ∈ J , to zero. Then we assign values to x j 1 , x j 2 , . . . , x j s sequentially, so that the determinant of ˆ H k is nonzero for all k. For k ∈ K 1 , the last row of ˆ H k has only one variable, namely x j 1 , whose value is not yet assigned (the rest are all set to zero). The cofactor of x j 1 in ˆ H k is non- zero. If we expand the determinant of ˆ H k in the last row, we see that the determinant can be written as b i k x i k , where b i k is the cofactor of x i k in ˆ H k . We have a non-zero value if x j 1 is non-zero, for all k ∈ K 1 . We can assign any non-zero element of GF (q) to x j 1 , and make ˆ H k non-zero for all k ∈ K 1 .
Inductively, suppose that the values of x j 1 , . . . x j t−1 have been assigned. Consider the determinants of ˆ H k for k ∈ K t . The only variable in the last row of ˆ H k which has not been assigned a value yet is x j t . If we expand the determinant on the last row, we obtain a linear polynomial in the form of a i k + b i k x j t , where a i k is a constant and b i k is the cofactor of x j t in ˆ H k . There are at most K such degree-one polynomials, and thus we can assign a value to x j t such that all determinants of ˆ H k are non-zero. Here we have used the assumption that q ≥ K. Note that the assignment of x j t does not affect the determinants of previous users with indices in K 1 ∪ K 2 ∪ · · · ∪ K t−1 , because j t either does not appear in K 1 ∪ · · · ∪ K t−1 or the corresponding cofactor in ˆ H is equal to zero for ∈ K 1 ∪ · · · ∪ K t−1 .
After the end of the process, we have chosen the values for x 1 , x 2 , . . . , x N such that | ˆ H k | is non-zero for all k = 1, 2, . . . , K. This encoding vector is innovative to all users and contains at most K non-zero components.
We call the the method described in the proof of Theorem 2 the cofactor method. Using the cofactor method, we can produce innovative and K-sparse encoding vectors. For the decoding, the number of non-zero coefﬁcients in the linear system is no more than KN .
In ˆ H 1 the cofactors of x 1 and x 2 are −1 and 0 respectively. Hence, i 1 = 1. In ˆ H 2 , all cofactors of x 1 , x 2 and x 3 are non-zero. We thus have i 2 = 3. In ˆ H 3 , the cofactor of x 3 is nonzero, and so i 3 = 3. The index set J is equal to {1, 3}. The two index sets of users are K 1 = {1} and K 2 = {2, 3}. By the cofactor method, we ﬁrst assign 0 to x 2 . Then we go through the variable indices in J in ascending order. For x 1 , we can assign any nonzero value to x 1 . For example, we pick x 1 = 1. Once x 1 and x 2 are ﬁxed, we compute the determinants of ˆ H 2 and ˆ H 3 , which are −1 + x 3 and 2x 3 respectively. Finally, we want to assign a value to x 3 such that −1 + x 3 = 0 and 2x 3 = 0. The only choice in this example is x 3 = 2. The resulting encoding vector is [1 0 2].
In the cofactor method, the main complexity is related to the computation of r + 1 cofactors in an (r + 1) × (r + 1) matrix. A straightforward calculation of an r × r determinant requires O(r 3 ) arithmetic operations. The calculation of all cofactors in a matrix would require O(r 4 ) operations per each user in each step. We can use a more efﬁcient algorithm, called the Bareiss algorithm . The number of arithmetic operations over GF (q) required in the computation of cofactors per user can be reduced to O(N 3 ). Summing over all K users, the complexity for computing all cofactors is O(KN 3 ). The complexity of the rest of the cofactor method is of O(K 2 N ). The overall complexity of the cofactor method is O(KN 3 + K 2 N ). If Jaggi-Sanders algorithm in [13] is applied to solve the encoding problem, the complexity is O(KN 2 (K + N )). It means that the cofactor method is no worse than the algorithm in [13] in terms of the encoding complexity. But certainly the encoding vector produced by Jaggi-Sanders algorithm is not sparse. Details on the Bareiss algorithm is given in the appendix.
The cofactor method assumes that q ≥ K. If q < K, the cofactor method may fail to ﬁnd an assignment of the x i ’s such that all determinants are non-zero. In that case, we set those x i ’s to zero and the encoding vectors so generated may not be innovative. But anyway, the returned encoding vector is K-sparse. Hence we can still apply the cofactor method for the case q = 2 to obtain K-sparse encoding vectors, which are innovative to only a fraction of the K users.
In [14], the problem of generating the sparest innovative is considered, and is shown to be NP-hard when q ≥ K.
We evaluate the cofactor method via simulations. In the simulations, we divide the transmission into two phases. The source node ﬁrst transmits all packets one by one uncoded. The K users acknowledge the packets they have successfully received. The source node sets up K matrices C k , for k = 1, 2 . . . , K. The rows of C i are the encoding vectors received by user k. Since the packets are uncoded in the ﬁrst phase,
each row of C k contains exactly one nonzero component. We initialize I i to be the set of non-zero columns in C k . In the second phase, we transmit the packets using the encoding vectors generated by the cofactor method.
Each simulation points involved 1000 random realizations and we assume that N = 32 and P e = 0.3. The worst-case delay is deﬁned as the average of total number of transmissions for S to ensure that all users receive an intact ﬁle over 1000 random realizations. The average delay means the average number of transmissions for S so that an intact ﬁle can be received by a user. For the decoding complexity, we count the number of additions and multiplications in decoding. In our simulations, an addition operation involving two non-zero operands is counted. A multiplication operation is counted when none of the two operands is 1 or 0.
Figure 1 shows the worst-case delay performance of our system with the cofactor method, the random linear network code (RLNC) scheme in which the components are selected according to a uniform distribution, the sorted opportunistic method (SOM) in [6] and the maximum weight vertex search (MWVS) algorithm in [7] for encoding vector generations, where both SOM and MWVS generate instantly decodable packets. It is found that, for q = 2, the cofactor method always performs better than RLNC, SOM and MWVS in terms of the worst-case delay. In addition, we also ﬁnd that the worst-case
delay performance of the cofactor method with a small ﬁnite ﬁeld size ( q = 2) is comparable to that of RLNC with a large ﬁnite ﬁeld size ( q = 101). Next, we consider the average delay performance. According to information theory, the best we can do is to have N/(1 − P e ) = 45.7 transmissions on average. In Figure 2, we observe that both the cofactor method and RLNC with large enough ﬁnite ﬁeld size ( q = 101) can achieve the limit. From the ﬁgure, we also see that although all concerned methods may not be optimal when q = 2, the cofactor method always results in a smaller average delay.
The decoding algorithms in most of the previous work are basically Gauss-Jordan elimination except the instantly decodable schemes in [6], [7]. We implement the Gauss-Jordan elimination for sparse matrix in our simulation. Note that the K-sparse property of the cofactor method implies an upper bound on the number of non-zero entries in an encoding vector. In practice, the average number of non-zero entries is signiﬁcantly less than both K and N even for K > N . As a result, signiﬁcant decoding complexity reduction is expected for a system with the cofactor method. Figures 3 and 4 show the average total number of operations for all users in the system when q = 2 and q = 101, respectively. The cofactor method indeed yields signiﬁcant reduction in both the average total number of addition and multiplication operations when compared with RLNC. From Figure 3, we observe that,
with both SOM and MWVS which are instantly decodable, a receiver enjoys a low decoding complexity at the expense of larger delay. As a result, the cofactor method which always generates sparse encoding vectors is a promising choice in terms of delay performance and decoding complexity.
We devise a cofactor method to generate K-sparse encoding vector. When q ≥ K, it is guaranteed that the resulting encoding vector is innovative, and hence the broadcast system is delay-optimal. The sparsity can be exploited in devising faster decoding algorithm. Simulation result shows that the cofactor method outperforms RLNC, SOM and MWVS in terms of both the worst-case delay and average delay. On the other hand, when q = 2, the problem of determining the existence of an innovative encoding vector is NP-complete.
The Bareiss algorithm is a fraction-free algorithm for com- puting determinant [15]. To illustrate the idea, we apply Bareiss algorithm to an n × n matrix M whose elements are integers and the last row consists of indeterminates x 1 , x 2 , . . . , x n . At the end of the algorithm, the entry in the lower- right corner of M is a linear polynomial in x 1 , x 2 , . . . , x n , and the coefﬁcient of x i is the corresponding cofactor of x i in the original M. We remark that this is an in-place algorithm, and the complexity is in the order of n 3 .
Input: An n × n matrix M. Assume that all principle minors of M are nonzero.
Notation: Let m ij denote the (i, j)-entry of M, and m 00 1. for k = 1, . . . , n − 1 do
, for i, j = k+1, . . . , n. end for
After the ﬁrst pass of the for-loop ( k = 1), the partial result is
The coefﬁcients of x 1 , x 2 and x 3 of the polynomial in the (3, 3)-entry are the cofactors 2 3 5 6 , − 1 3 4 6 , and 1 2 4 5 respectively.
Furthermore, the algorithm can be run incrementally. Sup- pose that only the ﬁrst r rows in a matrix C is available,
The entries marked by “ ∗” are not known yet and will be revealed later. We can apply the Bareiss algorithm to the submatrix obtained by removing the “ ∗” entries and the right n− r columns. When the value of the (r + 1)-st row is known, we can run the Bareiss algorithm again on the submatrix obtained by removing rows r + 2 to n − 1 and the n − r − 1 columns on the right. We can see that the r 2 entries in the ﬁrst r rows and the ﬁrst r columns are the same as before and we do not need to re-calculate them. Only the calculation of the 2r + 1 new entries are required. For each user, the source node essentially runs the Bareiss algorithm on an N ×N matrix, and the complexity per user is O(N 3 ). Summing over all users, the complexity involving the computation of the cofactors is O(KN 3 ).
Acknowledgement: The authors are grateful to Prof. Wai Ho Mow and Dr. Kin-Kwong Leung for fruitful email discussions.
[[[ REFS ]]]
S.-Y. R. Li
R. W. Yeung
N. Cai
--
Linear network coding
----
R. Koetter
M. M´edard
--
An algebraic approach to network coding
----
M. Durvy
C. Fragouli
P. Thiran
--
Towards reliable broadcasting using ACKs
----
L. Keller
E. Drinea
C. Fragouli
--
Online broadcasting with network coding
----
X. Xiao
L. Yang
W. Wang
S. Zhang
--
A broadcasting retransmis- sion approach based on random linear network coding
----
P. Sadeghi
D. Traskov
R. Koetter
--
Adaptive network coding for broadcast channels
----
S. Sorour
S. Valaee
--
On minimizing broadcast completion delay for instantly decodable network coding
----
A. Eryilmaz
A. Ozdaglar
M. M´edard
--
On delay performance gains from network coding
----
M. Ghaderi
D. Towsley
J. Kurose
--
Reliability gain of network coding in lossy wireless networks
----
J. Heide
M. V. Pedersen
F. H. P. Fitzek
T. Larsen
--
Network coding for mobile devices – systematic binary random rateless codes
----
S. Y. El Rouayheb
M. A. R. Chaudhry
A. Sprintson
--
On the minimum number of transmissions in single-hop wireless coding networks
----
M. R. Gare
D. S. Johnso
W. H. Freema
--
Computers and intractability: A guide to the theory of NP-completeness 
----
S. Jaggi
P. Sanders
P. Chou
M. Effros
S. Egner
K. Jain
L. Tolhuizen
--
Polynomial time algorithms for multicast network code construction
----
C. W. Sung
K. W. Shum
H. Y. Kwan
--
On the sparsity of a linear network code for broadcast systems with feedback
----
C. K. Ya
--
Fundamental problems of algorithmic algebra
[[[ META ]]]
parsed -> yes
file -> E:\isit2011\053.pdf
[[[ LINKS ]]]

